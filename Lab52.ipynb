{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization, Activation, Conv2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_imagenes_desde_csv(file_path):\n",
    "    # Cargar los datos desde el archivo CSV omitiendo la primera fila (encabezados)\n",
    "    data = pd.read_csv(file_path, header=None, skiprows=[0])\n",
    "\n",
    "    # Extraer las etiquetas (si están en la primera columna)\n",
    "    labels = data.iloc[:, 0].values\n",
    "    data = data.iloc[:, 1:].values  # Excluir las etiquetas\n",
    "\n",
    "    # Convertir los valores a números de punto flotante\n",
    "    data = data.astype(np.float32)\n",
    "\n",
    "    # Normalizar los datos a [-1, 1] si es necesario\n",
    "    data = (data - 127.5) / 127.5  # Suponiendo que los valores están en el rango [0, 255]\n",
    "\n",
    "    # Redimensionar los datos según las dimensiones de las imágenes de MNIST (28x28)\n",
    "    data = data.reshape(-1, 28, 28, 1)  # Agregar una dimensión de canal\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el generador\n",
    "def generador_de_imagenes():\n",
    "    generador = Sequential()\n",
    "    generador.add(Dense(128 * 7 * 7, input_shape=(100,)))\n",
    "    generador.add(LeakyReLU())\n",
    "    generador.add(Reshape((7, 7, 128)))\n",
    "    generador.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    generador.add(LeakyReLU(alpha=0.2))\n",
    "    generador.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\", activation='tanh'))\n",
    "    return generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el discriminador\n",
    "def discriminador_de_imagenes():\n",
    "    discriminador = Sequential()\n",
    "    discriminador.add(Conv2D(64, kernel_size=3, padding=\"same\", input_shape=(28, 28, 1)))\n",
    "    discriminador.add(LeakyReLU(alpha=0.2))\n",
    "    discriminador.add(Conv2D(128, kernel_size=3, strides=(2, 2), padding=\"same\"))\n",
    "    discriminador.add(LeakyReLU(alpha=0.2))\n",
    "    discriminador.add(Conv2D(128, kernel_size=3, strides=(2, 2), padding=\"same\"))\n",
    "    discriminador.add(LeakyReLU(alpha=0.2))\n",
    "    discriminador.add(Conv2D(256, kernel_size=3, strides=(2, 2), padding=\"same\"))\n",
    "    discriminador.add(LeakyReLU(alpha=0.2))\n",
    "    discriminador.add(Flatten())\n",
    "    discriminador.add(Dropout(0.4))\n",
    "    discriminador.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminador.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear la GAN\n",
    "def crear_gan(discriminador, generador):\n",
    "    discriminador.trainable = False\n",
    "    gan = Sequential()\n",
    "    gan.add(generador)\n",
    "    gan.add(discriminador)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=opt)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar datos de entrada aleatorios\n",
    "def generar_datos_entrada(n_muestras):\n",
    "    X = np.random.randn(100 * n_muestras)\n",
    "    X = X.reshape(n_muestras, 100)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear datos falsos con el generador\n",
    "def crear_datos_fake(modelo_generador, n_muestras):\n",
    "    input = generar_datos_entrada(n_muestras)\n",
    "    X = modelo_generador.predict(input)\n",
    "    y = np.zeros((n_muestras, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar datos reales aleatorios\n",
    "def cargar_datos_reales(dataset, n_muestras):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_muestras)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((n_muestras, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el discriminador\n",
    "def entrenar_discriminador(modelo, dataset, n_iteraciones=20, batch=128):\n",
    "    medio_batch = int(batch / 2)\n",
    "\n",
    "    for i in range(n_iteraciones):\n",
    "        X_real, y_real = cargar_datos_reales(dataset, medio_batch)\n",
    "        _, acc_real = modelo.train_on_batch(X_real, y_real)\n",
    "\n",
    "        X_fake, y_fake = crear_datos_fake(modelo_generador, medio_batch)\n",
    "        _, acc_fake = modelo.train_on_batch(X_fake, y_fake)\n",
    "\n",
    "        print(str(i + 1) + ' Real:' + str(acc_real * 100) + ', Fake:' + str(acc_fake * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mostrar imágenes generadas\n",
    "def mostrar_imagenes_generadas(datos_fake, epoch):\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    datos_fake = (datos_fake + 1) / 2.0\n",
    "    for i in range(10):\n",
    "        plt.imshow(datos_fake[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        nombre = str(epoch) + '_imagen_generada_' + str(i) + '.png'\n",
    "        plt.savefig(nombre, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar y guardar el modelo generador\n",
    "def evaluar_y_guardar(modelo_generador, epoch, medio_dataset):\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    nombre = str(epoch) + '_' + str(now) + \"_modelo_generador.h5\"\n",
    "    modelo_generador.save(nombre)\n",
    "    X_real, _ = cargar_datos_reales(X_train, medio_dataset)\n",
    "    X_fake, _ = crear_datos_fake(modelo_generador, medio_dataset)\n",
    "    _, acc_real = discriminador.evaluate(X_real, np.ones((medio_dataset, 1)))\n",
    "    _, acc_fake = discriminador.evaluate(X_fake, np.zeros((medio_dataset, 1)))\n",
    "    print('Acc Real:' + str(acc_real * 100) + '% Acc Fake:' + str(acc_fake * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se guardarán las imágenes generadas\n",
    "output_dir = 'imagenes_generadas'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Modifica tu función entrenamiento\n",
    "def entrenamiento(datos, modelo_generador, discriminador, gan, epochs, n_batch, inicio=0):\n",
    "    dimension_batch = int(datos.shape[0] / n_batch)\n",
    "    medio_dataset = int(n_batch / 2)\n",
    "\n",
    "    for epoch in range(inicio, inicio + epochs):\n",
    "        for batch in range(n_batch):\n",
    "            X_real, y_real = cargar_datos_reales(datos, medio_dataset)\n",
    "            coste_discriminador_real, _ = discriminador.train_on_batch(X_real, y_real)\n",
    "\n",
    "            X_fake, y_fake = crear_datos_fake(modelo_generador, medio_dataset)\n",
    "            coste_discriminador_fake, _ = discriminador.train_on_batch(X_fake, y_fake)\n",
    "\n",
    "            X_gan = generar_datos_entrada(medio_dataset)\n",
    "            Y_gan = np.ones((medio_dataset, 1))\n",
    "            coste_gan = gan.train_on_batch(X_gan, Y_gan)\n",
    "\n",
    "        if epoch == inicio or epoch == inicio + epochs - 1:\n",
    "            evaluar_y_guardar(modelo_generador, epoch=epoch, medio_dataset=medio_dataset)\n",
    "\n",
    "    # Guardar la primera y la última imagen generada\n",
    "    guardar_imagen(X_fake[0], os.path.join(output_dir, 'imagen_epoca_1.png'))\n",
    "    guardar_imagen(X_fake[-1], os.path.join(output_dir, f'imagen_epoca_{epoch + 1}.png'))\n",
    "\n",
    "# Función para guardar una imagen en formato PNG usando Pillow\n",
    "def guardar_imagen(image, file_path):\n",
    "    # Crear una instancia de la clase Image de Pillow\n",
    "    img = Image.fromarray(image.squeeze() * 255).convert('L')\n",
    "    \n",
    "    # Guardar la imagen en formato PNG\n",
    "    img.save(file_path, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Ruta de los archivos CSV de MNIST\n",
    "train_file_path = 'mnist_train.csv'\n",
    "test_file_path = 'mnist_test.csv'\n",
    "\n",
    "# Cargar datos de entrenamiento\n",
    "X_train, y_train = cargar_imagenes_desde_csv(train_file_path)\n",
    "\n",
    "# Cargar datos de prueba\n",
    "X_test, y_test = cargar_imagenes_desde_csv(test_file_path)\n",
    "\n",
    "# Crear generador, discriminador y GAN\n",
    "modelo_generador = generador_de_imagenes()\n",
    "discriminador = discriminador_de_imagenes()\n",
    "gan = crear_gan(discriminador, modelo_generador)\n",
    "\n",
    "# Entrenar el modelo con save_interval = 20\n",
    "entrenamiento(X_train, modelo_generador, discriminador, gan, epochs=40, n_batch=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
