{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 5\n",
    "\n",
    "##### Javier Valle 20159\n",
    "##### Mario de Le√≥n 19019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 0/100000, D Loss: 0.8646382093429565, G Loss: 0.819901168346405\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100000, D Loss: 0.5854713878361508, G Loss: 0.5462244153022766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2/100000, D Loss: 0.7535999085375806, G Loss: 0.394120454788208\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3/100000, D Loss: 0.89628380825161, G Loss: 0.2985849976539612\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4/100000, D Loss: 0.9879426740762938, G Loss: 0.26385921239852905\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5/100000, D Loss: 1.0079610446664446, G Loss: 0.2668151259422302\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6/100000, D Loss: 0.9641351239249616, G Loss: 0.3137546181678772\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7/100000, D Loss: 0.8401250787128447, G Loss: 0.43168967962265015\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 8/100000, D Loss: 0.6755547952548113, G Loss: 0.6481205224990845\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 9/100000, D Loss: 0.4891512615386091, G Loss: 1.0193195343017578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 10/100000, D Loss: 0.3145413856036612, G Loss: 1.4874427318572998\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 11/100000, D Loss: 0.19756114585106843, G Loss: 1.984628438949585\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 12/100000, D Loss: 0.1307306951712235, G Loss: 2.3668479919433594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 13/100000, D Loss: 0.10517359673394822, G Loss: 2.6042487621307373\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 14/100000, D Loss: 0.09687404872965999, G Loss: 2.680652141571045\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 15/100000, D Loss: 0.10545229818671942, G Loss: 2.5702831745147705\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 16/100000, D Loss: 0.12909021019004285, G Loss: 2.398702383041382\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 17/100000, D Loss: 0.1791908387094736, G Loss: 2.151832103729248\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 18/100000, D Loss: 0.27759481966495514, G Loss: 1.8437483310699463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 19/100000, D Loss: 0.4175705760717392, G Loss: 1.533981442451477\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 20/100000, D Loss: 0.49047383666038513, G Loss: 1.342316746711731\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 21/100000, D Loss: 0.4901870936155319, G Loss: 1.3597736358642578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 22/100000, D Loss: 0.3923235759139061, G Loss: 1.5532617568969727\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 23/100000, D Loss: 0.2916935384273529, G Loss: 1.8858842849731445\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 24/100000, D Loss: 0.21681657060980797, G Loss: 2.2212307453155518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 25/100000, D Loss: 0.17811080440878868, G Loss: 2.4357657432556152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 26/100000, D Loss: 0.14175067469477654, G Loss: 2.598217248916626\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 27/100000, D Loss: 0.12370617315173149, G Loss: 2.640829563140869\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 28/100000, D Loss: 0.11034981906414032, G Loss: 2.6444950103759766\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 29/100000, D Loss: 0.09908624552190304, G Loss: 2.6672863960266113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 30/100000, D Loss: 0.091532526537776, G Loss: 2.695314407348633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 31/100000, D Loss: 0.08353648101910949, G Loss: 2.826472520828247\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 32/100000, D Loss: 0.06664268672466278, G Loss: 3.0749144554138184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 33/100000, D Loss: 0.05860814917832613, G Loss: 3.246626853942871\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 34/100000, D Loss: 0.04702839208766818, G Loss: 3.419066905975342\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 35/100000, D Loss: 0.04233078332617879, G Loss: 3.565120220184326\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 36/100000, D Loss: 0.03754837694577873, G Loss: 3.7114152908325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 37/100000, D Loss: 0.03574992436915636, G Loss: 3.773287296295166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 38/100000, D Loss: 0.03514385363087058, G Loss: 3.767805337905884\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 39/100000, D Loss: 0.037271194625645876, G Loss: 3.775977849960327\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 40/100000, D Loss: 0.037782313069328666, G Loss: 3.8246984481811523\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 41/100000, D Loss: 0.03651302820071578, G Loss: 3.8378236293792725\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 42/100000, D Loss: 0.03456012066453695, G Loss: 3.9109883308410645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 43/100000, D Loss: 0.03156166849657893, G Loss: 4.000263214111328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 44/100000, D Loss: 0.031462467508390546, G Loss: 4.050232410430908\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 45/100000, D Loss: 0.031617550645023584, G Loss: 4.066371917724609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 46/100000, D Loss: 0.029789142310619354, G Loss: 4.13103723526001\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 47/100000, D Loss: 0.029097750317305326, G Loss: 4.191089630126953\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 48/100000, D Loss: 0.02838256978429854, G Loss: 4.17688512802124\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 49/100000, D Loss: 0.028769447468221188, G Loss: 4.248207092285156\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 50/100000, D Loss: 0.02872025058604777, G Loss: 4.2321882247924805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 51/100000, D Loss: 0.028110618703067303, G Loss: 4.2734375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 52/100000, D Loss: 0.027348377741873264, G Loss: 4.327886581420898\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 53/100000, D Loss: 0.02721778815612197, G Loss: 4.2893524169921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 54/100000, D Loss: 0.026024225866422057, G Loss: 4.361557960510254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 55/100000, D Loss: 0.025575292762368917, G Loss: 4.417521953582764\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 56/100000, D Loss: 0.024829698260873556, G Loss: 4.431194305419922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 57/100000, D Loss: 0.02472137426957488, G Loss: 4.439737319946289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 58/100000, D Loss: 0.025504115968942642, G Loss: 4.465138912200928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 59/100000, D Loss: 0.024953648913651705, G Loss: 4.488492012023926\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 60/100000, D Loss: 0.023499821545556188, G Loss: 4.526816368103027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 61/100000, D Loss: 0.023805901408195496, G Loss: 4.566335201263428\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 62/100000, D Loss: 0.023945841006934643, G Loss: 4.586111545562744\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 63/100000, D Loss: 0.02308328030630946, G Loss: 4.63336181640625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 64/100000, D Loss: 0.021754956571385264, G Loss: 4.672985076904297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 65/100000, D Loss: 0.02169054513797164, G Loss: 4.7258405685424805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 66/100000, D Loss: 0.020355304004624486, G Loss: 4.705497741699219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 67/100000, D Loss: 0.01911754719913006, G Loss: 4.756919860839844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 68/100000, D Loss: 0.018497176468372345, G Loss: 4.764275550842285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 69/100000, D Loss: 0.0179800889454782, G Loss: 4.820984840393066\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 70/100000, D Loss: 0.017161001451313496, G Loss: 4.958208084106445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 71/100000, D Loss: 0.013989673461765051, G Loss: 5.103968620300293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 72/100000, D Loss: 0.012439409038051963, G Loss: 5.16239070892334\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 73/100000, D Loss: 0.01177264703437686, G Loss: 5.209310531616211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 74/100000, D Loss: 0.012170729227364063, G Loss: 5.240429878234863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 75/100000, D Loss: 0.012005783384665847, G Loss: 5.225771427154541\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 76/100000, D Loss: 0.012272014748305082, G Loss: 5.184868812561035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 77/100000, D Loss: 0.012798033887520432, G Loss: 5.205413341522217\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 78/100000, D Loss: 0.012964532244950533, G Loss: 5.300989151000977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 79/100000, D Loss: 0.01242691557854414, G Loss: 5.362642765045166\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 80/100000, D Loss: 0.009851738112047315, G Loss: 5.438730239868164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 81/100000, D Loss: 0.009863677434623241, G Loss: 5.529051780700684\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 82/100000, D Loss: 0.008854079525917768, G Loss: 5.695523738861084\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 83/100000, D Loss: 0.008116610930301249, G Loss: 5.834728717803955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 84/100000, D Loss: 0.007582421880215406, G Loss: 5.854856014251709\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 85/100000, D Loss: 0.00605958397500217, G Loss: 5.964254379272461\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 86/100000, D Loss: 0.005351675790734589, G Loss: 6.085309982299805\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 87/100000, D Loss: 0.004470824380405247, G Loss: 6.147918224334717\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 88/100000, D Loss: 0.0051097318064421415, G Loss: 6.2421393394470215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 89/100000, D Loss: 0.004029928590171039, G Loss: 6.2542595863342285\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 90/100000, D Loss: 0.0043440539157018065, G Loss: 6.312226295471191\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 91/100000, D Loss: 0.004759238683618605, G Loss: 6.368053436279297\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 92/100000, D Loss: 0.004061908111907542, G Loss: 6.238137245178223\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 93/100000, D Loss: 0.004424490733072162, G Loss: 6.2535810470581055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 94/100000, D Loss: 0.004445348458830267, G Loss: 6.124640464782715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 95/100000, D Loss: 0.0043973547872155905, G Loss: 6.160403251647949\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 96/100000, D Loss: 0.004210231069009751, G Loss: 6.168755531311035\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 97/100000, D Loss: 0.004361059051007032, G Loss: 6.153215408325195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 98/100000, D Loss: 0.004384804924484342, G Loss: 6.239138603210449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 99/100000, D Loss: 0.004335556644946337, G Loss: 6.342426300048828\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 100/100000, D Loss: 0.004166067868936807, G Loss: 6.368206977844238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 101/100000, D Loss: 0.0037970809498801827, G Loss: 6.376899719238281\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 102/100000, D Loss: 0.0035002990043722093, G Loss: 6.389763832092285\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 103/100000, D Loss: 0.003259849618189037, G Loss: 6.532083511352539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 104/100000, D Loss: 0.003389132907614112, G Loss: 6.471799373626709\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 105/100000, D Loss: 0.0035415749298408628, G Loss: 6.512895584106445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 106/100000, D Loss: 0.0036795034538954496, G Loss: 6.482970714569092\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 107/100000, D Loss: 0.0038659460842609406, G Loss: 6.495475769042969\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 108/100000, D Loss: 0.0037224554689601064, G Loss: 6.443803787231445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 109/100000, D Loss: 0.0033993246033787727, G Loss: 6.4181718826293945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 110/100000, D Loss: 0.004117591073736548, G Loss: 6.390137672424316\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 111/100000, D Loss: 0.0037310734624043107, G Loss: 6.412533760070801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 112/100000, D Loss: 0.0038867032271809876, G Loss: 6.445648193359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 113/100000, D Loss: 0.003925651195459068, G Loss: 6.42538595199585\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 114/100000, D Loss: 0.00403138471301645, G Loss: 6.455931663513184\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 115/100000, D Loss: 0.0040592135628685355, G Loss: 6.376880168914795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 116/100000, D Loss: 0.004137708980124444, G Loss: 6.4080810546875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 117/100000, D Loss: 0.004215733031742275, G Loss: 6.2683424949646\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 118/100000, D Loss: 0.004859192296862602, G Loss: 6.370643138885498\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 119/100000, D Loss: 0.0045479341060854495, G Loss: 6.304513931274414\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 120/100000, D Loss: 0.004602435568813235, G Loss: 6.241140365600586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 121/100000, D Loss: 0.005090060760267079, G Loss: 6.198724269866943\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 122/100000, D Loss: 0.005449003307148814, G Loss: 6.213068008422852\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 123/100000, D Loss: 0.005782441352494061, G Loss: 6.099662780761719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 124/100000, D Loss: 0.0057593833189457655, G Loss: 6.107807159423828\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 125/100000, D Loss: 0.005823737126775086, G Loss: 6.068465709686279\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 126/100000, D Loss: 0.00626050221035257, G Loss: 6.068111419677734\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 127/100000, D Loss: 0.006767583312466741, G Loss: 5.983918190002441\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 128/100000, D Loss: 0.006737323245033622, G Loss: 6.022921562194824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 129/100000, D Loss: 0.007566379732452333, G Loss: 6.02406120300293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 130/100000, D Loss: 0.006916122394613922, G Loss: 6.0773725509643555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 131/100000, D Loss: 0.008000329951755702, G Loss: 5.915633678436279\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 132/100000, D Loss: 0.007864300278015435, G Loss: 5.989450931549072\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 133/100000, D Loss: 0.007134051411412656, G Loss: 5.835111618041992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 134/100000, D Loss: 0.008261032518930733, G Loss: 5.787590503692627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 135/100000, D Loss: 0.009007556596770883, G Loss: 5.690847396850586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 136/100000, D Loss: 0.008832904626615345, G Loss: 5.627056121826172\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 137/100000, D Loss: 0.010101747466251254, G Loss: 5.601078033447266\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 138/100000, D Loss: 0.009995609405450523, G Loss: 5.554018020629883\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 139/100000, D Loss: 0.010997163015417755, G Loss: 5.484859466552734\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 140/100000, D Loss: 0.010402160696685314, G Loss: 5.434629917144775\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 141/100000, D Loss: 0.011961367912590504, G Loss: 5.246813774108887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 142/100000, D Loss: 0.012309255776926875, G Loss: 5.273014068603516\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 143/100000, D Loss: 0.011319277691654861, G Loss: 5.257453918457031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 144/100000, D Loss: 0.01162317581474781, G Loss: 5.1963982582092285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 145/100000, D Loss: 0.012421767227351665, G Loss: 5.18693208694458\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 146/100000, D Loss: 0.012596216285601258, G Loss: 5.162369251251221\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 147/100000, D Loss: 0.010708018438890576, G Loss: 5.1462931632995605\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 148/100000, D Loss: 0.011694216751493514, G Loss: 5.105983734130859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 149/100000, D Loss: 0.011909849243238568, G Loss: 5.19699764251709\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 150/100000, D Loss: 0.01226035039871931, G Loss: 5.03451681137085\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 151/100000, D Loss: 0.01282718253787607, G Loss: 5.017892360687256\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 152/100000, D Loss: 0.012717347824946046, G Loss: 5.01637077331543\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 153/100000, D Loss: 0.01141868729609996, G Loss: 5.062960624694824\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 154/100000, D Loss: 0.011638182681053877, G Loss: 4.970620155334473\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 155/100000, D Loss: 0.012408052454702556, G Loss: 5.070219039916992\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 156/100000, D Loss: 0.011680455296300352, G Loss: 4.889752388000488\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 157/100000, D Loss: 0.012111220741644502, G Loss: 4.8394036293029785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 158/100000, D Loss: 0.0126367905177176, G Loss: 4.863455295562744\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 159/100000, D Loss: 0.01282206131145358, G Loss: 4.804076671600342\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 160/100000, D Loss: 0.013082645484246314, G Loss: 4.773121356964111\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 161/100000, D Loss: 0.013426117599010468, G Loss: 4.664011001586914\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 162/100000, D Loss: 0.014374068065080792, G Loss: 4.668713092803955\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 163/100000, D Loss: 0.013849773560650647, G Loss: 4.577764987945557\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 164/100000, D Loss: 0.014978720108047128, G Loss: 4.6360979080200195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 165/100000, D Loss: 0.015140561677981168, G Loss: 4.577189922332764\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 166/100000, D Loss: 0.014338631997816265, G Loss: 4.556845188140869\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 167/100000, D Loss: 0.015643758524674922, G Loss: 4.37523078918457\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 168/100000, D Loss: 0.016919507645070553, G Loss: 4.42017936706543\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 169/100000, D Loss: 0.016897834895644337, G Loss: 4.317822456359863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 170/100000, D Loss: 0.016914873500354588, G Loss: 4.153565406799316\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 171/100000, D Loss: 0.017830110038630664, G Loss: 4.1368207931518555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 172/100000, D Loss: 0.019751583109609783, G Loss: 4.04361629486084\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 173/100000, D Loss: 0.020316922280471772, G Loss: 3.9257795810699463\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 174/100000, D Loss: 0.02258432738017291, G Loss: 3.8798892498016357\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 175/100000, D Loss: 0.0235082526342012, G Loss: 3.874464511871338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 176/100000, D Loss: 0.02339326951187104, G Loss: 3.7989912033081055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 177/100000, D Loss: 0.02608256903477013, G Loss: 3.691880464553833\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 178/100000, D Loss: 0.028550758259370923, G Loss: 3.545384645462036\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 179/100000, D Loss: 0.028796418802812696, G Loss: 3.4946274757385254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 180/100000, D Loss: 0.03038998506963253, G Loss: 3.4099225997924805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 181/100000, D Loss: 0.0322731863707304, G Loss: 3.351458787918091\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 182/100000, D Loss: 0.03256201930344105, G Loss: 3.258321523666382\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 183/100000, D Loss: 0.03388244321104139, G Loss: 3.2053627967834473\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 184/100000, D Loss: 0.036269270116463304, G Loss: 3.176652431488037\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 185/100000, D Loss: 0.03960123867727816, G Loss: 3.0565366744995117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 186/100000, D Loss: 0.04336547490675002, G Loss: 3.0570404529571533\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 187/100000, D Loss: 0.042361870408058167, G Loss: 2.94802188873291\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 188/100000, D Loss: 0.043364974204450846, G Loss: 2.878462314605713\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 189/100000, D Loss: 0.0477259261533618, G Loss: 2.890733242034912\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 190/100000, D Loss: 0.0514402239350602, G Loss: 2.779911518096924\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 191/100000, D Loss: 0.05261316802352667, G Loss: 2.736924171447754\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 192/100000, D Loss: 0.05339880578685552, G Loss: 2.677053689956665\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 193/100000, D Loss: 0.05792634095996618, G Loss: 2.6041274070739746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 194/100000, D Loss: 0.0583784308983013, G Loss: 2.608163356781006\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 195/100000, D Loss: 0.06043102475814521, G Loss: 2.512442111968994\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 196/100000, D Loss: 0.0630694127175957, G Loss: 2.4461870193481445\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 197/100000, D Loss: 0.067840846022591, G Loss: 2.3586196899414062\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 198/100000, D Loss: 0.07002014084719121, G Loss: 2.3134279251098633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 199/100000, D Loss: 0.07338340347632766, G Loss: 2.2545790672302246\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 200/100000, D Loss: 0.07544675457756966, G Loss: 2.2151951789855957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 201/100000, D Loss: 0.07795957522466779, G Loss: 2.152557611465454\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 202/100000, D Loss: 0.08212103182449937, G Loss: 2.092026948928833\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 203/100000, D Loss: 0.08715315908193588, G Loss: 2.0449678897857666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 204/100000, D Loss: 0.08827050914987922, G Loss: 2.059563159942627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 205/100000, D Loss: 0.09266735543496907, G Loss: 1.9612237215042114\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 206/100000, D Loss: 0.09379635704681277, G Loss: 1.9319794178009033\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 207/100000, D Loss: 0.09605071693658829, G Loss: 1.8965342044830322\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 208/100000, D Loss: 0.09949347609654069, G Loss: 1.900009036064148\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 209/100000, D Loss: 0.10000280826352537, G Loss: 1.8554859161376953\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 210/100000, D Loss: 0.10162270092405379, G Loss: 1.8245494365692139\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 211/100000, D Loss: 0.10186594305559993, G Loss: 1.81878662109375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 212/100000, D Loss: 0.10286622028797865, G Loss: 1.8303756713867188\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 213/100000, D Loss: 0.10054940776899457, G Loss: 1.8206992149353027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 214/100000, D Loss: 0.09893602295778692, G Loss: 1.840221881866455\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 215/100000, D Loss: 0.0961592379026115, G Loss: 1.8366037607192993\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 216/100000, D Loss: 0.09680300601758063, G Loss: 1.8777999877929688\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 217/100000, D Loss: 0.09274744568392634, G Loss: 1.8795170783996582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 218/100000, D Loss: 0.09397600591182709, G Loss: 1.9094988107681274\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 219/100000, D Loss: 0.08892651810310781, G Loss: 1.9171273708343506\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 220/100000, D Loss: 0.08656922774389386, G Loss: 1.9369094371795654\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 221/100000, D Loss: 0.08513805898837745, G Loss: 1.96060311794281\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 222/100000, D Loss: 0.0835454873740673, G Loss: 1.9741193056106567\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 223/100000, D Loss: 0.08054879726842046, G Loss: 2.015500783920288\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 224/100000, D Loss: 0.07834005204495043, G Loss: 2.0309414863586426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 225/100000, D Loss: 0.0788593792822212, G Loss: 2.0459585189819336\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 226/100000, D Loss: 0.07521725445985794, G Loss: 2.0711519718170166\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 227/100000, D Loss: 0.07279730052687228, G Loss: 2.0951125621795654\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 228/100000, D Loss: 0.07282377732917666, G Loss: 2.1101090908050537\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 229/100000, D Loss: 0.07064285408705473, G Loss: 2.129685401916504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 230/100000, D Loss: 0.06886609154753387, G Loss: 2.146005630493164\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 231/100000, D Loss: 0.06663823965936899, G Loss: 2.1752169132232666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 232/100000, D Loss: 0.06463707238435745, G Loss: 2.19956636428833\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 233/100000, D Loss: 0.06410491303540766, G Loss: 2.223379373550415\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 234/100000, D Loss: 0.06218016101047397, G Loss: 2.2464513778686523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 235/100000, D Loss: 0.06071094702929258, G Loss: 2.268012046813965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 236/100000, D Loss: 0.05888248886913061, G Loss: 2.2884585857391357\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 237/100000, D Loss: 0.058196729980409145, G Loss: 2.3052358627319336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 238/100000, D Loss: 0.057147642015479505, G Loss: 2.3199121952056885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 239/100000, D Loss: 0.05589203163981438, G Loss: 2.3331148624420166\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 240/100000, D Loss: 0.05559305928181857, G Loss: 2.3436615467071533\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 241/100000, D Loss: 0.05529224802739918, G Loss: 2.3513588905334473\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 242/100000, D Loss: 0.0557179048191756, G Loss: 2.3542263507843018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 243/100000, D Loss: 0.05552362045273185, G Loss: 2.3538007736206055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 244/100000, D Loss: 0.05690774926915765, G Loss: 2.3466179370880127\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 245/100000, D Loss: 0.05622305138967931, G Loss: 2.3388195037841797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 246/100000, D Loss: 0.05623794277198613, G Loss: 2.3302199840545654\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 247/100000, D Loss: 0.056270856061019, G Loss: 2.327770709991455\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 248/100000, D Loss: 0.05596860218793154, G Loss: 2.3275814056396484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 249/100000, D Loss: 0.05608778982423246, G Loss: 2.3292181491851807\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 250/100000, D Loss: 0.05692753614857793, G Loss: 2.33017897605896\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 251/100000, D Loss: 0.05566987523343414, G Loss: 2.3319036960601807\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 252/100000, D Loss: 0.055305192596279085, G Loss: 2.34354567527771\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 253/100000, D Loss: 0.05488577578216791, G Loss: 2.354281187057495\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 254/100000, D Loss: 0.0540241114795208, G Loss: 2.365539073944092\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 255/100000, D Loss: 0.053468545782379806, G Loss: 2.377748966217041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 256/100000, D Loss: 0.0527135111624375, G Loss: 2.392648935317993\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 257/100000, D Loss: 0.05154195602517575, G Loss: 2.410358428955078\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 258/100000, D Loss: 0.05081379017792642, G Loss: 2.427523136138916\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 259/100000, D Loss: 0.04995268594939262, G Loss: 2.444392681121826\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 260/100000, D Loss: 0.049095868482254446, G Loss: 2.460655927658081\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 261/100000, D Loss: 0.04859116626903415, G Loss: 2.4749321937561035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 262/100000, D Loss: 0.04834084352478385, G Loss: 2.48580002784729\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 263/100000, D Loss: 0.04771821410395205, G Loss: 2.4939723014831543\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 264/100000, D Loss: 0.04739922238513827, G Loss: 2.4996495246887207\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 265/100000, D Loss: 0.04710487416014075, G Loss: 2.5036773681640625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 266/100000, D Loss: 0.04667361348401755, G Loss: 2.5071589946746826\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 267/100000, D Loss: 0.0466125370003283, G Loss: 2.5100014209747314\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 268/100000, D Loss: 0.04659855423960835, G Loss: 2.5114104747772217\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 269/100000, D Loss: 0.04656489170156419, G Loss: 2.511995315551758\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 270/100000, D Loss: 0.046897768042981625, G Loss: 2.511996269226074\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 271/100000, D Loss: 0.046796938753686845, G Loss: 2.5126254558563232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 272/100000, D Loss: 0.047387099359184504, G Loss: 2.511138439178467\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 273/100000, D Loss: 0.04677788901608437, G Loss: 2.510188102722168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 274/100000, D Loss: 0.047081816708669066, G Loss: 2.50878643989563\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 275/100000, D Loss: 0.04707801260519773, G Loss: 2.507694959640503\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 276/100000, D Loss: 0.047211305471137166, G Loss: 2.506394863128662\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 277/100000, D Loss: 0.047205906827002764, G Loss: 2.5055651664733887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 278/100000, D Loss: 0.04736164375208318, G Loss: 2.5056848526000977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 279/100000, D Loss: 0.04712288617156446, G Loss: 2.5078186988830566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 280/100000, D Loss: 0.04744684905745089, G Loss: 2.5089235305786133\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 281/100000, D Loss: 0.047911847941577435, G Loss: 2.508232593536377\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 282/100000, D Loss: 0.04736855160444975, G Loss: 2.508071184158325\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 283/100000, D Loss: 0.04714225162751973, G Loss: 2.5105550289154053\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 284/100000, D Loss: 0.047781984554603696, G Loss: 2.512068748474121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 285/100000, D Loss: 0.047087485319934785, G Loss: 2.515089511871338\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 286/100000, D Loss: 0.047167859505862, G Loss: 2.5186262130737305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 287/100000, D Loss: 0.04675249173305929, G Loss: 2.524176836013794\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 288/100000, D Loss: 0.04645093251019716, G Loss: 2.533967971801758\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 289/100000, D Loss: 0.0458451013546437, G Loss: 2.546308994293213\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 290/100000, D Loss: 0.045462421723641455, G Loss: 2.558985710144043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 291/100000, D Loss: 0.04540962912142277, G Loss: 2.5700526237487793\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 292/100000, D Loss: 0.04432445764541626, G Loss: 2.5840187072753906\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 293/100000, D Loss: 0.043877552496269345, G Loss: 2.600630760192871\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 294/100000, D Loss: 0.04318328690715134, G Loss: 2.617734909057617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 295/100000, D Loss: 0.042471715714782476, G Loss: 2.634127140045166\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 296/100000, D Loss: 0.041710116202011704, G Loss: 2.6521875858306885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 297/100000, D Loss: 0.040145019185729325, G Loss: 2.6748905181884766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 298/100000, D Loss: 0.0397624596953392, G Loss: 2.6956627368927\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 299/100000, D Loss: 0.03868550853803754, G Loss: 2.7212419509887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 300/100000, D Loss: 0.03745799814350903, G Loss: 2.7494964599609375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 301/100000, D Loss: 0.036286537535488605, G Loss: 2.7894654273986816\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 302/100000, D Loss: 0.03430741059128195, G Loss: 2.8447675704956055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 303/100000, D Loss: 0.032368321786634624, G Loss: 2.900629758834839\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 304/100000, D Loss: 0.03060276131145656, G Loss: 2.9557440280914307\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 305/100000, D Loss: 0.029328671749681234, G Loss: 3.0068817138671875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 306/100000, D Loss: 0.028463783208280802, G Loss: 3.04915189743042\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 307/100000, D Loss: 0.02698883251287043, G Loss: 3.085545063018799\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 308/100000, D Loss: 0.025413117953576148, G Loss: 3.124255418777466\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 309/100000, D Loss: 0.024382784846238792, G Loss: 3.1610841751098633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 310/100000, D Loss: 0.023400005651637912, G Loss: 3.1992907524108887\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 311/100000, D Loss: 0.022525146487168968, G Loss: 3.23303484916687\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 312/100000, D Loss: 0.021539881476201117, G Loss: 3.2727346420288086\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 313/100000, D Loss: 0.021002387162297964, G Loss: 3.30783748626709\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 314/100000, D Loss: 0.02017197059467435, G Loss: 3.343442440032959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 315/100000, D Loss: 0.019420368887949735, G Loss: 3.378237247467041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 316/100000, D Loss: 0.018802727572619915, G Loss: 3.407972812652588\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 317/100000, D Loss: 0.018391086836345494, G Loss: 3.4302492141723633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 318/100000, D Loss: 0.018042791285552084, G Loss: 3.451258897781372\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 319/100000, D Loss: 0.017907057306729257, G Loss: 3.468082904815674\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 320/100000, D Loss: 0.017354580748360604, G Loss: 3.478955030441284\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 321/100000, D Loss: 0.017133229761384428, G Loss: 3.496131420135498\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 322/100000, D Loss: 0.017027377616614103, G Loss: 3.496184825897217\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 323/100000, D Loss: 0.01683523302199319, G Loss: 3.5101547241210938\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 324/100000, D Loss: 0.01671836117748171, G Loss: 3.5168540477752686\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 325/100000, D Loss: 0.016621873015537858, G Loss: 3.526613235473633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 326/100000, D Loss: 0.01654306787531823, G Loss: 3.5266895294189453\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 327/100000, D Loss: 0.01655939023476094, G Loss: 3.531391143798828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 328/100000, D Loss: 0.016399799089413136, G Loss: 3.53477144241333\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 329/100000, D Loss: 0.016426372283603996, G Loss: 3.5343475341796875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 330/100000, D Loss: 0.016423488617874682, G Loss: 3.5367798805236816\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 331/100000, D Loss: 0.016438791702967137, G Loss: 3.534669876098633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 332/100000, D Loss: 0.016333894047420472, G Loss: 3.536777973175049\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 333/100000, D Loss: 0.016749416769016534, G Loss: 3.529132843017578\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 334/100000, D Loss: 0.016613826854154468, G Loss: 3.5288660526275635\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 335/100000, D Loss: 0.01686379761667922, G Loss: 3.5174872875213623\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 336/100000, D Loss: 0.01693927956512198, G Loss: 3.5132412910461426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 337/100000, D Loss: 0.016974065802060068, G Loss: 3.5011184215545654\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 338/100000, D Loss: 0.01721021521370858, G Loss: 3.4971325397491455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 339/100000, D Loss: 0.01756289676995948, G Loss: 3.488818645477295\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 340/100000, D Loss: 0.017488788871560246, G Loss: 3.4797754287719727\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 341/100000, D Loss: 0.017524555674754083, G Loss: 3.4688401222229004\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 342/100000, D Loss: 0.017819883360061795, G Loss: 3.4559030532836914\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 343/100000, D Loss: 0.017997405026108027, G Loss: 3.4485561847686768\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 344/100000, D Loss: 0.018340224982239306, G Loss: 3.4474711418151855\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 345/100000, D Loss: 0.01841088553192094, G Loss: 3.4357657432556152\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 346/100000, D Loss: 0.0184188048588112, G Loss: 3.431724786758423\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 347/100000, D Loss: 0.01893874106463045, G Loss: 3.4227232933044434\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 348/100000, D Loss: 0.018966591800563037, G Loss: 3.413849353790283\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 349/100000, D Loss: 0.01912405912298709, G Loss: 3.4045186042785645\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 350/100000, D Loss: 0.01920914778020233, G Loss: 3.400057792663574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 351/100000, D Loss: 0.019361123209819198, G Loss: 3.391620635986328\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 352/100000, D Loss: 0.019545222399756312, G Loss: 3.383685350418091\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 353/100000, D Loss: 0.019834508188068867, G Loss: 3.381089925765991\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 354/100000, D Loss: 0.019811272039078176, G Loss: 3.3776512145996094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 355/100000, D Loss: 0.019690703484229743, G Loss: 3.377987861633301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 356/100000, D Loss: 0.019662309205159545, G Loss: 3.3889598846435547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 357/100000, D Loss: 0.02006497955881059, G Loss: 3.3893680572509766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 358/100000, D Loss: 0.019674081355333328, G Loss: 3.3995633125305176\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 359/100000, D Loss: 0.019538657972589135, G Loss: 3.4084601402282715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 360/100000, D Loss: 0.019258264219388366, G Loss: 3.4223685264587402\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 361/100000, D Loss: 0.019477542955428362, G Loss: 3.4397268295288086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 362/100000, D Loss: 0.01882141293026507, G Loss: 3.449655055999756\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 363/100000, D Loss: 0.01867316954303533, G Loss: 3.4620933532714844\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 364/100000, D Loss: 0.018327305791899562, G Loss: 3.479853630065918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 365/100000, D Loss: 0.017771827057003975, G Loss: 3.5015869140625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 366/100000, D Loss: 0.017699501710012555, G Loss: 3.525333881378174\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 367/100000, D Loss: 0.01749298209324479, G Loss: 3.5373616218566895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 368/100000, D Loss: 0.01737106661312282, G Loss: 3.5585694313049316\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 369/100000, D Loss: 0.01721644843928516, G Loss: 3.5628983974456787\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 370/100000, D Loss: 0.017327224370092154, G Loss: 3.5624332427978516\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 371/100000, D Loss: 0.017375454073771834, G Loss: 3.567437171936035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 372/100000, D Loss: 0.01736128283664584, G Loss: 3.5717251300811768\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 373/100000, D Loss: 0.017603229847736657, G Loss: 3.5687732696533203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 374/100000, D Loss: 0.01756124955136329, G Loss: 3.5719547271728516\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 375/100000, D Loss: 0.01698578556533903, G Loss: 3.584428310394287\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 376/100000, D Loss: 0.016994591103866696, G Loss: 3.614818572998047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 377/100000, D Loss: 0.017181935720145702, G Loss: 3.6196165084838867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 378/100000, D Loss: 0.016785238636657596, G Loss: 3.6347546577453613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 379/100000, D Loss: 0.016646747943013906, G Loss: 3.6460554599761963\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 380/100000, D Loss: 0.016627513337880373, G Loss: 3.6464130878448486\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 381/100000, D Loss: 0.016749895992688835, G Loss: 3.63954496383667\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 382/100000, D Loss: 0.016750429989770055, G Loss: 3.666067123413086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 383/100000, D Loss: 0.01615159591892734, G Loss: 3.670769214630127\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 384/100000, D Loss: 0.015693574212491512, G Loss: 3.7061774730682373\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 385/100000, D Loss: 0.015357501804828644, G Loss: 3.734299659729004\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 386/100000, D Loss: 0.015132914064452052, G Loss: 3.7693352699279785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 387/100000, D Loss: 0.015039478312246501, G Loss: 3.7998244762420654\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 388/100000, D Loss: 0.01412407134193927, G Loss: 3.847963809967041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 389/100000, D Loss: 0.013895974145270884, G Loss: 3.8753538131713867\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 390/100000, D Loss: 0.013370868284255266, G Loss: 3.9003682136535645\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 391/100000, D Loss: 0.012486862658988684, G Loss: 3.964407444000244\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 392/100000, D Loss: 0.011611272173468024, G Loss: 4.02108097076416\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 393/100000, D Loss: 0.011014979507308453, G Loss: 4.092914581298828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 394/100000, D Loss: 0.010310063778888434, G Loss: 4.166901588439941\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 395/100000, D Loss: 0.009653939807321876, G Loss: 4.199062824249268\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 396/100000, D Loss: 0.009360384079627693, G Loss: 4.253350257873535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 397/100000, D Loss: 0.008526381861884147, G Loss: 4.307824611663818\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 398/100000, D Loss: 0.00820562127046287, G Loss: 4.346777439117432\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 399/100000, D Loss: 0.007938386173918843, G Loss: 4.3948469161987305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 400/100000, D Loss: 0.007867203559726477, G Loss: 4.416290283203125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 401/100000, D Loss: 0.007853711722418666, G Loss: 4.425297260284424\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 402/100000, D Loss: 0.007981138827744871, G Loss: 4.420098781585693\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 403/100000, D Loss: 0.007993771811015904, G Loss: 4.417900085449219\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 404/100000, D Loss: 0.008427798398770392, G Loss: 4.371613025665283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 405/100000, D Loss: 0.008611495955847204, G Loss: 4.3702239990234375\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 406/100000, D Loss: 0.008960688312072307, G Loss: 4.365859031677246\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 407/100000, D Loss: 0.00978730316273868, G Loss: 4.302886486053467\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 408/100000, D Loss: 0.009836942015681416, G Loss: 4.288311958312988\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 409/100000, D Loss: 0.010554030304774642, G Loss: 4.298370361328125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 410/100000, D Loss: 0.011233326164074242, G Loss: 4.246094226837158\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 411/100000, D Loss: 0.011804136796854436, G Loss: 4.235001087188721\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 412/100000, D Loss: 0.012318585999310017, G Loss: 4.23552131652832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 413/100000, D Loss: 0.012841424671933055, G Loss: 4.216421127319336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 414/100000, D Loss: 0.013879373436793685, G Loss: 4.174680233001709\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 415/100000, D Loss: 0.014573494670912623, G Loss: 4.217041492462158\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 416/100000, D Loss: 0.013805104186758399, G Loss: 4.222480773925781\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 417/100000, D Loss: 0.014390221331268549, G Loss: 4.273826599121094\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 418/100000, D Loss: 0.014085344970226288, G Loss: 4.276316165924072\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 419/100000, D Loss: 0.012916734791360795, G Loss: 4.306777000427246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 420/100000, D Loss: 0.014144830289296806, G Loss: 4.382569313049316\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 421/100000, D Loss: 0.013788531068712473, G Loss: 4.467345714569092\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 422/100000, D Loss: 0.011688713100738823, G Loss: 4.526388645172119\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 423/100000, D Loss: 0.011628898559138179, G Loss: 4.54652738571167\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 424/100000, D Loss: 0.010215856484137475, G Loss: 4.6257476806640625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 425/100000, D Loss: 0.009945942554622889, G Loss: 4.682369232177734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 426/100000, D Loss: 0.00870571075938642, G Loss: 4.694710731506348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 427/100000, D Loss: 0.008264192612841725, G Loss: 4.7242560386657715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 428/100000, D Loss: 0.008141206344589591, G Loss: 4.749418258666992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 429/100000, D Loss: 0.007614905131049454, G Loss: 4.798224925994873\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 430/100000, D Loss: 0.00723045994527638, G Loss: 4.797683238983154\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 431/100000, D Loss: 0.0070924952160567045, G Loss: 4.804713249206543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 432/100000, D Loss: 0.0070459829876199365, G Loss: 4.814670562744141\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 433/100000, D Loss: 0.007336828857660294, G Loss: 4.813103675842285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 434/100000, D Loss: 0.007279167301021516, G Loss: 4.769373416900635\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 435/100000, D Loss: 0.007640897296369076, G Loss: 4.730424880981445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 436/100000, D Loss: 0.008163045509718359, G Loss: 4.671622276306152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 437/100000, D Loss: 0.007899146643467247, G Loss: 4.616066932678223\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 438/100000, D Loss: 0.008026561932638288, G Loss: 4.540719985961914\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 439/100000, D Loss: 0.008075762423686683, G Loss: 4.534663200378418\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 440/100000, D Loss: 0.008186731953173876, G Loss: 4.533300399780273\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 441/100000, D Loss: 0.008167160674929619, G Loss: 4.533990859985352\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 442/100000, D Loss: 0.007918484276160598, G Loss: 4.559597015380859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 443/100000, D Loss: 0.007675989414565265, G Loss: 4.582928657531738\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 444/100000, D Loss: 0.00745002122130245, G Loss: 4.615644454956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 445/100000, D Loss: 0.007814944023266435, G Loss: 4.614017486572266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 446/100000, D Loss: 0.008033199235796928, G Loss: 4.597627639770508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 447/100000, D Loss: 0.008059431333094835, G Loss: 4.556525230407715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 448/100000, D Loss: 0.008009603945538402, G Loss: 4.568709373474121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 449/100000, D Loss: 0.008513664361089468, G Loss: 4.525949001312256\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 450/100000, D Loss: 0.009019736316986382, G Loss: 4.510466575622559\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 451/100000, D Loss: 0.00896300992462784, G Loss: 4.483279228210449\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 452/100000, D Loss: 0.008978675701655447, G Loss: 4.468189239501953\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 453/100000, D Loss: 0.009161549853160977, G Loss: 4.441916465759277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 454/100000, D Loss: 0.010473731206730008, G Loss: 4.459275245666504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 455/100000, D Loss: 0.010401940904557705, G Loss: 4.39870548248291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 456/100000, D Loss: 0.010303399641998112, G Loss: 4.396477699279785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 457/100000, D Loss: 0.01077741279732436, G Loss: 4.3937883377075195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 458/100000, D Loss: 0.010813826462253928, G Loss: 4.376931190490723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 459/100000, D Loss: 0.011424491880461574, G Loss: 4.408397674560547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 460/100000, D Loss: 0.011673802975565195, G Loss: 4.378321647644043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 461/100000, D Loss: 0.011496620485559106, G Loss: 4.3187360763549805\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 462/100000, D Loss: 0.011853973614051938, G Loss: 4.35391902923584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 463/100000, D Loss: 0.011679999181069434, G Loss: 4.30386209487915\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 464/100000, D Loss: 0.012203891528770328, G Loss: 4.336211681365967\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 465/100000, D Loss: 0.012170963687822223, G Loss: 4.3165693283081055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 466/100000, D Loss: 0.013083206955343485, G Loss: 4.275500297546387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 467/100000, D Loss: 0.012769268825650215, G Loss: 4.252970218658447\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 468/100000, D Loss: 0.013188094133511186, G Loss: 4.278029441833496\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 469/100000, D Loss: 0.012980787781998515, G Loss: 4.257852554321289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 470/100000, D Loss: 0.01308706821873784, G Loss: 4.282072067260742\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 471/100000, D Loss: 0.013791232835501432, G Loss: 4.292148590087891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 472/100000, D Loss: 0.014598045032471418, G Loss: 4.202305793762207\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 473/100000, D Loss: 0.014433844480663538, G Loss: 4.132419586181641\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 474/100000, D Loss: 0.014716286212205887, G Loss: 4.179125785827637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 475/100000, D Loss: 0.01560433441773057, G Loss: 4.198881149291992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 476/100000, D Loss: 0.015215301653370261, G Loss: 4.165348529815674\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 477/100000, D Loss: 0.016482492676004767, G Loss: 4.10663366317749\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 478/100000, D Loss: 0.018055343767628074, G Loss: 4.082973957061768\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 479/100000, D Loss: 0.018304181285202503, G Loss: 4.076783657073975\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 480/100000, D Loss: 0.019761799136176705, G Loss: 4.001315116882324\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 481/100000, D Loss: 0.018795402254909277, G Loss: 4.048455238342285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 482/100000, D Loss: 0.018317285925149918, G Loss: 4.072637557983398\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 483/100000, D Loss: 0.01868468103930354, G Loss: 4.101073741912842\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 484/100000, D Loss: 0.017134223598986864, G Loss: 4.144852161407471\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 485/100000, D Loss: 0.015073574148118496, G Loss: 4.236691951751709\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 486/100000, D Loss: 0.013996605528518558, G Loss: 4.377678394317627\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 487/100000, D Loss: 0.013301666360348463, G Loss: 4.406230449676514\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 488/100000, D Loss: 0.012489390559494495, G Loss: 4.449044227600098\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 489/100000, D Loss: 0.011685701087117195, G Loss: 4.501039505004883\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 490/100000, D Loss: 0.012025164673104882, G Loss: 4.421810626983643\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 491/100000, D Loss: 0.01240855222567916, G Loss: 4.4094624519348145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 492/100000, D Loss: 0.012852044776082039, G Loss: 4.3856706619262695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 493/100000, D Loss: 0.013431748608127236, G Loss: 4.322603225708008\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 494/100000, D Loss: 0.013531778356991708, G Loss: 4.340173721313477\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 495/100000, D Loss: 0.013548910152167082, G Loss: 4.33471155166626\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 496/100000, D Loss: 0.013668077066540718, G Loss: 4.228199005126953\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 497/100000, D Loss: 0.013886503293178976, G Loss: 4.281848430633545\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 498/100000, D Loss: 0.014270002488046885, G Loss: 4.229722023010254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 499/100000, D Loss: 0.013327228021807969, G Loss: 4.20765495300293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 500/100000, D Loss: 0.013477123342454433, G Loss: 4.260791778564453\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 501/100000, D Loss: 0.012570420978590846, G Loss: 4.249725341796875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 502/100000, D Loss: 0.012173297116532922, G Loss: 4.267791271209717\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 503/100000, D Loss: 0.011793354875408113, G Loss: 4.2853288650512695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 504/100000, D Loss: 0.012183420127257705, G Loss: 4.278489112854004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 505/100000, D Loss: 0.012679435079917312, G Loss: 4.246828556060791\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 506/100000, D Loss: 0.011964854318648577, G Loss: 4.180811405181885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 507/100000, D Loss: 0.012040127883665264, G Loss: 4.135454177856445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 508/100000, D Loss: 0.012038745684549212, G Loss: 4.136416435241699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 509/100000, D Loss: 0.012022767215967178, G Loss: 4.174315452575684\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 510/100000, D Loss: 0.012140557868406177, G Loss: 4.180867671966553\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 511/100000, D Loss: 0.013037017080932856, G Loss: 4.147069931030273\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 512/100000, D Loss: 0.012726855929940939, G Loss: 4.071473121643066\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 513/100000, D Loss: 0.012242426513694227, G Loss: 4.07727575302124\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 514/100000, D Loss: 0.012471464113332331, G Loss: 4.090448379516602\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 515/100000, D Loss: 0.01205490913707763, G Loss: 4.14443826675415\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 516/100000, D Loss: 0.012160411453805864, G Loss: 4.147953987121582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 517/100000, D Loss: 0.011961313197389245, G Loss: 4.14272928237915\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 518/100000, D Loss: 0.011767412070184946, G Loss: 4.150089263916016\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 519/100000, D Loss: 0.012311375699937344, G Loss: 4.1330671310424805\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 520/100000, D Loss: 0.012020793627016246, G Loss: 4.118313789367676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 521/100000, D Loss: 0.011506785871461034, G Loss: 4.152941703796387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 522/100000, D Loss: 0.011072719935327768, G Loss: 4.183526992797852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 523/100000, D Loss: 0.011406223522499204, G Loss: 4.218715667724609\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 524/100000, D Loss: 0.011143347714096308, G Loss: 4.221310138702393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 525/100000, D Loss: 0.011159247369505465, G Loss: 4.22893762588501\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 526/100000, D Loss: 0.01063599856570363, G Loss: 4.233915328979492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 527/100000, D Loss: 0.01007842505350709, G Loss: 4.276361465454102\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 528/100000, D Loss: 0.009663003613241017, G Loss: 4.301017761230469\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 529/100000, D Loss: 0.009999621426686645, G Loss: 4.347350120544434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 530/100000, D Loss: 0.009442336158826947, G Loss: 4.344388961791992\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 531/100000, D Loss: 0.009469867567531765, G Loss: 4.347440719604492\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 532/100000, D Loss: 0.009044482605531812, G Loss: 4.382655143737793\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 533/100000, D Loss: 0.009211294818669558, G Loss: 4.377200126647949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 534/100000, D Loss: 0.009540352737531066, G Loss: 4.377716064453125\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 535/100000, D Loss: 0.009295203955844045, G Loss: 4.346294403076172\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 536/100000, D Loss: 0.009398092748597264, G Loss: 4.334554195404053\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 537/100000, D Loss: 0.009948807768523693, G Loss: 4.293682098388672\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 538/100000, D Loss: 0.010384278488345444, G Loss: 4.248518943786621\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 539/100000, D Loss: 0.010375729762017727, G Loss: 4.228598594665527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 540/100000, D Loss: 0.01091521861962974, G Loss: 4.205773830413818\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 541/100000, D Loss: 0.010786107159219682, G Loss: 4.2139739990234375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 542/100000, D Loss: 0.011596716474741697, G Loss: 4.2034220695495605\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 543/100000, D Loss: 0.010819087969139218, G Loss: 4.239147186279297\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 544/100000, D Loss: 0.01125180535018444, G Loss: 4.233701705932617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 545/100000, D Loss: 0.011588233523070812, G Loss: 4.247551441192627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 546/100000, D Loss: 0.01105115539394319, G Loss: 4.29348087310791\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 547/100000, D Loss: 0.011848070658743382, G Loss: 4.322622776031494\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 548/100000, D Loss: 0.012543907854706049, G Loss: 4.365087985992432\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 549/100000, D Loss: 0.013042557635344565, G Loss: 4.395840167999268\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 550/100000, D Loss: 0.013412219937890768, G Loss: 4.361754417419434\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 551/100000, D Loss: 0.0158017766661942, G Loss: 4.425961494445801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 552/100000, D Loss: 0.016815655399113894, G Loss: 4.423058032989502\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 553/100000, D Loss: 0.020547755993902683, G Loss: 4.539566993713379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 554/100000, D Loss: 0.026474056765437126, G Loss: 4.602056503295898\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 555/100000, D Loss: 0.0272395689971745, G Loss: 4.774559020996094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 556/100000, D Loss: 0.023983892053365707, G Loss: 4.996488571166992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 557/100000, D Loss: 0.02306642010807991, G Loss: 5.097504615783691\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 558/100000, D Loss: 0.02211214299313724, G Loss: 5.2467851638793945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 559/100000, D Loss: 0.024474679958075285, G Loss: 5.44529914855957\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 560/100000, D Loss: 0.021189070073887706, G Loss: 5.765844345092773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 561/100000, D Loss: 0.020055475644767284, G Loss: 5.883970260620117\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 562/100000, D Loss: 0.014658221509307623, G Loss: 6.146152019500732\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 563/100000, D Loss: 0.013718270929530263, G Loss: 6.28665828704834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 564/100000, D Loss: 0.010227379272691905, G Loss: 6.195865154266357\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 565/100000, D Loss: 0.007989285979419947, G Loss: 6.1638994216918945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 566/100000, D Loss: 0.0069760039914399385, G Loss: 6.303983211517334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 567/100000, D Loss: 0.005294781818520278, G Loss: 6.257630348205566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 568/100000, D Loss: 0.005315947695635259, G Loss: 6.210569381713867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 569/100000, D Loss: 0.004838484630454332, G Loss: 6.029873371124268\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 570/100000, D Loss: 0.004529768193606287, G Loss: 6.129242897033691\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 571/100000, D Loss: 0.004503411706537008, G Loss: 5.972317695617676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 572/100000, D Loss: 0.004285235307179391, G Loss: 5.907036781311035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 573/100000, D Loss: 0.00467705400660634, G Loss: 5.772192001342773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 574/100000, D Loss: 0.004753779910970479, G Loss: 5.688854217529297\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 575/100000, D Loss: 0.004953633819241077, G Loss: 5.59657621383667\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 576/100000, D Loss: 0.0053749235812574625, G Loss: 5.410019397735596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 577/100000, D Loss: 0.005881571676582098, G Loss: 5.327367782592773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 578/100000, D Loss: 0.006193805485963821, G Loss: 5.2663068771362305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 579/100000, D Loss: 0.006539468769915402, G Loss: 5.187734603881836\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 580/100000, D Loss: 0.00700205349130556, G Loss: 5.086970329284668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 581/100000, D Loss: 0.007474026409909129, G Loss: 5.023576259613037\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 582/100000, D Loss: 0.008560146437957883, G Loss: 4.929484844207764\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 583/100000, D Loss: 0.00867184076923877, G Loss: 4.887811660766602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 584/100000, D Loss: 0.00979267479851842, G Loss: 4.828160285949707\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 585/100000, D Loss: 0.009593736613169312, G Loss: 4.882992267608643\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 586/100000, D Loss: 0.010837652022019029, G Loss: 4.843316078186035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 587/100000, D Loss: 0.012300244765356183, G Loss: 4.7411088943481445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 588/100000, D Loss: 0.01256029843352735, G Loss: 4.787505626678467\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 589/100000, D Loss: 0.012526151724159718, G Loss: 4.897748947143555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 590/100000, D Loss: 0.011706979828886688, G Loss: 4.90345573425293\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 591/100000, D Loss: 0.012541321571916342, G Loss: 4.93027400970459\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 592/100000, D Loss: 0.011962692369706929, G Loss: 4.943737983703613\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 593/100000, D Loss: 0.012326464289799333, G Loss: 5.059118747711182\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 594/100000, D Loss: 0.01203747489489615, G Loss: 4.992908477783203\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 595/100000, D Loss: 0.011681451462209225, G Loss: 5.086677551269531\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 596/100000, D Loss: 0.011593072558753192, G Loss: 5.162755966186523\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 597/100000, D Loss: 0.010441145626828074, G Loss: 5.205633163452148\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 598/100000, D Loss: 0.00905454542953521, G Loss: 5.241044044494629\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 599/100000, D Loss: 0.009231604402884841, G Loss: 5.300046443939209\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 600/100000, D Loss: 0.008547212113626301, G Loss: 5.308991432189941\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 601/100000, D Loss: 0.008173674577847123, G Loss: 5.3396687507629395\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 602/100000, D Loss: 0.008103854721412063, G Loss: 5.325460433959961\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 603/100000, D Loss: 0.007823710795491934, G Loss: 5.371136665344238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 604/100000, D Loss: 0.007376635097898543, G Loss: 5.352314472198486\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 605/100000, D Loss: 0.007299177814275026, G Loss: 5.270367622375488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 606/100000, D Loss: 0.00681791128590703, G Loss: 5.361359596252441\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 607/100000, D Loss: 0.006380226346664131, G Loss: 5.254312038421631\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 608/100000, D Loss: 0.007024463848210871, G Loss: 5.239619731903076\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 609/100000, D Loss: 0.00708992755971849, G Loss: 5.203153133392334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 610/100000, D Loss: 0.007021410274319351, G Loss: 5.271132946014404\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 611/100000, D Loss: 0.0067614244762808084, G Loss: 5.236515522003174\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 612/100000, D Loss: 0.007183726876974106, G Loss: 5.239749431610107\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 613/100000, D Loss: 0.007146436953917146, G Loss: 5.187157154083252\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 614/100000, D Loss: 0.00718893064185977, G Loss: 5.168924331665039\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 615/100000, D Loss: 0.007261679973453283, G Loss: 5.186198711395264\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 616/100000, D Loss: 0.006648756330832839, G Loss: 5.160161972045898\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 617/100000, D Loss: 0.006919661769643426, G Loss: 5.176944732666016\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 618/100000, D Loss: 0.006085278349928558, G Loss: 5.245828628540039\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 619/100000, D Loss: 0.00613750796765089, G Loss: 5.281426906585693\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 620/100000, D Loss: 0.005540273850783706, G Loss: 5.2663068771362305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 621/100000, D Loss: 0.005592602305114269, G Loss: 5.312005043029785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 622/100000, D Loss: 0.0053229701006785035, G Loss: 5.3013200759887695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 623/100000, D Loss: 0.0048040993278846145, G Loss: 5.364498138427734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 624/100000, D Loss: 0.004581063985824585, G Loss: 5.411591529846191\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 625/100000, D Loss: 0.004397359269205481, G Loss: 5.425763130187988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 626/100000, D Loss: 0.0043130271951667964, G Loss: 5.460247039794922\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 627/100000, D Loss: 0.004141097771935165, G Loss: 5.440081596374512\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 628/100000, D Loss: 0.004091446578968316, G Loss: 5.458693981170654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 629/100000, D Loss: 0.004105159372556955, G Loss: 5.41762638092041\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 630/100000, D Loss: 0.004037481965497136, G Loss: 5.389007568359375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 631/100000, D Loss: 0.0040863401372917, G Loss: 5.349163055419922\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 632/100000, D Loss: 0.004563908441923559, G Loss: 5.2892866134643555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 633/100000, D Loss: 0.0044037121697328985, G Loss: 5.224204063415527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 634/100000, D Loss: 0.004726502986159176, G Loss: 5.22634220123291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 635/100000, D Loss: 0.004789635888300836, G Loss: 5.165287017822266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 636/100000, D Loss: 0.005194039549678564, G Loss: 5.164633750915527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 637/100000, D Loss: 0.005217185243964195, G Loss: 5.135746479034424\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 638/100000, D Loss: 0.005367005709558725, G Loss: 5.098154067993164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 639/100000, D Loss: 0.005611339118331671, G Loss: 5.083515167236328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 640/100000, D Loss: 0.0056991123128682375, G Loss: 5.040888786315918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 641/100000, D Loss: 0.005919893737882376, G Loss: 5.030966281890869\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 642/100000, D Loss: 0.005425249808467925, G Loss: 5.089415550231934\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 643/100000, D Loss: 0.005522566381841898, G Loss: 5.071662902832031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 644/100000, D Loss: 0.0058800880797207355, G Loss: 5.125297546386719\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 645/100000, D Loss: 0.005796517361886799, G Loss: 5.077950477600098\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 646/100000, D Loss: 0.00594564201310277, G Loss: 5.083989143371582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 647/100000, D Loss: 0.006214843830093741, G Loss: 5.086757183074951\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 648/100000, D Loss: 0.006167554995045066, G Loss: 5.066282272338867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 649/100000, D Loss: 0.006293010548688471, G Loss: 5.082371711730957\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 650/100000, D Loss: 0.006509282626211643, G Loss: 5.061914443969727\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 651/100000, D Loss: 0.007040947792120278, G Loss: 4.996485233306885\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 652/100000, D Loss: 0.007002464961260557, G Loss: 5.073089599609375\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 653/100000, D Loss: 0.00727313116658479, G Loss: 5.045954704284668\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 654/100000, D Loss: 0.008037397172302008, G Loss: 4.9946465492248535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 655/100000, D Loss: 0.008380001178011298, G Loss: 4.968118190765381\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 656/100000, D Loss: 0.008425087668001652, G Loss: 4.962553024291992\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 657/100000, D Loss: 0.00879632355645299, G Loss: 5.007817268371582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 658/100000, D Loss: 0.009356809314340353, G Loss: 5.029561519622803\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 659/100000, D Loss: 0.009729789104312658, G Loss: 5.017901420593262\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 660/100000, D Loss: 0.010713753756135702, G Loss: 5.062426567077637\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 661/100000, D Loss: 0.01016700966283679, G Loss: 5.022194862365723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 662/100000, D Loss: 0.010187143925577402, G Loss: 4.978446006774902\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 663/100000, D Loss: 0.012465145206078887, G Loss: 4.978816986083984\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 664/100000, D Loss: 0.011943296063691378, G Loss: 5.179939270019531\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 665/100000, D Loss: 0.012500968296080828, G Loss: 5.222782135009766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 666/100000, D Loss: 0.013004823122173548, G Loss: 5.084380149841309\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 667/100000, D Loss: 0.012649393640458584, G Loss: 5.11447286605835\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 668/100000, D Loss: 0.012865519849583507, G Loss: 5.275142669677734\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 669/100000, D Loss: 0.012843379518017173, G Loss: 5.355522632598877\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 670/100000, D Loss: 0.014806741382926702, G Loss: 5.294175148010254\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 671/100000, D Loss: 0.015401931712403893, G Loss: 5.388537883758545\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 672/100000, D Loss: 0.015016027260571718, G Loss: 5.496463775634766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 673/100000, D Loss: 0.013722039991989732, G Loss: 5.579390525817871\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 674/100000, D Loss: 0.014554980676621199, G Loss: 5.51785945892334\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 675/100000, D Loss: 0.01101756002753973, G Loss: 5.497697830200195\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 676/100000, D Loss: 0.009292142349295318, G Loss: 5.600067138671875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 677/100000, D Loss: 0.008387691108509898, G Loss: 5.798153400421143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 678/100000, D Loss: 0.007935839705169201, G Loss: 5.659030437469482\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 679/100000, D Loss: 0.008017244981601834, G Loss: 5.512399196624756\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 680/100000, D Loss: 0.007207725662738085, G Loss: 5.566166877746582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 681/100000, D Loss: 0.0063864069525152445, G Loss: 5.672582626342773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 682/100000, D Loss: 0.005167611176148057, G Loss: 5.704533100128174\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 683/100000, D Loss: 0.006288497243076563, G Loss: 5.583159446716309\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 684/100000, D Loss: 0.006092184339649975, G Loss: 5.494684219360352\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 685/100000, D Loss: 0.006339051527902484, G Loss: 5.361140251159668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 686/100000, D Loss: 0.006102010316681117, G Loss: 5.4637861251831055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 687/100000, D Loss: 0.005991342826746404, G Loss: 5.446679592132568\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 688/100000, D Loss: 0.006653559394180775, G Loss: 5.336809158325195\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 689/100000, D Loss: 0.006823972798883915, G Loss: 5.225647926330566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 690/100000, D Loss: 0.007581936428323388, G Loss: 5.0898942947387695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 691/100000, D Loss: 0.007353031076490879, G Loss: 5.036465167999268\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 692/100000, D Loss: 0.007057703332975507, G Loss: 5.064460754394531\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 693/100000, D Loss: 0.007526674773544073, G Loss: 5.157654762268066\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 694/100000, D Loss: 0.007477347040548921, G Loss: 5.099815368652344\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 695/100000, D Loss: 0.007163991220295429, G Loss: 5.067473411560059\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 696/100000, D Loss: 0.006851106183603406, G Loss: 5.133806228637695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 697/100000, D Loss: 0.007132757920771837, G Loss: 5.188567161560059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 698/100000, D Loss: 0.006587423733435571, G Loss: 5.214813232421875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 699/100000, D Loss: 0.006734722759574652, G Loss: 5.217005252838135\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 700/100000, D Loss: 0.007059942581690848, G Loss: 5.168102741241455\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 701/100000, D Loss: 0.007522313739173114, G Loss: 5.072880744934082\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 702/100000, D Loss: 0.008368391077965498, G Loss: 4.975866794586182\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 703/100000, D Loss: 0.008755124639719725, G Loss: 5.027692794799805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 704/100000, D Loss: 0.00951695372350514, G Loss: 4.962252140045166\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 705/100000, D Loss: 0.009430881589651108, G Loss: 4.971303939819336\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 706/100000, D Loss: 0.010087386006489396, G Loss: 4.908726692199707\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 707/100000, D Loss: 0.009372078231535852, G Loss: 4.939506530761719\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 708/100000, D Loss: 0.010289532132446766, G Loss: 4.938074588775635\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 709/100000, D Loss: 0.011490778997540474, G Loss: 4.943315505981445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 710/100000, D Loss: 0.011058957315981388, G Loss: 4.927888870239258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 711/100000, D Loss: 0.012914807302877307, G Loss: 4.865371227264404\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 712/100000, D Loss: 0.01161717833019793, G Loss: 4.924045562744141\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 713/100000, D Loss: 0.011267083697021008, G Loss: 4.94699764251709\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 714/100000, D Loss: 0.01318728574551642, G Loss: 4.922460556030273\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 715/100000, D Loss: 0.015878338366746902, G Loss: 4.792418479919434\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 716/100000, D Loss: 0.014153725001960993, G Loss: 5.001482963562012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 717/100000, D Loss: 0.015008807182312012, G Loss: 5.031241416931152\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 718/100000, D Loss: 0.01781658409163356, G Loss: 4.917280197143555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 719/100000, D Loss: 0.014966818504035473, G Loss: 4.916568756103516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 720/100000, D Loss: 0.014921193709596992, G Loss: 5.078550815582275\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 721/100000, D Loss: 0.015787528827786446, G Loss: 5.228921890258789\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 722/100000, D Loss: 0.02090880088508129, G Loss: 4.9184770584106445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 723/100000, D Loss: 0.020611196290701628, G Loss: 5.085374355316162\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 724/100000, D Loss: 0.01913457363843918, G Loss: 5.533334255218506\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 725/100000, D Loss: 0.027237292379140854, G Loss: 4.970472812652588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 726/100000, D Loss: 0.020802523591555655, G Loss: 5.102925777435303\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 727/100000, D Loss: 0.015712941996753216, G Loss: 5.670596122741699\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 728/100000, D Loss: 0.025522458367049694, G Loss: 5.299033164978027\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 729/100000, D Loss: 0.02195649896748364, G Loss: 5.437316417694092\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 730/100000, D Loss: 0.015370892360806465, G Loss: 5.780782699584961\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 731/100000, D Loss: 0.023766210302710533, G Loss: 5.520988464355469\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 732/100000, D Loss: 0.017113525420427322, G Loss: 5.603237152099609\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 733/100000, D Loss: 0.019027486443519592, G Loss: 5.634476661682129\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 734/100000, D Loss: 0.016904777847230434, G Loss: 5.6760711669921875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 735/100000, D Loss: 0.01683531841263175, G Loss: 5.484843730926514\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 736/100000, D Loss: 0.021611335687339306, G Loss: 5.757598876953125\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 737/100000, D Loss: 0.01477139350026846, G Loss: 6.031741619110107\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 738/100000, D Loss: 0.01878978544846177, G Loss: 5.522420406341553\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 739/100000, D Loss: 0.015221006935462356, G Loss: 5.465284824371338\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 740/100000, D Loss: 0.011614917078986764, G Loss: 5.841026782989502\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 741/100000, D Loss: 0.013185798190534115, G Loss: 5.917311668395996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 742/100000, D Loss: 0.014438004232943058, G Loss: 5.464549541473389\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 743/100000, D Loss: 0.012573318323120475, G Loss: 5.506072044372559\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 744/100000, D Loss: 0.012913452694192529, G Loss: 5.5158467292785645\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 745/100000, D Loss: 0.012322567868977785, G Loss: 5.668728351593018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 746/100000, D Loss: 0.017654753755778074, G Loss: 5.350472450256348\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 747/100000, D Loss: 0.017664103535935283, G Loss: 5.516451835632324\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 748/100000, D Loss: 0.012242791010066867, G Loss: 5.893304824829102\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 749/100000, D Loss: 0.01452985405921936, G Loss: 5.773561477661133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 750/100000, D Loss: 0.014168355613946915, G Loss: 5.713167190551758\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 751/100000, D Loss: 0.012051803292706609, G Loss: 5.789151191711426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 752/100000, D Loss: 0.012981881154701114, G Loss: 6.032701015472412\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 753/100000, D Loss: 0.011920605786144733, G Loss: 5.959075927734375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 754/100000, D Loss: 0.016316703986376524, G Loss: 5.920162200927734\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 755/100000, D Loss: 0.013206661213189363, G Loss: 5.941164016723633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 756/100000, D Loss: 0.010573041625320911, G Loss: 5.9094743728637695\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 757/100000, D Loss: 0.012194885406643152, G Loss: 5.9555134773254395\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 758/100000, D Loss: 0.011457737069576979, G Loss: 5.941341400146484\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 759/100000, D Loss: 0.011647040955722332, G Loss: 5.81330680847168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 760/100000, D Loss: 0.0116462423466146, G Loss: 5.686115264892578\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 761/100000, D Loss: 0.013678219402208924, G Loss: 5.7468647956848145\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 762/100000, D Loss: 0.010991782182827592, G Loss: 5.735587120056152\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 763/100000, D Loss: 0.013523203320801258, G Loss: 5.54937744140625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 764/100000, D Loss: 0.012447432149201632, G Loss: 5.441425800323486\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 765/100000, D Loss: 0.012109521310776472, G Loss: 5.459992408752441\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 766/100000, D Loss: 0.009865351719781756, G Loss: 5.520803451538086\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 767/100000, D Loss: 0.011381628923118114, G Loss: 5.367580890655518\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 768/100000, D Loss: 0.012835881439968944, G Loss: 5.150752067565918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 769/100000, D Loss: 0.011907170061022043, G Loss: 5.280342102050781\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 770/100000, D Loss: 0.011211554054170847, G Loss: 5.431605339050293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 771/100000, D Loss: 0.013835139572620392, G Loss: 5.1614990234375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 772/100000, D Loss: 0.012865169672295451, G Loss: 5.166317462921143\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 773/100000, D Loss: 0.011803097557276487, G Loss: 5.321115970611572\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 774/100000, D Loss: 0.013582374900579453, G Loss: 5.1923627853393555\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 775/100000, D Loss: 0.015295368153601885, G Loss: 4.964062690734863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 776/100000, D Loss: 0.013295568292960525, G Loss: 5.069823741912842\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 777/100000, D Loss: 0.014161996077746153, G Loss: 5.216488838195801\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 778/100000, D Loss: 0.020369116216897964, G Loss: 4.9053053855896\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 779/100000, D Loss: 0.019638376776129007, G Loss: 4.9800567626953125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 780/100000, D Loss: 0.013774923048913479, G Loss: 5.3063645362854\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 781/100000, D Loss: 0.019625358283519745, G Loss: 5.094864845275879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 782/100000, D Loss: 0.01821840088814497, G Loss: 5.179230690002441\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 783/100000, D Loss: 0.018429927993565798, G Loss: 5.392806053161621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 784/100000, D Loss: 0.012252146610990167, G Loss: 5.705833911895752\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 785/100000, D Loss: 0.017249221447855234, G Loss: 5.548548221588135\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 786/100000, D Loss: 0.01645231805741787, G Loss: 5.665858268737793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 787/100000, D Loss: 0.015675948467105627, G Loss: 5.86668586730957\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 788/100000, D Loss: 0.01628673728555441, G Loss: 5.903468132019043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 789/100000, D Loss: 0.01960015669465065, G Loss: 5.894969463348389\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 790/100000, D Loss: 0.02190065011382103, G Loss: 5.936054229736328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 791/100000, D Loss: 0.0222061388194561, G Loss: 6.058392524719238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 792/100000, D Loss: 0.01915382407605648, G Loss: 6.440120220184326\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 793/100000, D Loss: 0.02350117824971676, G Loss: 6.172501087188721\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 794/100000, D Loss: 0.02167753642424941, G Loss: 7.086166858673096\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 795/100000, D Loss: 0.016868124715983868, G Loss: 7.275923728942871\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 796/100000, D Loss: 0.02103305933997035, G Loss: 7.004085063934326\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 797/100000, D Loss: 0.0196796883828938, G Loss: 7.215672492980957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 798/100000, D Loss: 0.016154304146766663, G Loss: 7.651026725769043\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 799/100000, D Loss: 0.021431180648505688, G Loss: 6.624675273895264\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 800/100000, D Loss: 0.024317406117916107, G Loss: 6.909370422363281\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 801/100000, D Loss: 0.008515490218997002, G Loss: 7.870180130004883\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 802/100000, D Loss: 0.029768697917461395, G Loss: 6.5710930824279785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 803/100000, D Loss: 0.023292599944397807, G Loss: 6.707314491271973\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 804/100000, D Loss: 0.009060854790732265, G Loss: 7.848841667175293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 805/100000, D Loss: 0.02042819932103157, G Loss: 6.4079270362854\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 806/100000, D Loss: 0.022568763000890613, G Loss: 6.363345623016357\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 807/100000, D Loss: 0.010523614939302206, G Loss: 6.632259845733643\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 808/100000, D Loss: 0.012765571475028992, G Loss: 6.839829444885254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 809/100000, D Loss: 0.017125137150287628, G Loss: 6.076862335205078\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 810/100000, D Loss: 0.016848910599946976, G Loss: 5.791332721710205\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 811/100000, D Loss: 0.01339996000751853, G Loss: 6.196547031402588\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 812/100000, D Loss: 0.01796414703130722, G Loss: 5.566720962524414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 813/100000, D Loss: 0.020312161184847355, G Loss: 5.493165016174316\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 814/100000, D Loss: 0.015067717991769314, G Loss: 5.738668441772461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 815/100000, D Loss: 0.021643281914293766, G Loss: 5.306565284729004\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 816/100000, D Loss: 0.02702816016972065, G Loss: 4.93021297454834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 817/100000, D Loss: 0.01831023208796978, G Loss: 5.483687400817871\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 818/100000, D Loss: 0.025220701470971107, G Loss: 5.01870059967041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 819/100000, D Loss: 0.021384213119745255, G Loss: 5.21923303604126\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 820/100000, D Loss: 0.020687817595899105, G Loss: 5.133519172668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 821/100000, D Loss: 0.025336746126413345, G Loss: 4.897286415100098\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 822/100000, D Loss: 0.02701203292235732, G Loss: 5.104107856750488\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 823/100000, D Loss: 0.02880209870636463, G Loss: 5.011300563812256\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 824/100000, D Loss: 0.03703003562986851, G Loss: 4.701169967651367\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 825/100000, D Loss: 0.0292788315564394, G Loss: 5.231387138366699\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 826/100000, D Loss: 0.03757853806018829, G Loss: 4.950408458709717\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 827/100000, D Loss: 0.03138764575123787, G Loss: 5.29748010635376\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 828/100000, D Loss: 0.03081178106367588, G Loss: 5.354546546936035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 829/100000, D Loss: 0.031730552203953266, G Loss: 5.526204586029053\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 830/100000, D Loss: 0.02253587171435356, G Loss: 5.7543230056762695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 831/100000, D Loss: 0.024968618527054787, G Loss: 5.875485420227051\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 832/100000, D Loss: 0.02239687368273735, G Loss: 6.156088352203369\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 833/100000, D Loss: 0.0182022200897336, G Loss: 6.084054946899414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 834/100000, D Loss: 0.018793991766870022, G Loss: 5.978594779968262\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 835/100000, D Loss: 0.014597071800380945, G Loss: 5.974634170532227\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 836/100000, D Loss: 0.0139921260997653, G Loss: 6.188940525054932\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 837/100000, D Loss: 0.017523097805678844, G Loss: 5.656209468841553\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 838/100000, D Loss: 0.01913887821137905, G Loss: 5.511911392211914\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 839/100000, D Loss: 0.020041117910295725, G Loss: 5.485445499420166\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 840/100000, D Loss: 0.022412026301026344, G Loss: 5.480391502380371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 841/100000, D Loss: 0.01919653546065092, G Loss: 5.524657726287842\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 842/100000, D Loss: 0.017400890588760376, G Loss: 5.687167644500732\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 843/100000, D Loss: 0.01515223365277052, G Loss: 5.801541328430176\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 844/100000, D Loss: 0.01846023090183735, G Loss: 5.444098949432373\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 845/100000, D Loss: 0.021241487469524145, G Loss: 5.282025337219238\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 846/100000, D Loss: 0.020168502815067768, G Loss: 5.693533897399902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 847/100000, D Loss: 0.035064298659563065, G Loss: 5.060725212097168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 848/100000, D Loss: 0.029777430929243565, G Loss: 5.283363342285156\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 849/100000, D Loss: 0.03296162374317646, G Loss: 5.426743507385254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 850/100000, D Loss: 0.028576934710144997, G Loss: 5.284944534301758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 851/100000, D Loss: 0.022340429946780205, G Loss: 5.576995849609375\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 852/100000, D Loss: 0.02020756434649229, G Loss: 5.64743709564209\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 853/100000, D Loss: 0.02377382293343544, G Loss: 5.509212493896484\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 854/100000, D Loss: 0.02524084597826004, G Loss: 5.591869831085205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 855/100000, D Loss: 0.025348554830998182, G Loss: 5.934677600860596\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 856/100000, D Loss: 0.02983646746724844, G Loss: 5.939731597900391\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 857/100000, D Loss: 0.03971210867166519, G Loss: 5.814157485961914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 858/100000, D Loss: 0.03957331459969282, G Loss: 5.935163497924805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 859/100000, D Loss: 0.04636092483997345, G Loss: 5.665937900543213\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 860/100000, D Loss: 0.040408854372799397, G Loss: 5.959015369415283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 861/100000, D Loss: 0.02343524619936943, G Loss: 6.070372104644775\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 862/100000, D Loss: 0.024512801319360733, G Loss: 5.86801815032959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 863/100000, D Loss: 0.01625308021903038, G Loss: 5.763364791870117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 864/100000, D Loss: 0.008106554509140551, G Loss: 6.199519634246826\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 865/100000, D Loss: 0.005762593587860465, G Loss: 6.693355560302734\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 866/100000, D Loss: 0.006344228982925415, G Loss: 6.749523162841797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 867/100000, D Loss: 0.007284061051905155, G Loss: 6.368715763092041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 868/100000, D Loss: 0.007659413851797581, G Loss: 5.788393497467041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 869/100000, D Loss: 0.011311798822134733, G Loss: 5.46531343460083\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 870/100000, D Loss: 0.012719730846583843, G Loss: 5.529587268829346\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 871/100000, D Loss: 0.013742708135396242, G Loss: 5.641151428222656\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 872/100000, D Loss: 0.020713848993182182, G Loss: 5.266096115112305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 873/100000, D Loss: 0.026132610626518726, G Loss: 5.090771675109863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 874/100000, D Loss: 0.0282689044252038, G Loss: 5.507220268249512\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 875/100000, D Loss: 0.03880387544631958, G Loss: 5.1424055099487305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 876/100000, D Loss: 0.03111739596351981, G Loss: 5.539797782897949\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 877/100000, D Loss: 0.022740076761692762, G Loss: 6.158945560455322\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 878/100000, D Loss: 0.028032132424414158, G Loss: 5.913942337036133\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 879/100000, D Loss: 0.02469365019351244, G Loss: 5.898131370544434\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 880/100000, D Loss: 0.022828795947134495, G Loss: 6.0494890213012695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 881/100000, D Loss: 0.026334104128181934, G Loss: 5.9509758949279785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 882/100000, D Loss: 0.02531398832798004, G Loss: 6.199535369873047\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 883/100000, D Loss: 0.020138700492680073, G Loss: 6.745803356170654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 884/100000, D Loss: 0.02753540314733982, G Loss: 5.859261512756348\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 885/100000, D Loss: 0.023404522333294153, G Loss: 6.023927688598633\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 886/100000, D Loss: 0.01794421300292015, G Loss: 6.322811126708984\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 887/100000, D Loss: 0.0229384433478117, G Loss: 5.989035606384277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 888/100000, D Loss: 0.02074327878654003, G Loss: 5.807479381561279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 889/100000, D Loss: 0.016603673808276653, G Loss: 6.130629539489746\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 890/100000, D Loss: 0.01709540095180273, G Loss: 6.148811340332031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 891/100000, D Loss: 0.019291769713163376, G Loss: 5.8912882804870605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 892/100000, D Loss: 0.016243630088865757, G Loss: 5.937727928161621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 893/100000, D Loss: 0.01458329614251852, G Loss: 6.087628364562988\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 894/100000, D Loss: 0.015451482497155666, G Loss: 5.825124740600586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 895/100000, D Loss: 0.014709270093590021, G Loss: 5.754913330078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 896/100000, D Loss: 0.017642810940742493, G Loss: 5.61732816696167\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 897/100000, D Loss: 0.01474655931815505, G Loss: 5.776963233947754\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 898/100000, D Loss: 0.01991670299321413, G Loss: 5.476969242095947\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 899/100000, D Loss: 0.021636310033500195, G Loss: 5.419807434082031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 900/100000, D Loss: 0.019874134100973606, G Loss: 5.429664611816406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 901/100000, D Loss: 0.02711858507245779, G Loss: 5.150449752807617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 902/100000, D Loss: 0.020330327097326517, G Loss: 5.399563312530518\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 903/100000, D Loss: 0.02428165078163147, G Loss: 5.505380630493164\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 904/100000, D Loss: 0.031315237283706665, G Loss: 5.019163131713867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 905/100000, D Loss: 0.030477638356387615, G Loss: 5.498090744018555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 906/100000, D Loss: 0.024356245063245296, G Loss: 5.699822425842285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 907/100000, D Loss: 0.025542314164340496, G Loss: 5.379799842834473\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 908/100000, D Loss: 0.020784657448530197, G Loss: 5.809765815734863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 909/100000, D Loss: 0.01584435533732176, G Loss: 6.162825584411621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 910/100000, D Loss: 0.019298432394862175, G Loss: 5.752983570098877\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 911/100000, D Loss: 0.014287370722740889, G Loss: 5.646948337554932\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 912/100000, D Loss: 0.017708715982735157, G Loss: 5.70219087600708\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 913/100000, D Loss: 0.015233964659273624, G Loss: 5.736965656280518\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 914/100000, D Loss: 0.029216238297522068, G Loss: 4.89806604385376\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 915/100000, D Loss: 0.025540639646351337, G Loss: 5.379894733428955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 916/100000, D Loss: 0.03729388862848282, G Loss: 4.793603897094727\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 917/100000, D Loss: 0.040384313091635704, G Loss: 5.04932165145874\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 918/100000, D Loss: 0.03980361111462116, G Loss: 5.00459098815918\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 919/100000, D Loss: 0.03327164985239506, G Loss: 4.926980495452881\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 920/100000, D Loss: 0.02250499278306961, G Loss: 5.313865661621094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 921/100000, D Loss: 0.022976229898631573, G Loss: 5.094916343688965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 922/100000, D Loss: 0.029758987948298454, G Loss: 4.826704025268555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 923/100000, D Loss: 0.032647719606757164, G Loss: 5.113349437713623\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 924/100000, D Loss: 0.046519964933395386, G Loss: 4.61195182800293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 925/100000, D Loss: 0.04977354779839516, G Loss: 4.8649373054504395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 926/100000, D Loss: 0.06212986633181572, G Loss: 4.505688190460205\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 927/100000, D Loss: 0.04987197369337082, G Loss: 5.000851631164551\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 928/100000, D Loss: 0.07691266760230064, G Loss: 4.429080963134766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 929/100000, D Loss: 0.030730905011296272, G Loss: 5.362362861633301\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 930/100000, D Loss: 0.06564333289861679, G Loss: 4.3401198387146\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 931/100000, D Loss: 0.028886782936751842, G Loss: 5.328843116760254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 932/100000, D Loss: 0.02468170039355755, G Loss: 5.545084476470947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 933/100000, D Loss: 0.05930216237902641, G Loss: 4.39401912689209\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 934/100000, D Loss: 0.03420217940583825, G Loss: 5.6071648597717285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 935/100000, D Loss: 0.05472116731107235, G Loss: 4.780312538146973\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 936/100000, D Loss: 0.03666478302329779, G Loss: 5.335177898406982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 937/100000, D Loss: 0.016424217727035284, G Loss: 6.30018424987793\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 938/100000, D Loss: 0.03529117628931999, G Loss: 4.742815971374512\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 939/100000, D Loss: 0.030979726929217577, G Loss: 5.490588188171387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 940/100000, D Loss: 0.013851017225533724, G Loss: 6.589255332946777\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 941/100000, D Loss: 0.046571141108870506, G Loss: 4.323941230773926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 942/100000, D Loss: 0.05426724947756156, G Loss: 5.840607643127441\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 943/100000, D Loss: 0.007788621820509434, G Loss: 8.745357513427734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 944/100000, D Loss: 0.19427382200956345, G Loss: 2.2218170166015625\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 945/100000, D Loss: 0.5835160507504042, G Loss: 7.876706123352051\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 946/100000, D Loss: 0.0016357368344870338, G Loss: 20.75756072998047\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 947/100000, D Loss: 6.08100186601223, G Loss: 3.6326775550842285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 948/100000, D Loss: 1.897208985325051, G Loss: 0.33551111817359924\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 949/100000, D Loss: 1.661447294585912, G Loss: 2.2592813968658447\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 950/100000, D Loss: 0.009800246410350155, G Loss: 9.923678398132324\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 951/100000, D Loss: 0.006125662388512865, G Loss: 16.344158172607422\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 952/100000, D Loss: 0.46693123915110846, G Loss: 16.023767471313477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 953/100000, D Loss: 0.44893915940338047, G Loss: 12.014814376831055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 954/100000, D Loss: 0.053983321820851415, G Loss: 8.440616607666016\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 955/100000, D Loss: 0.00920839561149478, G Loss: 5.143516540527344\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 956/100000, D Loss: 0.11198912959298468, G Loss: 3.523406982421875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 957/100000, D Loss: 0.16631723117598085, G Loss: 3.859339475631714\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 958/100000, D Loss: 0.06014452294039074, G Loss: 5.823622703552246\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 959/100000, D Loss: 0.013797335122944787, G Loss: 7.744140625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 960/100000, D Loss: 0.009366778889670968, G Loss: 9.068751335144043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 961/100000, D Loss: 0.07505930680781603, G Loss: 7.989749431610107\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 962/100000, D Loss: 0.12903219647705555, G Loss: 5.249678611755371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 963/100000, D Loss: 0.16773002222180367, G Loss: 3.4980432987213135\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 964/100000, D Loss: 0.17739154119044542, G Loss: 4.157877445220947\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 965/100000, D Loss: 0.1198643185198307, G Loss: 5.172152519226074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 966/100000, D Loss: 0.41720518469810486, G Loss: 2.561122179031372\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 967/100000, D Loss: 0.2964191194623709, G Loss: 2.9370834827423096\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 968/100000, D Loss: 0.08663753792643547, G Loss: 4.658750534057617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 969/100000, D Loss: 0.31163182109594345, G Loss: 2.535080909729004\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 970/100000, D Loss: 0.24186514131724834, G Loss: 2.5995724201202393\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 971/100000, D Loss: 0.06557046808302402, G Loss: 4.2971320152282715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 972/100000, D Loss: 0.17876157723367214, G Loss: 3.6964778900146484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 973/100000, D Loss: 0.11559825763106346, G Loss: 3.022254705429077\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 974/100000, D Loss: 0.10057159513235092, G Loss: 3.4154911041259766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 975/100000, D Loss: 0.06661583296954632, G Loss: 4.161352157592773\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 976/100000, D Loss: 0.12158121913671494, G Loss: 3.499678611755371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 977/100000, D Loss: 0.10806480795145035, G Loss: 3.289931297302246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 978/100000, D Loss: 0.08449205942451954, G Loss: 3.755601644515991\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 979/100000, D Loss: 0.08052699267864227, G Loss: 3.870964288711548\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 980/100000, D Loss: 0.09521061554551125, G Loss: 3.584045886993408\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 981/100000, D Loss: 0.11298038810491562, G Loss: 3.435931921005249\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 982/100000, D Loss: 0.11065574735403061, G Loss: 3.5921804904937744\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 983/100000, D Loss: 0.110024593770504, G Loss: 3.6078972816467285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 984/100000, D Loss: 0.14295446872711182, G Loss: 3.415848731994629\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 985/100000, D Loss: 0.12909821420907974, G Loss: 3.3407232761383057\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 986/100000, D Loss: 0.13652091845870018, G Loss: 3.3923535346984863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 987/100000, D Loss: 0.14769811928272247, G Loss: 3.5050110816955566\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 988/100000, D Loss: 0.14261206984519958, G Loss: 3.4244742393493652\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 989/100000, D Loss: 0.1353226825594902, G Loss: 3.6633005142211914\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 990/100000, D Loss: 0.10408608615398407, G Loss: 4.049162864685059\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 991/100000, D Loss: 0.0920524075627327, G Loss: 4.02419376373291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 992/100000, D Loss: 0.07650024816393852, G Loss: 4.082185745239258\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 993/100000, D Loss: 0.05439439043402672, G Loss: 4.371549129486084\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 994/100000, D Loss: 0.04301559925079346, G Loss: 4.808083534240723\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 995/100000, D Loss: 0.05021314136683941, G Loss: 4.502372741699219\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 996/100000, D Loss: 0.06416254118084908, G Loss: 4.051065444946289\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 997/100000, D Loss: 0.07499398291110992, G Loss: 3.7678639888763428\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 998/100000, D Loss: 0.0631120540201664, G Loss: 4.170056343078613\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 999/100000, D Loss: 0.08650698512792587, G Loss: 3.893224000930786\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1000/100000, D Loss: 0.1086781807243824, G Loss: 3.5190422534942627\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1001/100000, D Loss: 0.09222055226564407, G Loss: 3.5088796615600586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1002/100000, D Loss: 0.07694192789494991, G Loss: 3.96532940864563\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1003/100000, D Loss: 0.07208038866519928, G Loss: 3.901465654373169\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1004/100000, D Loss: 0.07413923740386963, G Loss: 3.6312241554260254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1005/100000, D Loss: 0.0571875274181366, G Loss: 3.7762722969055176\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1006/100000, D Loss: 0.05270686745643616, G Loss: 4.14008903503418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1007/100000, D Loss: 0.0508158877491951, G Loss: 4.175347805023193\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1008/100000, D Loss: 0.0485409926623106, G Loss: 4.080775260925293\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1009/100000, D Loss: 0.04505520686507225, G Loss: 3.9994008541107178\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1010/100000, D Loss: 0.04387043137103319, G Loss: 3.9972984790802\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1011/100000, D Loss: 0.04241609945893288, G Loss: 4.049479007720947\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1012/100000, D Loss: 0.05864252708852291, G Loss: 3.7230114936828613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1013/100000, D Loss: 0.0667642205953598, G Loss: 3.4436237812042236\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1014/100000, D Loss: 0.06922592408955097, G Loss: 3.4903671741485596\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1015/100000, D Loss: 0.08453138917684555, G Loss: 3.4148099422454834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1016/100000, D Loss: 0.08241578564047813, G Loss: 3.445373058319092\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1017/100000, D Loss: 0.07552134618163109, G Loss: 3.57393741607666\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1018/100000, D Loss: 0.09349208697676659, G Loss: 3.3043720722198486\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1019/100000, D Loss: 0.08138146996498108, G Loss: 3.5163774490356445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1020/100000, D Loss: 0.06253084726631641, G Loss: 3.820295572280884\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1021/100000, D Loss: 0.06520004570484161, G Loss: 3.8255345821380615\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1022/100000, D Loss: 0.06055004149675369, G Loss: 3.635560989379883\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1023/100000, D Loss: 0.06193782016634941, G Loss: 3.6170530319213867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1024/100000, D Loss: 0.0526856891810894, G Loss: 3.880540370941162\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1025/100000, D Loss: 0.05524280108511448, G Loss: 3.837864875793457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1026/100000, D Loss: 0.06342891976237297, G Loss: 3.6718945503234863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1027/100000, D Loss: 0.07498237863183022, G Loss: 3.445462703704834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1028/100000, D Loss: 0.08035391569137573, G Loss: 3.417557716369629\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1029/100000, D Loss: 0.07959816604852676, G Loss: 3.5578994750976562\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1030/100000, D Loss: 0.1009860523045063, G Loss: 3.398953914642334\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1031/100000, D Loss: 0.12158788368105888, G Loss: 3.4252443313598633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1032/100000, D Loss: 0.11873744428157806, G Loss: 3.4991512298583984\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1033/100000, D Loss: 0.12813905254006386, G Loss: 3.351853847503662\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1034/100000, D Loss: 0.1363372877240181, G Loss: 3.3206005096435547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1035/100000, D Loss: 0.10834132134914398, G Loss: 3.6747426986694336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1036/100000, D Loss: 0.08391391485929489, G Loss: 4.168736934661865\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1037/100000, D Loss: 0.06958658993244171, G Loss: 4.40333890914917\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1038/100000, D Loss: 0.05104227364063263, G Loss: 4.645593643188477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1039/100000, D Loss: 0.04003332927823067, G Loss: 4.981448173522949\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1040/100000, D Loss: 0.04272220656275749, G Loss: 5.173300266265869\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1041/100000, D Loss: 0.04910514876246452, G Loss: 5.23832893371582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1042/100000, D Loss: 0.06537743471562862, G Loss: 5.19399356842041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1043/100000, D Loss: 0.06632933020591736, G Loss: 5.054093360900879\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1044/100000, D Loss: 0.0666869692504406, G Loss: 5.0815229415893555\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1045/100000, D Loss: 0.04527961649000645, G Loss: 5.22700309753418\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1046/100000, D Loss: 0.04742513224482536, G Loss: 5.087658882141113\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1047/100000, D Loss: 0.03834113851189613, G Loss: 4.772373199462891\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1048/100000, D Loss: 0.032603937201201916, G Loss: 4.6817474365234375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1049/100000, D Loss: 0.02705235779285431, G Loss: 4.731412410736084\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1050/100000, D Loss: 0.03373226709663868, G Loss: 4.720787048339844\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1051/100000, D Loss: 0.035103512927889824, G Loss: 4.472200393676758\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1052/100000, D Loss: 0.03544835653156042, G Loss: 4.280505180358887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1053/100000, D Loss: 0.03863576706498861, G Loss: 4.268863677978516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1054/100000, D Loss: 0.04077727347612381, G Loss: 4.227439880371094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1055/100000, D Loss: 0.05385665223002434, G Loss: 3.9614288806915283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1056/100000, D Loss: 0.0650869570672512, G Loss: 3.758333206176758\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1057/100000, D Loss: 0.07518956065177917, G Loss: 3.9568653106689453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1058/100000, D Loss: 0.07361413910984993, G Loss: 4.101234436035156\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1059/100000, D Loss: 0.08294561877846718, G Loss: 4.057305335998535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1060/100000, D Loss: 0.078775804489851, G Loss: 4.158692359924316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1061/100000, D Loss: 0.05622474104166031, G Loss: 4.348575592041016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1062/100000, D Loss: 0.053798338398337364, G Loss: 4.379075527191162\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1063/100000, D Loss: 0.046590715646743774, G Loss: 4.3524580001831055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1064/100000, D Loss: 0.04756111651659012, G Loss: 4.294508457183838\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1065/100000, D Loss: 0.04242757335305214, G Loss: 4.302670478820801\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1066/100000, D Loss: 0.03880973346531391, G Loss: 4.332616329193115\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1067/100000, D Loss: 0.0452205091714859, G Loss: 4.340113162994385\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1068/100000, D Loss: 0.04230397753417492, G Loss: 4.171256065368652\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1069/100000, D Loss: 0.04308488965034485, G Loss: 4.300328731536865\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1070/100000, D Loss: 0.0431672390550375, G Loss: 4.3828887939453125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1071/100000, D Loss: 0.04722306504845619, G Loss: 4.297979831695557\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1072/100000, D Loss: 0.05390953831374645, G Loss: 4.17938232421875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1073/100000, D Loss: 0.05357297137379646, G Loss: 4.240209579467773\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1074/100000, D Loss: 0.05912534147500992, G Loss: 4.286975860595703\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1075/100000, D Loss: 0.06886566430330276, G Loss: 4.225444793701172\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1076/100000, D Loss: 0.0661470852792263, G Loss: 4.240042686462402\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1077/100000, D Loss: 0.06848855316638947, G Loss: 4.218594551086426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1078/100000, D Loss: 0.06419696658849716, G Loss: 4.120195388793945\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1079/100000, D Loss: 0.06800346076488495, G Loss: 3.772864818572998\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1080/100000, D Loss: 0.0632927156984806, G Loss: 3.7373998165130615\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1081/100000, D Loss: 0.05319606326520443, G Loss: 3.9969964027404785\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1082/100000, D Loss: 0.048944393172860146, G Loss: 3.976438045501709\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1083/100000, D Loss: 0.04838800057768822, G Loss: 3.8139419555664062\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1084/100000, D Loss: 0.04070691205561161, G Loss: 3.7299156188964844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1085/100000, D Loss: 0.033880166709423065, G Loss: 4.052758693695068\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1086/100000, D Loss: 0.030462561175227165, G Loss: 4.188624858856201\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1087/100000, D Loss: 0.036412563174963, G Loss: 4.1753435134887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1088/100000, D Loss: 0.03664827719330788, G Loss: 3.9370622634887695\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1089/100000, D Loss: 0.04481199197471142, G Loss: 3.7339773178100586\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1090/100000, D Loss: 0.04862547665834427, G Loss: 3.694499969482422\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1091/100000, D Loss: 0.04692941531538963, G Loss: 3.786609411239624\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1092/100000, D Loss: 0.05465574748814106, G Loss: 3.746762990951538\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1093/100000, D Loss: 0.05221154913306236, G Loss: 3.7256503105163574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1094/100000, D Loss: 0.04827127046883106, G Loss: 3.7223665714263916\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1095/100000, D Loss: 0.04732499271631241, G Loss: 3.719597816467285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1096/100000, D Loss: 0.04682750627398491, G Loss: 3.809126377105713\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1097/100000, D Loss: 0.044659845530986786, G Loss: 3.834522247314453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1098/100000, D Loss: 0.037776537239551544, G Loss: 3.886371612548828\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1099/100000, D Loss: 0.04102594964206219, G Loss: 4.008813381195068\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1100/100000, D Loss: 0.04086587764322758, G Loss: 3.8964858055114746\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1101/100000, D Loss: 0.0448615588247776, G Loss: 3.740877151489258\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1102/100000, D Loss: 0.04208832606673241, G Loss: 3.774651288986206\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1103/100000, D Loss: 0.04267709515988827, G Loss: 3.8842477798461914\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1104/100000, D Loss: 0.0535240825265646, G Loss: 3.7399942874908447\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1105/100000, D Loss: 0.05767976865172386, G Loss: 3.6036081314086914\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1106/100000, D Loss: 0.052105722948908806, G Loss: 3.711305618286133\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 1107/100000, D Loss: 0.054141806438565254, G Loss: 3.7627737522125244\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1108/100000, D Loss: 0.051725080236792564, G Loss: 3.7437996864318848\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1109/100000, D Loss: 0.049864986911416054, G Loss: 3.704010009765625\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1110/100000, D Loss: 0.05701926723122597, G Loss: 3.679912805557251\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1111/100000, D Loss: 0.05364015884697437, G Loss: 3.698420286178589\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1112/100000, D Loss: 0.068476602435112, G Loss: 3.520352840423584\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1113/100000, D Loss: 0.07159331440925598, G Loss: 3.3705456256866455\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1114/100000, D Loss: 0.07643528655171394, G Loss: 3.333641529083252\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1115/100000, D Loss: 0.0624937005341053, G Loss: 3.5264012813568115\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1116/100000, D Loss: 0.06652851775288582, G Loss: 3.584122657775879\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1117/100000, D Loss: 0.06115059368312359, G Loss: 3.5710105895996094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1118/100000, D Loss: 0.050423163920640945, G Loss: 3.5878334045410156\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1119/100000, D Loss: 0.04952810890972614, G Loss: 3.700488328933716\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1120/100000, D Loss: 0.042987480759620667, G Loss: 3.8287854194641113\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1121/100000, D Loss: 0.04758116975426674, G Loss: 3.7616751194000244\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1122/100000, D Loss: 0.060417961329221725, G Loss: 3.4462838172912598\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1123/100000, D Loss: 0.07894782908260822, G Loss: 3.3407387733459473\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1124/100000, D Loss: 0.0900895856320858, G Loss: 3.466006278991699\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1125/100000, D Loss: 0.11799126490950584, G Loss: 3.2387266159057617\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1126/100000, D Loss: 0.1506388857960701, G Loss: 3.187237024307251\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1127/100000, D Loss: 0.1587536707520485, G Loss: 3.270688056945801\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1128/100000, D Loss: 0.19587669521570206, G Loss: 3.2718701362609863\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1129/100000, D Loss: 0.16467446833848953, G Loss: 3.6305720806121826\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1130/100000, D Loss: 0.14148306846618652, G Loss: 4.072872161865234\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1131/100000, D Loss: 0.1165335550904274, G Loss: 4.1849493980407715\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1132/100000, D Loss: 0.0926096923649311, G Loss: 4.73643684387207\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1133/100000, D Loss: 0.07321738079190254, G Loss: 4.97288703918457\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1134/100000, D Loss: 0.06893333047628403, G Loss: 5.1549296379089355\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1135/100000, D Loss: 0.06652965769171715, G Loss: 5.227447509765625\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1136/100000, D Loss: 0.07295134663581848, G Loss: 4.88889217376709\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1137/100000, D Loss: 0.0645541176199913, G Loss: 5.066626071929932\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1138/100000, D Loss: 0.05486611649394035, G Loss: 4.970271587371826\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1139/100000, D Loss: 0.05164509080350399, G Loss: 5.073554992675781\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1140/100000, D Loss: 0.06137988716363907, G Loss: 4.917544364929199\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1141/100000, D Loss: 0.05792287737131119, G Loss: 4.795807838439941\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1142/100000, D Loss: 0.04035148583352566, G Loss: 5.128798007965088\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1143/100000, D Loss: 0.03968615084886551, G Loss: 5.198573112487793\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1144/100000, D Loss: 0.033862920477986336, G Loss: 5.158150672912598\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1145/100000, D Loss: 0.04272734373807907, G Loss: 4.891986846923828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1146/100000, D Loss: 0.036524878814816475, G Loss: 4.830848693847656\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1147/100000, D Loss: 0.050519293174147606, G Loss: 4.670626640319824\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1148/100000, D Loss: 0.05977010726928711, G Loss: 4.418856143951416\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1149/100000, D Loss: 0.05979882925748825, G Loss: 4.40187931060791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1150/100000, D Loss: 0.05909920856356621, G Loss: 4.434388637542725\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1151/100000, D Loss: 0.07950254529714584, G Loss: 4.23209285736084\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1152/100000, D Loss: 0.063504409044981, G Loss: 4.312934875488281\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1153/100000, D Loss: 0.0635173823684454, G Loss: 4.394687652587891\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1154/100000, D Loss: 0.06829961389303207, G Loss: 4.463467597961426\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1155/100000, D Loss: 0.07739247009158134, G Loss: 4.436511993408203\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1156/100000, D Loss: 0.07953821495175362, G Loss: 4.520285606384277\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1157/100000, D Loss: 0.08950329944491386, G Loss: 4.349584579467773\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1158/100000, D Loss: 0.09660470113158226, G Loss: 4.190948486328125\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1159/100000, D Loss: 0.08633999899029732, G Loss: 4.40224027633667\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1160/100000, D Loss: 0.08553387597203255, G Loss: 4.154836654663086\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1161/100000, D Loss: 0.09880487248301506, G Loss: 4.278746128082275\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1162/100000, D Loss: 0.07620231807231903, G Loss: 4.596944332122803\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1163/100000, D Loss: 0.06895158812403679, G Loss: 4.547111511230469\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1164/100000, D Loss: 0.05125562474131584, G Loss: 4.761990547180176\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1165/100000, D Loss: 0.040747812017798424, G Loss: 4.850894927978516\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1166/100000, D Loss: 0.04385385848581791, G Loss: 4.738771438598633\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1167/100000, D Loss: 0.04143961239606142, G Loss: 4.832015037536621\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1168/100000, D Loss: 0.03566531464457512, G Loss: 4.984074115753174\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1169/100000, D Loss: 0.04350427910685539, G Loss: 4.851789474487305\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1170/100000, D Loss: 0.041884053498506546, G Loss: 4.63134765625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1171/100000, D Loss: 0.044434914365410805, G Loss: 4.574769496917725\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1172/100000, D Loss: 0.040019853971898556, G Loss: 4.765962600708008\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1173/100000, D Loss: 0.032569343224167824, G Loss: 5.124906063079834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1174/100000, D Loss: 0.039063461124897, G Loss: 4.992828845977783\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "Epoch 1175/100000, D Loss: 0.03811302408576012, G Loss: 4.737547874450684\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1176/100000, D Loss: 0.04155947268009186, G Loss: 4.864945888519287\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1177/100000, D Loss: 0.03913590591400862, G Loss: 4.907955169677734\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1178/100000, D Loss: 0.06002368405461311, G Loss: 4.813133239746094\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1179/100000, D Loss: 0.06991994008421898, G Loss: 4.528041839599609\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1180/100000, D Loss: 0.07868814840912819, G Loss: 4.568235397338867\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1181/100000, D Loss: 0.08314497023820877, G Loss: 4.609241485595703\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1182/100000, D Loss: 0.07808120548725128, G Loss: 4.397104740142822\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1183/100000, D Loss: 0.07447635382413864, G Loss: 4.497093677520752\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1184/100000, D Loss: 0.07008234411478043, G Loss: 4.435310363769531\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1185/100000, D Loss: 0.07144803181290627, G Loss: 4.389842987060547\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1186/100000, D Loss: 0.06885587237775326, G Loss: 4.459696292877197\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1187/100000, D Loss: 0.06587225943803787, G Loss: 4.367067813873291\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1188/100000, D Loss: 0.0725552886724472, G Loss: 4.265895843505859\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1189/100000, D Loss: 0.07718174904584885, G Loss: 4.134096622467041\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1190/100000, D Loss: 0.06989080272614956, G Loss: 4.1318440437316895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1191/100000, D Loss: 0.07208921760320663, G Loss: 4.228278160095215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1192/100000, D Loss: 0.07167106121778488, G Loss: 4.116408348083496\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1193/100000, D Loss: 0.05145082250237465, G Loss: 4.349151611328125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1194/100000, D Loss: 0.04223538935184479, G Loss: 4.496104717254639\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1195/100000, D Loss: 0.041616976261138916, G Loss: 4.5032548904418945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1196/100000, D Loss: 0.04773128405213356, G Loss: 4.258578300476074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1197/100000, D Loss: 0.049430858343839645, G Loss: 4.022261619567871\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1198/100000, D Loss: 0.043234217911958694, G Loss: 4.1461896896362305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1199/100000, D Loss: 0.03755675628781319, G Loss: 4.2556257247924805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1200/100000, D Loss: 0.04692860506474972, G Loss: 4.127175807952881\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1201/100000, D Loss: 0.044757988303899765, G Loss: 3.9689199924468994\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1202/100000, D Loss: 0.038935475051403046, G Loss: 3.98690128326416\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1203/100000, D Loss: 0.043496206402778625, G Loss: 4.005499839782715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1204/100000, D Loss: 0.036426495760679245, G Loss: 4.110671043395996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1205/100000, D Loss: 0.03433900885283947, G Loss: 4.176560401916504\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "Epoch 1206/100000, D Loss: 0.03289799578487873, G Loss: 4.1376800537109375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1207/100000, D Loss: 0.03745938464999199, G Loss: 3.993285655975342\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1208/100000, D Loss: 0.03943444415926933, G Loss: 3.896907329559326\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1209/100000, D Loss: 0.033211540430784225, G Loss: 4.043937683105469\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1210/100000, D Loss: 0.03510616905987263, G Loss: 4.245493412017822\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1211/100000, D Loss: 0.03585789166390896, G Loss: 4.136134624481201\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1212/100000, D Loss: 0.04045478068292141, G Loss: 3.8996386528015137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1213/100000, D Loss: 0.040265778079628944, G Loss: 3.8969337940216064\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1214/100000, D Loss: 0.03775673359632492, G Loss: 4.1144208908081055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1215/100000, D Loss: 0.035072483122348785, G Loss: 4.237089157104492\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1216/100000, D Loss: 0.04439852386713028, G Loss: 3.852067232131958\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1217/100000, D Loss: 0.04259035736322403, G Loss: 3.7730746269226074\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1218/100000, D Loss: 0.04617260955274105, G Loss: 3.9158730506896973\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1219/100000, D Loss: 0.0496924202889204, G Loss: 3.9714105129241943\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1220/100000, D Loss: 0.04953146353363991, G Loss: 3.8517274856567383\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1221/100000, D Loss: 0.062249962240457535, G Loss: 3.7020938396453857\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1222/100000, D Loss: 0.05618763715028763, G Loss: 3.9358279705047607\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1223/100000, D Loss: 0.06705144792795181, G Loss: 3.903487205505371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1224/100000, D Loss: 0.062173619866371155, G Loss: 3.858994960784912\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1225/100000, D Loss: 0.0710829496383667, G Loss: 3.823955774307251\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1226/100000, D Loss: 0.08420472592115402, G Loss: 3.8096117973327637\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1227/100000, D Loss: 0.07248170301318169, G Loss: 4.003692150115967\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1228/100000, D Loss: 0.10725870728492737, G Loss: 3.7114224433898926\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1229/100000, D Loss: 0.12170009315013885, G Loss: 3.646493673324585\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1230/100000, D Loss: 0.13106951862573624, G Loss: 3.9587457180023193\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1231/100000, D Loss: 0.1434495449066162, G Loss: 3.7173333168029785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1232/100000, D Loss: 0.13770107924938202, G Loss: 3.829129219055176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1233/100000, D Loss: 0.12114381045103073, G Loss: 4.0747971534729\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1234/100000, D Loss: 0.13378597795963287, G Loss: 4.171065330505371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1235/100000, D Loss: 0.09514398872852325, G Loss: 4.416731834411621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1236/100000, D Loss: 0.09598497673869133, G Loss: 4.230007171630859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1237/100000, D Loss: 0.10111103951931, G Loss: 4.059081077575684\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1238/100000, D Loss: 0.06275667808949947, G Loss: 4.50421142578125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1239/100000, D Loss: 0.06969753466546535, G Loss: 4.240703582763672\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1240/100000, D Loss: 0.05181913450360298, G Loss: 3.9875741004943848\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1241/100000, D Loss: 0.035897061228752136, G Loss: 4.315059661865234\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1242/100000, D Loss: 0.021664065308868885, G Loss: 4.858026504516602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1243/100000, D Loss: 0.021555514074862003, G Loss: 5.11363410949707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1244/100000, D Loss: 0.02121178526431322, G Loss: 5.09495735168457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1245/100000, D Loss: 0.019842205569148064, G Loss: 4.858704090118408\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1246/100000, D Loss: 0.017428331542760134, G Loss: 4.74137544631958\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1247/100000, D Loss: 0.01855597598478198, G Loss: 4.713252067565918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1248/100000, D Loss: 0.018947190139442682, G Loss: 4.769113540649414\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1249/100000, D Loss: 0.025914263911545277, G Loss: 4.786319732666016\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1250/100000, D Loss: 0.026461435481905937, G Loss: 4.870218276977539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1251/100000, D Loss: 0.03550359793007374, G Loss: 4.687119960784912\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1252/100000, D Loss: 0.045889392495155334, G Loss: 4.630958080291748\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1253/100000, D Loss: 0.057293059304356575, G Loss: 4.849878787994385\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1254/100000, D Loss: 0.06296145543456078, G Loss: 4.992243766784668\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "Epoch 1255/100000, D Loss: 0.093559630215168, G Loss: 4.773396015167236\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1256/100000, D Loss: 0.102117158472538, G Loss: 4.71763277053833\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1257/100000, D Loss: 0.12622172385454178, G Loss: 4.711234092712402\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1258/100000, D Loss: 0.1306276023387909, G Loss: 5.081242084503174\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1259/100000, D Loss: 0.1260920837521553, G Loss: 5.034698963165283\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1260/100000, D Loss: 0.14041567593812943, G Loss: 5.0165557861328125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1261/100000, D Loss: 0.1353679932653904, G Loss: 4.886630535125732\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1262/100000, D Loss: 0.1600629687309265, G Loss: 4.714471340179443\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1263/100000, D Loss: 0.1778760701417923, G Loss: 4.875205993652344\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1264/100000, D Loss: 0.13040227442979813, G Loss: 4.912088394165039\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1265/100000, D Loss: 0.09834783524274826, G Loss: 4.671176910400391\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1266/100000, D Loss: 0.10994071140885353, G Loss: 4.145907402038574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1267/100000, D Loss: 0.08121152967214584, G Loss: 4.083022594451904\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1268/100000, D Loss: 0.07514839619398117, G Loss: 4.239492416381836\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1269/100000, D Loss: 0.0682857371866703, G Loss: 4.250086307525635\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1270/100000, D Loss: 0.07207104563713074, G Loss: 3.9115991592407227\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1271/100000, D Loss: 0.07265298813581467, G Loss: 3.8911614418029785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1272/100000, D Loss: 0.06792106665670872, G Loss: 4.279712677001953\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1273/100000, D Loss: 0.06942719593644142, G Loss: 4.262127876281738\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1274/100000, D Loss: 0.06291703134775162, G Loss: 4.226473808288574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1275/100000, D Loss: 0.0541994571685791, G Loss: 4.463534355163574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1276/100000, D Loss: 0.05349143221974373, G Loss: 4.393590927124023\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1277/100000, D Loss: 0.06752343103289604, G Loss: 4.309003829956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1278/100000, D Loss: 0.06301500648260117, G Loss: 4.398968696594238\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1279/100000, D Loss: 0.06486114300787449, G Loss: 4.6765899658203125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1280/100000, D Loss: 0.08465380221605301, G Loss: 4.396157264709473\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1281/100000, D Loss: 0.07729808986186981, G Loss: 4.400575160980225\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1282/100000, D Loss: 0.07549864053726196, G Loss: 4.410287380218506\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1283/100000, D Loss: 0.06849759072065353, G Loss: 4.502405643463135\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1284/100000, D Loss: 0.07427854835987091, G Loss: 4.504809379577637\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1285/100000, D Loss: 0.06536590680480003, G Loss: 4.517199993133545\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1286/100000, D Loss: 0.06530085019767284, G Loss: 4.664910316467285\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1287/100000, D Loss: 0.06910185888409615, G Loss: 4.693840026855469\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1288/100000, D Loss: 0.052265772596001625, G Loss: 4.624032020568848\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1289/100000, D Loss: 0.056735411286354065, G Loss: 4.572470188140869\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1290/100000, D Loss: 0.05809330381453037, G Loss: 4.5669779777526855\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1291/100000, D Loss: 0.06848357617855072, G Loss: 4.427900314331055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1292/100000, D Loss: 0.05587448552250862, G Loss: 4.356879234313965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1293/100000, D Loss: 0.08358781412243843, G Loss: 4.013156890869141\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1294/100000, D Loss: 0.08448277413845062, G Loss: 4.054886817932129\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1295/100000, D Loss: 0.1034848541021347, G Loss: 4.03875732421875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1296/100000, D Loss: 0.1236179955303669, G Loss: 3.811215400695801\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1297/100000, D Loss: 0.12653274834156036, G Loss: 4.04339599609375\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1298/100000, D Loss: 0.1527048870921135, G Loss: 3.8354883193969727\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1299/100000, D Loss: 0.17803554981946945, G Loss: 3.8921713829040527\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1300/100000, D Loss: 0.12834317237138748, G Loss: 4.2582292556762695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1301/100000, D Loss: 0.10087773948907852, G Loss: 4.39092493057251\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1302/100000, D Loss: 0.09299023076891899, G Loss: 4.352740287780762\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1303/100000, D Loss: 0.06395257636904716, G Loss: 4.760786056518555\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1304/100000, D Loss: 0.04510979354381561, G Loss: 5.084807395935059\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1305/100000, D Loss: 0.04897519573569298, G Loss: 4.887642860412598\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1306/100000, D Loss: 0.04526778310537338, G Loss: 4.555624961853027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1307/100000, D Loss: 0.05264150910079479, G Loss: 4.538209915161133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1308/100000, D Loss: 0.05790093541145325, G Loss: 4.677375793457031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1309/100000, D Loss: 0.06453119590878487, G Loss: 4.405060768127441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1310/100000, D Loss: 0.06558361649513245, G Loss: 4.283538818359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1311/100000, D Loss: 0.07303135842084885, G Loss: 4.291370391845703\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1312/100000, D Loss: 0.10629782825708389, G Loss: 4.0277509689331055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1313/100000, D Loss: 0.16847778856754303, G Loss: 3.8133883476257324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1314/100000, D Loss: 0.1287112645804882, G Loss: 3.904571771621704\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1315/100000, D Loss: 0.2556415870785713, G Loss: 3.395740032196045\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1316/100000, D Loss: 0.12531215697526932, G Loss: 4.076306343078613\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1317/100000, D Loss: 0.1565481461584568, G Loss: 3.491140365600586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1318/100000, D Loss: 0.14170947298407555, G Loss: 3.770156145095825\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1319/100000, D Loss: 0.12705832719802856, G Loss: 3.8736798763275146\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1320/100000, D Loss: 0.16464149206876755, G Loss: 3.4963836669921875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1321/100000, D Loss: 0.17914170026779175, G Loss: 3.848954916000366\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1322/100000, D Loss: 0.20920789241790771, G Loss: 3.6946256160736084\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1323/100000, D Loss: 0.1723959743976593, G Loss: 3.643761157989502\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1324/100000, D Loss: 0.14721285551786423, G Loss: 3.8126399517059326\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1325/100000, D Loss: 0.10469997674226761, G Loss: 4.060311794281006\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1326/100000, D Loss: 0.07971407473087311, G Loss: 4.037139892578125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1327/100000, D Loss: 0.09395808726549149, G Loss: 3.806459903717041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1328/100000, D Loss: 0.10098254308104515, G Loss: 3.891385078430176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1329/100000, D Loss: 0.08253126963973045, G Loss: 4.164793014526367\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1330/100000, D Loss: 0.09953705966472626, G Loss: 3.8694119453430176\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1331/100000, D Loss: 0.09693866968154907, G Loss: 3.7905027866363525\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1332/100000, D Loss: 0.08696369454264641, G Loss: 4.323879241943359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1333/100000, D Loss: 0.0917055681347847, G Loss: 4.260333061218262\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1334/100000, D Loss: 0.09404045343399048, G Loss: 4.081674575805664\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1335/100000, D Loss: 0.09827003628015518, G Loss: 4.0062456130981445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1336/100000, D Loss: 0.07696513459086418, G Loss: 4.311256408691406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1337/100000, D Loss: 0.0846543200314045, G Loss: 4.245044708251953\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1338/100000, D Loss: 0.09154746681451797, G Loss: 4.108316898345947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1339/100000, D Loss: 0.0787474550306797, G Loss: 4.202443599700928\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1340/100000, D Loss: 0.09103715792298317, G Loss: 4.268941879272461\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1341/100000, D Loss: 0.08434190601110458, G Loss: 4.227639675140381\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1342/100000, D Loss: 0.09732085466384888, G Loss: 4.051412582397461\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1343/100000, D Loss: 0.0880810096859932, G Loss: 4.085911273956299\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1344/100000, D Loss: 0.08652685582637787, G Loss: 4.155758857727051\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1345/100000, D Loss: 0.07122275978326797, G Loss: 4.297740936279297\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1346/100000, D Loss: 0.07526659965515137, G Loss: 4.182535171508789\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1347/100000, D Loss: 0.07328303158283234, G Loss: 4.095050811767578\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1348/100000, D Loss: 0.06791744381189346, G Loss: 4.226724624633789\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1349/100000, D Loss: 0.08416067436337471, G Loss: 4.128818511962891\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1350/100000, D Loss: 0.0786137767136097, G Loss: 4.108884334564209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1351/100000, D Loss: 0.07824932411313057, G Loss: 4.116507053375244\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 1352/100000, D Loss: 0.0826309360563755, G Loss: 3.9681644439697266\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1353/100000, D Loss: 0.07645563781261444, G Loss: 4.2259521484375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1354/100000, D Loss: 0.06623106822371483, G Loss: 4.452642917633057\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1355/100000, D Loss: 0.0728662870824337, G Loss: 4.289409637451172\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1356/100000, D Loss: 0.07353626564145088, G Loss: 4.0474677085876465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1357/100000, D Loss: 0.0669631864875555, G Loss: 4.138177871704102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1358/100000, D Loss: 0.06488240137696266, G Loss: 4.468778610229492\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1359/100000, D Loss: 0.06058785133063793, G Loss: 4.479855060577393\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1360/100000, D Loss: 0.07552191242575645, G Loss: 4.183310508728027\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1361/100000, D Loss: 0.09011185169219971, G Loss: 4.061171054840088\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1362/100000, D Loss: 0.09888451173901558, G Loss: 4.3657050132751465\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1363/100000, D Loss: 0.1081676036119461, G Loss: 4.656847953796387\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1364/100000, D Loss: 0.09249616414308548, G Loss: 4.837809085845947\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1365/100000, D Loss: 0.12918464094400406, G Loss: 4.828001022338867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1366/100000, D Loss: 0.13788411021232605, G Loss: 5.292783737182617\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1367/100000, D Loss: 0.09762733429670334, G Loss: 5.966073989868164\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1368/100000, D Loss: 0.11122068017721176, G Loss: 6.100648403167725\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1369/100000, D Loss: 0.14309865608811378, G Loss: 5.78109073638916\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1370/100000, D Loss: 0.15520190447568893, G Loss: 5.5542426109313965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1371/100000, D Loss: 0.15759828686714172, G Loss: 5.850174903869629\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1372/100000, D Loss: 0.16437650471925735, G Loss: 6.080758094787598\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1373/100000, D Loss: 0.1379784494638443, G Loss: 5.85875129699707\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1374/100000, D Loss: 0.10003619268536568, G Loss: 5.852689743041992\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1375/100000, D Loss: 0.041752773337066174, G Loss: 6.494838237762451\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1376/100000, D Loss: 0.021487006917595863, G Loss: 6.909085273742676\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1377/100000, D Loss: 0.018533937633037567, G Loss: 6.74513053894043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1378/100000, D Loss: 0.021385847590863705, G Loss: 6.331304550170898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1379/100000, D Loss: 0.011418251786381006, G Loss: 5.897489547729492\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1380/100000, D Loss: 0.014872955158352852, G Loss: 5.873040676116943\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1381/100000, D Loss: 0.017240368761122227, G Loss: 6.12455940246582\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1382/100000, D Loss: 0.016688239760696888, G Loss: 6.215653896331787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1383/100000, D Loss: 0.017381762620061636, G Loss: 6.472066402435303\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1384/100000, D Loss: 0.022467310540378094, G Loss: 6.236454963684082\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1385/100000, D Loss: 0.023346800357103348, G Loss: 5.786828994750977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1386/100000, D Loss: 0.03045899048447609, G Loss: 5.60420036315918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1387/100000, D Loss: 0.030887932516634464, G Loss: 5.3983306884765625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1388/100000, D Loss: 0.03458985686302185, G Loss: 5.382840633392334\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1389/100000, D Loss: 0.028389262966811657, G Loss: 5.471702575683594\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1390/100000, D Loss: 0.02777164988219738, G Loss: 5.524856090545654\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1391/100000, D Loss: 0.029994193464517593, G Loss: 5.6041259765625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1392/100000, D Loss: 0.023392528295516968, G Loss: 5.6589155197143555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1393/100000, D Loss: 0.0305938720703125, G Loss: 5.679156303405762\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1394/100000, D Loss: 0.030627600848674774, G Loss: 5.640940189361572\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1395/100000, D Loss: 0.03170269541442394, G Loss: 5.526776313781738\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1396/100000, D Loss: 0.026431789621710777, G Loss: 5.540544033050537\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1397/100000, D Loss: 0.02948572486639023, G Loss: 5.509726524353027\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1398/100000, D Loss: 0.03719417005777359, G Loss: 5.11254358291626\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1399/100000, D Loss: 0.031400291249156, G Loss: 5.228557586669922\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1400/100000, D Loss: 0.029278629459440708, G Loss: 5.434955596923828\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1401/100000, D Loss: 0.031056074425578117, G Loss: 5.488958835601807\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1402/100000, D Loss: 0.044105589389801025, G Loss: 5.134575843811035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1403/100000, D Loss: 0.06062045320868492, G Loss: 5.083979606628418\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1404/100000, D Loss: 0.05443451553583145, G Loss: 5.332760334014893\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1405/100000, D Loss: 0.061187898740172386, G Loss: 5.3998026847839355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1406/100000, D Loss: 0.08098244294524193, G Loss: 5.128396034240723\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1407/100000, D Loss: 0.08473066799342632, G Loss: 5.3400421142578125\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1408/100000, D Loss: 0.10502488538622856, G Loss: 5.5505475997924805\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1409/100000, D Loss: 0.11777480691671371, G Loss: 5.437572956085205\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1410/100000, D Loss: 0.13057148456573486, G Loss: 5.351851463317871\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1411/100000, D Loss: 0.14385339617729187, G Loss: 5.305069923400879\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1412/100000, D Loss: 0.09563262015581131, G Loss: 5.852869033813477\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1413/100000, D Loss: 0.07608318701386452, G Loss: 6.165940284729004\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1414/100000, D Loss: 0.07124359160661697, G Loss: 6.074677467346191\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1415/100000, D Loss: 0.06777996569871902, G Loss: 6.19853401184082\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1416/100000, D Loss: 0.033418781124055386, G Loss: 6.56430721282959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1417/100000, D Loss: 0.04109523072838783, G Loss: 6.426455020904541\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1418/100000, D Loss: 0.024763084016740322, G Loss: 6.32564640045166\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1419/100000, D Loss: 0.03570237196981907, G Loss: 5.876397132873535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1420/100000, D Loss: 0.038021575659513474, G Loss: 5.9391069412231445\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1421/100000, D Loss: 0.03783850185573101, G Loss: 6.10306453704834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1422/100000, D Loss: 0.0313027948141098, G Loss: 5.9955644607543945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1423/100000, D Loss: 0.030579756014049053, G Loss: 5.695476055145264\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1424/100000, D Loss: 0.04293828457593918, G Loss: 5.451868057250977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1425/100000, D Loss: 0.03596651554107666, G Loss: 5.562337398529053\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1426/100000, D Loss: 0.034423623234033585, G Loss: 5.807474136352539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1427/100000, D Loss: 0.03923318348824978, G Loss: 5.710418701171875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1428/100000, D Loss: 0.03885963559150696, G Loss: 5.573144435882568\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1429/100000, D Loss: 0.04132457636296749, G Loss: 5.345170974731445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1430/100000, D Loss: 0.03128078021109104, G Loss: 5.778372764587402\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1431/100000, D Loss: 0.038903988897800446, G Loss: 5.688589096069336\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1432/100000, D Loss: 0.041954994201660156, G Loss: 5.630691051483154\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1433/100000, D Loss: 0.03693778067827225, G Loss: 5.485419273376465\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1434/100000, D Loss: 0.027554974891245365, G Loss: 5.438840389251709\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1435/100000, D Loss: 0.02420296985656023, G Loss: 5.650811195373535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1436/100000, D Loss: 0.0283176489174366, G Loss: 5.602761268615723\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1437/100000, D Loss: 0.028517614118754864, G Loss: 5.450798034667969\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1438/100000, D Loss: 0.03257713280618191, G Loss: 5.219537734985352\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1439/100000, D Loss: 0.04271266050636768, G Loss: 5.094956874847412\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1440/100000, D Loss: 0.04036966152489185, G Loss: 5.171764850616455\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1441/100000, D Loss: 0.04946817643940449, G Loss: 5.1822099685668945\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1442/100000, D Loss: 0.049504199996590614, G Loss: 5.102151870727539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1443/100000, D Loss: 0.055630333721637726, G Loss: 5.09730863571167\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1444/100000, D Loss: 0.07930999621748924, G Loss: 4.642322540283203\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1445/100000, D Loss: 0.0733952596783638, G Loss: 4.900940418243408\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1446/100000, D Loss: 0.07563039660453796, G Loss: 4.848683834075928\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1447/100000, D Loss: 0.08335253968834877, G Loss: 4.6279778480529785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1448/100000, D Loss: 0.06875945627689362, G Loss: 4.546787261962891\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1449/100000, D Loss: 0.06618239171802998, G Loss: 4.6961259841918945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1450/100000, D Loss: 0.07979395240545273, G Loss: 4.627549171447754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1451/100000, D Loss: 0.08839604631066322, G Loss: 4.449920177459717\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1452/100000, D Loss: 0.07487627491354942, G Loss: 4.7978949546813965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1453/100000, D Loss: 0.10436675697565079, G Loss: 4.445255756378174\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1454/100000, D Loss: 0.12239331007003784, G Loss: 4.252199172973633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1455/100000, D Loss: 0.11434076726436615, G Loss: 4.51326322555542\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1456/100000, D Loss: 0.16531451046466827, G Loss: 4.242021560668945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1457/100000, D Loss: 0.14815960079431534, G Loss: 4.345739364624023\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1458/100000, D Loss: 0.19310205429792404, G Loss: 4.332669258117676\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1459/100000, D Loss: 0.19287099689245224, G Loss: 4.347845077514648\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1460/100000, D Loss: 0.2151867374777794, G Loss: 4.261874198913574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1461/100000, D Loss: 0.25006040930747986, G Loss: 4.4059672355651855\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1462/100000, D Loss: 0.2652396485209465, G Loss: 4.307077884674072\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1463/100000, D Loss: 0.19553978741168976, G Loss: 4.486504077911377\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1464/100000, D Loss: 0.272283211350441, G Loss: 4.565067291259766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1465/100000, D Loss: 0.2159530520439148, G Loss: 4.762069225311279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1466/100000, D Loss: 0.1736205816268921, G Loss: 4.981612682342529\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1467/100000, D Loss: 0.10891689732670784, G Loss: 5.060668468475342\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1468/100000, D Loss: 0.11497924849390984, G Loss: 4.704078674316406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1469/100000, D Loss: 0.111786387860775, G Loss: 4.563191890716553\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1470/100000, D Loss: 0.08871638402342796, G Loss: 4.770728588104248\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1471/100000, D Loss: 0.11302665621042252, G Loss: 4.423862457275391\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1472/100000, D Loss: 0.11221316456794739, G Loss: 4.211296558380127\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1473/100000, D Loss: 0.09851081296801567, G Loss: 4.515655517578125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1474/100000, D Loss: 0.09880131855607033, G Loss: 4.201593399047852\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1475/100000, D Loss: 0.11600672826170921, G Loss: 3.8921289443969727\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1476/100000, D Loss: 0.09867449104785919, G Loss: 3.9872469902038574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1477/100000, D Loss: 0.10000180825591087, G Loss: 3.970426559448242\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1478/100000, D Loss: 0.09098208695650101, G Loss: 4.025351047515869\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1479/100000, D Loss: 0.10334478318691254, G Loss: 3.8456084728240967\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1480/100000, D Loss: 0.09764793142676353, G Loss: 3.981717824935913\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1481/100000, D Loss: 0.06355289742350578, G Loss: 4.295340538024902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1482/100000, D Loss: 0.08059450052678585, G Loss: 4.011425495147705\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1483/100000, D Loss: 0.0862182006239891, G Loss: 3.828979730606079\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1484/100000, D Loss: 0.0654042512178421, G Loss: 4.130804538726807\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1485/100000, D Loss: 0.09180436283349991, G Loss: 3.8373172283172607\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1486/100000, D Loss: 0.11114837229251862, G Loss: 3.722499370574951\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1487/100000, D Loss: 0.11420319601893425, G Loss: 3.716144323348999\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1488/100000, D Loss: 0.09381595253944397, G Loss: 3.84981107711792\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1489/100000, D Loss: 0.12615946307778358, G Loss: 3.618847370147705\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1490/100000, D Loss: 0.11461767926812172, G Loss: 3.685206413269043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1491/100000, D Loss: 0.10376694053411484, G Loss: 3.713449001312256\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1492/100000, D Loss: 0.11045839637517929, G Loss: 3.6091065406799316\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1493/100000, D Loss: 0.06785212084650993, G Loss: 3.879887580871582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1494/100000, D Loss: 0.05479912646114826, G Loss: 4.112842082977295\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1495/100000, D Loss: 0.0464294720441103, G Loss: 4.1729326248168945\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1496/100000, D Loss: 0.029284567572176456, G Loss: 4.39731502532959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1497/100000, D Loss: 0.03346987161785364, G Loss: 4.453104496002197\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1498/100000, D Loss: 0.026577336713671684, G Loss: 4.55778694152832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1499/100000, D Loss: 0.02751130610704422, G Loss: 4.448041915893555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1500/100000, D Loss: 0.02871294505894184, G Loss: 4.36053466796875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1501/100000, D Loss: 0.026774165220558643, G Loss: 4.384378433227539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1502/100000, D Loss: 0.023385613225400448, G Loss: 4.555318355560303\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1503/100000, D Loss: 0.026332772336900234, G Loss: 4.549531936645508\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1504/100000, D Loss: 0.03552611917257309, G Loss: 4.272377014160156\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1505/100000, D Loss: 0.0343896709382534, G Loss: 4.111787796020508\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1506/100000, D Loss: 0.041385287418961525, G Loss: 4.008923053741455\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1507/100000, D Loss: 0.04985824041068554, G Loss: 4.062144756317139\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1508/100000, D Loss: 0.04810184985399246, G Loss: 4.217005729675293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1509/100000, D Loss: 0.05863219499588013, G Loss: 3.9988226890563965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1510/100000, D Loss: 0.06688801199197769, G Loss: 3.871392250061035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1511/100000, D Loss: 0.07299036532640457, G Loss: 3.856210231781006\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1512/100000, D Loss: 0.07249567657709122, G Loss: 4.035347938537598\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1513/100000, D Loss: 0.06182866171002388, G Loss: 4.109300136566162\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1514/100000, D Loss: 0.07764457538723946, G Loss: 3.9124903678894043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1515/100000, D Loss: 0.08448396623134613, G Loss: 3.8114266395568848\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1516/100000, D Loss: 0.07337172329425812, G Loss: 3.9262185096740723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1517/100000, D Loss: 0.0803180430084467, G Loss: 3.965806007385254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1518/100000, D Loss: 0.074019655585289, G Loss: 4.022295951843262\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1519/100000, D Loss: 0.0807405486702919, G Loss: 3.9719631671905518\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1520/100000, D Loss: 0.07279887422919273, G Loss: 4.1417131423950195\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1521/100000, D Loss: 0.08806147426366806, G Loss: 4.006213665008545\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1522/100000, D Loss: 0.08707326650619507, G Loss: 3.905768394470215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1523/100000, D Loss: 0.08947718143463135, G Loss: 4.045461654663086\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1524/100000, D Loss: 0.0994737558066845, G Loss: 3.9901084899902344\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1525/100000, D Loss: 0.13563716039061546, G Loss: 3.5612432956695557\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1526/100000, D Loss: 0.12420311942696571, G Loss: 4.098341464996338\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1527/100000, D Loss: 0.10638883709907532, G Loss: 4.242236137390137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1528/100000, D Loss: 0.13104944676160812, G Loss: 3.5805134773254395\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1529/100000, D Loss: 0.15771722793579102, G Loss: 3.6745450496673584\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1530/100000, D Loss: 0.11400463804602623, G Loss: 4.192831993103027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1531/100000, D Loss: 0.14181965216994286, G Loss: 3.712920665740967\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1532/100000, D Loss: 0.13227719068527222, G Loss: 3.640056610107422\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1533/100000, D Loss: 0.11006619781255722, G Loss: 3.9828081130981445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1534/100000, D Loss: 0.10805760696530342, G Loss: 3.921823740005493\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1535/100000, D Loss: 0.10228652507066727, G Loss: 3.719583749771118\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1536/100000, D Loss: 0.10532275587320328, G Loss: 3.8689403533935547\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1537/100000, D Loss: 0.10468724370002747, G Loss: 3.773613929748535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1538/100000, D Loss: 0.1028851605951786, G Loss: 3.708092451095581\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1539/100000, D Loss: 0.11330602318048477, G Loss: 3.7905778884887695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1540/100000, D Loss: 0.09248754009604454, G Loss: 4.11981201171875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1541/100000, D Loss: 0.0827479287981987, G Loss: 4.166892051696777\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1542/100000, D Loss: 0.10412178933620453, G Loss: 3.823533058166504\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1543/100000, D Loss: 0.10561053827404976, G Loss: 3.8837716579437256\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1544/100000, D Loss: 0.08387249708175659, G Loss: 4.1513590812683105\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1545/100000, D Loss: 0.09655525162816048, G Loss: 3.9147238731384277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1546/100000, D Loss: 0.08894020318984985, G Loss: 3.9364285469055176\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1547/100000, D Loss: 0.10186760500073433, G Loss: 4.038845062255859\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1548/100000, D Loss: 0.1075226292014122, G Loss: 3.9291505813598633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1549/100000, D Loss: 0.12053586542606354, G Loss: 3.8644466400146484\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1550/100000, D Loss: 0.08142436668276787, G Loss: 4.381880760192871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1551/100000, D Loss: 0.0980838481336832, G Loss: 4.231672763824463\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1552/100000, D Loss: 0.13083939999341965, G Loss: 3.872748374938965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1553/100000, D Loss: 0.10167522728443146, G Loss: 4.316800594329834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1554/100000, D Loss: 0.10678835958242416, G Loss: 4.62528657913208\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1555/100000, D Loss: 0.07684098184108734, G Loss: 4.840516090393066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1556/100000, D Loss: 0.06642449274659157, G Loss: 4.872533798217773\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1557/100000, D Loss: 0.04551284946501255, G Loss: 5.087367057800293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1558/100000, D Loss: 0.04209967702627182, G Loss: 5.4127326011657715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1559/100000, D Loss: 0.03883734717965126, G Loss: 5.843068599700928\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1560/100000, D Loss: 0.03481147065758705, G Loss: 6.135031700134277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1561/100000, D Loss: 0.034918658435344696, G Loss: 6.5326666831970215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1562/100000, D Loss: 0.04040258750319481, G Loss: 6.775737285614014\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1563/100000, D Loss: 0.0390798794105649, G Loss: 6.962607383728027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1564/100000, D Loss: 0.04314288683235645, G Loss: 7.07103157043457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1565/100000, D Loss: 0.05571388825774193, G Loss: 7.015722751617432\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1566/100000, D Loss: 0.056193768978118896, G Loss: 6.910861015319824\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1567/100000, D Loss: 0.06346867978572845, G Loss: 6.686964511871338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1568/100000, D Loss: 0.0711230169981718, G Loss: 6.685338020324707\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1569/100000, D Loss: 0.048933301120996475, G Loss: 6.952263832092285\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1570/100000, D Loss: 0.05557011999189854, G Loss: 6.8875555992126465\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1571/100000, D Loss: 0.060282059013843536, G Loss: 6.459094524383545\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1572/100000, D Loss: 0.05335581116378307, G Loss: 6.625089645385742\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1573/100000, D Loss: 0.0551141481846571, G Loss: 6.910550594329834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1574/100000, D Loss: 0.03328455798327923, G Loss: 7.324889183044434\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1575/100000, D Loss: 0.04609536938369274, G Loss: 7.337760925292969\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1576/100000, D Loss: 0.03241734579205513, G Loss: 7.477724075317383\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1577/100000, D Loss: 0.046228935942053795, G Loss: 7.390576362609863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1578/100000, D Loss: 0.047365257516503334, G Loss: 7.387965202331543\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1579/100000, D Loss: 0.044265203177928925, G Loss: 7.122827053070068\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1580/100000, D Loss: 0.06193356867879629, G Loss: 7.640035629272461\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1581/100000, D Loss: 0.05930267460644245, G Loss: 7.850430488586426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1582/100000, D Loss: 0.07259216159582138, G Loss: 7.53958797454834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1583/100000, D Loss: 0.09247587621212006, G Loss: 7.02376127243042\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1584/100000, D Loss: 0.07526665925979614, G Loss: 6.851614952087402\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1585/100000, D Loss: 0.06664588674902916, G Loss: 6.871860504150391\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1586/100000, D Loss: 0.059422122314572334, G Loss: 6.733447551727295\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1587/100000, D Loss: 0.05344754084944725, G Loss: 6.504086017608643\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1588/100000, D Loss: 0.051211344078183174, G Loss: 5.97723388671875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1589/100000, D Loss: 0.04290871508419514, G Loss: 5.764648914337158\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1590/100000, D Loss: 0.032202497124671936, G Loss: 5.719316005706787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1591/100000, D Loss: 0.03649824485182762, G Loss: 5.830684185028076\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1592/100000, D Loss: 0.034968119114637375, G Loss: 5.817981719970703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1593/100000, D Loss: 0.04022686183452606, G Loss: 5.880728721618652\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1594/100000, D Loss: 0.04570226930081844, G Loss: 5.853699684143066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1595/100000, D Loss: 0.05504387430846691, G Loss: 5.784074783325195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1596/100000, D Loss: 0.0596629548817873, G Loss: 5.985523223876953\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1597/100000, D Loss: 0.0485179778188467, G Loss: 6.032550811767578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1598/100000, D Loss: 0.06757399812340736, G Loss: 5.762732028961182\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1599/100000, D Loss: 0.07757247239351273, G Loss: 5.722461700439453\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1600/100000, D Loss: 0.06415248289704323, G Loss: 6.102398872375488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1601/100000, D Loss: 0.05869263783097267, G Loss: 6.318955421447754\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1602/100000, D Loss: 0.0664875116199255, G Loss: 6.308121204376221\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1603/100000, D Loss: 0.05073757469654083, G Loss: 6.0754923820495605\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1604/100000, D Loss: 0.04626348055899143, G Loss: 5.9850239753723145\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1605/100000, D Loss: 0.03297311533242464, G Loss: 5.833785533905029\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1606/100000, D Loss: 0.025884083472192287, G Loss: 6.18055534362793\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1607/100000, D Loss: 0.02324967458844185, G Loss: 6.234771728515625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1608/100000, D Loss: 0.02686136495321989, G Loss: 6.186315536499023\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1609/100000, D Loss: 0.020606637001037598, G Loss: 6.033596038818359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1610/100000, D Loss: 0.022597898729145527, G Loss: 5.904443740844727\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1611/100000, D Loss: 0.023831771686673164, G Loss: 5.774702548980713\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1612/100000, D Loss: 0.02345400210469961, G Loss: 5.7067036628723145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1613/100000, D Loss: 0.026907953433692455, G Loss: 5.871796607971191\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1614/100000, D Loss: 0.030101905576884747, G Loss: 5.516007423400879\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1615/100000, D Loss: 0.02915255632251501, G Loss: 5.462148189544678\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1616/100000, D Loss: 0.029966440051794052, G Loss: 5.228166580200195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1617/100000, D Loss: 0.03381439112126827, G Loss: 4.996016979217529\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1618/100000, D Loss: 0.03035042993724346, G Loss: 5.016079902648926\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1619/100000, D Loss: 0.043317558243870735, G Loss: 4.8037285804748535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1620/100000, D Loss: 0.03935885429382324, G Loss: 4.645773887634277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1621/100000, D Loss: 0.04016139917075634, G Loss: 4.831842422485352\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1622/100000, D Loss: 0.04256703704595566, G Loss: 4.682422637939453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1623/100000, D Loss: 0.034885549917817116, G Loss: 4.936811447143555\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1624/100000, D Loss: 0.033096328377723694, G Loss: 5.062845706939697\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1625/100000, D Loss: 0.030047165229916573, G Loss: 5.068253993988037\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1626/100000, D Loss: 0.026250495575368404, G Loss: 5.095791339874268\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1627/100000, D Loss: 0.02710042055696249, G Loss: 5.144403457641602\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1628/100000, D Loss: 0.024605752900242805, G Loss: 5.133639335632324\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1629/100000, D Loss: 0.02542853821069002, G Loss: 5.0652360916137695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1630/100000, D Loss: 0.029317409731447697, G Loss: 4.979920387268066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1631/100000, D Loss: 0.028461618348956108, G Loss: 5.007424831390381\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1632/100000, D Loss: 0.025023743510246277, G Loss: 5.094283580780029\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1633/100000, D Loss: 0.023084450513124466, G Loss: 5.0689568519592285\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1634/100000, D Loss: 0.02010983694344759, G Loss: 5.101001262664795\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1635/100000, D Loss: 0.024788073264062405, G Loss: 4.853058815002441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1636/100000, D Loss: 0.023819747380912304, G Loss: 4.735642433166504\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1637/100000, D Loss: 0.02345423214137554, G Loss: 4.764250755310059\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1638/100000, D Loss: 0.02897535916417837, G Loss: 4.758670806884766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1639/100000, D Loss: 0.025310532189905643, G Loss: 4.781950950622559\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1640/100000, D Loss: 0.02688670065253973, G Loss: 4.755420684814453\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1641/100000, D Loss: 0.030986664816737175, G Loss: 4.673646926879883\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1642/100000, D Loss: 0.04252133518457413, G Loss: 4.47482442855835\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1643/100000, D Loss: 0.043759219348430634, G Loss: 4.439230442047119\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1644/100000, D Loss: 0.0403414499014616, G Loss: 4.490298271179199\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1645/100000, D Loss: 0.04493978060781956, G Loss: 4.686146259307861\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1646/100000, D Loss: 0.042672695592045784, G Loss: 4.656565189361572\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1647/100000, D Loss: 0.044015903025865555, G Loss: 4.555953025817871\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1648/100000, D Loss: 0.04002438858151436, G Loss: 4.60774564743042\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1649/100000, D Loss: 0.04363498277962208, G Loss: 4.616872787475586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1650/100000, D Loss: 0.039879085496068, G Loss: 4.880409240722656\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1651/100000, D Loss: 0.04137507639825344, G Loss: 4.992156982421875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1652/100000, D Loss: 0.04815903306007385, G Loss: 4.578656196594238\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1653/100000, D Loss: 0.043042318895459175, G Loss: 4.487078666687012\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1654/100000, D Loss: 0.03937802277505398, G Loss: 4.872278213500977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1655/100000, D Loss: 0.03238280117511749, G Loss: 5.233455657958984\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1656/100000, D Loss: 0.052225276827812195, G Loss: 4.87841272354126\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1657/100000, D Loss: 0.04146326705813408, G Loss: 4.502656936645508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1658/100000, D Loss: 0.034786781296133995, G Loss: 4.974884510040283\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1659/100000, D Loss: 0.033252108842134476, G Loss: 5.363550186157227\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1660/100000, D Loss: 0.03846297040581703, G Loss: 5.247097969055176\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1661/100000, D Loss: 0.03316344507038593, G Loss: 5.132073879241943\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1662/100000, D Loss: 0.03652051091194153, G Loss: 5.0646820068359375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1663/100000, D Loss: 0.040303910151124, G Loss: 5.022582054138184\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1664/100000, D Loss: 0.034631320275366306, G Loss: 5.171814918518066\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1665/100000, D Loss: 0.04085717536509037, G Loss: 5.277961730957031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1666/100000, D Loss: 0.04340701550245285, G Loss: 4.973482131958008\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1667/100000, D Loss: 0.045580869540572166, G Loss: 4.9344892501831055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1668/100000, D Loss: 0.05345338396728039, G Loss: 4.886899948120117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1669/100000, D Loss: 0.05461830087006092, G Loss: 4.847247123718262\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1670/100000, D Loss: 0.07621507719159126, G Loss: 4.66087532043457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1671/100000, D Loss: 0.09485360234975815, G Loss: 4.654910087585449\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1672/100000, D Loss: 0.09619079157710075, G Loss: 4.558578968048096\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1673/100000, D Loss: 0.0869545191526413, G Loss: 4.62498140335083\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1674/100000, D Loss: 0.11037169769406319, G Loss: 4.491050720214844\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1675/100000, D Loss: 0.10032360255718231, G Loss: 4.618890762329102\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1676/100000, D Loss: 0.0774913914501667, G Loss: 4.901978969573975\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1677/100000, D Loss: 0.09648498147726059, G Loss: 4.641345977783203\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1678/100000, D Loss: 0.06908536702394485, G Loss: 4.820138931274414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1679/100000, D Loss: 0.06728582084178925, G Loss: 5.164090156555176\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1680/100000, D Loss: 0.06657333299517632, G Loss: 5.030133247375488\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1681/100000, D Loss: 0.06666037626564503, G Loss: 4.507464408874512\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1682/100000, D Loss: 0.07888578251004219, G Loss: 4.6162519454956055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1683/100000, D Loss: 0.051173312589526176, G Loss: 5.084721088409424\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1684/100000, D Loss: 0.06282982975244522, G Loss: 4.736594200134277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1685/100000, D Loss: 0.06718669459223747, G Loss: 4.362092971801758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1686/100000, D Loss: 0.05957568809390068, G Loss: 4.585239410400391\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1687/100000, D Loss: 0.055118437856435776, G Loss: 4.816286087036133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1688/100000, D Loss: 0.07942968048155308, G Loss: 4.362630844116211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1689/100000, D Loss: 0.06525332853198051, G Loss: 4.4279046058654785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1690/100000, D Loss: 0.07287006638944149, G Loss: 4.695016860961914\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1691/100000, D Loss: 0.047008708119392395, G Loss: 4.819598197937012\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1692/100000, D Loss: 0.08082477003335953, G Loss: 4.11727237701416\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1693/100000, D Loss: 0.07771504670381546, G Loss: 4.230415344238281\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1694/100000, D Loss: 0.05659922584891319, G Loss: 4.8296403884887695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1695/100000, D Loss: 0.06616732105612755, G Loss: 4.4540815353393555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1696/100000, D Loss: 0.07396918535232544, G Loss: 4.1781535148620605\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1697/100000, D Loss: 0.06129549443721771, G Loss: 4.436338424682617\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1698/100000, D Loss: 0.05737411417067051, G Loss: 4.645503044128418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1699/100000, D Loss: 0.08783862367272377, G Loss: 4.018088340759277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1700/100000, D Loss: 0.0965748131275177, G Loss: 4.264019012451172\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1701/100000, D Loss: 0.08154816180467606, G Loss: 4.609015941619873\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1702/100000, D Loss: 0.10405920073390007, G Loss: 4.000165939331055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1703/100000, D Loss: 0.09359022974967957, G Loss: 4.310212135314941\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1704/100000, D Loss: 0.07824300788342953, G Loss: 4.464170932769775\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1705/100000, D Loss: 0.0888785794377327, G Loss: 3.816967487335205\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1706/100000, D Loss: 0.08403927832841873, G Loss: 4.284955024719238\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1707/100000, D Loss: 0.09197339415550232, G Loss: 4.267624855041504\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1708/100000, D Loss: 0.12247482687234879, G Loss: 3.861989736557007\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1709/100000, D Loss: 0.07500535249710083, G Loss: 4.585926055908203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1710/100000, D Loss: 0.08569556660950184, G Loss: 4.366334915161133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1711/100000, D Loss: 0.10182346776127815, G Loss: 4.0945634841918945\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1712/100000, D Loss: 0.10149308294057846, G Loss: 4.342231750488281\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1713/100000, D Loss: 0.11423005908727646, G Loss: 4.136455535888672\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1714/100000, D Loss: 0.1534561961889267, G Loss: 4.289052963256836\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1715/100000, D Loss: 0.11564603447914124, G Loss: 4.670998573303223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1716/100000, D Loss: 0.12308406829833984, G Loss: 4.050204277038574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1717/100000, D Loss: 0.1133597306907177, G Loss: 4.691490173339844\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1718/100000, D Loss: 0.08373589813709259, G Loss: 5.386740684509277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1719/100000, D Loss: 0.09745928645133972, G Loss: 4.381774425506592\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1720/100000, D Loss: 0.08358396403491497, G Loss: 4.73422908782959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1721/100000, D Loss: 0.05004299245774746, G Loss: 5.622755527496338\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1722/100000, D Loss: 0.06753139942884445, G Loss: 4.996756553649902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1723/100000, D Loss: 0.060342999175190926, G Loss: 4.69843864440918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1724/100000, D Loss: 0.04482975974678993, G Loss: 5.246083736419678\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1725/100000, D Loss: 0.03418578766286373, G Loss: 5.54119873046875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1726/100000, D Loss: 0.04233750142157078, G Loss: 5.102415084838867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1727/100000, D Loss: 0.03834977000951767, G Loss: 4.711418628692627\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1728/100000, D Loss: 0.031270419247448444, G Loss: 4.960402011871338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1729/100000, D Loss: 0.04576542042195797, G Loss: 4.835409164428711\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1730/100000, D Loss: 0.04558548703789711, G Loss: 4.648465633392334\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1731/100000, D Loss: 0.05930628255009651, G Loss: 4.466316223144531\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1732/100000, D Loss: 0.05034951493144035, G Loss: 4.806992053985596\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1733/100000, D Loss: 0.05487903952598572, G Loss: 4.816449165344238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1734/100000, D Loss: 0.057873597368597984, G Loss: 4.473186016082764\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1735/100000, D Loss: 0.07331391423940659, G Loss: 4.430461883544922\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1736/100000, D Loss: 0.09033951535820961, G Loss: 4.724642753601074\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1737/100000, D Loss: 0.08068753406405449, G Loss: 4.895388603210449\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1738/100000, D Loss: 0.08850578963756561, G Loss: 4.834195137023926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1739/100000, D Loss: 0.10368067026138306, G Loss: 5.16446590423584\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1740/100000, D Loss: 0.0818832777440548, G Loss: 5.943896770477295\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1741/100000, D Loss: 0.1203824058175087, G Loss: 5.719307899475098\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1742/100000, D Loss: 0.12885019183158875, G Loss: 5.456066131591797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1743/100000, D Loss: 0.15736856311559677, G Loss: 5.849699974060059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1744/100000, D Loss: 0.14837481081485748, G Loss: 6.220884323120117\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1745/100000, D Loss: 0.21508600562810898, G Loss: 5.798153877258301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1746/100000, D Loss: 0.18324914574623108, G Loss: 6.445880889892578\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1747/100000, D Loss: 0.1846514493227005, G Loss: 7.014546871185303\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1748/100000, D Loss: 0.19186675548553467, G Loss: 6.089976787567139\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1749/100000, D Loss: 0.17287111282348633, G Loss: 5.609401702880859\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1750/100000, D Loss: 0.12231994420289993, G Loss: 5.908449172973633\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1751/100000, D Loss: 0.092296302318573, G Loss: 5.794917106628418\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1752/100000, D Loss: 0.05575309321284294, G Loss: 5.8213396072387695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1753/100000, D Loss: 0.062073685228824615, G Loss: 5.418389320373535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1754/100000, D Loss: 0.05515068396925926, G Loss: 5.095891952514648\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1755/100000, D Loss: 0.04529894143342972, G Loss: 5.178919792175293\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1756/100000, D Loss: 0.03825573995709419, G Loss: 5.530974388122559\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1757/100000, D Loss: 0.05186799541115761, G Loss: 5.543693542480469\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1758/100000, D Loss: 0.04764741100370884, G Loss: 5.551344871520996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1759/100000, D Loss: 0.056612033396959305, G Loss: 5.305426597595215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1760/100000, D Loss: 0.07708144932985306, G Loss: 4.973536014556885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1761/100000, D Loss: 0.0697237178683281, G Loss: 5.293753147125244\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1762/100000, D Loss: 0.06798943318426609, G Loss: 5.555834770202637\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1763/100000, D Loss: 0.0736013762652874, G Loss: 5.300291061401367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1764/100000, D Loss: 0.06783764064311981, G Loss: 5.060296058654785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1765/100000, D Loss: 0.07461686432361603, G Loss: 5.158045291900635\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1766/100000, D Loss: 0.07102760672569275, G Loss: 4.999462604522705\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1767/100000, D Loss: 0.052841078490018845, G Loss: 5.17007303237915\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1768/100000, D Loss: 0.06727868691086769, G Loss: 5.050997734069824\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1769/100000, D Loss: 0.07500075735151768, G Loss: 4.766564846038818\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1770/100000, D Loss: 0.06595656648278236, G Loss: 4.931811332702637\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1771/100000, D Loss: 0.0641489289700985, G Loss: 5.110791206359863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1772/100000, D Loss: 0.06894680298864841, G Loss: 4.952939033508301\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1773/100000, D Loss: 0.07354069128632545, G Loss: 4.668267726898193\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1774/100000, D Loss: 0.07458380237221718, G Loss: 4.495349884033203\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1775/100000, D Loss: 0.06143752112984657, G Loss: 4.8176398277282715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1776/100000, D Loss: 0.05774976313114166, G Loss: 5.061346530914307\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1777/100000, D Loss: 0.058314258232712746, G Loss: 4.889105796813965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1778/100000, D Loss: 0.06636861339211464, G Loss: 4.632752895355225\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1779/100000, D Loss: 0.07976039871573448, G Loss: 4.65083122253418\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1780/100000, D Loss: 0.0610637441277504, G Loss: 4.832932472229004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1781/100000, D Loss: 0.062260860577225685, G Loss: 4.864441871643066\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1782/100000, D Loss: 0.05377504974603653, G Loss: 4.783921718597412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1783/100000, D Loss: 0.06172940135002136, G Loss: 4.614467620849609\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1784/100000, D Loss: 0.05285113863646984, G Loss: 4.539127349853516\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1785/100000, D Loss: 0.056878313422203064, G Loss: 4.625447750091553\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1786/100000, D Loss: 0.05451898276805878, G Loss: 4.693184852600098\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1787/100000, D Loss: 0.056692831218242645, G Loss: 4.603891372680664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1788/100000, D Loss: 0.04959157295525074, G Loss: 4.712762832641602\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1789/100000, D Loss: 0.05142892152070999, G Loss: 4.711095333099365\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1790/100000, D Loss: 0.05120169743895531, G Loss: 4.640255928039551\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1791/100000, D Loss: 0.050772059708833694, G Loss: 4.609130859375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1792/100000, D Loss: 0.04788553714752197, G Loss: 4.648473739624023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1793/100000, D Loss: 0.06642952561378479, G Loss: 4.435762405395508\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1794/100000, D Loss: 0.06640397757291794, G Loss: 4.37207555770874\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1795/100000, D Loss: 0.044606734067201614, G Loss: 4.702958106994629\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1796/100000, D Loss: 0.07470002770423889, G Loss: 4.43231725692749\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1797/100000, D Loss: 0.07597588375210762, G Loss: 4.424287796020508\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1798/100000, D Loss: 0.058016274124383926, G Loss: 4.677868843078613\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1799/100000, D Loss: 0.054438065737485886, G Loss: 4.576848983764648\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1800/100000, D Loss: 0.06577397882938385, G Loss: 4.373842716217041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1801/100000, D Loss: 0.052969617769122124, G Loss: 4.599325180053711\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1802/100000, D Loss: 0.05496043339371681, G Loss: 4.655259132385254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1803/100000, D Loss: 0.051693402230739594, G Loss: 4.57696533203125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1804/100000, D Loss: 0.052207646891474724, G Loss: 4.468444347381592\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1805/100000, D Loss: 0.06108325347304344, G Loss: 4.525187015533447\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1806/100000, D Loss: 0.05538489110767841, G Loss: 4.847466468811035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1807/100000, D Loss: 0.0525121483951807, G Loss: 4.819273948669434\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1808/100000, D Loss: 0.09102510660886765, G Loss: 4.312310218811035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1809/100000, D Loss: 0.06686251237988472, G Loss: 4.792854309082031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1810/100000, D Loss: 0.06425273418426514, G Loss: 5.212536811828613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1811/100000, D Loss: 0.09110258892178535, G Loss: 4.51293420791626\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1812/100000, D Loss: 0.07864228636026382, G Loss: 4.390196800231934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1813/100000, D Loss: 0.08776649087667465, G Loss: 4.626898765563965\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1814/100000, D Loss: 0.08723035454750061, G Loss: 4.768734455108643\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1815/100000, D Loss: 0.12466686964035034, G Loss: 4.542896270751953\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1816/100000, D Loss: 0.15282394737005234, G Loss: 4.453943252563477\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1817/100000, D Loss: 0.12270577996969223, G Loss: 4.636299133300781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1818/100000, D Loss: 0.1441451460123062, G Loss: 4.470363616943359\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1819/100000, D Loss: 0.1858898624777794, G Loss: 4.5023603439331055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1820/100000, D Loss: 0.14827007800340652, G Loss: 4.8678297996521\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1821/100000, D Loss: 0.17214415967464447, G Loss: 4.738003730773926\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1822/100000, D Loss: 0.18734316527843475, G Loss: 5.024563312530518\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1823/100000, D Loss: 0.18112671375274658, G Loss: 5.207352638244629\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1824/100000, D Loss: 0.14285969734191895, G Loss: 5.054163455963135\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1825/100000, D Loss: 0.1753338947892189, G Loss: 5.170432090759277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1826/100000, D Loss: 0.17726030200719833, G Loss: 5.4877095222473145\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1827/100000, D Loss: 0.12877758592367172, G Loss: 6.232524394989014\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1828/100000, D Loss: 0.15670910477638245, G Loss: 5.771585941314697\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1829/100000, D Loss: 0.16936662793159485, G Loss: 5.8677287101745605\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1830/100000, D Loss: 0.1272287592291832, G Loss: 6.817654132843018\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1831/100000, D Loss: 0.12659139931201935, G Loss: 7.765931606292725\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1832/100000, D Loss: 0.14075152203440666, G Loss: 7.120291709899902\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1833/100000, D Loss: 0.16458123177289963, G Loss: 6.585200309753418\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1834/100000, D Loss: 0.11843918263912201, G Loss: 7.123233318328857\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1835/100000, D Loss: 0.12169381976127625, G Loss: 8.461248397827148\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1836/100000, D Loss: 0.13216758519411087, G Loss: 8.625370025634766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1837/100000, D Loss: 0.14323855191469193, G Loss: 8.006781578063965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1838/100000, D Loss: 0.12352700531482697, G Loss: 7.844695568084717\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1839/100000, D Loss: 0.08078611269593239, G Loss: 8.377702713012695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1840/100000, D Loss: 0.08102913573384285, G Loss: 8.721285820007324\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1841/100000, D Loss: 0.06481089070439339, G Loss: 8.638925552368164\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1842/100000, D Loss: 0.0704176053404808, G Loss: 8.273064613342285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1843/100000, D Loss: 0.05033707991242409, G Loss: 7.863258361816406\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1844/100000, D Loss: 0.054928312078118324, G Loss: 7.758021831512451\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1845/100000, D Loss: 0.052222006022930145, G Loss: 7.661005973815918\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1846/100000, D Loss: 0.0519015584141016, G Loss: 7.443507194519043\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1847/100000, D Loss: 0.05864700488746166, G Loss: 7.045805931091309\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1848/100000, D Loss: 0.055706070736050606, G Loss: 6.6617817878723145\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1849/100000, D Loss: 0.055765872821211815, G Loss: 6.677005767822266\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1850/100000, D Loss: 0.0404882300645113, G Loss: 6.5895185470581055\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1851/100000, D Loss: 0.04606681130826473, G Loss: 6.481829643249512\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1852/100000, D Loss: 0.03612878359854221, G Loss: 6.1614580154418945\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1853/100000, D Loss: 0.04942847229540348, G Loss: 5.6247453689575195\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1854/100000, D Loss: 0.054482342675328255, G Loss: 5.549572944641113\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1855/100000, D Loss: 0.04046228528022766, G Loss: 5.628159523010254\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1856/100000, D Loss: 0.05736995115876198, G Loss: 5.232936859130859\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1857/100000, D Loss: 0.06725167110562325, G Loss: 4.963541507720947\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1858/100000, D Loss: 0.06672345846891403, G Loss: 4.909059524536133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1859/100000, D Loss: 0.06602481007575989, G Loss: 5.1182379722595215\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1860/100000, D Loss: 0.06915786117315292, G Loss: 4.958904266357422\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1861/100000, D Loss: 0.064352473244071, G Loss: 4.7191925048828125\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1862/100000, D Loss: 0.07108594849705696, G Loss: 4.475183486938477\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1863/100000, D Loss: 0.0893457643687725, G Loss: 4.484993934631348\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1864/100000, D Loss: 0.06648899614810944, G Loss: 4.818475723266602\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1865/100000, D Loss: 0.0712212510406971, G Loss: 4.755694389343262\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1866/100000, D Loss: 0.09248236939311028, G Loss: 4.531589508056641\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1867/100000, D Loss: 0.07170510664582253, G Loss: 4.699104309082031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1868/100000, D Loss: 0.0565131064504385, G Loss: 5.073999404907227\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1869/100000, D Loss: 0.05571948364377022, G Loss: 5.2204179763793945\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1870/100000, D Loss: 0.05030984431505203, G Loss: 5.012567520141602\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1871/100000, D Loss: 0.07074004039168358, G Loss: 4.49204158782959\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1872/100000, D Loss: 0.049376947805285454, G Loss: 4.981523513793945\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1873/100000, D Loss: 0.04252324067056179, G Loss: 5.222443580627441\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1874/100000, D Loss: 0.0645094271749258, G Loss: 4.81024169921875\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1875/100000, D Loss: 0.05024765618145466, G Loss: 4.647811412811279\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1876/100000, D Loss: 0.06108964793384075, G Loss: 4.816874027252197\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1877/100000, D Loss: 0.051860591396689415, G Loss: 4.955641746520996\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1878/100000, D Loss: 0.05381025746464729, G Loss: 4.726828575134277\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1879/100000, D Loss: 0.07320240512490273, G Loss: 4.430651664733887\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1880/100000, D Loss: 0.05183000862598419, G Loss: 4.7568769454956055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1881/100000, D Loss: 0.07896589115262032, G Loss: 4.421402454376221\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1882/100000, D Loss: 0.07642471417784691, G Loss: 4.392025947570801\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1883/100000, D Loss: 0.05474959686398506, G Loss: 4.841920852661133\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1884/100000, D Loss: 0.06609805673360825, G Loss: 4.816644191741943\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1885/100000, D Loss: 0.07251011207699776, G Loss: 4.388487339019775\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1886/100000, D Loss: 0.05442260950803757, G Loss: 4.405204772949219\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1887/100000, D Loss: 0.047345466911792755, G Loss: 4.751440048217773\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1888/100000, D Loss: 0.04895334504544735, G Loss: 4.663405418395996\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 1889/100000, D Loss: 0.07052915543317795, G Loss: 4.331052780151367\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1890/100000, D Loss: 0.06183524429798126, G Loss: 4.448733806610107\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1891/100000, D Loss: 0.06419297493994236, G Loss: 4.571409225463867\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1892/100000, D Loss: 0.05788532644510269, G Loss: 4.606412410736084\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1893/100000, D Loss: 0.08514967560768127, G Loss: 4.20712947845459\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1894/100000, D Loss: 0.09405180439352989, G Loss: 4.265244960784912\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1895/100000, D Loss: 0.09801753237843513, G Loss: 4.57307243347168\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1896/100000, D Loss: 0.12058233469724655, G Loss: 4.105632781982422\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 1897/100000, D Loss: 0.15105697512626648, G Loss: 4.320606708526611\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1898/100000, D Loss: 0.10836970806121826, G Loss: 4.672567367553711\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1899/100000, D Loss: 0.18177075684070587, G Loss: 3.952704429626465\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1900/100000, D Loss: 0.13467492908239365, G Loss: 4.641249656677246\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1901/100000, D Loss: 0.1586562804877758, G Loss: 4.4916815757751465\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1902/100000, D Loss: 0.17107228934764862, G Loss: 4.450167655944824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1903/100000, D Loss: 0.13760026544332504, G Loss: 4.483771800994873\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1904/100000, D Loss: 0.14471155405044556, G Loss: 4.330689907073975\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1905/100000, D Loss: 0.1483157053589821, G Loss: 4.270597457885742\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1906/100000, D Loss: 0.12045858055353165, G Loss: 4.528175354003906\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1907/100000, D Loss: 0.1568520925939083, G Loss: 4.279270648956299\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1908/100000, D Loss: 0.1412605568766594, G Loss: 4.368339538574219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1909/100000, D Loss: 0.12008741497993469, G Loss: 4.818653106689453\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1910/100000, D Loss: 0.12595951929688454, G Loss: 4.497419357299805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1911/100000, D Loss: 0.10702776908874512, G Loss: 4.566642761230469\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1912/100000, D Loss: 0.09492293372750282, G Loss: 4.880329132080078\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1913/100000, D Loss: 0.0815180093050003, G Loss: 4.705229759216309\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1914/100000, D Loss: 0.09929769486188889, G Loss: 4.485324859619141\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1915/100000, D Loss: 0.08737251907587051, G Loss: 4.772517204284668\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1916/100000, D Loss: 0.07451417297124863, G Loss: 4.933651924133301\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1917/100000, D Loss: 0.08267476223409176, G Loss: 4.671665191650391\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1918/100000, D Loss: 0.08940978720784187, G Loss: 4.537988185882568\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1919/100000, D Loss: 0.10379629954695702, G Loss: 4.414899826049805\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1920/100000, D Loss: 0.12336424738168716, G Loss: 4.537664890289307\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1921/100000, D Loss: 0.11535413563251495, G Loss: 4.795668601989746\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1922/100000, D Loss: 0.10517634451389313, G Loss: 4.467150688171387\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1923/100000, D Loss: 0.12966245040297508, G Loss: 4.353780746459961\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1924/100000, D Loss: 0.159139022231102, G Loss: 4.443317413330078\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1925/100000, D Loss: 0.11648998782038689, G Loss: 4.792872905731201\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1926/100000, D Loss: 0.1813056841492653, G Loss: 4.220946311950684\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1927/100000, D Loss: 0.14382093399763107, G Loss: 4.918654441833496\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 1928/100000, D Loss: 0.11986202746629715, G Loss: 5.161435604095459\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1929/100000, D Loss: 0.13942798972129822, G Loss: 4.221335411071777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1930/100000, D Loss: 0.13810518011450768, G Loss: 4.797565460205078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1931/100000, D Loss: 0.12754852697253227, G Loss: 5.334619522094727\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1932/100000, D Loss: 0.15229789540171623, G Loss: 4.529796600341797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1933/100000, D Loss: 0.13949860632419586, G Loss: 4.8779826164245605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1934/100000, D Loss: 0.11207710206508636, G Loss: 5.591123580932617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1935/100000, D Loss: 0.12052042037248611, G Loss: 5.110586166381836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1936/100000, D Loss: 0.08451716229319572, G Loss: 5.24075984954834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1937/100000, D Loss: 0.07762407511472702, G Loss: 5.736383438110352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1938/100000, D Loss: 0.07005997188389301, G Loss: 5.991673469543457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1939/100000, D Loss: 0.0632463525980711, G Loss: 5.9058637619018555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1940/100000, D Loss: 0.07191905379295349, G Loss: 5.873178482055664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1941/100000, D Loss: 0.0811799168586731, G Loss: 5.844195365905762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1942/100000, D Loss: 0.06471454352140427, G Loss: 6.049280166625977\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1943/100000, D Loss: 0.08193783834576607, G Loss: 5.9851179122924805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1944/100000, D Loss: 0.07638639956712723, G Loss: 6.093603610992432\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1945/100000, D Loss: 0.07658322528004646, G Loss: 5.99193811416626\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1946/100000, D Loss: 0.08860768005251884, G Loss: 6.126655101776123\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1947/100000, D Loss: 0.09248939156532288, G Loss: 6.342180252075195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1948/100000, D Loss: 0.09812522307038307, G Loss: 6.329927444458008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1949/100000, D Loss: 0.07198643684387207, G Loss: 6.876870632171631\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1950/100000, D Loss: 0.07516477815806866, G Loss: 6.4967498779296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1951/100000, D Loss: 0.07051259651780128, G Loss: 6.252396583557129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1952/100000, D Loss: 0.06993003934621811, G Loss: 6.205905914306641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1953/100000, D Loss: 0.0410156175494194, G Loss: 6.660386562347412\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1954/100000, D Loss: 0.062042481265962124, G Loss: 5.971397876739502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1955/100000, D Loss: 0.054688284173607826, G Loss: 5.469913482666016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1956/100000, D Loss: 0.04155783448368311, G Loss: 5.762816429138184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1957/100000, D Loss: 0.04912463389337063, G Loss: 5.843584060668945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1958/100000, D Loss: 0.05358859710395336, G Loss: 5.473943710327148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1959/100000, D Loss: 0.0454680360853672, G Loss: 5.136887550354004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1960/100000, D Loss: 0.050366293638944626, G Loss: 5.131002426147461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1961/100000, D Loss: 0.03565192222595215, G Loss: 5.232488632202148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1962/100000, D Loss: 0.04732685349881649, G Loss: 5.250280380249023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1963/100000, D Loss: 0.04911663942039013, G Loss: 4.974009037017822\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1964/100000, D Loss: 0.049253031611442566, G Loss: 4.86167049407959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1965/100000, D Loss: 0.042437030002474785, G Loss: 4.985827445983887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1966/100000, D Loss: 0.03788595460355282, G Loss: 5.10528564453125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1967/100000, D Loss: 0.036738503724336624, G Loss: 5.081048011779785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1968/100000, D Loss: 0.05710064247250557, G Loss: 4.7652812004089355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1969/100000, D Loss: 0.05549170449376106, G Loss: 5.0507402420043945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1970/100000, D Loss: 0.04714865796267986, G Loss: 5.2784576416015625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1971/100000, D Loss: 0.08746662735939026, G Loss: 4.861159801483154\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1972/100000, D Loss: 0.09345894679427147, G Loss: 4.849416732788086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1973/100000, D Loss: 0.06528163328766823, G Loss: 5.453255653381348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1974/100000, D Loss: 0.07697034999728203, G Loss: 5.493844509124756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1975/100000, D Loss: 0.09639113023877144, G Loss: 5.107383728027344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1976/100000, D Loss: 0.11728788167238235, G Loss: 5.074925422668457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1977/100000, D Loss: 0.08406415581703186, G Loss: 5.855653762817383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1978/100000, D Loss: 0.10448792576789856, G Loss: 6.042743682861328\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1979/100000, D Loss: 0.10754028707742691, G Loss: 5.623421669006348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1980/100000, D Loss: 0.09509680420160294, G Loss: 5.7868804931640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1981/100000, D Loss: 0.06860855408012867, G Loss: 6.217659950256348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1982/100000, D Loss: 0.0936797596514225, G Loss: 6.18533182144165\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1983/100000, D Loss: 0.10966113582253456, G Loss: 5.909690856933594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1984/100000, D Loss: 0.09294834733009338, G Loss: 6.068421363830566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1985/100000, D Loss: 0.10550040006637573, G Loss: 5.748420715332031\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1986/100000, D Loss: 0.11475478112697601, G Loss: 5.711857318878174\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1987/100000, D Loss: 0.11866221576929092, G Loss: 5.79388427734375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1988/100000, D Loss: 0.10271506011486053, G Loss: 6.221962928771973\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1989/100000, D Loss: 0.1660940945148468, G Loss: 5.681766510009766\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1990/100000, D Loss: 0.1623620018362999, G Loss: 5.355450630187988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1991/100000, D Loss: 0.1697230190038681, G Loss: 5.49824857711792\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1992/100000, D Loss: 0.154266357421875, G Loss: 5.503380298614502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1993/100000, D Loss: 0.17700264602899551, G Loss: 4.974190711975098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1994/100000, D Loss: 0.14522957801818848, G Loss: 5.12342643737793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1995/100000, D Loss: 0.13476666435599327, G Loss: 4.918599605560303\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1996/100000, D Loss: 0.11771993711590767, G Loss: 4.734011650085449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1997/100000, D Loss: 0.11361271888017654, G Loss: 4.773092746734619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1998/100000, D Loss: 0.0849335640668869, G Loss: 5.105097770690918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1999/100000, D Loss: 0.09423153661191463, G Loss: 4.945622444152832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2000/100000, D Loss: 0.08273347839713097, G Loss: 5.070806503295898\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2001/100000, D Loss: 0.0821644738316536, G Loss: 5.164116859436035\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2002/100000, D Loss: 0.06320548430085182, G Loss: 5.325357437133789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2003/100000, D Loss: 0.06548039615154266, G Loss: 5.5536298751831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2004/100000, D Loss: 0.06138124503195286, G Loss: 5.392729759216309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2005/100000, D Loss: 0.07323967665433884, G Loss: 4.909567356109619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2006/100000, D Loss: 0.0803244411945343, G Loss: 4.916543960571289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2007/100000, D Loss: 0.07425441034138203, G Loss: 5.209481716156006\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2008/100000, D Loss: 0.07419508695602417, G Loss: 5.056430339813232\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2009/100000, D Loss: 0.08638859912753105, G Loss: 4.762406349182129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2010/100000, D Loss: 0.08410388976335526, G Loss: 4.582996368408203\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2011/100000, D Loss: 0.0782017707824707, G Loss: 4.849428653717041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2012/100000, D Loss: 0.09271467477083206, G Loss: 4.66146993637085\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2013/100000, D Loss: 0.07668517902493477, G Loss: 4.678337097167969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2014/100000, D Loss: 0.07679307460784912, G Loss: 4.77470588684082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2015/100000, D Loss: 0.08394960686564445, G Loss: 4.817623138427734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2016/100000, D Loss: 0.07609326392412186, G Loss: 4.775725364685059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2017/100000, D Loss: 0.09734215959906578, G Loss: 4.348739147186279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2018/100000, D Loss: 0.1034056693315506, G Loss: 4.428635120391846\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2019/100000, D Loss: 0.08779295533895493, G Loss: 4.729286193847656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2020/100000, D Loss: 0.09723320975899696, G Loss: 4.386284828186035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2021/100000, D Loss: 0.12985307723283768, G Loss: 4.025786399841309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2022/100000, D Loss: 0.10010240599513054, G Loss: 4.351277828216553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2023/100000, D Loss: 0.09434854239225388, G Loss: 4.370749473571777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2024/100000, D Loss: 0.11384452506899834, G Loss: 4.218011379241943\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2025/100000, D Loss: 0.11914435401558876, G Loss: 4.414971351623535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2026/100000, D Loss: 0.11923965066671371, G Loss: 4.373590469360352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2027/100000, D Loss: 0.1654191017150879, G Loss: 4.010226249694824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2028/100000, D Loss: 0.14693477004766464, G Loss: 4.580937385559082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2029/100000, D Loss: 0.12434697151184082, G Loss: 4.587563514709473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2030/100000, D Loss: 0.208677738904953, G Loss: 3.711585760116577\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2031/100000, D Loss: 0.21616125106811523, G Loss: 4.3306121826171875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2032/100000, D Loss: 0.21747417747974396, G Loss: 4.35035514831543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2033/100000, D Loss: 0.2195894867181778, G Loss: 3.6619653701782227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2034/100000, D Loss: 0.17443439364433289, G Loss: 4.210553169250488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2035/100000, D Loss: 0.13520693592727184, G Loss: 4.591317176818848\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2036/100000, D Loss: 0.14543940126895905, G Loss: 3.892841100692749\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2037/100000, D Loss: 0.14027410745620728, G Loss: 4.124495029449463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2038/100000, D Loss: 0.07878879457712173, G Loss: 4.833468437194824\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2039/100000, D Loss: 0.10304082930088043, G Loss: 4.365828514099121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2040/100000, D Loss: 0.10213705524802208, G Loss: 3.9440624713897705\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2041/100000, D Loss: 0.09626609832048416, G Loss: 4.255145072937012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2042/100000, D Loss: 0.11493411287665367, G Loss: 4.291064739227295\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2043/100000, D Loss: 0.10355287045240402, G Loss: 4.211670875549316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2044/100000, D Loss: 0.13190648332238197, G Loss: 3.9452643394470215\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2045/100000, D Loss: 0.09500494971871376, G Loss: 4.270768165588379\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2046/100000, D Loss: 0.10874078422784805, G Loss: 4.396662712097168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2047/100000, D Loss: 0.1066056340932846, G Loss: 4.347796440124512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2048/100000, D Loss: 0.1108219251036644, G Loss: 4.075631141662598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2049/100000, D Loss: 0.08796671777963638, G Loss: 4.262341022491455\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2050/100000, D Loss: 0.05930127575993538, G Loss: 4.79302978515625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2051/100000, D Loss: 0.06620888411998749, G Loss: 4.644309043884277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2052/100000, D Loss: 0.05797203443944454, G Loss: 4.406999588012695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2053/100000, D Loss: 0.06395279243588448, G Loss: 4.258851051330566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2054/100000, D Loss: 0.059257159009575844, G Loss: 4.415195465087891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2055/100000, D Loss: 0.07122951373457909, G Loss: 4.391265869140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2056/100000, D Loss: 0.06500876322388649, G Loss: 4.2547526359558105\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2057/100000, D Loss: 0.0677975695580244, G Loss: 4.153449058532715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2058/100000, D Loss: 0.07421103864908218, G Loss: 4.1184563636779785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2059/100000, D Loss: 0.08090336620807648, G Loss: 4.040785789489746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2060/100000, D Loss: 0.1074158325791359, G Loss: 3.8387861251831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2061/100000, D Loss: 0.10578787699341774, G Loss: 3.9924638271331787\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2062/100000, D Loss: 0.12402729317545891, G Loss: 3.8314971923828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2063/100000, D Loss: 0.13806882873177528, G Loss: 3.7471983432769775\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2064/100000, D Loss: 0.133984062820673, G Loss: 3.863536834716797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2065/100000, D Loss: 0.11495968699455261, G Loss: 4.026012420654297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2066/100000, D Loss: 0.1486222743988037, G Loss: 3.649714946746826\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2067/100000, D Loss: 0.1605873703956604, G Loss: 3.8651044368743896\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2068/100000, D Loss: 0.10964203998446465, G Loss: 4.236078262329102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2069/100000, D Loss: 0.125418558716774, G Loss: 3.8349411487579346\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2070/100000, D Loss: 0.136545829474926, G Loss: 3.781325101852417\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2071/100000, D Loss: 0.07661277055740356, G Loss: 4.435413360595703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2072/100000, D Loss: 0.09904146008193493, G Loss: 4.298553943634033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2073/100000, D Loss: 0.09704709053039551, G Loss: 3.958603858947754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2074/100000, D Loss: 0.09082331508398056, G Loss: 4.1681928634643555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2075/100000, D Loss: 0.09344038926064968, G Loss: 4.333185195922852\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2076/100000, D Loss: 0.11736557632684708, G Loss: 4.028583526611328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2077/100000, D Loss: 0.11530699953436852, G Loss: 4.014130115509033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2078/100000, D Loss: 0.10059299319982529, G Loss: 4.356164932250977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2079/100000, D Loss: 0.12335281819105148, G Loss: 3.9945926666259766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2080/100000, D Loss: 0.11530089005827904, G Loss: 3.82627534866333\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2081/100000, D Loss: 0.1221940815448761, G Loss: 4.00526237487793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2082/100000, D Loss: 0.11604820191860199, G Loss: 4.07391357421875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2083/100000, D Loss: 0.10106027126312256, G Loss: 3.941016674041748\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2084/100000, D Loss: 0.10712045803666115, G Loss: 3.8895039558410645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2085/100000, D Loss: 0.08619590848684311, G Loss: 4.036348342895508\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2086/100000, D Loss: 0.10067791119217873, G Loss: 4.006345272064209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2087/100000, D Loss: 0.0912652350962162, G Loss: 4.039294719696045\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2088/100000, D Loss: 0.09058668464422226, G Loss: 4.140069007873535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2089/100000, D Loss: 0.07549024932086468, G Loss: 4.129745006561279\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2090/100000, D Loss: 0.07383571565151215, G Loss: 4.091581344604492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2091/100000, D Loss: 0.08020066097378731, G Loss: 4.059159278869629\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2092/100000, D Loss: 0.09001212567090988, G Loss: 4.319289207458496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2093/100000, D Loss: 0.08022617362439632, G Loss: 4.561032772064209\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2094/100000, D Loss: 0.10118522122502327, G Loss: 4.26222038269043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2095/100000, D Loss: 0.10564292594790459, G Loss: 4.470433712005615\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2096/100000, D Loss: 0.11289674043655396, G Loss: 4.80281925201416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2097/100000, D Loss: 0.13485382869839668, G Loss: 4.7205915451049805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2098/100000, D Loss: 0.13765280693769455, G Loss: 4.958434581756592\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2099/100000, D Loss: 0.19439228624105453, G Loss: 4.80961799621582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2100/100000, D Loss: 0.17443718761205673, G Loss: 5.325511455535889\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2101/100000, D Loss: 0.22653227299451828, G Loss: 5.325064659118652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2102/100000, D Loss: 0.24003596603870392, G Loss: 5.270381450653076\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2103/100000, D Loss: 0.22269931435585022, G Loss: 5.451526165008545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2104/100000, D Loss: 0.22808438539505005, G Loss: 5.73658561706543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2105/100000, D Loss: 0.19762161374092102, G Loss: 5.726042747497559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2106/100000, D Loss: 0.22259769588708878, G Loss: 5.516303062438965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2107/100000, D Loss: 0.16886979341506958, G Loss: 6.4690022468566895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2108/100000, D Loss: 0.16505257040262222, G Loss: 7.055474281311035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2109/100000, D Loss: 0.19752569496631622, G Loss: 7.0759782791137695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2110/100000, D Loss: 0.2253291755914688, G Loss: 6.777595520019531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2111/100000, D Loss: 0.19772598147392273, G Loss: 6.391413688659668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2112/100000, D Loss: 0.16831494867801666, G Loss: 6.79892635345459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2113/100000, D Loss: 0.18903611600399017, G Loss: 7.022887229919434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2114/100000, D Loss: 0.16731107980012894, G Loss: 6.785939693450928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2115/100000, D Loss: 0.11711280047893524, G Loss: 6.52518892288208\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2116/100000, D Loss: 0.11153148859739304, G Loss: 5.877788543701172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2117/100000, D Loss: 0.09703732281923294, G Loss: 5.843476295471191\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2118/100000, D Loss: 0.05703970976173878, G Loss: 6.042816162109375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2119/100000, D Loss: 0.06498682498931885, G Loss: 5.440282821655273\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2120/100000, D Loss: 0.06331654079258442, G Loss: 5.049012184143066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2121/100000, D Loss: 0.05254880338907242, G Loss: 5.026295185089111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2122/100000, D Loss: 0.04941238835453987, G Loss: 5.606166362762451\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2123/100000, D Loss: 0.050939273089170456, G Loss: 5.651885032653809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2124/100000, D Loss: 0.03969630412757397, G Loss: 5.657889366149902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2125/100000, D Loss: 0.05608873441815376, G Loss: 5.1465559005737305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2126/100000, D Loss: 0.05982125923037529, G Loss: 5.113837242126465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2127/100000, D Loss: 0.06804337352514267, G Loss: 5.059938430786133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2128/100000, D Loss: 0.06417263485491276, G Loss: 5.446807861328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2129/100000, D Loss: 0.0690498873591423, G Loss: 5.260732650756836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2130/100000, D Loss: 0.08625512197613716, G Loss: 5.175131320953369\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2131/100000, D Loss: 0.07721013203263283, G Loss: 5.158699035644531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2132/100000, D Loss: 0.08044084534049034, G Loss: 4.919288635253906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2133/100000, D Loss: 0.08946257829666138, G Loss: 4.870935916900635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2134/100000, D Loss: 0.09565269201993942, G Loss: 4.952863693237305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2135/100000, D Loss: 0.11231422424316406, G Loss: 4.824088096618652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2136/100000, D Loss: 0.10812627151608467, G Loss: 4.920382976531982\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2137/100000, D Loss: 0.1347189024090767, G Loss: 4.58057165145874\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2138/100000, D Loss: 0.1262611523270607, G Loss: 4.796553611755371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2139/100000, D Loss: 0.12607667595148087, G Loss: 4.825314044952393\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2140/100000, D Loss: 0.10733362287282944, G Loss: 4.652600288391113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2141/100000, D Loss: 0.13493946939706802, G Loss: 4.540963649749756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2142/100000, D Loss: 0.10471773147583008, G Loss: 4.857589244842529\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2143/100000, D Loss: 0.09333149716258049, G Loss: 4.953470230102539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2144/100000, D Loss: 0.09714100137352943, G Loss: 4.505219459533691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2145/100000, D Loss: 0.08657355234026909, G Loss: 4.794968605041504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2146/100000, D Loss: 0.07140243798494339, G Loss: 5.384500503540039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2147/100000, D Loss: 0.060450099408626556, G Loss: 5.321486473083496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2148/100000, D Loss: 0.09384568780660629, G Loss: 4.465749263763428\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2149/100000, D Loss: 0.0848812647163868, G Loss: 4.377830982208252\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2150/100000, D Loss: 0.05788050405681133, G Loss: 5.192220687866211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2151/100000, D Loss: 0.07558274827897549, G Loss: 5.176063537597656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2152/100000, D Loss: 0.062229666858911514, G Loss: 4.752635955810547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2153/100000, D Loss: 0.07753585278987885, G Loss: 4.490808010101318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2154/100000, D Loss: 0.05508279800415039, G Loss: 4.8724684715271\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2155/100000, D Loss: 0.057262860238552094, G Loss: 5.347466468811035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2156/100000, D Loss: 0.04737395327538252, G Loss: 5.180898666381836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2157/100000, D Loss: 0.06103278137743473, G Loss: 4.5942182540893555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2158/100000, D Loss: 0.0672052912414074, G Loss: 4.330718994140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2159/100000, D Loss: 0.046058692038059235, G Loss: 4.7238335609436035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2160/100000, D Loss: 0.05271095223724842, G Loss: 4.958477973937988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2161/100000, D Loss: 0.08393269591033459, G Loss: 4.254871368408203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2162/100000, D Loss: 0.10307849943637848, G Loss: 3.793158769607544\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2163/100000, D Loss: 0.08397463336586952, G Loss: 4.323938369750977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2164/100000, D Loss: 0.09646805562078953, G Loss: 4.435614585876465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2165/100000, D Loss: 0.15651532262563705, G Loss: 3.474299907684326\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2166/100000, D Loss: 0.13186736404895782, G Loss: 3.951007127761841\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2167/100000, D Loss: 0.1265324428677559, G Loss: 4.239013671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2168/100000, D Loss: 0.17134025320410728, G Loss: 3.5950937271118164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2169/100000, D Loss: 0.1872539520263672, G Loss: 3.5895817279815674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2170/100000, D Loss: 0.14050637558102608, G Loss: 3.9464364051818848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2171/100000, D Loss: 0.1804465726017952, G Loss: 3.459904670715332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2172/100000, D Loss: 0.16263918578624725, G Loss: 3.7462680339813232\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2173/100000, D Loss: 0.11575918644666672, G Loss: 4.134427547454834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2174/100000, D Loss: 0.14105505496263504, G Loss: 3.7131247520446777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2175/100000, D Loss: 0.14998478442430496, G Loss: 3.7198023796081543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2176/100000, D Loss: 0.10854719206690788, G Loss: 4.06199836730957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2177/100000, D Loss: 0.1113472580909729, G Loss: 3.7976009845733643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2178/100000, D Loss: 0.1259143352508545, G Loss: 3.6638269424438477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2179/100000, D Loss: 0.09344499185681343, G Loss: 4.1089701652526855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2180/100000, D Loss: 0.09378781914710999, G Loss: 4.016334056854248\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2181/100000, D Loss: 0.1079748123884201, G Loss: 3.684526205062866\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2182/100000, D Loss: 0.12020363658666611, G Loss: 3.813788890838623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2183/100000, D Loss: 0.09325313195586205, G Loss: 4.018354892730713\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2184/100000, D Loss: 0.12794431298971176, G Loss: 3.5488343238830566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2185/100000, D Loss: 0.16825131326913834, G Loss: 3.5346109867095947\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2186/100000, D Loss: 0.10051034390926361, G Loss: 4.176727294921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2187/100000, D Loss: 0.1645980030298233, G Loss: 3.5034964084625244\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2188/100000, D Loss: 0.16412533819675446, G Loss: 3.543301820755005\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2189/100000, D Loss: 0.10497615113854408, G Loss: 4.245355606079102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2190/100000, D Loss: 0.1348142772912979, G Loss: 3.675673484802246\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2191/100000, D Loss: 0.12883231043815613, G Loss: 3.5497055053710938\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2192/100000, D Loss: 0.10388163104653358, G Loss: 4.092710018157959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2193/100000, D Loss: 0.09408089146018028, G Loss: 4.235368728637695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2194/100000, D Loss: 0.10680169239640236, G Loss: 3.885596990585327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2195/100000, D Loss: 0.08863439410924911, G Loss: 3.8629343509674072\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2196/100000, D Loss: 0.08492063730955124, G Loss: 4.165316104888916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2197/100000, D Loss: 0.09366334229707718, G Loss: 4.152864456176758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2198/100000, D Loss: 0.09659666568040848, G Loss: 3.963963747024536\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2199/100000, D Loss: 0.0849122405052185, G Loss: 4.152801036834717\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2200/100000, D Loss: 0.07124443724751472, G Loss: 4.3602294921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2201/100000, D Loss: 0.10495678335428238, G Loss: 3.9202210903167725\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2202/100000, D Loss: 0.1070825569331646, G Loss: 3.7822203636169434\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2203/100000, D Loss: 0.10002681612968445, G Loss: 4.157402038574219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2204/100000, D Loss: 0.1088024377822876, G Loss: 3.961394786834717\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2205/100000, D Loss: 0.15636593103408813, G Loss: 3.453740119934082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2206/100000, D Loss: 0.13699723035097122, G Loss: 3.786900520324707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2207/100000, D Loss: 0.1406545713543892, G Loss: 3.941676139831543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2208/100000, D Loss: 0.17162317782640457, G Loss: 3.2342801094055176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2209/100000, D Loss: 0.23887939751148224, G Loss: 3.636112928390503\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2210/100000, D Loss: 0.15651950240135193, G Loss: 4.23919677734375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2211/100000, D Loss: 0.23682141304016113, G Loss: 3.1567258834838867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2212/100000, D Loss: 0.22847089916467667, G Loss: 3.4767560958862305\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2213/100000, D Loss: 0.15794704854488373, G Loss: 4.227786540985107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2214/100000, D Loss: 0.19588612392544746, G Loss: 3.473926067352295\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2215/100000, D Loss: 0.23011524975299835, G Loss: 3.1954708099365234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2216/100000, D Loss: 0.13831739500164986, G Loss: 3.8774521350860596\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2217/100000, D Loss: 0.15641159564256668, G Loss: 3.840543508529663\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2218/100000, D Loss: 0.1683271825313568, G Loss: 3.245152473449707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2219/100000, D Loss: 0.13766084611415863, G Loss: 3.6840600967407227\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2220/100000, D Loss: 0.13653962314128876, G Loss: 4.027990341186523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2221/100000, D Loss: 0.1393151693046093, G Loss: 3.6077091693878174\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2222/100000, D Loss: 0.1511760577559471, G Loss: 3.4538018703460693\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2223/100000, D Loss: 0.10179203376173973, G Loss: 4.0817461013793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2224/100000, D Loss: 0.11091099120676517, G Loss: 4.194658279418945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2225/100000, D Loss: 0.08082571625709534, G Loss: 3.939056396484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2226/100000, D Loss: 0.08004782721400261, G Loss: 3.9899942874908447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2227/100000, D Loss: 0.08283066004514694, G Loss: 4.3228631019592285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2228/100000, D Loss: 0.06354829296469688, G Loss: 4.646499156951904\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2229/100000, D Loss: 0.0843423455953598, G Loss: 4.355859279632568\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2230/100000, D Loss: 0.05983646586537361, G Loss: 4.310427665710449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2231/100000, D Loss: 0.06102319806814194, G Loss: 4.2812113761901855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2232/100000, D Loss: 0.05682060867547989, G Loss: 4.412117004394531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2233/100000, D Loss: 0.046877143904566765, G Loss: 4.486392021179199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2234/100000, D Loss: 0.0658729188144207, G Loss: 4.3720316886901855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2235/100000, D Loss: 0.07076263055205345, G Loss: 4.163269996643066\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2236/100000, D Loss: 0.07266385480761528, G Loss: 4.295434474945068\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2237/100000, D Loss: 0.06454815715551376, G Loss: 4.453325271606445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2238/100000, D Loss: 0.07126310467720032, G Loss: 4.3424530029296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2239/100000, D Loss: 0.08795979619026184, G Loss: 4.121280670166016\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2240/100000, D Loss: 0.07810672000050545, G Loss: 4.0782976150512695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2241/100000, D Loss: 0.08077402412891388, G Loss: 4.196618556976318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2242/100000, D Loss: 0.10973610356450081, G Loss: 4.043432235717773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2243/100000, D Loss: 0.10302239656448364, G Loss: 4.009432315826416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2244/100000, D Loss: 0.10191492363810539, G Loss: 4.151462078094482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2245/100000, D Loss: 0.0887979045510292, G Loss: 4.121372222900391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2246/100000, D Loss: 0.12232878804206848, G Loss: 3.773881435394287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2247/100000, D Loss: 0.08883848041296005, G Loss: 4.036502361297607\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2248/100000, D Loss: 0.08903255313634872, G Loss: 4.276696681976318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2249/100000, D Loss: 0.09070809185504913, G Loss: 4.2376508712768555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2250/100000, D Loss: 0.07471120730042458, G Loss: 4.247091770172119\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2251/100000, D Loss: 0.07555862702429295, G Loss: 4.42722225189209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2252/100000, D Loss: 0.06578567624092102, G Loss: 4.267120361328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2253/100000, D Loss: 0.06415960378944874, G Loss: 4.236079692840576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2254/100000, D Loss: 0.06882322952151299, G Loss: 4.344404220581055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2255/100000, D Loss: 0.05054766684770584, G Loss: 4.646472930908203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2256/100000, D Loss: 0.055437659844756126, G Loss: 4.711840629577637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2257/100000, D Loss: 0.06540282070636749, G Loss: 4.345831394195557\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2258/100000, D Loss: 0.049196088686585426, G Loss: 4.352130889892578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2259/100000, D Loss: 0.06027316674590111, G Loss: 4.4265947341918945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2260/100000, D Loss: 0.059357352554798126, G Loss: 4.378645420074463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2261/100000, D Loss: 0.05939866229891777, G Loss: 4.478267669677734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2262/100000, D Loss: 0.06937868893146515, G Loss: 4.373908996582031\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2263/100000, D Loss: 0.07504316046833992, G Loss: 4.355284214019775\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2264/100000, D Loss: 0.0709453709423542, G Loss: 4.153724670410156\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2265/100000, D Loss: 0.09411586076021194, G Loss: 4.060812950134277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2266/100000, D Loss: 0.0740678645670414, G Loss: 4.397723197937012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2267/100000, D Loss: 0.0643833540380001, G Loss: 4.465704917907715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2268/100000, D Loss: 0.0912921205163002, G Loss: 3.849142551422119\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2269/100000, D Loss: 0.11518271267414093, G Loss: 3.769498825073242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2270/100000, D Loss: 0.08622412011027336, G Loss: 4.2195963859558105\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2271/100000, D Loss: 0.10668674856424332, G Loss: 4.166521072387695\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2272/100000, D Loss: 0.11699585244059563, G Loss: 3.7112648487091064\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2273/100000, D Loss: 0.09210845828056335, G Loss: 4.048888683319092\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2274/100000, D Loss: 0.08591494336724281, G Loss: 4.353240013122559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2275/100000, D Loss: 0.08269216120243073, G Loss: 4.3612871170043945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2276/100000, D Loss: 0.08642125502228737, G Loss: 4.195596694946289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2277/100000, D Loss: 0.09133820235729218, G Loss: 4.062412738800049\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2278/100000, D Loss: 0.08244704082608223, G Loss: 4.153381824493408\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2279/100000, D Loss: 0.07993792369961739, G Loss: 4.349270820617676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2280/100000, D Loss: 0.1031155064702034, G Loss: 4.199342250823975\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2281/100000, D Loss: 0.10067193955183029, G Loss: 3.947767972946167\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2282/100000, D Loss: 0.12024052068591118, G Loss: 3.9675722122192383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2283/100000, D Loss: 0.13256806135177612, G Loss: 4.052234649658203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2284/100000, D Loss: 0.1483612097799778, G Loss: 3.808281183242798\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2285/100000, D Loss: 0.17544995993375778, G Loss: 3.8830833435058594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2286/100000, D Loss: 0.1669287495315075, G Loss: 3.964651107788086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2287/100000, D Loss: 0.1765626296401024, G Loss: 3.816382884979248\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2288/100000, D Loss: 0.1691334918141365, G Loss: 3.8660340309143066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2289/100000, D Loss: 0.1856013461947441, G Loss: 3.8656938076019287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2290/100000, D Loss: 0.22428317368030548, G Loss: 3.676011323928833\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2291/100000, D Loss: 0.14769374579191208, G Loss: 4.089933395385742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2292/100000, D Loss: 0.13990287482738495, G Loss: 4.046417236328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2293/100000, D Loss: 0.13028457388281822, G Loss: 3.7815873622894287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2294/100000, D Loss: 0.11925580725073814, G Loss: 4.105129241943359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2295/100000, D Loss: 0.11912490427494049, G Loss: 3.9529924392700195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2296/100000, D Loss: 0.096070297062397, G Loss: 3.912008762359619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2297/100000, D Loss: 0.09413516148924828, G Loss: 3.993124008178711\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2298/100000, D Loss: 0.08552871271967888, G Loss: 4.0353264808654785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2299/100000, D Loss: 0.09198328107595444, G Loss: 3.9169251918792725\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2300/100000, D Loss: 0.10890347510576248, G Loss: 3.7365002632141113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2301/100000, D Loss: 0.10157874971628189, G Loss: 4.099611282348633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2302/100000, D Loss: 0.10350489243865013, G Loss: 4.215780258178711\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2303/100000, D Loss: 0.11874493584036827, G Loss: 3.8212122917175293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2304/100000, D Loss: 0.13410263508558273, G Loss: 3.880277156829834\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2305/100000, D Loss: 0.11175057291984558, G Loss: 4.449292182922363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2306/100000, D Loss: 0.12989403307437897, G Loss: 4.172304153442383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2307/100000, D Loss: 0.1272209733724594, G Loss: 4.0662407875061035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2308/100000, D Loss: 0.1167847067117691, G Loss: 4.38456916809082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2309/100000, D Loss: 0.09091264009475708, G Loss: 5.0351457595825195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2310/100000, D Loss: 0.10994642600417137, G Loss: 5.111935615539551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2311/100000, D Loss: 0.0878424383699894, G Loss: 5.269979476928711\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2312/100000, D Loss: 0.07265212386846542, G Loss: 5.491328716278076\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2313/100000, D Loss: 0.07322155684232712, G Loss: 5.819011211395264\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2314/100000, D Loss: 0.07793150097131729, G Loss: 6.306403636932373\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2315/100000, D Loss: 0.07669534161686897, G Loss: 6.270298957824707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2316/100000, D Loss: 0.10963326692581177, G Loss: 6.395265579223633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2317/100000, D Loss: 0.10435618460178375, G Loss: 6.857861518859863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2318/100000, D Loss: 0.11551299691200256, G Loss: 6.96644401550293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2319/100000, D Loss: 0.1370118409395218, G Loss: 7.069314002990723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2320/100000, D Loss: 0.12053245306015015, G Loss: 6.92165470123291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2321/100000, D Loss: 0.14366858825087547, G Loss: 7.312305927276611\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2322/100000, D Loss: 0.14564114809036255, G Loss: 7.27918815612793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2323/100000, D Loss: 0.11928197741508484, G Loss: 7.389523506164551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2324/100000, D Loss: 0.1146543025970459, G Loss: 7.092594146728516\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2325/100000, D Loss: 0.10318344831466675, G Loss: 7.082796096801758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2326/100000, D Loss: 0.08934241160750389, G Loss: 7.308352947235107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2327/100000, D Loss: 0.05686883628368378, G Loss: 7.647336006164551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2328/100000, D Loss: 0.06425831094384193, G Loss: 7.5417304039001465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2329/100000, D Loss: 0.05662984400987625, G Loss: 6.732855319976807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2330/100000, D Loss: 0.05273906886577606, G Loss: 6.226061820983887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2331/100000, D Loss: 0.04375405050814152, G Loss: 6.036888599395752\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2332/100000, D Loss: 0.04815306328237057, G Loss: 6.173488140106201\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2333/100000, D Loss: 0.04352632164955139, G Loss: 6.454880714416504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2334/100000, D Loss: 0.04189268872141838, G Loss: 6.589666366577148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2335/100000, D Loss: 0.038287746720016, G Loss: 6.29037618637085\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2336/100000, D Loss: 0.038089415058493614, G Loss: 5.722246170043945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2337/100000, D Loss: 0.050300322473049164, G Loss: 5.524384498596191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2338/100000, D Loss: 0.04243423044681549, G Loss: 5.57034969329834\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2339/100000, D Loss: 0.04653516784310341, G Loss: 5.474898338317871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2340/100000, D Loss: 0.057710180059075356, G Loss: 5.269199371337891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2341/100000, D Loss: 0.056077269837260246, G Loss: 5.286872386932373\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2342/100000, D Loss: 0.06992615386843681, G Loss: 5.211383819580078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2343/100000, D Loss: 0.06925414130091667, G Loss: 5.2616071701049805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2344/100000, D Loss: 0.06995167769491673, G Loss: 5.152666091918945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2345/100000, D Loss: 0.06038110516965389, G Loss: 5.228279113769531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2346/100000, D Loss: 0.05462197586894035, G Loss: 5.308534145355225\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2347/100000, D Loss: 0.06068515032529831, G Loss: 5.205530643463135\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2348/100000, D Loss: 0.06164945103228092, G Loss: 4.925603866577148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2349/100000, D Loss: 0.05325695872306824, G Loss: 5.065153121948242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2350/100000, D Loss: 0.06787223182618618, G Loss: 4.821009635925293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2351/100000, D Loss: 0.053560638800263405, G Loss: 5.196955680847168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2352/100000, D Loss: 0.06619098410010338, G Loss: 4.973353862762451\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2353/100000, D Loss: 0.06280349753797054, G Loss: 5.053654670715332\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2354/100000, D Loss: 0.06559404730796814, G Loss: 5.126338481903076\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2355/100000, D Loss: 0.050558943301439285, G Loss: 5.3078227043151855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2356/100000, D Loss: 0.051726847887039185, G Loss: 5.253839492797852\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2357/100000, D Loss: 0.052283091470599174, G Loss: 5.278829574584961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2358/100000, D Loss: 0.0491459034383297, G Loss: 5.1920576095581055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2359/100000, D Loss: 0.04215012118220329, G Loss: 5.161225318908691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2360/100000, D Loss: 0.03741167671978474, G Loss: 5.129220485687256\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2361/100000, D Loss: 0.051375776529312134, G Loss: 5.163372993469238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2362/100000, D Loss: 0.03892363980412483, G Loss: 5.2253923416137695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2363/100000, D Loss: 0.041230978444218636, G Loss: 5.080173015594482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2364/100000, D Loss: 0.03554287180304527, G Loss: 5.135928153991699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2365/100000, D Loss: 0.0421194639056921, G Loss: 4.938061237335205\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2366/100000, D Loss: 0.03362325206398964, G Loss: 4.992741584777832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2367/100000, D Loss: 0.04021112620830536, G Loss: 4.928275108337402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2368/100000, D Loss: 0.034991213120520115, G Loss: 5.069431781768799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2369/100000, D Loss: 0.04427969641983509, G Loss: 4.706473350524902\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2370/100000, D Loss: 0.039285724982619286, G Loss: 4.826763153076172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2371/100000, D Loss: 0.047578275203704834, G Loss: 5.036813735961914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2372/100000, D Loss: 0.039047482423484325, G Loss: 5.056801795959473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2373/100000, D Loss: 0.03964426554739475, G Loss: 4.86707878112793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2374/100000, D Loss: 0.04138856939971447, G Loss: 4.738457679748535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2375/100000, D Loss: 0.03578855097293854, G Loss: 4.944202423095703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2376/100000, D Loss: 0.03088258020579815, G Loss: 5.054997444152832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2377/100000, D Loss: 0.031041485257446766, G Loss: 5.153241157531738\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2378/100000, D Loss: 0.03143840655684471, G Loss: 5.1222453117370605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2379/100000, D Loss: 0.03335953690111637, G Loss: 5.093327045440674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2380/100000, D Loss: 0.03928958997130394, G Loss: 4.857938766479492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2381/100000, D Loss: 0.040286215022206306, G Loss: 4.844869613647461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2382/100000, D Loss: 0.03646506555378437, G Loss: 5.0050153732299805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2383/100000, D Loss: 0.03320319019258022, G Loss: 5.068614482879639\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2384/100000, D Loss: 0.050281910225749016, G Loss: 4.541723251342773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2385/100000, D Loss: 0.05224180407822132, G Loss: 4.322117805480957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2386/100000, D Loss: 0.040687445551157, G Loss: 4.7170257568359375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2387/100000, D Loss: 0.05620439536869526, G Loss: 4.667436599731445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2388/100000, D Loss: 0.07116501405835152, G Loss: 4.189617156982422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2389/100000, D Loss: 0.07948348671197891, G Loss: 4.466684341430664\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2390/100000, D Loss: 0.07248995080590248, G Loss: 4.912664413452148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2391/100000, D Loss: 0.0881972685456276, G Loss: 4.642001152038574\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2392/100000, D Loss: 0.12707336619496346, G Loss: 4.2945170402526855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2393/100000, D Loss: 0.12377898767590523, G Loss: 4.646764755249023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2394/100000, D Loss: 0.16255104541778564, G Loss: 4.753574371337891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2395/100000, D Loss: 0.14795450121164322, G Loss: 4.852144241333008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2396/100000, D Loss: 0.194374680519104, G Loss: 4.81866979598999\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2397/100000, D Loss: 0.21809513866901398, G Loss: 5.248929977416992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2398/100000, D Loss: 0.18127702921628952, G Loss: 5.768882751464844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2399/100000, D Loss: 0.24282234907150269, G Loss: 5.521025657653809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2400/100000, D Loss: 0.18898262083530426, G Loss: 6.065507411956787\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2401/100000, D Loss: 0.13365577161312103, G Loss: 6.582882881164551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2402/100000, D Loss: 0.13599925860762596, G Loss: 5.976059913635254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2403/100000, D Loss: 0.12568439170718193, G Loss: 5.361177444458008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2404/100000, D Loss: 0.10127829015254974, G Loss: 5.780316352844238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2405/100000, D Loss: 0.06500832363963127, G Loss: 6.5112104415893555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2406/100000, D Loss: 0.06069945078343153, G Loss: 6.105950832366943\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2407/100000, D Loss: 0.0562046654522419, G Loss: 5.635416030883789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2408/100000, D Loss: 0.05262888967990875, G Loss: 5.705877304077148\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2409/100000, D Loss: 0.046966202557086945, G Loss: 6.203580856323242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2410/100000, D Loss: 0.05664128437638283, G Loss: 6.111593723297119\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2411/100000, D Loss: 0.05772388353943825, G Loss: 5.676693916320801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2412/100000, D Loss: 0.06008857861161232, G Loss: 5.512117385864258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2413/100000, D Loss: 0.06775246933102608, G Loss: 5.615001678466797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2414/100000, D Loss: 0.08764195069670677, G Loss: 5.469523906707764\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2415/100000, D Loss: 0.08895700424909592, G Loss: 5.275257587432861\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2416/100000, D Loss: 0.09359763562679291, G Loss: 5.221162796020508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2417/100000, D Loss: 0.12343956157565117, G Loss: 4.934229850769043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2418/100000, D Loss: 0.19096267223358154, G Loss: 5.043943405151367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2419/100000, D Loss: 0.1598891019821167, G Loss: 5.376214981079102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2420/100000, D Loss: 0.20342405885457993, G Loss: 5.178311824798584\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2421/100000, D Loss: 0.21092833578586578, G Loss: 5.013206481933594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2422/100000, D Loss: 0.21717122197151184, G Loss: 5.470381736755371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2423/100000, D Loss: 0.19460764527320862, G Loss: 5.556529998779297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2424/100000, D Loss: 0.19043957442045212, G Loss: 5.360849857330322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2425/100000, D Loss: 0.19919094443321228, G Loss: 5.150335788726807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2426/100000, D Loss: 0.16108432412147522, G Loss: 5.122995376586914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2427/100000, D Loss: 0.14341328293085098, G Loss: 5.208256721496582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2428/100000, D Loss: 0.12084004655480385, G Loss: 5.081272125244141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2429/100000, D Loss: 0.11499403044581413, G Loss: 5.053288459777832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2430/100000, D Loss: 0.08058134838938713, G Loss: 5.189759254455566\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2431/100000, D Loss: 0.0882493257522583, G Loss: 5.162212371826172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2432/100000, D Loss: 0.07896014302968979, G Loss: 5.100827217102051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2433/100000, D Loss: 0.07325903698801994, G Loss: 5.154754638671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2434/100000, D Loss: 0.05400974117219448, G Loss: 5.43557071685791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2435/100000, D Loss: 0.05808563157916069, G Loss: 5.601902008056641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2436/100000, D Loss: 0.05580284632742405, G Loss: 5.502046585083008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2437/100000, D Loss: 0.06416304409503937, G Loss: 5.355337142944336\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2438/100000, D Loss: 0.05892908573150635, G Loss: 5.564929485321045\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2439/100000, D Loss: 0.053637679666280746, G Loss: 5.537831783294678\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2440/100000, D Loss: 0.07519952207803726, G Loss: 5.391469955444336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2441/100000, D Loss: 0.058267343789339066, G Loss: 5.38890266418457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2442/100000, D Loss: 0.06773793697357178, G Loss: 5.278249263763428\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2443/100000, D Loss: 0.0860796868801117, G Loss: 5.1643805503845215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2444/100000, D Loss: 0.06905507296323776, G Loss: 5.038639068603516\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2445/100000, D Loss: 0.0737382173538208, G Loss: 5.088133335113525\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2446/100000, D Loss: 0.07115699723362923, G Loss: 5.269221782684326\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2447/100000, D Loss: 0.07717115432024002, G Loss: 5.279213905334473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2448/100000, D Loss: 0.08200576901435852, G Loss: 5.2312421798706055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2449/100000, D Loss: 0.07782868295907974, G Loss: 5.205158710479736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2450/100000, D Loss: 0.08946704864501953, G Loss: 5.298159122467041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2451/100000, D Loss: 0.07582125067710876, G Loss: 5.3188796043396\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2452/100000, D Loss: 0.07939352840185165, G Loss: 5.326908111572266\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2453/100000, D Loss: 0.0992177277803421, G Loss: 5.199747085571289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2454/100000, D Loss: 0.11368465796113014, G Loss: 5.120803356170654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2455/100000, D Loss: 0.12361988052725792, G Loss: 4.959300518035889\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2456/100000, D Loss: 0.15917538851499557, G Loss: 4.77393913269043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2457/100000, D Loss: 0.1309366077184677, G Loss: 4.72824764251709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2458/100000, D Loss: 0.13495920225977898, G Loss: 4.825071334838867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2459/100000, D Loss: 0.14784280210733414, G Loss: 4.653571128845215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2460/100000, D Loss: 0.12444057315587997, G Loss: 4.70053768157959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2461/100000, D Loss: 0.17135629057884216, G Loss: 4.751015663146973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2462/100000, D Loss: 0.15538765490055084, G Loss: 4.865704536437988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2463/100000, D Loss: 0.14280181378126144, G Loss: 4.863241195678711\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2464/100000, D Loss: 0.12959051132202148, G Loss: 5.179640293121338\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2465/100000, D Loss: 0.13671036064624786, G Loss: 5.20510196685791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2466/100000, D Loss: 0.13733229041099548, G Loss: 4.955691337585449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2467/100000, D Loss: 0.13209384679794312, G Loss: 5.108143329620361\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2468/100000, D Loss: 0.10062742978334427, G Loss: 5.700151443481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2469/100000, D Loss: 0.13586032763123512, G Loss: 4.974454879760742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2470/100000, D Loss: 0.130983866751194, G Loss: 4.802950382232666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2471/100000, D Loss: 0.112990852445364, G Loss: 5.206265449523926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2472/100000, D Loss: 0.14766578376293182, G Loss: 4.707978248596191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2473/100000, D Loss: 0.14867381006479263, G Loss: 4.5671186447143555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2474/100000, D Loss: 0.1688212752342224, G Loss: 4.559924125671387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2475/100000, D Loss: 0.16775348037481308, G Loss: 4.675288677215576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2476/100000, D Loss: 0.17860795184969902, G Loss: 4.447079658508301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2477/100000, D Loss: 0.17839683592319489, G Loss: 4.4873762130737305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2478/100000, D Loss: 0.17202752083539963, G Loss: 4.783265590667725\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2479/100000, D Loss: 0.1438223123550415, G Loss: 4.803579330444336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2480/100000, D Loss: 0.17076142877340317, G Loss: 4.326778411865234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2481/100000, D Loss: 0.15537268668413162, G Loss: 4.706002712249756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2482/100000, D Loss: 0.14709053188562393, G Loss: 4.70045804977417\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2483/100000, D Loss: 0.1593482792377472, G Loss: 4.51669979095459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2484/100000, D Loss: 0.16742585599422455, G Loss: 4.593076229095459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2485/100000, D Loss: 0.16343267261981964, G Loss: 4.570882320404053\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2486/100000, D Loss: 0.1508209928870201, G Loss: 4.376833915710449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2487/100000, D Loss: 0.13857725262641907, G Loss: 4.3486762046813965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2488/100000, D Loss: 0.14074267446994781, G Loss: 4.513327598571777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2489/100000, D Loss: 0.15288126468658447, G Loss: 4.191319465637207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2490/100000, D Loss: 0.14581387490034103, G Loss: 4.253067970275879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2491/100000, D Loss: 0.10058208554983139, G Loss: 5.016139030456543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2492/100000, D Loss: 0.14418281614780426, G Loss: 4.3100199699401855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2493/100000, D Loss: 0.13492311537265778, G Loss: 4.213803768157959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2494/100000, D Loss: 0.07807016000151634, G Loss: 4.902130126953125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2495/100000, D Loss: 0.10718987509608269, G Loss: 4.636786460876465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2496/100000, D Loss: 0.08131790906190872, G Loss: 4.368825912475586\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2497/100000, D Loss: 0.09828159958124161, G Loss: 4.2850728034973145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2498/100000, D Loss: 0.0767272487282753, G Loss: 4.675172805786133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2499/100000, D Loss: 0.09672433137893677, G Loss: 4.478079795837402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2500/100000, D Loss: 0.11139336600899696, G Loss: 4.106891632080078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2501/100000, D Loss: 0.12456972524523735, G Loss: 3.942429542541504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2502/100000, D Loss: 0.12085453793406487, G Loss: 4.326156139373779\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2503/100000, D Loss: 0.12841356545686722, G Loss: 4.305765151977539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2504/100000, D Loss: 0.17284582555294037, G Loss: 3.7291817665100098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2505/100000, D Loss: 0.1488674283027649, G Loss: 4.16471004486084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2506/100000, D Loss: 0.13983402401208878, G Loss: 4.2467241287231445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2507/100000, D Loss: 0.16902394592761993, G Loss: 3.9365768432617188\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2508/100000, D Loss: 0.11773084476590157, G Loss: 4.200294017791748\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2509/100000, D Loss: 0.1260225959122181, G Loss: 4.295702934265137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2510/100000, D Loss: 0.1603265032172203, G Loss: 3.796588897705078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2511/100000, D Loss: 0.09556237608194351, G Loss: 4.352099418640137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2512/100000, D Loss: 0.11286220327019691, G Loss: 4.436671733856201\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2513/100000, D Loss: 0.12297843396663666, G Loss: 3.9204037189483643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2514/100000, D Loss: 0.10643628239631653, G Loss: 4.0702972412109375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2515/100000, D Loss: 0.0955376923084259, G Loss: 4.495542526245117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2516/100000, D Loss: 0.1424321010708809, G Loss: 4.034392356872559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2517/100000, D Loss: 0.1670731082558632, G Loss: 3.777923107147217\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2518/100000, D Loss: 0.12903249263763428, G Loss: 4.221630096435547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2519/100000, D Loss: 0.12676972523331642, G Loss: 4.271116256713867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2520/100000, D Loss: 0.14126840233802795, G Loss: 3.7959418296813965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2521/100000, D Loss: 0.1448330208659172, G Loss: 3.903698444366455\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2522/100000, D Loss: 0.14565624296665192, G Loss: 4.143094539642334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2523/100000, D Loss: 0.16466272994875908, G Loss: 3.692483425140381\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2524/100000, D Loss: 0.15620417892932892, G Loss: 3.85123872756958\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2525/100000, D Loss: 0.13370558619499207, G Loss: 4.014074802398682\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2526/100000, D Loss: 0.13969770073890686, G Loss: 3.679234266281128\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2527/100000, D Loss: 0.1412620097398758, G Loss: 3.7659950256347656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2528/100000, D Loss: 0.11726903915405273, G Loss: 4.094202041625977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2529/100000, D Loss: 0.10560961440205574, G Loss: 3.9574193954467773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2530/100000, D Loss: 0.10194823145866394, G Loss: 3.7850914001464844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2531/100000, D Loss: 0.06867348030209541, G Loss: 4.283100128173828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2532/100000, D Loss: 0.08176864311099052, G Loss: 4.489162445068359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2533/100000, D Loss: 0.06698358617722988, G Loss: 4.365528106689453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2534/100000, D Loss: 0.05862918496131897, G Loss: 4.360161304473877\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2535/100000, D Loss: 0.08153493143618107, G Loss: 3.940822124481201\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2536/100000, D Loss: 0.07447849214076996, G Loss: 4.082172393798828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2537/100000, D Loss: 0.06649941392242908, G Loss: 4.512446403503418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2538/100000, D Loss: 0.09840953722596169, G Loss: 4.073146820068359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2539/100000, D Loss: 0.11287512630224228, G Loss: 3.687786102294922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2540/100000, D Loss: 0.09673739597201347, G Loss: 4.134796619415283\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2541/100000, D Loss: 0.10390038415789604, G Loss: 4.188068866729736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2542/100000, D Loss: 0.11947071179747581, G Loss: 3.873096466064453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2543/100000, D Loss: 0.12372003495693207, G Loss: 3.9051194190979004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2544/100000, D Loss: 0.13558070734143257, G Loss: 3.990009307861328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2545/100000, D Loss: 0.14256465807557106, G Loss: 3.828369140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2546/100000, D Loss: 0.12456107139587402, G Loss: 4.074154853820801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2547/100000, D Loss: 0.12474104017019272, G Loss: 4.118607044219971\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2548/100000, D Loss: 0.12256207317113876, G Loss: 4.077459335327148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2549/100000, D Loss: 0.11295266076922417, G Loss: 4.034266948699951\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2550/100000, D Loss: 0.12928713485598564, G Loss: 3.8138315677642822\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2551/100000, D Loss: 0.10496071726083755, G Loss: 4.141257286071777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2552/100000, D Loss: 0.11131955683231354, G Loss: 4.158755302429199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2553/100000, D Loss: 0.12142893299460411, G Loss: 3.9662060737609863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2554/100000, D Loss: 0.12621897086501122, G Loss: 4.119502544403076\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2555/100000, D Loss: 0.1061025969684124, G Loss: 4.339728832244873\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2556/100000, D Loss: 0.11861241981387138, G Loss: 4.041637897491455\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2557/100000, D Loss: 0.13917109742760658, G Loss: 3.766313076019287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2558/100000, D Loss: 0.13266664743423462, G Loss: 4.146824359893799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2559/100000, D Loss: 0.12056314572691917, G Loss: 4.44810676574707\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2560/100000, D Loss: 0.12451870366930962, G Loss: 3.8038949966430664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2561/100000, D Loss: 0.17691011726856232, G Loss: 3.7545440196990967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2562/100000, D Loss: 0.09083290211856365, G Loss: 4.60744571685791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2563/100000, D Loss: 0.10718625038862228, G Loss: 4.30515718460083\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2564/100000, D Loss: 0.10155907273292542, G Loss: 3.809950828552246\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2565/100000, D Loss: 0.08336576446890831, G Loss: 4.141298294067383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2566/100000, D Loss: 0.06834311410784721, G Loss: 4.598833084106445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2567/100000, D Loss: 0.08463248237967491, G Loss: 4.288949489593506\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2568/100000, D Loss: 0.11943214386701584, G Loss: 3.644578695297241\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2569/100000, D Loss: 0.08977577090263367, G Loss: 4.2653961181640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2570/100000, D Loss: 0.09741503559052944, G Loss: 4.50478458404541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2571/100000, D Loss: 0.09429024904966354, G Loss: 3.9789609909057617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2572/100000, D Loss: 0.0892437994480133, G Loss: 4.086883544921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2573/100000, D Loss: 0.09120217710733414, G Loss: 4.1628007888793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2574/100000, D Loss: 0.11023357510566711, G Loss: 4.040722846984863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2575/100000, D Loss: 0.06664241850376129, G Loss: 4.3998565673828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2576/100000, D Loss: 0.09068331867456436, G Loss: 4.161434173583984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2577/100000, D Loss: 0.07667510211467743, G Loss: 4.1491899490356445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2578/100000, D Loss: 0.0663049928843975, G Loss: 4.329435348510742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2579/100000, D Loss: 0.06355396471917629, G Loss: 4.3848114013671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2580/100000, D Loss: 0.08610827475786209, G Loss: 4.108729362487793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2581/100000, D Loss: 0.0638106968253851, G Loss: 4.434086799621582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2582/100000, D Loss: 0.05382724106311798, G Loss: 4.630688667297363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2583/100000, D Loss: 0.058561570942401886, G Loss: 4.75234842300415\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2584/100000, D Loss: 0.07136327773332596, G Loss: 4.227652549743652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2585/100000, D Loss: 0.06173295900225639, G Loss: 4.260116100311279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2586/100000, D Loss: 0.04798934608697891, G Loss: 4.730372428894043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2587/100000, D Loss: 0.04038651380687952, G Loss: 5.002135276794434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2588/100000, D Loss: 0.06028739735484123, G Loss: 4.400647163391113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2589/100000, D Loss: 0.07661695405840874, G Loss: 4.122453212738037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2590/100000, D Loss: 0.07053454220294952, G Loss: 4.563510894775391\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2591/100000, D Loss: 0.06232310086488724, G Loss: 4.880128860473633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2592/100000, D Loss: 0.0770709216594696, G Loss: 4.53567361831665\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2593/100000, D Loss: 0.09994502365589142, G Loss: 4.197068214416504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2594/100000, D Loss: 0.08701351657509804, G Loss: 4.551574230194092\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2595/100000, D Loss: 0.08046602457761765, G Loss: 4.71734619140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2596/100000, D Loss: 0.10514593124389648, G Loss: 4.053469657897949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2597/100000, D Loss: 0.09955614432692528, G Loss: 4.256742477416992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2598/100000, D Loss: 0.09346437454223633, G Loss: 4.792469024658203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2599/100000, D Loss: 0.0933304913341999, G Loss: 4.73159122467041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2600/100000, D Loss: 0.09181435033679008, G Loss: 4.458505630493164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2601/100000, D Loss: 0.08424971252679825, G Loss: 4.558474540710449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2602/100000, D Loss: 0.07431477680802345, G Loss: 4.782948017120361\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2603/100000, D Loss: 0.07565293088555336, G Loss: 4.896915435791016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2604/100000, D Loss: 0.08359329774975777, G Loss: 4.447242736816406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2605/100000, D Loss: 0.08238000422716141, G Loss: 4.518233299255371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2606/100000, D Loss: 0.08871088922023773, G Loss: 4.652859687805176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2607/100000, D Loss: 0.09674952551722527, G Loss: 4.708767890930176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2608/100000, D Loss: 0.12133285775780678, G Loss: 4.337939739227295\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2609/100000, D Loss: 0.10576027631759644, G Loss: 4.488588333129883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2610/100000, D Loss: 0.11661940068006516, G Loss: 4.594726085662842\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2611/100000, D Loss: 0.15468855202198029, G Loss: 4.220004081726074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2612/100000, D Loss: 0.1723037287592888, G Loss: 4.3673248291015625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2613/100000, D Loss: 0.13728022575378418, G Loss: 4.607414245605469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2614/100000, D Loss: 0.1504657007753849, G Loss: 4.411538124084473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2615/100000, D Loss: 0.1385115310549736, G Loss: 4.279365062713623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2616/100000, D Loss: 0.13860907033085823, G Loss: 4.791404724121094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2617/100000, D Loss: 0.15320880711078644, G Loss: 4.538663864135742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2618/100000, D Loss: 0.15005284547805786, G Loss: 4.3446431159973145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2619/100000, D Loss: 0.177087239921093, G Loss: 4.79848575592041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2620/100000, D Loss: 0.24178560078144073, G Loss: 4.499530792236328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2621/100000, D Loss: 0.19175851345062256, G Loss: 4.678120136260986\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2622/100000, D Loss: 0.2056288719177246, G Loss: 4.729000091552734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2623/100000, D Loss: 0.23253458738327026, G Loss: 4.859443187713623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2624/100000, D Loss: 0.2041233479976654, G Loss: 5.057440757751465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2625/100000, D Loss: 0.20697284489870071, G Loss: 5.135380744934082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2626/100000, D Loss: 0.15557759627699852, G Loss: 5.15280294418335\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2627/100000, D Loss: 0.17284385114908218, G Loss: 5.063698768615723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2628/100000, D Loss: 0.09644397348165512, G Loss: 5.610910415649414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2629/100000, D Loss: 0.08220780082046986, G Loss: 5.897287368774414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2630/100000, D Loss: 0.09111848846077919, G Loss: 5.305195331573486\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2631/100000, D Loss: 0.08881137892603874, G Loss: 5.440452575683594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2632/100000, D Loss: 0.057750532403588295, G Loss: 5.963372230529785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2633/100000, D Loss: 0.05519230663776398, G Loss: 6.310154438018799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2634/100000, D Loss: 0.0653783567249775, G Loss: 5.665426731109619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2635/100000, D Loss: 0.05155131407082081, G Loss: 5.314538955688477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2636/100000, D Loss: 0.06720365211367607, G Loss: 5.399226188659668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2637/100000, D Loss: 0.047138527035713196, G Loss: 6.049713134765625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2638/100000, D Loss: 0.05172930471599102, G Loss: 6.072450637817383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2639/100000, D Loss: 0.053587423637509346, G Loss: 6.057166576385498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2640/100000, D Loss: 0.053290361538529396, G Loss: 5.934797763824463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2641/100000, D Loss: 0.06147889420390129, G Loss: 5.7524027824401855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2642/100000, D Loss: 0.05668204091489315, G Loss: 5.721250534057617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2643/100000, D Loss: 0.050906769931316376, G Loss: 5.994773864746094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2644/100000, D Loss: 0.06883201561868191, G Loss: 5.849612236022949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2645/100000, D Loss: 0.06870431080460548, G Loss: 5.96372127532959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2646/100000, D Loss: 0.07441257312893867, G Loss: 6.2019829750061035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2647/100000, D Loss: 0.052726272493600845, G Loss: 6.458263397216797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2648/100000, D Loss: 0.08553586155176163, G Loss: 5.856495380401611\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2649/100000, D Loss: 0.06872541084885597, G Loss: 5.450916290283203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2650/100000, D Loss: 0.07544611766934395, G Loss: 5.843389511108398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2651/100000, D Loss: 0.053900957107543945, G Loss: 6.2852325439453125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2652/100000, D Loss: 0.08000895008444786, G Loss: 5.37272310256958\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2653/100000, D Loss: 0.10106402263045311, G Loss: 4.81511116027832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2654/100000, D Loss: 0.06817424297332764, G Loss: 5.319215774536133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2655/100000, D Loss: 0.048667317256331444, G Loss: 5.808900833129883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2656/100000, D Loss: 0.06110473908483982, G Loss: 5.420231819152832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2657/100000, D Loss: 0.05529114976525307, G Loss: 5.102705001831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2658/100000, D Loss: 0.04987924546003342, G Loss: 5.1010942459106445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2659/100000, D Loss: 0.042748916894197464, G Loss: 5.437936782836914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2660/100000, D Loss: 0.038017814978957176, G Loss: 5.744889259338379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2661/100000, D Loss: 0.04890510067343712, G Loss: 5.4820685386657715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2662/100000, D Loss: 0.046713393181562424, G Loss: 5.196113586425781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2663/100000, D Loss: 0.03727203235030174, G Loss: 5.420106410980225\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2664/100000, D Loss: 0.03656451776623726, G Loss: 5.420037269592285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2665/100000, D Loss: 0.04903760552406311, G Loss: 5.402742385864258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2666/100000, D Loss: 0.050484562292695045, G Loss: 5.050662994384766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2667/100000, D Loss: 0.0564106572419405, G Loss: 5.1501851081848145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2668/100000, D Loss: 0.047649746760725975, G Loss: 5.545065879821777\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2669/100000, D Loss: 0.047205667942762375, G Loss: 5.3509521484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2670/100000, D Loss: 0.053860604763031006, G Loss: 4.982142448425293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2671/100000, D Loss: 0.05713645741343498, G Loss: 4.902649879455566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2672/100000, D Loss: 0.05304010212421417, G Loss: 4.96119499206543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2673/100000, D Loss: 0.06892292760312557, G Loss: 4.863102912902832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2674/100000, D Loss: 0.07057810761034489, G Loss: 4.799530982971191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2675/100000, D Loss: 0.07298472709953785, G Loss: 4.7558135986328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2676/100000, D Loss: 0.06165556609630585, G Loss: 4.968987464904785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2677/100000, D Loss: 0.05699807591736317, G Loss: 5.16621208190918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2678/100000, D Loss: 0.08107536472380161, G Loss: 4.797657012939453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2679/100000, D Loss: 0.0660870298743248, G Loss: 4.959066867828369\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2680/100000, D Loss: 0.05838088318705559, G Loss: 5.269440650939941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2681/100000, D Loss: 0.07227443531155586, G Loss: 5.017567157745361\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2682/100000, D Loss: 0.06613107956945896, G Loss: 4.912718772888184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2683/100000, D Loss: 0.06157594732940197, G Loss: 5.192819118499756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2684/100000, D Loss: 0.051050158217549324, G Loss: 5.41701602935791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2685/100000, D Loss: 0.042108336463570595, G Loss: 5.3573431968688965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2686/100000, D Loss: 0.054874252527952194, G Loss: 4.992386817932129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2687/100000, D Loss: 0.05916447006165981, G Loss: 5.016692638397217\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2688/100000, D Loss: 0.07704486697912216, G Loss: 4.91170072555542\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2689/100000, D Loss: 0.06713113188743591, G Loss: 5.066537857055664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2690/100000, D Loss: 0.09637913852930069, G Loss: 4.868951797485352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2691/100000, D Loss: 0.09935350343585014, G Loss: 5.09269905090332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2692/100000, D Loss: 0.11732790619134903, G Loss: 5.107371807098389\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2693/100000, D Loss: 0.13547828793525696, G Loss: 4.977932929992676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2694/100000, D Loss: 0.1483118012547493, G Loss: 5.324831485748291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2695/100000, D Loss: 0.16097725182771683, G Loss: 5.286312580108643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2696/100000, D Loss: 0.2019410878419876, G Loss: 5.296018600463867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2697/100000, D Loss: 0.2414793074131012, G Loss: 5.151224136352539\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2698/100000, D Loss: 0.24068200588226318, G Loss: 5.730676651000977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2699/100000, D Loss: 0.25674770772457123, G Loss: 5.829965114593506\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2700/100000, D Loss: 0.3351920545101166, G Loss: 5.883700847625732\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2701/100000, D Loss: 0.2512076646089554, G Loss: 6.0028486251831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2702/100000, D Loss: 0.272702157497406, G Loss: 6.337645530700684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2703/100000, D Loss: 0.2255689576268196, G Loss: 6.510689735412598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2704/100000, D Loss: 0.1835382580757141, G Loss: 6.314184188842773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2705/100000, D Loss: 0.17132993787527084, G Loss: 7.158926010131836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2706/100000, D Loss: 0.1697278395295143, G Loss: 7.501613616943359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2707/100000, D Loss: 0.13233603164553642, G Loss: 6.879665851593018\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2708/100000, D Loss: 0.10994041338562965, G Loss: 6.7215704917907715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2709/100000, D Loss: 0.07436293736100197, G Loss: 7.1402997970581055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2710/100000, D Loss: 0.05831984058022499, G Loss: 6.943078994750977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2711/100000, D Loss: 0.06048520281910896, G Loss: 6.777622222900391\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2712/100000, D Loss: 0.05955737270414829, G Loss: 6.657925605773926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2713/100000, D Loss: 0.06099233590066433, G Loss: 6.990955829620361\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2714/100000, D Loss: 0.06632968410849571, G Loss: 7.165854454040527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2715/100000, D Loss: 0.1131700724363327, G Loss: 6.5442962646484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2716/100000, D Loss: 0.13786789029836655, G Loss: 6.605757713317871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2717/100000, D Loss: 0.1551448553800583, G Loss: 6.735727310180664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2718/100000, D Loss: 0.15998592972755432, G Loss: 6.736075401306152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2719/100000, D Loss: 0.26577216386795044, G Loss: 6.00948429107666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2720/100000, D Loss: 0.21171998977661133, G Loss: 6.410281181335449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2721/100000, D Loss: 0.19644494354724884, G Loss: 6.77573823928833\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2722/100000, D Loss: 0.18839799612760544, G Loss: 6.342232704162598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2723/100000, D Loss: 0.19305846095085144, G Loss: 5.989694118499756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2724/100000, D Loss: 0.1354823112487793, G Loss: 6.387849807739258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2725/100000, D Loss: 0.10876581817865372, G Loss: 6.808721542358398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2726/100000, D Loss: 0.10764099471271038, G Loss: 6.280298233032227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2727/100000, D Loss: 0.10595574229955673, G Loss: 5.838061332702637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2728/100000, D Loss: 0.05942924506962299, G Loss: 6.081071376800537\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2729/100000, D Loss: 0.06284720823168755, G Loss: 6.227548599243164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2730/100000, D Loss: 0.06876015290617943, G Loss: 6.385659217834473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2731/100000, D Loss: 0.0681220032274723, G Loss: 6.046210289001465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2732/100000, D Loss: 0.05326089449226856, G Loss: 6.034215927124023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2733/100000, D Loss: 0.07183824479579926, G Loss: 6.183874130249023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2734/100000, D Loss: 0.06344303116202354, G Loss: 5.79915189743042\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2735/100000, D Loss: 0.06571309268474579, G Loss: 5.792080879211426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2736/100000, D Loss: 0.08339286968111992, G Loss: 6.06694221496582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2737/100000, D Loss: 0.068311782553792, G Loss: 6.348494529724121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2738/100000, D Loss: 0.09118345379829407, G Loss: 6.11896276473999\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2739/100000, D Loss: 0.08134885877370834, G Loss: 6.043795108795166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2740/100000, D Loss: 0.11738330870866776, G Loss: 5.867341995239258\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2741/100000, D Loss: 0.0981772392988205, G Loss: 6.087656021118164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2742/100000, D Loss: 0.1330467239022255, G Loss: 6.018404006958008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2743/100000, D Loss: 0.12999515235424042, G Loss: 5.558722019195557\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2744/100000, D Loss: 0.12836800143122673, G Loss: 5.419584274291992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2745/100000, D Loss: 0.1321817710995674, G Loss: 5.8940019607543945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2746/100000, D Loss: 0.13387813791632652, G Loss: 5.579009532928467\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2747/100000, D Loss: 0.1447814702987671, G Loss: 5.518976211547852\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2748/100000, D Loss: 0.1386181265115738, G Loss: 5.418776512145996\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2749/100000, D Loss: 0.1712559461593628, G Loss: 5.219336986541748\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2750/100000, D Loss: 0.21528679132461548, G Loss: 5.215142250061035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2751/100000, D Loss: 0.1676449179649353, G Loss: 5.385165214538574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2752/100000, D Loss: 0.2252482920885086, G Loss: 5.2567138671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2753/100000, D Loss: 0.18549317121505737, G Loss: 5.349035263061523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2754/100000, D Loss: 0.20960035920143127, G Loss: 4.933018684387207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2755/100000, D Loss: 0.20874876528978348, G Loss: 5.539191246032715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2756/100000, D Loss: 0.19852983951568604, G Loss: 5.450307369232178\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2757/100000, D Loss: 0.20598997175693512, G Loss: 5.383171558380127\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2758/100000, D Loss: 0.17849363386631012, G Loss: 5.792336463928223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2759/100000, D Loss: 0.2161518782377243, G Loss: 5.560020446777344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2760/100000, D Loss: 0.21723227202892303, G Loss: 5.070500373840332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2761/100000, D Loss: 0.20071150362491608, G Loss: 5.610222339630127\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2762/100000, D Loss: 0.21536223590373993, G Loss: 5.540325164794922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2763/100000, D Loss: 0.2765577435493469, G Loss: 4.956973075866699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2764/100000, D Loss: 0.2592109143733978, G Loss: 5.173426151275635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2765/100000, D Loss: 0.2510747164487839, G Loss: 5.5017242431640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2766/100000, D Loss: 0.28884536772966385, G Loss: 5.239124298095703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2767/100000, D Loss: 0.2734633907675743, G Loss: 5.322719573974609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2768/100000, D Loss: 0.22890697419643402, G Loss: 5.876125335693359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2769/100000, D Loss: 0.18827765434980392, G Loss: 5.830754280090332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2770/100000, D Loss: 0.19856172055006027, G Loss: 5.668085098266602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2771/100000, D Loss: 0.1859048381447792, G Loss: 5.763005256652832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2772/100000, D Loss: 0.15273188054561615, G Loss: 6.517333984375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2773/100000, D Loss: 0.17103946954011917, G Loss: 5.717455863952637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2774/100000, D Loss: 0.20847618579864502, G Loss: 4.912336349487305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2775/100000, D Loss: 0.15245910361409187, G Loss: 6.092950344085693\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2776/100000, D Loss: 0.14334920048713684, G Loss: 6.3045854568481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2777/100000, D Loss: 0.19009606540203094, G Loss: 4.99937105178833\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2778/100000, D Loss: 0.16335930302739143, G Loss: 5.651753902435303\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2779/100000, D Loss: 0.1067602913826704, G Loss: 6.265449523925781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2780/100000, D Loss: 0.13762624561786652, G Loss: 5.200284004211426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2781/100000, D Loss: 0.15406887978315353, G Loss: 4.942070007324219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2782/100000, D Loss: 0.08621501177549362, G Loss: 5.967970371246338\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2783/100000, D Loss: 0.12281762808561325, G Loss: 5.256617546081543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2784/100000, D Loss: 0.11699384078383446, G Loss: 4.500322341918945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2785/100000, D Loss: 0.0990338921546936, G Loss: 5.062875270843506\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2786/100000, D Loss: 0.08909433335065842, G Loss: 5.25842809677124\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2787/100000, D Loss: 0.10898095369338989, G Loss: 4.391115188598633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2788/100000, D Loss: 0.11280912160873413, G Loss: 4.387633323669434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2789/100000, D Loss: 0.06331093795597553, G Loss: 5.131155967712402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2790/100000, D Loss: 0.0836508497595787, G Loss: 4.685757160186768\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2791/100000, D Loss: 0.11740816384553909, G Loss: 4.056387901306152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2792/100000, D Loss: 0.09857133775949478, G Loss: 4.494707107543945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2793/100000, D Loss: 0.07773192599415779, G Loss: 4.94111442565918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2794/100000, D Loss: 0.12204263731837273, G Loss: 4.18789005279541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2795/100000, D Loss: 0.1418500319123268, G Loss: 4.145105838775635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2796/100000, D Loss: 0.09243898466229439, G Loss: 4.825784683227539\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2797/100000, D Loss: 0.122813630849123, G Loss: 4.154567718505859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2798/100000, D Loss: 0.1415657103061676, G Loss: 3.9394497871398926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2799/100000, D Loss: 0.12030846253037453, G Loss: 4.244547367095947\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2800/100000, D Loss: 0.13269462436437607, G Loss: 4.202480316162109\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2801/100000, D Loss: 0.1306486576795578, G Loss: 3.9650697708129883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2802/100000, D Loss: 0.14770174771547318, G Loss: 3.862466335296631\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2803/100000, D Loss: 0.1562354788184166, G Loss: 4.125587463378906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2804/100000, D Loss: 0.15111888200044632, G Loss: 4.12406063079834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2805/100000, D Loss: 0.14201252907514572, G Loss: 4.010523796081543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2806/100000, D Loss: 0.13633379712700844, G Loss: 4.388908863067627\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2807/100000, D Loss: 0.174754548817873, G Loss: 3.9258852005004883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2808/100000, D Loss: 0.1955321878194809, G Loss: 4.159605026245117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2809/100000, D Loss: 0.09796380810439587, G Loss: 4.961857318878174\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2810/100000, D Loss: 0.16750149801373482, G Loss: 3.8687267303466797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2811/100000, D Loss: 0.19441784918308258, G Loss: 4.192657470703125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2812/100000, D Loss: 0.11376865766942501, G Loss: 4.869870662689209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2813/100000, D Loss: 0.19165509194135666, G Loss: 3.501624822616577\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2814/100000, D Loss: 0.1844245120882988, G Loss: 4.628290176391602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2815/100000, D Loss: 0.1358235366642475, G Loss: 5.122808933258057\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2816/100000, D Loss: 0.1805352009832859, G Loss: 3.6149702072143555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2817/100000, D Loss: 0.22731423377990723, G Loss: 4.598712921142578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2818/100000, D Loss: 0.15881894528865814, G Loss: 5.163027763366699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2819/100000, D Loss: 0.24098056554794312, G Loss: 3.596649408340454\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2820/100000, D Loss: 0.2089243307709694, G Loss: 4.702592849731445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2821/100000, D Loss: 0.16802488826215267, G Loss: 5.16322135925293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2822/100000, D Loss: 0.25446145236492157, G Loss: 3.6701879501342773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2823/100000, D Loss: 0.25565584003925323, G Loss: 4.840891361236572\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2824/100000, D Loss: 0.1995622217655182, G Loss: 5.633530616760254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2825/100000, D Loss: 0.34120795130729675, G Loss: 3.7312088012695312\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2826/100000, D Loss: 0.33724523335695267, G Loss: 5.090363502502441\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2827/100000, D Loss: 0.27771036326885223, G Loss: 6.1892852783203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2828/100000, D Loss: 0.5233924388885498, G Loss: 3.843400001525879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2829/100000, D Loss: 0.409538097679615, G Loss: 5.512284755706787\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2830/100000, D Loss: 0.29210177063941956, G Loss: 7.220887660980225\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2831/100000, D Loss: 0.5292082130908966, G Loss: 4.532765865325928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2832/100000, D Loss: 0.45095470547676086, G Loss: 5.235993385314941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2833/100000, D Loss: 0.23744986951351166, G Loss: 7.506135940551758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2834/100000, D Loss: 0.2916877865791321, G Loss: 7.466954231262207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2835/100000, D Loss: 0.3460862636566162, G Loss: 5.700911045074463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2836/100000, D Loss: 0.19071978703141212, G Loss: 6.7114033699035645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2837/100000, D Loss: 0.10629411786794662, G Loss: 8.34382152557373\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2838/100000, D Loss: 0.16168782487511635, G Loss: 7.307464599609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2839/100000, D Loss: 0.11831238493323326, G Loss: 6.2118682861328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2840/100000, D Loss: 0.08451100066304207, G Loss: 6.056220054626465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2841/100000, D Loss: 0.04832552932202816, G Loss: 7.226754188537598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2842/100000, D Loss: 0.04015118535608053, G Loss: 7.792656898498535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2843/100000, D Loss: 0.08614030480384827, G Loss: 7.271162033081055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2844/100000, D Loss: 0.07390606962144375, G Loss: 6.743925094604492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2845/100000, D Loss: 0.07419170625507832, G Loss: 6.65824031829834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2846/100000, D Loss: 0.04763047769665718, G Loss: 7.210509300231934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2847/100000, D Loss: 0.06445523537695408, G Loss: 7.382454872131348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2848/100000, D Loss: 0.06821361556649208, G Loss: 7.335056304931641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2849/100000, D Loss: 0.09900631383061409, G Loss: 6.6041154861450195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2850/100000, D Loss: 0.11355112493038177, G Loss: 6.356103897094727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2851/100000, D Loss: 0.09634159505367279, G Loss: 6.67237663269043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2852/100000, D Loss: 0.0768118929117918, G Loss: 6.800892353057861\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2853/100000, D Loss: 0.08388189971446991, G Loss: 6.583957672119141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2854/100000, D Loss: 0.09029515460133553, G Loss: 5.953295707702637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2855/100000, D Loss: 0.07524002715945244, G Loss: 5.997024059295654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2856/100000, D Loss: 0.06866007670760155, G Loss: 6.473793029785156\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2857/100000, D Loss: 0.06506515294313431, G Loss: 6.406271934509277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2858/100000, D Loss: 0.07044312730431557, G Loss: 5.953129768371582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2859/100000, D Loss: 0.06470755487680435, G Loss: 5.970515251159668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2860/100000, D Loss: 0.06348629668354988, G Loss: 5.90792179107666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2861/100000, D Loss: 0.07812917232513428, G Loss: 5.809601783752441\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2862/100000, D Loss: 0.08412599563598633, G Loss: 5.679296493530273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2863/100000, D Loss: 0.07844288647174835, G Loss: 5.93552303314209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2864/100000, D Loss: 0.06986648216843605, G Loss: 6.144223213195801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2865/100000, D Loss: 0.09673893079161644, G Loss: 5.524859428405762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2866/100000, D Loss: 0.09775189310312271, G Loss: 5.3535237312316895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2867/100000, D Loss: 0.07318166643381119, G Loss: 5.655433654785156\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2868/100000, D Loss: 0.08243940025568008, G Loss: 5.556029319763184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2869/100000, D Loss: 0.10701050236821175, G Loss: 5.207871437072754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2870/100000, D Loss: 0.08909760043025017, G Loss: 5.331951141357422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2871/100000, D Loss: 0.09377846121788025, G Loss: 5.714303016662598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2872/100000, D Loss: 0.08481928333640099, G Loss: 5.688179969787598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2873/100000, D Loss: 0.07452324777841568, G Loss: 5.432273864746094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2874/100000, D Loss: 0.09992726892232895, G Loss: 5.182110786437988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2875/100000, D Loss: 0.11710219457745552, G Loss: 5.514209747314453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2876/100000, D Loss: 0.10089008882641792, G Loss: 5.852324962615967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2877/100000, D Loss: 0.12999888509511948, G Loss: 5.531862735748291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2878/100000, D Loss: 0.12387360632419586, G Loss: 5.690003395080566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2879/100000, D Loss: 0.1343606635928154, G Loss: 5.764228343963623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2880/100000, D Loss: 0.12720604613423347, G Loss: 6.089664936065674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2881/100000, D Loss: 0.15082097798585892, G Loss: 6.257755279541016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2882/100000, D Loss: 0.18207882344722748, G Loss: 5.761185646057129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2883/100000, D Loss: 0.16303713619709015, G Loss: 6.268153190612793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2884/100000, D Loss: 0.13690395653247833, G Loss: 6.958123683929443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2885/100000, D Loss: 0.16074207425117493, G Loss: 6.7820143699646\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2886/100000, D Loss: 0.17546851933002472, G Loss: 6.361058712005615\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2887/100000, D Loss: 0.1559511125087738, G Loss: 6.8415327072143555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2888/100000, D Loss: 0.13479596748948097, G Loss: 6.990330696105957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2889/100000, D Loss: 0.17669054865837097, G Loss: 7.2145538330078125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2890/100000, D Loss: 0.15642361342906952, G Loss: 7.37220573425293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2891/100000, D Loss: 0.14389553666114807, G Loss: 7.234781742095947\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2892/100000, D Loss: 0.14876005798578262, G Loss: 6.756635665893555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2893/100000, D Loss: 0.14229165017604828, G Loss: 7.015751838684082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2894/100000, D Loss: 0.1662466675043106, G Loss: 7.33676815032959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2895/100000, D Loss: 0.16658228635787964, G Loss: 6.97946310043335\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2896/100000, D Loss: 0.17066095769405365, G Loss: 6.559512138366699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2897/100000, D Loss: 0.14955943822860718, G Loss: 6.750783920288086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2898/100000, D Loss: 0.16089896857738495, G Loss: 6.961603164672852\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2899/100000, D Loss: 0.12677127122879028, G Loss: 6.6124138832092285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2900/100000, D Loss: 0.13680804520845413, G Loss: 5.968716621398926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2901/100000, D Loss: 0.10397622734308243, G Loss: 6.1657304763793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2902/100000, D Loss: 0.09807249903678894, G Loss: 6.060572624206543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2903/100000, D Loss: 0.09317882359027863, G Loss: 5.642714500427246\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2904/100000, D Loss: 0.09402945265173912, G Loss: 5.312732696533203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2905/100000, D Loss: 0.10214850306510925, G Loss: 5.34226655960083\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2906/100000, D Loss: 0.1161937266588211, G Loss: 5.289158821105957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2907/100000, D Loss: 0.07988347858190536, G Loss: 5.212224006652832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2908/100000, D Loss: 0.10130871459841728, G Loss: 5.107003211975098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2909/100000, D Loss: 0.10179251059889793, G Loss: 4.7965779304504395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2910/100000, D Loss: 0.1251566857099533, G Loss: 4.456555366516113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2911/100000, D Loss: 0.13746896386146545, G Loss: 4.800071716308594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2912/100000, D Loss: 0.11585091054439545, G Loss: 4.944706916809082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2913/100000, D Loss: 0.11642588675022125, G Loss: 4.897805213928223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2914/100000, D Loss: 0.1300939917564392, G Loss: 4.503524303436279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2915/100000, D Loss: 0.12028945609927177, G Loss: 4.639895915985107\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 2916/100000, D Loss: 0.10610223561525345, G Loss: 4.919017791748047\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2917/100000, D Loss: 0.12351541221141815, G Loss: 4.682619571685791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2918/100000, D Loss: 0.1316828690469265, G Loss: 4.431347846984863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2919/100000, D Loss: 0.12411458045244217, G Loss: 4.433465957641602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2920/100000, D Loss: 0.14168832451105118, G Loss: 4.6187357902526855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2921/100000, D Loss: 0.1343158297240734, G Loss: 4.482171058654785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2922/100000, D Loss: 0.15907295793294907, G Loss: 4.263223648071289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2923/100000, D Loss: 0.14539293199777603, G Loss: 4.569686412811279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2924/100000, D Loss: 0.1160978302359581, G Loss: 4.802748203277588\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2925/100000, D Loss: 0.1221044771373272, G Loss: 4.287363529205322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2926/100000, D Loss: 0.13806036114692688, G Loss: 4.120576858520508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2927/100000, D Loss: 0.09480585157871246, G Loss: 4.665838241577148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2928/100000, D Loss: 0.08373503386974335, G Loss: 4.824228286743164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2929/100000, D Loss: 0.10573721304535866, G Loss: 4.294005393981934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2930/100000, D Loss: 0.10795822739601135, G Loss: 4.310463905334473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2931/100000, D Loss: 0.06543034687638283, G Loss: 4.916162490844727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2932/100000, D Loss: 0.07939054444432259, G Loss: 4.7195353507995605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2933/100000, D Loss: 0.09552031755447388, G Loss: 4.176931381225586\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2934/100000, D Loss: 0.11777159199118614, G Loss: 4.161454677581787\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2935/100000, D Loss: 0.08716561272740364, G Loss: 4.641171455383301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2936/100000, D Loss: 0.11566950008273125, G Loss: 4.274710655212402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2937/100000, D Loss: 0.12857700139284134, G Loss: 4.183253288269043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2938/100000, D Loss: 0.09547720849514008, G Loss: 4.764402389526367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2939/100000, D Loss: 0.11235510930418968, G Loss: 4.453583240509033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2940/100000, D Loss: 0.18424731492996216, G Loss: 4.07174825668335\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2941/100000, D Loss: 0.14019297063350677, G Loss: 4.601958751678467\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2942/100000, D Loss: 0.14521940425038338, G Loss: 4.372010707855225\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2943/100000, D Loss: 0.1688251718878746, G Loss: 4.005770206451416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2944/100000, D Loss: 0.1878088265657425, G Loss: 4.418988227844238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2945/100000, D Loss: 0.1330908089876175, G Loss: 4.783495903015137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2946/100000, D Loss: 0.18368137627840042, G Loss: 4.180641174316406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2947/100000, D Loss: 0.1918497085571289, G Loss: 4.20223331451416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2948/100000, D Loss: 0.15460741519927979, G Loss: 4.871453285217285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2949/100000, D Loss: 0.16755525022745132, G Loss: 4.465471267700195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2950/100000, D Loss: 0.17628653347492218, G Loss: 4.161229610443115\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2951/100000, D Loss: 0.16085543483495712, G Loss: 4.609192848205566\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 2952/100000, D Loss: 0.15949194878339767, G Loss: 4.552623748779297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2953/100000, D Loss: 0.16281691938638687, G Loss: 4.341174602508545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2954/100000, D Loss: 0.15607930719852448, G Loss: 4.426338195800781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2955/100000, D Loss: 0.146161038428545, G Loss: 4.515983581542969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2956/100000, D Loss: 0.14351430162787437, G Loss: 4.252209186553955\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2957/100000, D Loss: 0.23639251291751862, G Loss: 4.274148941040039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2958/100000, D Loss: 0.14011907577514648, G Loss: 4.666140556335449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2959/100000, D Loss: 0.16982406750321388, G Loss: 4.024444580078125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2960/100000, D Loss: 0.1388198584318161, G Loss: 4.1536712646484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2961/100000, D Loss: 0.15835198014974594, G Loss: 4.3588361740112305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2962/100000, D Loss: 0.1362219974398613, G Loss: 4.4125471115112305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2963/100000, D Loss: 0.1532665640115738, G Loss: 3.999363422393799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2964/100000, D Loss: 0.1207212433218956, G Loss: 4.241765975952148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2965/100000, D Loss: 0.11158307641744614, G Loss: 4.6135406494140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2966/100000, D Loss: 0.12339316308498383, G Loss: 4.070550918579102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2967/100000, D Loss: 0.1254165843129158, G Loss: 4.1386494636535645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2968/100000, D Loss: 0.11238572001457214, G Loss: 4.5048112869262695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2969/100000, D Loss: 0.1560956984758377, G Loss: 4.1222639083862305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2970/100000, D Loss: 0.15102536231279373, G Loss: 3.935999870300293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2971/100000, D Loss: 0.10175637155771255, G Loss: 4.500237464904785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2972/100000, D Loss: 0.14216570556163788, G Loss: 4.053549766540527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2973/100000, D Loss: 0.16309282928705215, G Loss: 3.992868423461914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2974/100000, D Loss: 0.14640852063894272, G Loss: 4.197403907775879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2975/100000, D Loss: 0.1823771931231022, G Loss: 3.8822073936462402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2976/100000, D Loss: 0.23335278779268265, G Loss: 3.839482545852661\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2977/100000, D Loss: 0.1910833939909935, G Loss: 4.028717517852783\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2978/100000, D Loss: 0.17566394805908203, G Loss: 3.907036304473877\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2979/100000, D Loss: 0.17366597056388855, G Loss: 3.9539718627929688\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2980/100000, D Loss: 0.19594700634479523, G Loss: 3.902447462081909\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2981/100000, D Loss: 0.17467983812093735, G Loss: 3.9508414268493652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2982/100000, D Loss: 0.16260989010334015, G Loss: 3.991283416748047\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2983/100000, D Loss: 0.1339733973145485, G Loss: 4.302227973937988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2984/100000, D Loss: 0.17119262367486954, G Loss: 4.0449419021606445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2985/100000, D Loss: 0.15062225610017776, G Loss: 4.39405632019043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2986/100000, D Loss: 0.12984854727983475, G Loss: 4.598259449005127\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2987/100000, D Loss: 0.1762252375483513, G Loss: 3.8083059787750244\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2988/100000, D Loss: 0.13906195014715195, G Loss: 4.5021562576293945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2989/100000, D Loss: 0.1372784823179245, G Loss: 4.597128868103027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2990/100000, D Loss: 0.20603851228952408, G Loss: 3.6464407444000244\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2991/100000, D Loss: 0.1920211985707283, G Loss: 4.241935729980469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2992/100000, D Loss: 0.16312488913536072, G Loss: 4.4923529624938965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2993/100000, D Loss: 0.24372150748968124, G Loss: 3.7047653198242188\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2994/100000, D Loss: 0.26392343640327454, G Loss: 4.443525314331055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2995/100000, D Loss: 0.2598039321601391, G Loss: 4.271127700805664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2996/100000, D Loss: 0.34830090403556824, G Loss: 3.8326022624969482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2997/100000, D Loss: 0.30644190311431885, G Loss: 4.549304008483887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2998/100000, D Loss: 0.35819798707962036, G Loss: 3.934757709503174\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 2999/100000, D Loss: 0.32351963222026825, G Loss: 4.145967960357666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3000/100000, D Loss: 0.3419092744588852, G Loss: 3.9984850883483887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3001/100000, D Loss: 0.3589043915271759, G Loss: 3.770064353942871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3002/100000, D Loss: 0.2817908078432083, G Loss: 4.16972541809082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3003/100000, D Loss: 0.2724507451057434, G Loss: 3.8517978191375732\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3004/100000, D Loss: 0.28098492324352264, G Loss: 3.9782166481018066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3005/100000, D Loss: 0.23433299362659454, G Loss: 4.313593864440918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3006/100000, D Loss: 0.20257830619812012, G Loss: 3.8695552349090576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3007/100000, D Loss: 0.20253672450780869, G Loss: 4.121384620666504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3008/100000, D Loss: 0.16466492787003517, G Loss: 4.414716720581055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3009/100000, D Loss: 0.19065368548035622, G Loss: 3.8992185592651367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3010/100000, D Loss: 0.2053247094154358, G Loss: 3.999077558517456\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3011/100000, D Loss: 0.15517592802643776, G Loss: 4.58392333984375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3012/100000, D Loss: 0.19816096872091293, G Loss: 3.999178886413574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3013/100000, D Loss: 0.19634567201137543, G Loss: 3.871661424636841\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3014/100000, D Loss: 0.17438089847564697, G Loss: 4.356597900390625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3015/100000, D Loss: 0.17577100172638893, G Loss: 4.3358635902404785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3016/100000, D Loss: 0.19600678980350494, G Loss: 3.8830206394195557\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3017/100000, D Loss: 0.17770802229642868, G Loss: 4.393184661865234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3018/100000, D Loss: 0.14807059615850449, G Loss: 5.037160396575928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3019/100000, D Loss: 0.15900574997067451, G Loss: 4.386544227600098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3020/100000, D Loss: 0.16841021180152893, G Loss: 4.1936469078063965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3021/100000, D Loss: 0.16159364581108093, G Loss: 4.4762701988220215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3022/100000, D Loss: 0.19437187910079956, G Loss: 4.322277069091797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3023/100000, D Loss: 0.15853457525372505, G Loss: 4.669591903686523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3024/100000, D Loss: 0.1636849194765091, G Loss: 4.5653486251831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3025/100000, D Loss: 0.21876013278961182, G Loss: 4.6028594970703125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3026/100000, D Loss: 0.18013691902160645, G Loss: 4.544276237487793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3027/100000, D Loss: 0.12772560864686966, G Loss: 5.067190170288086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3028/100000, D Loss: 0.182791106402874, G Loss: 5.126453876495361\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3029/100000, D Loss: 0.1759314239025116, G Loss: 4.802670955657959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3030/100000, D Loss: 0.18253402411937714, G Loss: 5.270983695983887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3031/100000, D Loss: 0.17591417580842972, G Loss: 5.553266525268555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3032/100000, D Loss: 0.15949437022209167, G Loss: 6.062429904937744\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3033/100000, D Loss: 0.14001712948083878, G Loss: 6.611124515533447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3034/100000, D Loss: 0.14807046204805374, G Loss: 6.525339126586914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3035/100000, D Loss: 0.13258103653788567, G Loss: 6.7217864990234375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3036/100000, D Loss: 0.11254188045859337, G Loss: 6.976157188415527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3037/100000, D Loss: 0.13634176552295685, G Loss: 7.49069881439209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3038/100000, D Loss: 0.16828884184360504, G Loss: 7.137590408325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3039/100000, D Loss: 0.1843334287405014, G Loss: 6.951525688171387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3040/100000, D Loss: 0.19290528446435928, G Loss: 6.954355239868164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3041/100000, D Loss: 0.16535358875989914, G Loss: 7.090383529663086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3042/100000, D Loss: 0.18806720525026321, G Loss: 7.074731826782227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3043/100000, D Loss: 0.19893145561218262, G Loss: 7.0071845054626465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3044/100000, D Loss: 0.1712350696325302, G Loss: 6.654104709625244\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3045/100000, D Loss: 0.14839499443769455, G Loss: 6.661102294921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3046/100000, D Loss: 0.16735056042671204, G Loss: 6.461129665374756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3047/100000, D Loss: 0.12316646799445152, G Loss: 6.070846080780029\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3048/100000, D Loss: 0.1140751987695694, G Loss: 5.716749668121338\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3049/100000, D Loss: 0.08768777176737785, G Loss: 5.579683303833008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3050/100000, D Loss: 0.07736818492412567, G Loss: 5.682513236999512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3051/100000, D Loss: 0.07284723594784737, G Loss: 5.537378311157227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3052/100000, D Loss: 0.0736524760723114, G Loss: 5.113762855529785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3053/100000, D Loss: 0.07101374492049217, G Loss: 5.123408317565918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3054/100000, D Loss: 0.06136777997016907, G Loss: 5.449925422668457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3055/100000, D Loss: 0.06466103158891201, G Loss: 5.689723968505859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3056/100000, D Loss: 0.07017142698168755, G Loss: 5.500000953674316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3057/100000, D Loss: 0.09102815017104149, G Loss: 4.873257637023926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3058/100000, D Loss: 0.08760736137628555, G Loss: 4.901461601257324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3059/100000, D Loss: 0.0780474804341793, G Loss: 5.350079536437988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3060/100000, D Loss: 0.10755182802677155, G Loss: 5.138572692871094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3061/100000, D Loss: 0.09774800017476082, G Loss: 4.961164474487305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3062/100000, D Loss: 0.10113628581166267, G Loss: 4.5849199295043945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3063/100000, D Loss: 0.09731300920248032, G Loss: 4.797210693359375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3064/100000, D Loss: 0.10536878928542137, G Loss: 4.915442943572998\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3065/100000, D Loss: 0.11601532250642776, G Loss: 4.696263313293457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3066/100000, D Loss: 0.13588108122348785, G Loss: 4.550274848937988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3067/100000, D Loss: 0.10905585438013077, G Loss: 4.744046211242676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3068/100000, D Loss: 0.10969562828540802, G Loss: 4.649491310119629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3069/100000, D Loss: 0.14136747270822525, G Loss: 4.305902481079102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3070/100000, D Loss: 0.12378421425819397, G Loss: 4.281520843505859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3071/100000, D Loss: 0.1282833255827427, G Loss: 4.491352081298828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3072/100000, D Loss: 0.12141580134630203, G Loss: 4.5058979988098145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3073/100000, D Loss: 0.12214361131191254, G Loss: 4.287841796875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3074/100000, D Loss: 0.13028983771800995, G Loss: 4.284805774688721\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3075/100000, D Loss: 0.12595577538013458, G Loss: 4.549328804016113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3076/100000, D Loss: 0.1413070745766163, G Loss: 4.3648786544799805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3077/100000, D Loss: 0.1485515534877777, G Loss: 4.0283050537109375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3078/100000, D Loss: 0.14674222469329834, G Loss: 4.136799335479736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3079/100000, D Loss: 0.1574854776263237, G Loss: 4.137228012084961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3080/100000, D Loss: 0.1874990314245224, G Loss: 3.9359142780303955\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3081/100000, D Loss: 0.1733233630657196, G Loss: 4.036279678344727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3082/100000, D Loss: 0.20877157896757126, G Loss: 4.1596574783325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3083/100000, D Loss: 0.185246080160141, G Loss: 3.989072322845459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3084/100000, D Loss: 0.21072621643543243, G Loss: 4.109257698059082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3085/100000, D Loss: 0.21704115718603134, G Loss: 4.322513103485107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3086/100000, D Loss: 0.23847375810146332, G Loss: 4.412722587585449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3087/100000, D Loss: 0.24830907583236694, G Loss: 4.464381217956543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3088/100000, D Loss: 0.2080864980816841, G Loss: 4.895071983337402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3089/100000, D Loss: 0.2332465723156929, G Loss: 4.903326511383057\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3090/100000, D Loss: 0.21188119053840637, G Loss: 4.650669097900391\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3091/100000, D Loss: 0.17852338403463364, G Loss: 5.380169868469238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3092/100000, D Loss: 0.15706457197666168, G Loss: 5.120170593261719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3093/100000, D Loss: 0.16989143192768097, G Loss: 5.408123016357422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3094/100000, D Loss: 0.20762310922145844, G Loss: 4.8753662109375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3095/100000, D Loss: 0.19178007543087006, G Loss: 5.426156997680664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3096/100000, D Loss: 0.12755078077316284, G Loss: 6.244357109069824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3097/100000, D Loss: 0.18477744609117508, G Loss: 5.542845726013184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3098/100000, D Loss: 0.17343486845493317, G Loss: 4.834906578063965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3099/100000, D Loss: 0.16906968504190445, G Loss: 5.293362617492676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3100/100000, D Loss: 0.12312714010477066, G Loss: 6.158827781677246\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3101/100000, D Loss: 0.10731775313615799, G Loss: 6.010357856750488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3102/100000, D Loss: 0.1300761178135872, G Loss: 5.361588478088379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3103/100000, D Loss: 0.15649691224098206, G Loss: 4.771655082702637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3104/100000, D Loss: 0.1137719452381134, G Loss: 5.1296210289001465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3105/100000, D Loss: 0.1253160573542118, G Loss: 5.662535190582275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3106/100000, D Loss: 0.10446449741721153, G Loss: 5.752570152282715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3107/100000, D Loss: 0.10488719120621681, G Loss: 5.340470314025879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3108/100000, D Loss: 0.12066291645169258, G Loss: 4.964980125427246\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3109/100000, D Loss: 0.11562155187129974, G Loss: 5.020542144775391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3110/100000, D Loss: 0.12037279456853867, G Loss: 5.259728908538818\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3111/100000, D Loss: 0.11092571914196014, G Loss: 5.231030464172363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3112/100000, D Loss: 0.12399984523653984, G Loss: 4.948095321655273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3113/100000, D Loss: 0.12262766063213348, G Loss: 4.8950958251953125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 3114/100000, D Loss: 0.1390446275472641, G Loss: 4.617597579956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3115/100000, D Loss: 0.13022419810295105, G Loss: 4.818947792053223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3116/100000, D Loss: 0.12440274655818939, G Loss: 5.1318039894104\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3117/100000, D Loss: 0.13391121849417686, G Loss: 4.612265586853027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3118/100000, D Loss: 0.14575091749429703, G Loss: 4.34628438949585\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3119/100000, D Loss: 0.14984282106161118, G Loss: 4.4472784996032715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3120/100000, D Loss: 0.1214243546128273, G Loss: 4.838397979736328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3121/100000, D Loss: 0.12119695544242859, G Loss: 4.5085954666137695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3122/100000, D Loss: 0.13184768706560135, G Loss: 4.290376663208008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3123/100000, D Loss: 0.12384198606014252, G Loss: 4.4575042724609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3124/100000, D Loss: 0.09808169305324554, G Loss: 4.799577713012695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3125/100000, D Loss: 0.15482104569673538, G Loss: 4.421497821807861\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3126/100000, D Loss: 0.14500751346349716, G Loss: 4.267165660858154\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3127/100000, D Loss: 0.1267574056982994, G Loss: 4.808229923248291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3128/100000, D Loss: 0.14950000122189522, G Loss: 4.629879951477051\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3129/100000, D Loss: 0.1792706474661827, G Loss: 4.100557327270508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3130/100000, D Loss: 0.15012302994728088, G Loss: 4.267472743988037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3131/100000, D Loss: 0.14083145558834076, G Loss: 4.653904914855957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3132/100000, D Loss: 0.1476772390305996, G Loss: 4.599555492401123\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3133/100000, D Loss: 0.19918175041675568, G Loss: 3.9265050888061523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3134/100000, D Loss: 0.2060190737247467, G Loss: 4.521435737609863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3135/100000, D Loss: 0.17480558902025223, G Loss: 5.046281814575195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3136/100000, D Loss: 0.19635779410600662, G Loss: 4.720691204071045\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3137/100000, D Loss: 0.19467642903327942, G Loss: 4.545726299285889\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3138/100000, D Loss: 0.1908329501748085, G Loss: 4.856064319610596\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3139/100000, D Loss: 0.2085396647453308, G Loss: 4.999821662902832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3140/100000, D Loss: 0.20969051122665405, G Loss: 4.935317516326904\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3141/100000, D Loss: 0.20861061662435532, G Loss: 5.237035274505615\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3142/100000, D Loss: 0.20001988857984543, G Loss: 5.221350193023682\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3143/100000, D Loss: 0.20752116292715073, G Loss: 5.209685325622559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3144/100000, D Loss: 0.24722689390182495, G Loss: 5.243353366851807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3145/100000, D Loss: 0.28989332914352417, G Loss: 5.058116436004639\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3146/100000, D Loss: 0.25208742916584015, G Loss: 5.289592742919922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3147/100000, D Loss: 0.26983442902565, G Loss: 5.24993371963501\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3148/100000, D Loss: 0.3093290477991104, G Loss: 5.397148132324219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3149/100000, D Loss: 0.3121515363454819, G Loss: 5.285254001617432\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3150/100000, D Loss: 0.41946515440940857, G Loss: 5.203779220581055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3151/100000, D Loss: 0.3539690375328064, G Loss: 5.411173343658447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3152/100000, D Loss: 0.36649908125400543, G Loss: 5.159894943237305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3153/100000, D Loss: 0.32495279610157013, G Loss: 5.262350082397461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3154/100000, D Loss: 0.30851130187511444, G Loss: 5.32034969329834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3155/100000, D Loss: 0.3276170939207077, G Loss: 4.787172317504883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3156/100000, D Loss: 0.302382156252861, G Loss: 4.776166915893555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3157/100000, D Loss: 0.2361900508403778, G Loss: 5.2806220054626465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3158/100000, D Loss: 0.20699729025363922, G Loss: 4.5645222663879395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3159/100000, D Loss: 0.188252754509449, G Loss: 4.384543418884277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3160/100000, D Loss: 0.10874643549323082, G Loss: 4.902462959289551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3161/100000, D Loss: 0.11153411120176315, G Loss: 5.207068920135498\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3162/100000, D Loss: 0.1085033044219017, G Loss: 5.002434730529785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3163/100000, D Loss: 0.11889926344156265, G Loss: 4.585671424865723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3164/100000, D Loss: 0.11282284557819366, G Loss: 4.817279815673828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3165/100000, D Loss: 0.07362691313028336, G Loss: 5.3742804527282715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3166/100000, D Loss: 0.08723310381174088, G Loss: 5.29740571975708\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3167/100000, D Loss: 0.13864339888095856, G Loss: 4.440976142883301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3168/100000, D Loss: 0.11146096140146255, G Loss: 4.448098182678223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3169/100000, D Loss: 0.1258002109825611, G Loss: 4.891801834106445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3170/100000, D Loss: 0.1136278547346592, G Loss: 5.185895919799805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3171/100000, D Loss: 0.15390260517597198, G Loss: 4.474872589111328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3172/100000, D Loss: 0.16419526934623718, G Loss: 3.8264083862304688\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3173/100000, D Loss: 0.15128610283136368, G Loss: 4.446664333343506\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3174/100000, D Loss: 0.12314846366643906, G Loss: 4.9824042320251465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3175/100000, D Loss: 0.17141268029808998, G Loss: 4.26253604888916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3176/100000, D Loss: 0.1997152715921402, G Loss: 3.880033016204834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3177/100000, D Loss: 0.1536777913570404, G Loss: 4.47037410736084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3178/100000, D Loss: 0.1626262366771698, G Loss: 4.613701820373535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3179/100000, D Loss: 0.2622795104980469, G Loss: 3.730463981628418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3180/100000, D Loss: 0.22886207699775696, G Loss: 4.206620693206787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3181/100000, D Loss: 0.23466747999191284, G Loss: 4.733197212219238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3182/100000, D Loss: 0.2910454198718071, G Loss: 4.018873691558838\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3183/100000, D Loss: 0.3046935647726059, G Loss: 4.000467300415039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3184/100000, D Loss: 0.28185416758060455, G Loss: 4.549976348876953\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3185/100000, D Loss: 0.29091988503932953, G Loss: 4.428126335144043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3186/100000, D Loss: 0.32475003600120544, G Loss: 4.355536460876465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3187/100000, D Loss: 0.29165828227996826, G Loss: 5.179288864135742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3188/100000, D Loss: 0.3072594255208969, G Loss: 5.373164653778076\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3189/100000, D Loss: 0.34597185254096985, G Loss: 4.63040828704834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3190/100000, D Loss: 0.318594329059124, G Loss: 5.037286281585693\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3191/100000, D Loss: 0.30004388093948364, G Loss: 5.531686782836914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3192/100000, D Loss: 0.2698090374469757, G Loss: 5.71034049987793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3193/100000, D Loss: 0.3050294518470764, G Loss: 5.616213798522949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3194/100000, D Loss: 0.3540685921907425, G Loss: 5.133065700531006\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3195/100000, D Loss: 0.19308451563119888, G Loss: 5.6586151123046875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3196/100000, D Loss: 0.16811686754226685, G Loss: 6.090886116027832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3197/100000, D Loss: 0.16248223185539246, G Loss: 5.636274814605713\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3198/100000, D Loss: 0.11880344152450562, G Loss: 5.383591651916504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3199/100000, D Loss: 0.11000670865178108, G Loss: 5.289307117462158\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3200/100000, D Loss: 0.09566186368465424, G Loss: 5.490683078765869\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3201/100000, D Loss: 0.11483395099639893, G Loss: 5.3672590255737305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3202/100000, D Loss: 0.11019713059067726, G Loss: 5.270510673522949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3203/100000, D Loss: 0.10136980935931206, G Loss: 5.288209438323975\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3204/100000, D Loss: 0.10272099450230598, G Loss: 5.450384140014648\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3205/100000, D Loss: 0.11280393972992897, G Loss: 5.558991432189941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3206/100000, D Loss: 0.15845632553100586, G Loss: 5.180961608886719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3207/100000, D Loss: 0.18584652990102768, G Loss: 4.814483165740967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3208/100000, D Loss: 0.19822047650814056, G Loss: 5.065879821777344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3209/100000, D Loss: 0.20280574262142181, G Loss: 5.400398254394531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3210/100000, D Loss: 0.2429656758904457, G Loss: 4.751558303833008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3211/100000, D Loss: 0.23186174780130386, G Loss: 4.930356979370117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3212/100000, D Loss: 0.18278918415308, G Loss: 5.276645660400391\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3213/100000, D Loss: 0.18515365570783615, G Loss: 5.514334678649902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3214/100000, D Loss: 0.18185802549123764, G Loss: 4.895689964294434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3215/100000, D Loss: 0.18190721422433853, G Loss: 4.658265113830566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3216/100000, D Loss: 0.1446027234196663, G Loss: 5.283298492431641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3217/100000, D Loss: 0.13119106739759445, G Loss: 5.339815139770508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3218/100000, D Loss: 0.1292446218430996, G Loss: 5.113574981689453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3219/100000, D Loss: 0.14746666699647903, G Loss: 4.704421043395996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3220/100000, D Loss: 0.1382666453719139, G Loss: 4.900243759155273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3221/100000, D Loss: 0.11578960716724396, G Loss: 5.384531021118164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3222/100000, D Loss: 0.12123263627290726, G Loss: 5.338324546813965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3223/100000, D Loss: 0.13063127174973488, G Loss: 4.931428909301758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3224/100000, D Loss: 0.11208589375019073, G Loss: 4.786205291748047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3225/100000, D Loss: 0.11335558444261551, G Loss: 4.999873161315918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3226/100000, D Loss: 0.11893412470817566, G Loss: 5.057084083557129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3227/100000, D Loss: 0.1459886133670807, G Loss: 4.732745170593262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3228/100000, D Loss: 0.14203231781721115, G Loss: 4.354617118835449\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3229/100000, D Loss: 0.14645448327064514, G Loss: 4.754960060119629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3230/100000, D Loss: 0.16980817168951035, G Loss: 5.107296943664551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3231/100000, D Loss: 0.19895799458026886, G Loss: 4.626156330108643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3232/100000, D Loss: 0.23100890219211578, G Loss: 4.1910080909729\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3233/100000, D Loss: 0.2347882315516472, G Loss: 4.169854164123535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3234/100000, D Loss: 0.225134938955307, G Loss: 4.494218826293945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3235/100000, D Loss: 0.22209759056568146, G Loss: 4.672418117523193\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3236/100000, D Loss: 0.241770938038826, G Loss: 4.255800247192383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3237/100000, D Loss: 0.27058181166648865, G Loss: 4.3098883628845215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3238/100000, D Loss: 0.23833347111940384, G Loss: 4.511031150817871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3239/100000, D Loss: 0.25192274898290634, G Loss: 4.224928855895996\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3240/100000, D Loss: 0.230672687292099, G Loss: 4.315855026245117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3241/100000, D Loss: 0.20190270245075226, G Loss: 4.390730857849121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3242/100000, D Loss: 0.22267044335603714, G Loss: 4.2867536544799805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3243/100000, D Loss: 0.23069368302822113, G Loss: 4.1567277908325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3244/100000, D Loss: 0.2683388292789459, G Loss: 4.076140403747559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3245/100000, D Loss: 0.23012763261795044, G Loss: 4.003357887268066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3246/100000, D Loss: 0.24162261933088303, G Loss: 3.9752399921417236\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3247/100000, D Loss: 0.2749015837907791, G Loss: 3.988800048828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3248/100000, D Loss: 0.23764629662036896, G Loss: 4.102896213531494\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3249/100000, D Loss: 0.3131440579891205, G Loss: 3.538785457611084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3250/100000, D Loss: 0.3252466917037964, G Loss: 3.7445738315582275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3251/100000, D Loss: 0.2933279424905777, G Loss: 3.807373046875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3252/100000, D Loss: 0.26211266219615936, G Loss: 3.789686918258667\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3253/100000, D Loss: 0.2902162969112396, G Loss: 3.886847496032715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3254/100000, D Loss: 0.2638654410839081, G Loss: 4.1656107902526855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3255/100000, D Loss: 0.2622436657547951, G Loss: 3.97505521774292\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3256/100000, D Loss: 0.2374173328280449, G Loss: 4.120224952697754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3257/100000, D Loss: 0.1703001633286476, G Loss: 4.45350456237793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3258/100000, D Loss: 0.19023777544498444, G Loss: 4.430686950683594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3259/100000, D Loss: 0.1943288818001747, G Loss: 4.157190322875977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3260/100000, D Loss: 0.1490430384874344, G Loss: 4.286412239074707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3261/100000, D Loss: 0.11529284343123436, G Loss: 4.710167407989502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3262/100000, D Loss: 0.13832053542137146, G Loss: 4.644484996795654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3263/100000, D Loss: 0.11648013442754745, G Loss: 4.214175224304199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3264/100000, D Loss: 0.09400726482272148, G Loss: 4.785831928253174\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3265/100000, D Loss: 0.10098021291196346, G Loss: 4.71721887588501\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3266/100000, D Loss: 0.10505744442343712, G Loss: 4.337116718292236\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3267/100000, D Loss: 0.10000613331794739, G Loss: 4.292782306671143\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3268/100000, D Loss: 0.08191578462719917, G Loss: 4.6635026931762695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3269/100000, D Loss: 0.08399844169616699, G Loss: 4.714943885803223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3270/100000, D Loss: 0.08101585879921913, G Loss: 4.717905044555664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3271/100000, D Loss: 0.09165353327989578, G Loss: 4.231863021850586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3272/100000, D Loss: 0.09142004698514938, G Loss: 4.52978515625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3273/100000, D Loss: 0.07885930687189102, G Loss: 4.7721757888793945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3274/100000, D Loss: 0.10234230384230614, G Loss: 4.408010482788086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3275/100000, D Loss: 0.1316591165959835, G Loss: 4.035274028778076\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3276/100000, D Loss: 0.1170506589114666, G Loss: 4.304892063140869\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3277/100000, D Loss: 0.11110775172710419, G Loss: 4.434373378753662\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3278/100000, D Loss: 0.13244257867336273, G Loss: 4.076026439666748\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3279/100000, D Loss: 0.13184194639325142, G Loss: 3.9643077850341797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3280/100000, D Loss: 0.13861935213208199, G Loss: 4.019234657287598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3281/100000, D Loss: 0.1930990070104599, G Loss: 4.065241813659668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3282/100000, D Loss: 0.21265310049057007, G Loss: 3.850269317626953\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3283/100000, D Loss: 0.14315418526530266, G Loss: 4.060766696929932\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3284/100000, D Loss: 0.19526711106300354, G Loss: 3.9092354774475098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3285/100000, D Loss: 0.22974459826946259, G Loss: 3.7270467281341553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3286/100000, D Loss: 0.19017256796360016, G Loss: 4.163426399230957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3287/100000, D Loss: 0.24395833909511566, G Loss: 3.6577529907226562\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3288/100000, D Loss: 0.34056469798088074, G Loss: 3.465273857116699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3289/100000, D Loss: 0.2730981558561325, G Loss: 3.8922500610351562\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3290/100000, D Loss: 0.26850725710392, G Loss: 3.6242711544036865\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3291/100000, D Loss: 0.3498286157846451, G Loss: 3.430208206176758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3292/100000, D Loss: 0.29306405782699585, G Loss: 3.7997875213623047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3293/100000, D Loss: 0.2590743228793144, G Loss: 3.81371808052063\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3294/100000, D Loss: 0.333932988345623, G Loss: 3.6479034423828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3295/100000, D Loss: 0.27167846262454987, G Loss: 3.997236490249634\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3296/100000, D Loss: 0.26403647661209106, G Loss: 4.071040153503418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3297/100000, D Loss: 0.27258269488811493, G Loss: 3.836954116821289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3298/100000, D Loss: 0.2713654115796089, G Loss: 4.0456390380859375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3299/100000, D Loss: 0.23278653621673584, G Loss: 4.450733184814453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3300/100000, D Loss: 0.2506692633032799, G Loss: 4.1737284660339355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3301/100000, D Loss: 0.300214946269989, G Loss: 3.8904993534088135\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3302/100000, D Loss: 0.25342831015586853, G Loss: 4.349964141845703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3303/100000, D Loss: 0.21434929966926575, G Loss: 4.567225933074951\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3304/100000, D Loss: 0.2518767714500427, G Loss: 4.373602867126465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3305/100000, D Loss: 0.24820274859666824, G Loss: 4.298763275146484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3306/100000, D Loss: 0.15704554319381714, G Loss: 4.733486652374268\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3307/100000, D Loss: 0.1484600193798542, G Loss: 5.149685859680176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3308/100000, D Loss: 0.15518475696444511, G Loss: 4.892542839050293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3309/100000, D Loss: 0.18166061490774155, G Loss: 4.4893107414245605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3310/100000, D Loss: 0.1405322253704071, G Loss: 4.90997838973999\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3311/100000, D Loss: 0.16765515506267548, G Loss: 5.257366180419922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3312/100000, D Loss: 0.18702619522809982, G Loss: 5.033432960510254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3313/100000, D Loss: 0.19283591210842133, G Loss: 4.681094169616699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3314/100000, D Loss: 0.17397430539131165, G Loss: 5.177921295166016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3315/100000, D Loss: 0.2043467015028, G Loss: 5.1274614334106445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3316/100000, D Loss: 0.18114151060581207, G Loss: 5.079112529754639\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3317/100000, D Loss: 0.18963796645402908, G Loss: 4.819591522216797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3318/100000, D Loss: 0.19578731805086136, G Loss: 4.741395950317383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3319/100000, D Loss: 0.18855470418930054, G Loss: 4.749655246734619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3320/100000, D Loss: 0.21546900272369385, G Loss: 4.9862823486328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3321/100000, D Loss: 0.18213818222284317, G Loss: 4.897733688354492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3322/100000, D Loss: 0.19887053966522217, G Loss: 4.4720611572265625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3323/100000, D Loss: 0.1889973059296608, G Loss: 4.446683883666992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3324/100000, D Loss: 0.19719405472278595, G Loss: 4.617919921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3325/100000, D Loss: 0.18932628631591797, G Loss: 4.528905868530273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3326/100000, D Loss: 0.20352426171302795, G Loss: 4.493020057678223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3327/100000, D Loss: 0.20874572545289993, G Loss: 4.276247978210449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3328/100000, D Loss: 0.19033367186784744, G Loss: 4.5893025398254395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3329/100000, D Loss: 0.22764180600643158, G Loss: 4.55429744720459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3330/100000, D Loss: 0.18619240075349808, G Loss: 4.577706336975098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3331/100000, D Loss: 0.18208298087120056, G Loss: 4.70377254486084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3332/100000, D Loss: 0.1792077049612999, G Loss: 4.752496719360352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3333/100000, D Loss: 0.1814071387052536, G Loss: 4.839118003845215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3334/100000, D Loss: 0.18701699376106262, G Loss: 5.044753074645996\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3335/100000, D Loss: 0.17710831761360168, G Loss: 5.095407009124756\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3336/100000, D Loss: 0.19549982994794846, G Loss: 5.123380661010742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3337/100000, D Loss: 0.18377617746591568, G Loss: 5.000979900360107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3338/100000, D Loss: 0.18237528204917908, G Loss: 5.233509063720703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3339/100000, D Loss: 0.15900950878858566, G Loss: 5.242011547088623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3340/100000, D Loss: 0.1774534434080124, G Loss: 5.123842239379883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3341/100000, D Loss: 0.16270872950553894, G Loss: 5.020381927490234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3342/100000, D Loss: 0.16994133591651917, G Loss: 5.137089729309082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3343/100000, D Loss: 0.18457435816526413, G Loss: 5.26149845123291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3344/100000, D Loss: 0.16453201323747635, G Loss: 5.144656181335449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3345/100000, D Loss: 0.18438292294740677, G Loss: 5.120720863342285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3346/100000, D Loss: 0.18175511807203293, G Loss: 5.10417366027832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3347/100000, D Loss: 0.13862255215644836, G Loss: 5.093396186828613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3348/100000, D Loss: 0.16622183471918106, G Loss: 4.813961982727051\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3349/100000, D Loss: 0.19676057249307632, G Loss: 4.813881874084473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3350/100000, D Loss: 0.16873112320899963, G Loss: 5.298425674438477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3351/100000, D Loss: 0.1819312646985054, G Loss: 4.880764961242676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3352/100000, D Loss: 0.19997378438711166, G Loss: 4.335755825042725\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3353/100000, D Loss: 0.1711008995771408, G Loss: 4.68217658996582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3354/100000, D Loss: 0.19624990969896317, G Loss: 4.792531490325928\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3355/100000, D Loss: 0.22074861824512482, G Loss: 4.141077518463135\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3356/100000, D Loss: 0.21344970911741257, G Loss: 4.229084014892578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3357/100000, D Loss: 0.18590747565031052, G Loss: 4.577573299407959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3358/100000, D Loss: 0.2228950709104538, G Loss: 4.224431037902832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3359/100000, D Loss: 0.28652649372816086, G Loss: 4.179953098297119\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3360/100000, D Loss: 0.260537713766098, G Loss: 4.307336807250977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3361/100000, D Loss: 0.26250164210796356, G Loss: 4.117652416229248\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3362/100000, D Loss: 0.26690713316202164, G Loss: 4.20368766784668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3363/100000, D Loss: 0.2630336135625839, G Loss: 4.502589702606201\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3364/100000, D Loss: 0.17146136239171028, G Loss: 4.707929611206055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3365/100000, D Loss: 0.1841932162642479, G Loss: 4.4858574867248535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3366/100000, D Loss: 0.15419580042362213, G Loss: 4.225420951843262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3367/100000, D Loss: 0.13987956941127777, G Loss: 4.563774108886719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3368/100000, D Loss: 0.11729099601507187, G Loss: 4.924188137054443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3369/100000, D Loss: 0.11641327291727066, G Loss: 4.653172016143799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3370/100000, D Loss: 0.09661902859807014, G Loss: 4.533352851867676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3371/100000, D Loss: 0.07559367269277573, G Loss: 4.552436828613281\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3372/100000, D Loss: 0.09277954697608948, G Loss: 4.591704368591309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3373/100000, D Loss: 0.09338762611150742, G Loss: 4.43394660949707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3374/100000, D Loss: 0.09929758310317993, G Loss: 4.2984466552734375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3375/100000, D Loss: 0.12509040161967278, G Loss: 4.364336967468262\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3376/100000, D Loss: 0.12433185428380966, G Loss: 4.332215785980225\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3377/100000, D Loss: 0.11847051978111267, G Loss: 4.31212854385376\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3378/100000, D Loss: 0.11310674995183945, G Loss: 4.151887893676758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3379/100000, D Loss: 0.15051879361271858, G Loss: 3.9607276916503906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3380/100000, D Loss: 0.10632726550102234, G Loss: 4.05855655670166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3381/100000, D Loss: 0.12108210101723671, G Loss: 4.025470733642578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3382/100000, D Loss: 0.15453195199370384, G Loss: 3.9033963680267334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3383/100000, D Loss: 0.12711471319198608, G Loss: 4.096053600311279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3384/100000, D Loss: 0.11504512280225754, G Loss: 4.223010063171387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3385/100000, D Loss: 0.17650825530290604, G Loss: 3.93764066696167\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3386/100000, D Loss: 0.16473388671875, G Loss: 4.094066143035889\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3387/100000, D Loss: 0.14738069474697113, G Loss: 4.439853191375732\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3388/100000, D Loss: 0.14520608633756638, G Loss: 4.4237775802612305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3389/100000, D Loss: 0.1708955317735672, G Loss: 4.316140174865723\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3390/100000, D Loss: 0.14586957544088364, G Loss: 4.585752964019775\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3391/100000, D Loss: 0.18393244594335556, G Loss: 4.499783515930176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3392/100000, D Loss: 0.1819201484322548, G Loss: 4.986678123474121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3393/100000, D Loss: 0.16364682465791702, G Loss: 5.415470123291016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3394/100000, D Loss: 0.19665709137916565, G Loss: 5.522706508636475\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3395/100000, D Loss: 0.2030322253704071, G Loss: 5.630181312561035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3396/100000, D Loss: 0.2115602344274521, G Loss: 6.121309280395508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3397/100000, D Loss: 0.1985311657190323, G Loss: 6.1624016761779785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3398/100000, D Loss: 0.2725156396627426, G Loss: 5.659889221191406\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3399/100000, D Loss: 0.2669327110052109, G Loss: 5.508737564086914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3400/100000, D Loss: 0.2608117610216141, G Loss: 6.308495998382568\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3401/100000, D Loss: 0.25949032604694366, G Loss: 6.195765018463135\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3402/100000, D Loss: 0.29731735587120056, G Loss: 5.756259918212891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3403/100000, D Loss: 0.3392193466424942, G Loss: 5.412732124328613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3404/100000, D Loss: 0.24743594229221344, G Loss: 6.517641067504883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3405/100000, D Loss: 0.20458094030618668, G Loss: 6.703035354614258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3406/100000, D Loss: 0.26810941845178604, G Loss: 5.350421905517578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3407/100000, D Loss: 0.3054090589284897, G Loss: 4.494593620300293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3408/100000, D Loss: 0.2239641398191452, G Loss: 5.496058464050293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3409/100000, D Loss: 0.23055172711610794, G Loss: 5.6283111572265625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3410/100000, D Loss: 0.23781021684408188, G Loss: 4.882311820983887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3411/100000, D Loss: 0.247481569647789, G Loss: 4.303086280822754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3412/100000, D Loss: 0.18049830943346024, G Loss: 4.725451469421387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3413/100000, D Loss: 0.1671907976269722, G Loss: 4.979448318481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3414/100000, D Loss: 0.20561306178569794, G Loss: 4.304813385009766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3415/100000, D Loss: 0.25006619095802307, G Loss: 3.7350356578826904\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3416/100000, D Loss: 0.1572558730840683, G Loss: 4.176090717315674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3417/100000, D Loss: 0.1732521429657936, G Loss: 4.434728622436523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3418/100000, D Loss: 0.20771820843219757, G Loss: 4.215235710144043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3419/100000, D Loss: 0.21413404494524002, G Loss: 4.010666847229004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3420/100000, D Loss: 0.19181356579065323, G Loss: 4.176019668579102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3421/100000, D Loss: 0.19289620965719223, G Loss: 4.28818416595459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3422/100000, D Loss: 0.23558156192302704, G Loss: 4.204115390777588\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3423/100000, D Loss: 0.2471279799938202, G Loss: 4.219564437866211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3424/100000, D Loss: 0.2362031787633896, G Loss: 4.759628772735596\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3425/100000, D Loss: 0.2649385631084442, G Loss: 4.748632431030273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3426/100000, D Loss: 0.27531731873750687, G Loss: 4.646225452423096\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3427/100000, D Loss: 0.2997831702232361, G Loss: 4.365814208984375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3428/100000, D Loss: 0.2601967751979828, G Loss: 5.0166754722595215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3429/100000, D Loss: 0.31845856457948685, G Loss: 4.707106590270996\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3430/100000, D Loss: 0.3835247904062271, G Loss: 4.277339458465576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3431/100000, D Loss: 0.3001943528652191, G Loss: 4.59404182434082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3432/100000, D Loss: 0.24775031208992004, G Loss: 5.051694393157959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3433/100000, D Loss: 0.24684442579746246, G Loss: 4.941084861755371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3434/100000, D Loss: 0.28751374781131744, G Loss: 4.3495001792907715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3435/100000, D Loss: 0.22098182141780853, G Loss: 4.7364606857299805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3436/100000, D Loss: 0.19002406299114227, G Loss: 5.447299003601074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3437/100000, D Loss: 0.19139229133725166, G Loss: 5.407005310058594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3438/100000, D Loss: 0.19893783330917358, G Loss: 4.7934465408325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3439/100000, D Loss: 0.20892923325300217, G Loss: 4.670971870422363\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3440/100000, D Loss: 0.16569685190916061, G Loss: 5.159420967102051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3441/100000, D Loss: 0.18556717038154602, G Loss: 5.277860164642334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3442/100000, D Loss: 0.1918521523475647, G Loss: 4.832389831542969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3443/100000, D Loss: 0.18996582925319672, G Loss: 5.029545307159424\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3444/100000, D Loss: 0.1572703681886196, G Loss: 5.177023887634277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3445/100000, D Loss: 0.1522778570652008, G Loss: 5.346659183502197\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3446/100000, D Loss: 0.15083961933851242, G Loss: 5.24517297744751\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3447/100000, D Loss: 0.13940829411149025, G Loss: 5.150331974029541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3448/100000, D Loss: 0.12189791351556778, G Loss: 5.2849440574646\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3449/100000, D Loss: 0.14513878896832466, G Loss: 4.986179351806641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3450/100000, D Loss: 0.16353829205036163, G Loss: 4.808934211730957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3451/100000, D Loss: 0.164441779255867, G Loss: 4.995147228240967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3452/100000, D Loss: 0.1780059039592743, G Loss: 4.8643798828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3453/100000, D Loss: 0.2146332859992981, G Loss: 4.528225898742676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3454/100000, D Loss: 0.21760622411966324, G Loss: 4.793544769287109\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3455/100000, D Loss: 0.28615599125623703, G Loss: 4.405954360961914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3456/100000, D Loss: 0.3123566806316376, G Loss: 4.309147834777832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3457/100000, D Loss: 0.33631956577301025, G Loss: 4.388347625732422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3458/100000, D Loss: 0.32376955449581146, G Loss: 4.39392614364624\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3459/100000, D Loss: 0.31964878737926483, G Loss: 4.05695104598999\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3460/100000, D Loss: 0.315333291888237, G Loss: 4.377119064331055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3461/100000, D Loss: 0.2697537690401077, G Loss: 4.732022285461426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3462/100000, D Loss: 0.3121659606695175, G Loss: 4.211734771728516\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3463/100000, D Loss: 0.25067537277936935, G Loss: 4.473479270935059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3464/100000, D Loss: 0.16641497611999512, G Loss: 4.971065521240234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3465/100000, D Loss: 0.21365637332201004, G Loss: 4.647304534912109\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3466/100000, D Loss: 0.1393139623105526, G Loss: 4.690786361694336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3467/100000, D Loss: 0.12562252953648567, G Loss: 4.709366798400879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3468/100000, D Loss: 0.10729534924030304, G Loss: 5.151296138763428\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3469/100000, D Loss: 0.11327808350324631, G Loss: 5.127115249633789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3470/100000, D Loss: 0.09344889223575592, G Loss: 5.110124588012695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3471/100000, D Loss: 0.09876590222120285, G Loss: 4.963526725769043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3472/100000, D Loss: 0.09034745022654533, G Loss: 5.077780723571777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3473/100000, D Loss: 0.08492644503712654, G Loss: 5.372873306274414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3474/100000, D Loss: 0.09569182060658932, G Loss: 5.34094762802124\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 3475/100000, D Loss: 0.08047452569007874, G Loss: 5.134983062744141\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 3476/100000, D Loss: 0.1085355170071125, G Loss: 4.803863048553467\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3477/100000, D Loss: 0.10219712555408478, G Loss: 4.769505500793457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3478/100000, D Loss: 0.11926215514540672, G Loss: 4.877602577209473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3479/100000, D Loss: 0.12899067625403404, G Loss: 4.759279251098633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3480/100000, D Loss: 0.1550649255514145, G Loss: 4.60929012298584\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3481/100000, D Loss: 0.16698367148637772, G Loss: 4.309215068817139\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3482/100000, D Loss: 0.1730741187930107, G Loss: 4.557830810546875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3483/100000, D Loss: 0.18724146485328674, G Loss: 4.581380844116211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3484/100000, D Loss: 0.2340148389339447, G Loss: 4.162310600280762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3485/100000, D Loss: 0.2489328607916832, G Loss: 4.203311443328857\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3486/100000, D Loss: 0.23802481591701508, G Loss: 4.490401268005371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3487/100000, D Loss: 0.2675989419221878, G Loss: 4.20491886138916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3488/100000, D Loss: 0.2457205206155777, G Loss: 4.136172771453857\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3489/100000, D Loss: 0.24732305109500885, G Loss: 4.126111030578613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3490/100000, D Loss: 0.202658511698246, G Loss: 4.5788984298706055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3491/100000, D Loss: 0.17821796983480453, G Loss: 4.707998275756836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3492/100000, D Loss: 0.150496244430542, G Loss: 4.585038185119629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3493/100000, D Loss: 0.15990050137043, G Loss: 4.549439430236816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3494/100000, D Loss: 0.14644040167331696, G Loss: 4.8704047203063965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3495/100000, D Loss: 0.14396102726459503, G Loss: 5.280487537384033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3496/100000, D Loss: 0.1247992217540741, G Loss: 5.453520774841309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3497/100000, D Loss: 0.15467623621225357, G Loss: 5.218723297119141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3498/100000, D Loss: 0.15434850007295609, G Loss: 5.022978782653809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3499/100000, D Loss: 0.17863772809505463, G Loss: 5.130732536315918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3500/100000, D Loss: 0.1712833121418953, G Loss: 5.739351272583008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3501/100000, D Loss: 0.2543051838874817, G Loss: 5.32227897644043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3502/100000, D Loss: 0.31350356340408325, G Loss: 4.65047025680542\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3503/100000, D Loss: 0.2623210847377777, G Loss: 5.011134624481201\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3504/100000, D Loss: 0.2376570701599121, G Loss: 5.794524192810059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3505/100000, D Loss: 0.2321518138051033, G Loss: 5.829899311065674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3506/100000, D Loss: 0.2067265585064888, G Loss: 5.5194501876831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3507/100000, D Loss: 0.21138896048069, G Loss: 5.283580780029297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3508/100000, D Loss: 0.16243835538625717, G Loss: 5.312205791473389\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3509/100000, D Loss: 0.13869360089302063, G Loss: 5.672468662261963\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3510/100000, D Loss: 0.1486310437321663, G Loss: 5.946945667266846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3511/100000, D Loss: 0.15923843905329704, G Loss: 5.809927463531494\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3512/100000, D Loss: 0.15915601700544357, G Loss: 5.668102264404297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3513/100000, D Loss: 0.1432170681655407, G Loss: 5.574334144592285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3514/100000, D Loss: 0.15252114087343216, G Loss: 5.8836164474487305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3515/100000, D Loss: 0.1932925581932068, G Loss: 5.897713661193848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3516/100000, D Loss: 0.22436199337244034, G Loss: 5.385027885437012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3517/100000, D Loss: 0.17410457879304886, G Loss: 5.566730499267578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3518/100000, D Loss: 0.19845667481422424, G Loss: 5.323482513427734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3519/100000, D Loss: 0.18433590233325958, G Loss: 5.559329986572266\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3520/100000, D Loss: 0.16865115612745285, G Loss: 5.67069149017334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3521/100000, D Loss: 0.1958637684583664, G Loss: 5.042670726776123\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3522/100000, D Loss: 0.19357918202877045, G Loss: 4.673022747039795\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3523/100000, D Loss: 0.21518002450466156, G Loss: 5.304686546325684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3524/100000, D Loss: 0.23701196908950806, G Loss: 4.688918590545654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3525/100000, D Loss: 0.24015547335147858, G Loss: 4.743381500244141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3526/100000, D Loss: 0.21239686012268066, G Loss: 4.662792205810547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3527/100000, D Loss: 0.2537737786769867, G Loss: 4.773316860198975\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3528/100000, D Loss: 0.24216671288013458, G Loss: 4.618350982666016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3529/100000, D Loss: 0.24683299660682678, G Loss: 4.654788970947266\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3530/100000, D Loss: 0.24949292093515396, G Loss: 4.365170001983643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3531/100000, D Loss: 0.27112357318401337, G Loss: 4.68994140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3532/100000, D Loss: 0.2945849299430847, G Loss: 4.763115882873535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3533/100000, D Loss: 0.299861341714859, G Loss: 4.496335983276367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3534/100000, D Loss: 0.3074805289506912, G Loss: 4.691385269165039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3535/100000, D Loss: 0.32431837916374207, G Loss: 4.5297956466674805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3536/100000, D Loss: 0.24708005040884018, G Loss: 4.732422351837158\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3537/100000, D Loss: 0.26987242698669434, G Loss: 4.178186416625977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3538/100000, D Loss: 0.28067538142204285, G Loss: 4.166173934936523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3539/100000, D Loss: 0.25518104434013367, G Loss: 4.4177398681640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3540/100000, D Loss: 0.29679203033447266, G Loss: 4.260354518890381\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3541/100000, D Loss: 0.28118762373924255, G Loss: 4.272878646850586\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3542/100000, D Loss: 0.30732136964797974, G Loss: 4.032086372375488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3543/100000, D Loss: 0.32722727954387665, G Loss: 4.293122291564941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3544/100000, D Loss: 0.3079412057995796, G Loss: 4.316588401794434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3545/100000, D Loss: 0.31277839839458466, G Loss: 4.030337333679199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3546/100000, D Loss: 0.34476058185100555, G Loss: 4.298632621765137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3547/100000, D Loss: 0.2745251953601837, G Loss: 4.707457542419434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3548/100000, D Loss: 0.2826642096042633, G Loss: 4.34433650970459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3549/100000, D Loss: 0.24167168885469437, G Loss: 4.464213848114014\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3550/100000, D Loss: 0.2446572333574295, G Loss: 4.676200866699219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3551/100000, D Loss: 0.14912515133619308, G Loss: 5.447025299072266\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3552/100000, D Loss: 0.16128351166844368, G Loss: 5.3680620193481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3553/100000, D Loss: 0.15431570261716843, G Loss: 4.985860824584961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3554/100000, D Loss: 0.12239924445748329, G Loss: 4.965709686279297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3555/100000, D Loss: 0.08808400854468346, G Loss: 5.4804582595825195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3556/100000, D Loss: 0.09252895414829254, G Loss: 5.719790935516357\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3557/100000, D Loss: 0.08510636352002621, G Loss: 5.534393310546875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3558/100000, D Loss: 0.10150158405303955, G Loss: 5.0894927978515625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3559/100000, D Loss: 0.07765557244420052, G Loss: 5.073935508728027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3560/100000, D Loss: 0.07194641791284084, G Loss: 5.472925186157227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3561/100000, D Loss: 0.07725464925169945, G Loss: 5.588106632232666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3562/100000, D Loss: 0.1049332469701767, G Loss: 4.915961265563965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3563/100000, D Loss: 0.10515834763646126, G Loss: 4.728856563568115\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3564/100000, D Loss: 0.10925950109958649, G Loss: 4.911322116851807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3565/100000, D Loss: 0.11757785826921463, G Loss: 4.963762283325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3566/100000, D Loss: 0.1084129549562931, G Loss: 4.873671054840088\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3567/100000, D Loss: 0.14751895889639854, G Loss: 4.587407112121582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3568/100000, D Loss: 0.13405564427375793, G Loss: 4.520584583282471\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3569/100000, D Loss: 0.1458292230963707, G Loss: 4.812474250793457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3570/100000, D Loss: 0.14880816638469696, G Loss: 4.912785530090332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3571/100000, D Loss: 0.15794261172413826, G Loss: 4.62919282913208\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3572/100000, D Loss: 0.15288598090410233, G Loss: 4.375348091125488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3573/100000, D Loss: 0.1608315408229828, G Loss: 4.461772918701172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3574/100000, D Loss: 0.1580924689769745, G Loss: 4.540005683898926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3575/100000, D Loss: 0.2246195375919342, G Loss: 4.190250873565674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3576/100000, D Loss: 0.2178155779838562, G Loss: 4.21900749206543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3577/100000, D Loss: 0.19366538524627686, G Loss: 4.5144805908203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3578/100000, D Loss: 0.24665962159633636, G Loss: 4.129476547241211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3579/100000, D Loss: 0.2909124195575714, G Loss: 3.95373272895813\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3580/100000, D Loss: 0.22693170607089996, G Loss: 4.449069976806641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3581/100000, D Loss: 0.27628108859062195, G Loss: 4.0988616943359375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3582/100000, D Loss: 0.3027392476797104, G Loss: 3.6114983558654785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3583/100000, D Loss: 0.2695886939764023, G Loss: 3.9540317058563232\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3584/100000, D Loss: 0.24994763731956482, G Loss: 3.9627633094787598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3585/100000, D Loss: 0.22181451320648193, G Loss: 3.8852317333221436\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3586/100000, D Loss: 0.23153163492679596, G Loss: 3.907525062561035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3587/100000, D Loss: 0.2150254026055336, G Loss: 4.040945053100586\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3588/100000, D Loss: 0.1989825889468193, G Loss: 4.120235919952393\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3589/100000, D Loss: 0.19662107527256012, G Loss: 4.003515243530273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3590/100000, D Loss: 0.19710537046194077, G Loss: 3.9410057067871094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3591/100000, D Loss: 0.211294986307621, G Loss: 4.1085357666015625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3592/100000, D Loss: 0.19583405554294586, G Loss: 4.228909492492676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3593/100000, D Loss: 0.2521788626909256, G Loss: 3.9292728900909424\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3594/100000, D Loss: 0.24844303727149963, G Loss: 3.8318746089935303\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3595/100000, D Loss: 0.22240420430898666, G Loss: 3.899146556854248\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3596/100000, D Loss: 0.23879976570606232, G Loss: 3.8781065940856934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3597/100000, D Loss: 0.2505435645580292, G Loss: 3.8096938133239746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3598/100000, D Loss: 0.2345164492726326, G Loss: 3.963212013244629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3599/100000, D Loss: 0.21856463700532913, G Loss: 3.9440555572509766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3600/100000, D Loss: 0.2264721393585205, G Loss: 4.05705451965332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3601/100000, D Loss: 0.23088988661766052, G Loss: 3.904069185256958\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3602/100000, D Loss: 0.229333758354187, G Loss: 3.803990364074707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3603/100000, D Loss: 0.21470053493976593, G Loss: 3.9540371894836426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3604/100000, D Loss: 0.1978229060769081, G Loss: 4.085357666015625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3605/100000, D Loss: 0.23985014855861664, G Loss: 4.05919075012207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3606/100000, D Loss: 0.22853879630565643, G Loss: 3.8640613555908203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3607/100000, D Loss: 0.22619067877531052, G Loss: 3.8714139461517334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3608/100000, D Loss: 0.25191789865493774, G Loss: 3.771355628967285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3609/100000, D Loss: 0.2332068830728531, G Loss: 3.852158784866333\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3610/100000, D Loss: 0.24334128946065903, G Loss: 3.635782480239868\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3611/100000, D Loss: 0.24597980082035065, G Loss: 3.5414671897888184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3612/100000, D Loss: 0.2510032430291176, G Loss: 3.7155556678771973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3613/100000, D Loss: 0.2632318139076233, G Loss: 3.722766399383545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3614/100000, D Loss: 0.24312379956245422, G Loss: 3.7223618030548096\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3615/100000, D Loss: 0.2360401451587677, G Loss: 3.9606449604034424\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3616/100000, D Loss: 0.16770841926336288, G Loss: 4.099735260009766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3617/100000, D Loss: 0.18898788839578629, G Loss: 4.016497611999512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3618/100000, D Loss: 0.20653998106718063, G Loss: 3.8785085678100586\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3619/100000, D Loss: 0.1548284888267517, G Loss: 4.383454322814941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3620/100000, D Loss: 0.16006871312856674, G Loss: 4.422521591186523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3621/100000, D Loss: 0.21002362668514252, G Loss: 3.9112067222595215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3622/100000, D Loss: 0.19643697887659073, G Loss: 3.9312779903411865\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3623/100000, D Loss: 0.19888504594564438, G Loss: 4.244579315185547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3624/100000, D Loss: 0.2007201984524727, G Loss: 4.10017204284668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3625/100000, D Loss: 0.21677696704864502, G Loss: 3.7432467937469482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3626/100000, D Loss: 0.22647037357091904, G Loss: 3.885610580444336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3627/100000, D Loss: 0.2020554393529892, G Loss: 4.168545722961426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3628/100000, D Loss: 0.23779460787773132, G Loss: 3.9860901832580566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3629/100000, D Loss: 0.21539218723773956, G Loss: 4.059855937957764\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3630/100000, D Loss: 0.24455410242080688, G Loss: 4.008806228637695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3631/100000, D Loss: 0.23823750019073486, G Loss: 3.87827467918396\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3632/100000, D Loss: 0.1996975764632225, G Loss: 4.144739151000977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3633/100000, D Loss: 0.19141989946365356, G Loss: 4.231659889221191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3634/100000, D Loss: 0.2237560674548149, G Loss: 4.041131973266602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3635/100000, D Loss: 0.20504747331142426, G Loss: 4.034640312194824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3636/100000, D Loss: 0.19521819800138474, G Loss: 4.2497406005859375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3637/100000, D Loss: 0.20314180850982666, G Loss: 4.220013618469238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3638/100000, D Loss: 0.25858213752508163, G Loss: 3.773876428604126\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3639/100000, D Loss: 0.1748059317469597, G Loss: 4.181662559509277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3640/100000, D Loss: 0.20892111957073212, G Loss: 4.184853553771973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3641/100000, D Loss: 0.22037853300571442, G Loss: 4.060555458068848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3642/100000, D Loss: 0.22012928873300552, G Loss: 3.7750039100646973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3643/100000, D Loss: 0.20649929344654083, G Loss: 3.9219741821289062\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3644/100000, D Loss: 0.22118018567562103, G Loss: 3.9942126274108887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3645/100000, D Loss: 0.2376050502061844, G Loss: 3.817709445953369\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3646/100000, D Loss: 0.19846703112125397, G Loss: 4.114269256591797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3647/100000, D Loss: 0.22511904686689377, G Loss: 4.1449384689331055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3648/100000, D Loss: 0.20792073011398315, G Loss: 3.9799704551696777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3649/100000, D Loss: 0.1858324036002159, G Loss: 3.9678797721862793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3650/100000, D Loss: 0.1748221144080162, G Loss: 4.185426712036133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3651/100000, D Loss: 0.14686329290270805, G Loss: 4.340535640716553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3652/100000, D Loss: 0.1590452790260315, G Loss: 4.2545857429504395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3653/100000, D Loss: 0.12817053124308586, G Loss: 4.162336349487305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3654/100000, D Loss: 0.11203588545322418, G Loss: 4.504549026489258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3655/100000, D Loss: 0.11771053820848465, G Loss: 4.488724708557129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3656/100000, D Loss: 0.08961236476898193, G Loss: 4.633355140686035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3657/100000, D Loss: 0.10595624521374702, G Loss: 4.507508754730225\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3658/100000, D Loss: 0.11511308327317238, G Loss: 4.339814186096191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3659/100000, D Loss: 0.10105035454034805, G Loss: 4.328656196594238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3660/100000, D Loss: 0.09979536756873131, G Loss: 4.4116973876953125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3661/100000, D Loss: 0.10388178378343582, G Loss: 4.481927394866943\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3662/100000, D Loss: 0.11580909788608551, G Loss: 4.575164318084717\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3663/100000, D Loss: 0.1080501414835453, G Loss: 4.501426696777344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3664/100000, D Loss: 0.0926944687962532, G Loss: 4.629661560058594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3665/100000, D Loss: 0.10691232234239578, G Loss: 4.5367889404296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3666/100000, D Loss: 0.0909755639731884, G Loss: 4.5799641609191895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3667/100000, D Loss: 0.08717593923211098, G Loss: 4.662624359130859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3668/100000, D Loss: 0.09550942108035088, G Loss: 4.632393836975098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3669/100000, D Loss: 0.11284931004047394, G Loss: 4.333301544189453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3670/100000, D Loss: 0.11217044666409492, G Loss: 4.162622451782227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3671/100000, D Loss: 0.11004988849163055, G Loss: 4.33351993560791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3672/100000, D Loss: 0.09460093080997467, G Loss: 4.742720603942871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3673/100000, D Loss: 0.10186713188886642, G Loss: 4.753338813781738\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3674/100000, D Loss: 0.11778395622968674, G Loss: 4.212549209594727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3675/100000, D Loss: 0.11460632085800171, G Loss: 4.426187992095947\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3676/100000, D Loss: 0.10679586976766586, G Loss: 4.560373306274414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3677/100000, D Loss: 0.11724317818880081, G Loss: 4.4186835289001465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3678/100000, D Loss: 0.11061054468154907, G Loss: 4.341414451599121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3679/100000, D Loss: 0.10264847055077553, G Loss: 4.3046488761901855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3680/100000, D Loss: 0.10112311318516731, G Loss: 4.599020957946777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3681/100000, D Loss: 0.08723751083016396, G Loss: 4.57011604309082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3682/100000, D Loss: 0.10543901473283768, G Loss: 4.3615241050720215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3683/100000, D Loss: 0.12392161786556244, G Loss: 4.284404277801514\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3684/100000, D Loss: 0.1180604100227356, G Loss: 4.525079727172852\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3685/100000, D Loss: 0.08138915151357651, G Loss: 4.719679355621338\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3686/100000, D Loss: 0.08221669867634773, G Loss: 4.759700775146484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3687/100000, D Loss: 0.09525134414434433, G Loss: 4.332233428955078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3688/100000, D Loss: 0.10521278902888298, G Loss: 4.3866047859191895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3689/100000, D Loss: 0.08644065633416176, G Loss: 4.632634162902832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3690/100000, D Loss: 0.06264122948050499, G Loss: 5.000614166259766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3691/100000, D Loss: 0.09002911671996117, G Loss: 4.991074085235596\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3692/100000, D Loss: 0.08879801630973816, G Loss: 4.689556121826172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3693/100000, D Loss: 0.09151547029614449, G Loss: 4.438087463378906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3694/100000, D Loss: 0.09414289519190788, G Loss: 4.587871074676514\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3695/100000, D Loss: 0.0828012228012085, G Loss: 4.826274871826172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3696/100000, D Loss: 0.07109522074460983, G Loss: 5.2514190673828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3697/100000, D Loss: 0.11477354913949966, G Loss: 4.582765102386475\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3698/100000, D Loss: 0.11694646254181862, G Loss: 4.306571006774902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3699/100000, D Loss: 0.1106812097132206, G Loss: 4.743173599243164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3700/100000, D Loss: 0.09941751137375832, G Loss: 5.290927886962891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3701/100000, D Loss: 0.09688257426023483, G Loss: 4.795655250549316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3702/100000, D Loss: 0.12988800182938576, G Loss: 4.2823920249938965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3703/100000, D Loss: 0.1317635029554367, G Loss: 4.661475658416748\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3704/100000, D Loss: 0.1119522675871849, G Loss: 5.2803120613098145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3705/100000, D Loss: 0.1374746859073639, G Loss: 4.863502502441406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3706/100000, D Loss: 0.1370542123913765, G Loss: 4.34263277053833\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3707/100000, D Loss: 0.13730429112911224, G Loss: 4.6379804611206055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3708/100000, D Loss: 0.08414779976010323, G Loss: 5.521710395812988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3709/100000, D Loss: 0.12002662941813469, G Loss: 5.329159259796143\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3710/100000, D Loss: 0.15495043620467186, G Loss: 4.364535808563232\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3711/100000, D Loss: 0.1391657143831253, G Loss: 4.473614692687988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3712/100000, D Loss: 0.09848927706480026, G Loss: 5.2137651443481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3713/100000, D Loss: 0.1536901332437992, G Loss: 4.760970115661621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3714/100000, D Loss: 0.13888641446828842, G Loss: 4.357852458953857\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3715/100000, D Loss: 0.15986236929893494, G Loss: 4.507336616516113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3716/100000, D Loss: 0.13767383247613907, G Loss: 4.88808536529541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3717/100000, D Loss: 0.14194735139608383, G Loss: 4.720057010650635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3718/100000, D Loss: 0.1508011892437935, G Loss: 4.710139274597168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3719/100000, D Loss: 0.11928807944059372, G Loss: 4.845721244812012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3720/100000, D Loss: 0.13062923401594162, G Loss: 4.7649970054626465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3721/100000, D Loss: 0.13247663155198097, G Loss: 4.832057476043701\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3722/100000, D Loss: 0.12417641654610634, G Loss: 4.668545246124268\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3723/100000, D Loss: 0.1353469118475914, G Loss: 4.835756301879883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3724/100000, D Loss: 0.10847179219126701, G Loss: 5.074568748474121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3725/100000, D Loss: 0.11279945448040962, G Loss: 4.849327564239502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3726/100000, D Loss: 0.12581974267959595, G Loss: 4.631331443786621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3727/100000, D Loss: 0.10671645402908325, G Loss: 4.676480293273926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3728/100000, D Loss: 0.13820980116724968, G Loss: 4.60628604888916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3729/100000, D Loss: 0.1278628706932068, G Loss: 4.596782684326172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3730/100000, D Loss: 0.12069741263985634, G Loss: 4.704362392425537\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3731/100000, D Loss: 0.13911772519350052, G Loss: 4.624258518218994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3732/100000, D Loss: 0.13879362493753433, G Loss: 4.734862327575684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3733/100000, D Loss: 0.12653258442878723, G Loss: 4.711581230163574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3734/100000, D Loss: 0.13672534376382828, G Loss: 4.602476596832275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3735/100000, D Loss: 0.1107235886156559, G Loss: 4.629123210906982\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3736/100000, D Loss: 0.09967834874987602, G Loss: 4.800174236297607\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3737/100000, D Loss: 0.09991708770394325, G Loss: 5.0942230224609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3738/100000, D Loss: 0.09841632470488548, G Loss: 4.805639266967773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3739/100000, D Loss: 0.11209135875105858, G Loss: 4.485309600830078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3740/100000, D Loss: 0.10405068844556808, G Loss: 4.746356010437012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3741/100000, D Loss: 0.0896633118391037, G Loss: 4.916319370269775\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3742/100000, D Loss: 0.09120383486151695, G Loss: 4.978802680969238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3743/100000, D Loss: 0.09380972012877464, G Loss: 4.776006698608398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3744/100000, D Loss: 0.10747809335589409, G Loss: 4.44586181640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3745/100000, D Loss: 0.09412064403295517, G Loss: 4.77473783493042\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3746/100000, D Loss: 0.11760666221380234, G Loss: 4.543268203735352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3747/100000, D Loss: 0.1259898878633976, G Loss: 4.378129005432129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3748/100000, D Loss: 0.11859973520040512, G Loss: 4.636362075805664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3749/100000, D Loss: 0.15290432795882225, G Loss: 4.5203399658203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3750/100000, D Loss: 0.1496618539094925, G Loss: 4.2810821533203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3751/100000, D Loss: 0.15607824176549911, G Loss: 4.492068290710449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3752/100000, D Loss: 0.12020356953144073, G Loss: 4.831721782684326\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3753/100000, D Loss: 0.14932246506214142, G Loss: 4.172011852264404\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3754/100000, D Loss: 0.1537451446056366, G Loss: 4.019049167633057\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3755/100000, D Loss: 0.13568608835339546, G Loss: 4.713593006134033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3756/100000, D Loss: 0.14210062474012375, G Loss: 4.783814430236816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3757/100000, D Loss: 0.14601358026266098, G Loss: 4.3647074699401855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3758/100000, D Loss: 0.15047913789749146, G Loss: 4.110970497131348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3759/100000, D Loss: 0.15121402591466904, G Loss: 4.459205627441406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3760/100000, D Loss: 0.11682707071304321, G Loss: 4.771844863891602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3761/100000, D Loss: 0.15393541753292084, G Loss: 4.305262088775635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3762/100000, D Loss: 0.12366936355829239, G Loss: 4.367586135864258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3763/100000, D Loss: 0.10447738319635391, G Loss: 4.719743728637695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3764/100000, D Loss: 0.14423439279198647, G Loss: 4.70305061340332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3765/100000, D Loss: 0.14951936155557632, G Loss: 4.193200588226318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3766/100000, D Loss: 0.14863479137420654, G Loss: 4.444064617156982\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3767/100000, D Loss: 0.1058957576751709, G Loss: 4.862504005432129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3768/100000, D Loss: 0.1777156926691532, G Loss: 4.505372524261475\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3769/100000, D Loss: 0.13999874889850616, G Loss: 4.2881598472595215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3770/100000, D Loss: 0.11708153039216995, G Loss: 4.546658039093018\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3771/100000, D Loss: 0.12389352917671204, G Loss: 4.8455586433410645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3772/100000, D Loss: 0.13784029707312584, G Loss: 4.586771011352539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3773/100000, D Loss: 0.12627674266695976, G Loss: 4.584043025970459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3774/100000, D Loss: 0.1444673053920269, G Loss: 4.571094512939453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3775/100000, D Loss: 0.11196327209472656, G Loss: 4.5422444343566895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3776/100000, D Loss: 0.096914391964674, G Loss: 4.93183708190918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3777/100000, D Loss: 0.10179382562637329, G Loss: 4.718472480773926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3778/100000, D Loss: 0.12361229211091995, G Loss: 4.641312122344971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3779/100000, D Loss: 0.11343181133270264, G Loss: 4.8252739906311035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3780/100000, D Loss: 0.09554785117506981, G Loss: 5.111024856567383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3781/100000, D Loss: 0.09406617283821106, G Loss: 4.956422805786133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3782/100000, D Loss: 0.09345076605677605, G Loss: 4.54571533203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3783/100000, D Loss: 0.08968418091535568, G Loss: 4.684436321258545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3784/100000, D Loss: 0.08947883173823357, G Loss: 4.872623443603516\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3785/100000, D Loss: 0.06993518769741058, G Loss: 5.059279441833496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3786/100000, D Loss: 0.07483436539769173, G Loss: 5.030087471008301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3787/100000, D Loss: 0.09759441390633583, G Loss: 4.389382362365723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3788/100000, D Loss: 0.0935443826019764, G Loss: 4.549746513366699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3789/100000, D Loss: 0.08139897882938385, G Loss: 5.030600547790527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3790/100000, D Loss: 0.06141919270157814, G Loss: 5.382403373718262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3791/100000, D Loss: 0.1018385011702776, G Loss: 4.9851226806640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3792/100000, D Loss: 0.10874776542186737, G Loss: 4.478057861328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3793/100000, D Loss: 0.0792073979973793, G Loss: 4.722132682800293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3794/100000, D Loss: 0.07215356826782227, G Loss: 5.00274658203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3795/100000, D Loss: 0.09109625220298767, G Loss: 4.960409164428711\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3796/100000, D Loss: 0.10655409470200539, G Loss: 4.56861686706543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3797/100000, D Loss: 0.09637149423360825, G Loss: 4.690064430236816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 3798/100000, D Loss: 0.08383001014590263, G Loss: 4.92040491104126\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3799/100000, D Loss: 0.08659987896680832, G Loss: 4.972778797149658\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3800/100000, D Loss: 0.1062721498310566, G Loss: 4.638883590698242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3801/100000, D Loss: 0.08877534419298172, G Loss: 4.530904769897461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3802/100000, D Loss: 0.09464826807379723, G Loss: 4.706546306610107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3803/100000, D Loss: 0.07909616827964783, G Loss: 4.859552383422852\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3804/100000, D Loss: 0.08857068791985512, G Loss: 4.551090717315674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3805/100000, D Loss: 0.09434545412659645, G Loss: 4.202592849731445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3806/100000, D Loss: 0.08541303500533104, G Loss: 4.386258125305176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3807/100000, D Loss: 0.07929814979434013, G Loss: 4.7355875968933105\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3808/100000, D Loss: 0.08322377875447273, G Loss: 4.602311134338379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3809/100000, D Loss: 0.08695915341377258, G Loss: 4.336967468261719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3810/100000, D Loss: 0.08427228778600693, G Loss: 4.424935340881348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3811/100000, D Loss: 0.09282903373241425, G Loss: 4.703929901123047\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3812/100000, D Loss: 0.071988794952631, G Loss: 4.76613712310791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3813/100000, D Loss: 0.08691280148923397, G Loss: 4.416642189025879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3814/100000, D Loss: 0.07766607031226158, G Loss: 4.565274238586426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3815/100000, D Loss: 0.0862695537507534, G Loss: 4.605947494506836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3816/100000, D Loss: 0.07452094368636608, G Loss: 4.653062343597412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3817/100000, D Loss: 0.06441749259829521, G Loss: 4.778875827789307\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3818/100000, D Loss: 0.07406513765454292, G Loss: 4.594529151916504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3819/100000, D Loss: 0.06090805307030678, G Loss: 4.580924987792969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3820/100000, D Loss: 0.07638829946517944, G Loss: 4.672140121459961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3821/100000, D Loss: 0.04799269512295723, G Loss: 4.912120819091797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3822/100000, D Loss: 0.05599034205079079, G Loss: 4.959044456481934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3823/100000, D Loss: 0.06458429805934429, G Loss: 4.51725435256958\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3824/100000, D Loss: 0.06609433516860008, G Loss: 4.422863960266113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3825/100000, D Loss: 0.06593074649572372, G Loss: 4.833684921264648\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3826/100000, D Loss: 0.06124498322606087, G Loss: 5.017504692077637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3827/100000, D Loss: 0.06199966371059418, G Loss: 4.899905681610107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3828/100000, D Loss: 0.07179861143231392, G Loss: 4.448999404907227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3829/100000, D Loss: 0.06745107099413872, G Loss: 4.313186168670654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3830/100000, D Loss: 0.07462786138057709, G Loss: 4.641410827636719\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3831/100000, D Loss: 0.06667120940983295, G Loss: 4.924980163574219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3832/100000, D Loss: 0.06749373115599155, G Loss: 4.947169303894043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3833/100000, D Loss: 0.08093981631100178, G Loss: 4.473523139953613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3834/100000, D Loss: 0.0822676308453083, G Loss: 4.354427814483643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3835/100000, D Loss: 0.08205914497375488, G Loss: 4.757941246032715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3836/100000, D Loss: 0.07182420045137405, G Loss: 5.020235061645508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3837/100000, D Loss: 0.07776840776205063, G Loss: 4.484292030334473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3838/100000, D Loss: 0.0711730346083641, G Loss: 4.235982894897461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3839/100000, D Loss: 0.08810111880302429, G Loss: 4.44915246963501\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3840/100000, D Loss: 0.07561348751187325, G Loss: 4.88641357421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3841/100000, D Loss: 0.1059584952890873, G Loss: 4.597557544708252\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3842/100000, D Loss: 0.09711169078946114, G Loss: 4.18596887588501\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3843/100000, D Loss: 0.11837494000792503, G Loss: 4.16372013092041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3844/100000, D Loss: 0.10916255414485931, G Loss: 4.3463945388793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3845/100000, D Loss: 0.12695904076099396, G Loss: 4.335398197174072\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3846/100000, D Loss: 0.11645907163619995, G Loss: 4.277771949768066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3847/100000, D Loss: 0.12603332474827766, G Loss: 4.328560829162598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3848/100000, D Loss: 0.13924157992005348, G Loss: 4.472729682922363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3849/100000, D Loss: 0.15138687193393707, G Loss: 4.260066032409668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3850/100000, D Loss: 0.17786097526550293, G Loss: 4.194005966186523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3851/100000, D Loss: 0.18776604533195496, G Loss: 4.49216890335083\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3852/100000, D Loss: 0.22308126837015152, G Loss: 4.5587310791015625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3853/100000, D Loss: 0.2627863585948944, G Loss: 4.283697128295898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3854/100000, D Loss: 0.25642989575862885, G Loss: 4.357117652893066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3855/100000, D Loss: 0.2748558968305588, G Loss: 4.449861526489258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3856/100000, D Loss: 0.23690390586853027, G Loss: 4.6979217529296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3857/100000, D Loss: 0.22419199347496033, G Loss: 4.661693572998047\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3858/100000, D Loss: 0.22470557689666748, G Loss: 4.589756965637207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3859/100000, D Loss: 0.19930514693260193, G Loss: 4.734079360961914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3860/100000, D Loss: 0.15705471485853195, G Loss: 5.4394683837890625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3861/100000, D Loss: 0.15259238705039024, G Loss: 5.493673324584961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3862/100000, D Loss: 0.17513582110404968, G Loss: 5.04702091217041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3863/100000, D Loss: 0.12261166423559189, G Loss: 5.133649826049805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3864/100000, D Loss: 0.1520344242453575, G Loss: 5.316230773925781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3865/100000, D Loss: 0.13524850085377693, G Loss: 5.4654717445373535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3866/100000, D Loss: 0.16359133273363113, G Loss: 5.028200626373291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3867/100000, D Loss: 0.17917800694704056, G Loss: 5.187333106994629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3868/100000, D Loss: 0.15750239789485931, G Loss: 5.333395957946777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3869/100000, D Loss: 0.15827371925115585, G Loss: 5.52415132522583\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3870/100000, D Loss: 0.19255413860082626, G Loss: 4.924495697021484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3871/100000, D Loss: 0.15196365863084793, G Loss: 4.903818607330322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3872/100000, D Loss: 0.15109872072935104, G Loss: 5.292257785797119\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3873/100000, D Loss: 0.14783019572496414, G Loss: 5.2848219871521\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3874/100000, D Loss: 0.1421973668038845, G Loss: 5.0787177085876465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3875/100000, D Loss: 0.14567501842975616, G Loss: 5.039387226104736\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3876/100000, D Loss: 0.13153104484081268, G Loss: 5.049358367919922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3877/100000, D Loss: 0.126919724047184, G Loss: 5.197081565856934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3878/100000, D Loss: 0.14503486081957817, G Loss: 5.187856674194336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3879/100000, D Loss: 0.1392444595694542, G Loss: 5.0610198974609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3880/100000, D Loss: 0.1496419832110405, G Loss: 4.920342922210693\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3881/100000, D Loss: 0.13762759417295456, G Loss: 4.7064290046691895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3882/100000, D Loss: 0.13180936127901077, G Loss: 4.980170726776123\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3883/100000, D Loss: 0.13123124465346336, G Loss: 4.848726272583008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3884/100000, D Loss: 0.11487530916929245, G Loss: 4.992588520050049\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3885/100000, D Loss: 0.13045015186071396, G Loss: 4.655182361602783\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3886/100000, D Loss: 0.10672471672296524, G Loss: 5.024224281311035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3887/100000, D Loss: 0.08952540531754494, G Loss: 5.24393367767334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3888/100000, D Loss: 0.12329347990453243, G Loss: 5.1891255378723145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3889/100000, D Loss: 0.12656773999333382, G Loss: 4.584610939025879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3890/100000, D Loss: 0.09464989602565765, G Loss: 4.712033271789551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3891/100000, D Loss: 0.12821967154741287, G Loss: 5.07411527633667\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3892/100000, D Loss: 0.09804271534085274, G Loss: 4.924422740936279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3893/100000, D Loss: 0.11108941584825516, G Loss: 4.602911949157715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3894/100000, D Loss: 0.12121984362602234, G Loss: 4.446718215942383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3895/100000, D Loss: 0.12049773335456848, G Loss: 4.55143404006958\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3896/100000, D Loss: 0.10990771651268005, G Loss: 4.584050178527832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3897/100000, D Loss: 0.10665137320756912, G Loss: 4.676246166229248\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3898/100000, D Loss: 0.10533216595649719, G Loss: 4.299966812133789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3899/100000, D Loss: 0.115289855748415, G Loss: 4.283194541931152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3900/100000, D Loss: 0.09908468648791313, G Loss: 4.464499473571777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3901/100000, D Loss: 0.08663254603743553, G Loss: 4.6655802726745605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3902/100000, D Loss: 0.10309438407421112, G Loss: 4.299510955810547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3903/100000, D Loss: 0.09682728722691536, G Loss: 4.263619899749756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3904/100000, D Loss: 0.07997401058673859, G Loss: 4.684686660766602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3905/100000, D Loss: 0.06530367210507393, G Loss: 5.061010360717773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3906/100000, D Loss: 0.08928292617201805, G Loss: 4.686694622039795\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3907/100000, D Loss: 0.08543239533901215, G Loss: 4.271775245666504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3908/100000, D Loss: 0.08383429050445557, G Loss: 4.365917682647705\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3909/100000, D Loss: 0.06572546064853668, G Loss: 4.948104381561279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3910/100000, D Loss: 0.08572649583220482, G Loss: 4.986879825592041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3911/100000, D Loss: 0.06570076569914818, G Loss: 5.0070905685424805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3912/100000, D Loss: 0.08053493872284889, G Loss: 4.721291542053223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3913/100000, D Loss: 0.08746911212801933, G Loss: 4.559551239013672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3914/100000, D Loss: 0.07562224194407463, G Loss: 5.061888694763184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3915/100000, D Loss: 0.0856071189045906, G Loss: 5.043858051300049\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3916/100000, D Loss: 0.08340474404394627, G Loss: 4.711503982543945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3917/100000, D Loss: 0.10484566912055016, G Loss: 4.554868698120117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3918/100000, D Loss: 0.077370785176754, G Loss: 4.7421488761901855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3919/100000, D Loss: 0.09463335573673248, G Loss: 4.850583076477051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3920/100000, D Loss: 0.10363951325416565, G Loss: 4.633976936340332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3921/100000, D Loss: 0.10804791748523712, G Loss: 4.647490978240967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3922/100000, D Loss: 0.10569699853658676, G Loss: 4.4909281730651855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3923/100000, D Loss: 0.110697191208601, G Loss: 4.593077659606934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3924/100000, D Loss: 0.09515861421823502, G Loss: 4.619050025939941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3925/100000, D Loss: 0.1032676100730896, G Loss: 4.751269340515137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3926/100000, D Loss: 0.12257473915815353, G Loss: 4.423165321350098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3927/100000, D Loss: 0.13207000494003296, G Loss: 4.273233413696289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3928/100000, D Loss: 0.12999184429645538, G Loss: 4.3409423828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3929/100000, D Loss: 0.11602609604597092, G Loss: 4.653721809387207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3930/100000, D Loss: 0.13411183282732964, G Loss: 4.5238566398620605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3931/100000, D Loss: 0.17072295397520065, G Loss: 4.024068832397461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3932/100000, D Loss: 0.14487995207309723, G Loss: 4.095574855804443\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3933/100000, D Loss: 0.12616167962551117, G Loss: 4.479500770568848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3934/100000, D Loss: 0.18451421707868576, G Loss: 4.329181671142578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3935/100000, D Loss: 0.17667502164840698, G Loss: 4.049374103546143\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3936/100000, D Loss: 0.16484187543392181, G Loss: 4.208501815795898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3937/100000, D Loss: 0.1692959889769554, G Loss: 4.36884880065918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3938/100000, D Loss: 0.19541998952627182, G Loss: 4.332744598388672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3939/100000, D Loss: 0.20639961957931519, G Loss: 4.254487991333008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3940/100000, D Loss: 0.1924758404493332, G Loss: 4.409799575805664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3941/100000, D Loss: 0.18084367364645004, G Loss: 4.793850898742676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3942/100000, D Loss: 0.22529349476099014, G Loss: 4.416255950927734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3943/100000, D Loss: 0.23758263885974884, G Loss: 4.588191986083984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3944/100000, D Loss: 0.21659772843122482, G Loss: 4.9895477294921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3945/100000, D Loss: 0.21874818205833435, G Loss: 4.971148490905762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3946/100000, D Loss: 0.24231500923633575, G Loss: 5.011456489562988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3947/100000, D Loss: 0.16930190473794937, G Loss: 5.359987258911133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3948/100000, D Loss: 0.17826780676841736, G Loss: 5.2944488525390625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3949/100000, D Loss: 0.14318612217903137, G Loss: 5.590295791625977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3950/100000, D Loss: 0.1150011345744133, G Loss: 5.90283203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3951/100000, D Loss: 0.09406180679798126, G Loss: 5.903895854949951\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3952/100000, D Loss: 0.09097413718700409, G Loss: 5.451149940490723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3953/100000, D Loss: 0.0940483920276165, G Loss: 5.764156341552734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3954/100000, D Loss: 0.07770208269357681, G Loss: 6.009504318237305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3955/100000, D Loss: 0.09096376225352287, G Loss: 5.9100446701049805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3956/100000, D Loss: 0.09063555300235748, G Loss: 5.483205318450928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3957/100000, D Loss: 0.08974200487136841, G Loss: 5.450719356536865\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3958/100000, D Loss: 0.08939645811915398, G Loss: 5.975686073303223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3959/100000, D Loss: 0.08706017211079597, G Loss: 6.379857063293457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3960/100000, D Loss: 0.08524612337350845, G Loss: 6.309427261352539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3961/100000, D Loss: 0.10224389284849167, G Loss: 5.9070258140563965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3962/100000, D Loss: 0.13957082480192184, G Loss: 5.6500701904296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3963/100000, D Loss: 0.12286774814128876, G Loss: 5.7604875564575195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3964/100000, D Loss: 0.1257382333278656, G Loss: 5.922289848327637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3965/100000, D Loss: 0.12179221957921982, G Loss: 5.871697902679443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3966/100000, D Loss: 0.14064746350049973, G Loss: 5.471424579620361\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3967/100000, D Loss: 0.1228269413113594, G Loss: 5.780448913574219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3968/100000, D Loss: 0.12957680225372314, G Loss: 5.336902618408203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3969/100000, D Loss: 0.1362895593047142, G Loss: 5.300002098083496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3970/100000, D Loss: 0.13323847949504852, G Loss: 5.348173141479492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3971/100000, D Loss: 0.10957211628556252, G Loss: 5.539430618286133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3972/100000, D Loss: 0.11129900068044662, G Loss: 5.239838123321533\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3973/100000, D Loss: 0.11073613911867142, G Loss: 4.897154808044434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3974/100000, D Loss: 0.07933903485536575, G Loss: 4.994636535644531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3975/100000, D Loss: 0.10172538459300995, G Loss: 5.15694522857666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3976/100000, D Loss: 0.08736153692007065, G Loss: 4.995278358459473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3977/100000, D Loss: 0.08185936138033867, G Loss: 4.995667457580566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3978/100000, D Loss: 0.07171379774808884, G Loss: 4.844026565551758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3979/100000, D Loss: 0.07966327667236328, G Loss: 4.906556129455566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3980/100000, D Loss: 0.06236044690012932, G Loss: 4.973308563232422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3981/100000, D Loss: 0.0772005096077919, G Loss: 4.872614860534668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3982/100000, D Loss: 0.06615440919995308, G Loss: 5.022391319274902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3983/100000, D Loss: 0.06782270222902298, G Loss: 4.772400856018066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3984/100000, D Loss: 0.07738402858376503, G Loss: 4.582592010498047\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3985/100000, D Loss: 0.06768527440726757, G Loss: 4.5449981689453125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 3986/100000, D Loss: 0.08349682204425335, G Loss: 4.584358215332031\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3987/100000, D Loss: 0.07457517087459564, G Loss: 4.7264814376831055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3988/100000, D Loss: 0.059842728078365326, G Loss: 4.952298164367676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3989/100000, D Loss: 0.07174539193511009, G Loss: 4.740776062011719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3990/100000, D Loss: 0.0821660216897726, G Loss: 4.3588385581970215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3991/100000, D Loss: 0.08014007285237312, G Loss: 4.227362632751465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3992/100000, D Loss: 0.07888428121805191, G Loss: 4.471369743347168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3993/100000, D Loss: 0.07013730704784393, G Loss: 4.9053239822387695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3994/100000, D Loss: 0.08082276582717896, G Loss: 4.856252193450928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3995/100000, D Loss: 0.09711409732699394, G Loss: 4.560145378112793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3996/100000, D Loss: 0.10507261008024216, G Loss: 4.288054466247559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3997/100000, D Loss: 0.09065023809671402, G Loss: 4.696836948394775\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3998/100000, D Loss: 0.07300394028425217, G Loss: 4.989463806152344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 3999/100000, D Loss: 0.08460117317736149, G Loss: 4.916316509246826\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4000/100000, D Loss: 0.11221592128276825, G Loss: 4.246197700500488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4001/100000, D Loss: 0.09240015596151352, G Loss: 4.439607620239258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4002/100000, D Loss: 0.09366031363606453, G Loss: 4.992650032043457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4003/100000, D Loss: 0.09940510615706444, G Loss: 4.9470672607421875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4004/100000, D Loss: 0.10598856955766678, G Loss: 4.467136383056641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4005/100000, D Loss: 0.12673957645893097, G Loss: 4.393190383911133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4006/100000, D Loss: 0.09288900345563889, G Loss: 5.0003790855407715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4007/100000, D Loss: 0.10732316598296165, G Loss: 4.907789707183838\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4008/100000, D Loss: 0.12194064259529114, G Loss: 4.378507137298584\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4009/100000, D Loss: 0.13347652554512024, G Loss: 4.14253044128418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4010/100000, D Loss: 0.11330189555883408, G Loss: 4.842411518096924\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4011/100000, D Loss: 0.1262269839644432, G Loss: 4.953100681304932\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4012/100000, D Loss: 0.12700289115309715, G Loss: 4.460022449493408\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4013/100000, D Loss: 0.13633065670728683, G Loss: 4.218396186828613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4014/100000, D Loss: 0.10907277837395668, G Loss: 4.573732852935791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4015/100000, D Loss: 0.11406736075878143, G Loss: 5.049675941467285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4016/100000, D Loss: 0.16113006323575974, G Loss: 4.2712483406066895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4017/100000, D Loss: 0.18901918083429337, G Loss: 4.311704635620117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4018/100000, D Loss: 0.12411786243319511, G Loss: 4.8617777824401855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4019/100000, D Loss: 0.13053084537386894, G Loss: 4.74306583404541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4020/100000, D Loss: 0.1519741415977478, G Loss: 4.186429023742676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4021/100000, D Loss: 0.18717089295387268, G Loss: 4.260941982269287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4022/100000, D Loss: 0.140770111232996, G Loss: 5.044105052947998\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4023/100000, D Loss: 0.1745750531554222, G Loss: 4.706384658813477\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4024/100000, D Loss: 0.1639215312898159, G Loss: 4.355585098266602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4025/100000, D Loss: 0.14777157455682755, G Loss: 4.750935077667236\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4026/100000, D Loss: 0.14098089188337326, G Loss: 5.176816940307617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4027/100000, D Loss: 0.20094550400972366, G Loss: 4.758255958557129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4028/100000, D Loss: 0.15230175852775574, G Loss: 4.762971878051758\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4029/100000, D Loss: 0.11253437399864197, G Loss: 5.185530662536621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4030/100000, D Loss: 0.1320400983095169, G Loss: 5.048791408538818\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4031/100000, D Loss: 0.14442676305770874, G Loss: 5.059475898742676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4032/100000, D Loss: 0.17616727203130722, G Loss: 5.0945258140563965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4033/100000, D Loss: 0.14260489121079445, G Loss: 5.325745582580566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4034/100000, D Loss: 0.1872030645608902, G Loss: 5.135404109954834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4035/100000, D Loss: 0.1912163496017456, G Loss: 5.067604064941406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4036/100000, D Loss: 0.15935365110635757, G Loss: 5.664095401763916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4037/100000, D Loss: 0.16251647472381592, G Loss: 5.764182090759277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4038/100000, D Loss: 0.20633521676063538, G Loss: 5.31887149810791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4039/100000, D Loss: 0.17960476130247116, G Loss: 5.450654029846191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4040/100000, D Loss: 0.17466112226247787, G Loss: 5.5926313400268555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4041/100000, D Loss: 0.17685826122760773, G Loss: 5.656635761260986\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4042/100000, D Loss: 0.15628225356340408, G Loss: 5.8226165771484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4043/100000, D Loss: 0.14842823147773743, G Loss: 6.089972019195557\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4044/100000, D Loss: 0.14224375411868095, G Loss: 6.322116374969482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4045/100000, D Loss: 0.1461915411055088, G Loss: 6.073648452758789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4046/100000, D Loss: 0.16340439021587372, G Loss: 6.237449645996094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4047/100000, D Loss: 0.14215189218521118, G Loss: 5.947312355041504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4048/100000, D Loss: 0.1309734731912613, G Loss: 5.981225967407227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4049/100000, D Loss: 0.14294667541980743, G Loss: 6.167895317077637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4050/100000, D Loss: 0.13463695347309113, G Loss: 5.837714195251465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4051/100000, D Loss: 0.1113828644156456, G Loss: 5.934744834899902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4052/100000, D Loss: 0.1524197831749916, G Loss: 6.02036190032959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4053/100000, D Loss: 0.13563105463981628, G Loss: 5.716648578643799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4054/100000, D Loss: 0.16032174229621887, G Loss: 5.077548980712891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4055/100000, D Loss: 0.14402884989976883, G Loss: 5.177762985229492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4056/100000, D Loss: 0.10847410932183266, G Loss: 5.7713518142700195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4057/100000, D Loss: 0.16195666790008545, G Loss: 5.099109649658203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4058/100000, D Loss: 0.13969511538743973, G Loss: 4.711551666259766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4059/100000, D Loss: 0.141184464097023, G Loss: 5.181482315063477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4060/100000, D Loss: 0.12983589991927147, G Loss: 5.220771789550781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4061/100000, D Loss: 0.14957163110375404, G Loss: 4.827394485473633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4062/100000, D Loss: 0.1586899384856224, G Loss: 4.824638843536377\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4063/100000, D Loss: 0.15548153221607208, G Loss: 5.076842308044434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4064/100000, D Loss: 0.13142407685518265, G Loss: 4.981184959411621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4065/100000, D Loss: 0.14676444604992867, G Loss: 4.678983688354492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4066/100000, D Loss: 0.11894041672348976, G Loss: 4.780357360839844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4067/100000, D Loss: 0.11826694011688232, G Loss: 5.308950424194336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4068/100000, D Loss: 0.14010488986968994, G Loss: 5.0469770431518555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4069/100000, D Loss: 0.1287764571607113, G Loss: 4.738260746002197\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4070/100000, D Loss: 0.1342858150601387, G Loss: 4.937955856323242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4071/100000, D Loss: 0.10809338465332985, G Loss: 5.057724952697754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4072/100000, D Loss: 0.11313976347446442, G Loss: 4.930304527282715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4073/100000, D Loss: 0.1261853128671646, G Loss: 4.59170389175415\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4074/100000, D Loss: 0.11852740496397018, G Loss: 4.922635555267334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4075/100000, D Loss: 0.10477976873517036, G Loss: 5.396747589111328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4076/100000, D Loss: 0.14306984469294548, G Loss: 4.753970146179199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4077/100000, D Loss: 0.158631794154644, G Loss: 4.694186687469482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4078/100000, D Loss: 0.11386703327298164, G Loss: 5.040807247161865\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4079/100000, D Loss: 0.11282459646463394, G Loss: 4.897031784057617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4080/100000, D Loss: 0.11268879845738411, G Loss: 4.837438583374023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4081/100000, D Loss: 0.10914396494626999, G Loss: 5.077345371246338\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4082/100000, D Loss: 0.10916487127542496, G Loss: 5.169942855834961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4083/100000, D Loss: 0.08977220579981804, G Loss: 5.169215679168701\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4084/100000, D Loss: 0.09142041578888893, G Loss: 5.182052135467529\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4085/100000, D Loss: 0.0857000146061182, G Loss: 5.081523895263672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4086/100000, D Loss: 0.07638220489025116, G Loss: 4.920619010925293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4087/100000, D Loss: 0.09626303613185883, G Loss: 5.0816450119018555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4088/100000, D Loss: 0.06986548751592636, G Loss: 5.377490997314453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4089/100000, D Loss: 0.07566596381366253, G Loss: 5.299139022827148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4090/100000, D Loss: 0.0882219709455967, G Loss: 4.766997814178467\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4091/100000, D Loss: 0.0769164115190506, G Loss: 5.062010288238525\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4092/100000, D Loss: 0.06684519909322262, G Loss: 5.220084190368652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4093/100000, D Loss: 0.09343662671744823, G Loss: 5.164823532104492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4094/100000, D Loss: 0.08327538520097733, G Loss: 4.779175758361816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4095/100000, D Loss: 0.09834140539169312, G Loss: 4.774248123168945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4096/100000, D Loss: 0.10126802325248718, G Loss: 4.931915283203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4097/100000, D Loss: 0.10273206606507301, G Loss: 4.938286781311035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4098/100000, D Loss: 0.12304159626364708, G Loss: 4.7682037353515625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4099/100000, D Loss: 0.13314281404018402, G Loss: 4.43560791015625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4100/100000, D Loss: 0.13411549478769302, G Loss: 4.482638835906982\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4101/100000, D Loss: 0.12451217323541641, G Loss: 4.746880054473877\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4102/100000, D Loss: 0.1610489785671234, G Loss: 4.368898391723633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4103/100000, D Loss: 0.18142221868038177, G Loss: 4.193843841552734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4104/100000, D Loss: 0.14947445690631866, G Loss: 4.454825401306152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4105/100000, D Loss: 0.14519218355417252, G Loss: 4.476382732391357\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4106/100000, D Loss: 0.21862859278917313, G Loss: 4.043246269226074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4107/100000, D Loss: 0.17537540197372437, G Loss: 4.437455177307129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4108/100000, D Loss: 0.208180770277977, G Loss: 4.601373672485352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4109/100000, D Loss: 0.24232382327318192, G Loss: 3.912677526473999\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4110/100000, D Loss: 0.1554720252752304, G Loss: 4.594919204711914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4111/100000, D Loss: 0.22323250770568848, G Loss: 4.497331619262695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4112/100000, D Loss: 0.22728441655635834, G Loss: 3.9710588455200195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4113/100000, D Loss: 0.2226787880063057, G Loss: 4.425095558166504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4114/100000, D Loss: 0.17327557504177094, G Loss: 5.050778388977051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4115/100000, D Loss: 0.18859105929732323, G Loss: 4.618492603302002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4116/100000, D Loss: 0.1558770090341568, G Loss: 4.619171142578125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4117/100000, D Loss: 0.1848708838224411, G Loss: 4.809482574462891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4118/100000, D Loss: 0.1704774871468544, G Loss: 5.286005973815918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4119/100000, D Loss: 0.1948549821972847, G Loss: 4.916854381561279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4120/100000, D Loss: 0.16172371804714203, G Loss: 5.09481143951416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4121/100000, D Loss: 0.15352235734462738, G Loss: 5.407553672790527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4122/100000, D Loss: 0.17937585711479187, G Loss: 5.2417778968811035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4123/100000, D Loss: 0.15648553520441055, G Loss: 5.363581657409668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4124/100000, D Loss: 0.17698676884174347, G Loss: 5.432229995727539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4125/100000, D Loss: 0.15499021112918854, G Loss: 5.644396781921387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4126/100000, D Loss: 0.1853223741054535, G Loss: 5.3704938888549805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4127/100000, D Loss: 0.14722047001123428, G Loss: 5.721113204956055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4128/100000, D Loss: 0.14190100133419037, G Loss: 5.94346809387207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4129/100000, D Loss: 0.1359364464879036, G Loss: 5.917199611663818\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4130/100000, D Loss: 0.12704262137413025, G Loss: 5.739904403686523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4131/100000, D Loss: 0.11031269654631615, G Loss: 5.7776079177856445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4132/100000, D Loss: 0.11332546547055244, G Loss: 5.859297752380371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4133/100000, D Loss: 0.08126496523618698, G Loss: 5.831258296966553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4134/100000, D Loss: 0.11561506986618042, G Loss: 5.479081630706787\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4135/100000, D Loss: 0.1224154643714428, G Loss: 5.2874555587768555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4136/100000, D Loss: 0.09889617189764977, G Loss: 5.784958839416504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4137/100000, D Loss: 0.08609967492520809, G Loss: 5.9752302169799805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4138/100000, D Loss: 0.1412530317902565, G Loss: 5.548807144165039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4139/100000, D Loss: 0.12619322910904884, G Loss: 5.084296226501465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4140/100000, D Loss: 0.0861344188451767, G Loss: 5.425243854522705\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4141/100000, D Loss: 0.09443557448685169, G Loss: 5.790627479553223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4142/100000, D Loss: 0.10712908580899239, G Loss: 5.41267204284668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4143/100000, D Loss: 0.10913511365652084, G Loss: 4.86594295501709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4144/100000, D Loss: 0.09779078513383865, G Loss: 5.205118656158447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4145/100000, D Loss: 0.08159893751144409, G Loss: 5.656866550445557\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4146/100000, D Loss: 0.08307429403066635, G Loss: 5.788531303405762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4147/100000, D Loss: 0.08285771124064922, G Loss: 5.086809158325195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4148/100000, D Loss: 0.09734244644641876, G Loss: 4.808252334594727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4149/100000, D Loss: 0.0570880938321352, G Loss: 5.147430419921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4150/100000, D Loss: 0.07740185409784317, G Loss: 5.306914329528809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4151/100000, D Loss: 0.06647998839616776, G Loss: 5.52481746673584\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4152/100000, D Loss: 0.08465796336531639, G Loss: 5.207390308380127\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4153/100000, D Loss: 0.08998864889144897, G Loss: 5.005652904510498\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4154/100000, D Loss: 0.09365255013108253, G Loss: 4.860721588134766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4155/100000, D Loss: 0.07873941212892532, G Loss: 5.145532608032227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4156/100000, D Loss: 0.0821816511452198, G Loss: 5.165645599365234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4157/100000, D Loss: 0.09110786393284798, G Loss: 4.96061897277832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4158/100000, D Loss: 0.1039481982588768, G Loss: 4.686932563781738\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4159/100000, D Loss: 0.10617107152938843, G Loss: 4.461440086364746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4160/100000, D Loss: 0.10834170505404472, G Loss: 4.841618537902832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4161/100000, D Loss: 0.10652387887239456, G Loss: 4.946505069732666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4162/100000, D Loss: 0.1351391226053238, G Loss: 4.404480457305908\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4163/100000, D Loss: 0.11682185903191566, G Loss: 4.708148956298828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4164/100000, D Loss: 0.1345086582005024, G Loss: 4.782562255859375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4165/100000, D Loss: 0.11701155081391335, G Loss: 4.604753494262695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4166/100000, D Loss: 0.1338488832116127, G Loss: 4.522083282470703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4167/100000, D Loss: 0.105532206594944, G Loss: 4.812008857727051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4168/100000, D Loss: 0.09970688447356224, G Loss: 4.756164073944092\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4169/100000, D Loss: 0.11230222135782242, G Loss: 4.685613632202148\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4170/100000, D Loss: 0.12864122539758682, G Loss: 4.839822769165039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4171/100000, D Loss: 0.11543166637420654, G Loss: 4.702227592468262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4172/100000, D Loss: 0.14505064859986305, G Loss: 4.336372375488281\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4173/100000, D Loss: 0.11376076564192772, G Loss: 4.493590354919434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4174/100000, D Loss: 0.11518226563930511, G Loss: 4.577582359313965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4175/100000, D Loss: 0.12543044984340668, G Loss: 4.6603546142578125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4176/100000, D Loss: 0.13370196521282196, G Loss: 4.684277534484863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4177/100000, D Loss: 0.13321944326162338, G Loss: 4.558886528015137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4178/100000, D Loss: 0.16252823173999786, G Loss: 4.567368030548096\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4179/100000, D Loss: 0.16560430452227592, G Loss: 4.701683044433594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4180/100000, D Loss: 0.17047611624002457, G Loss: 4.573225975036621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4181/100000, D Loss: 0.1592094823718071, G Loss: 4.656069755554199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4182/100000, D Loss: 0.15799644589424133, G Loss: 4.7531328201293945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4183/100000, D Loss: 0.1455206573009491, G Loss: 4.796274185180664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4184/100000, D Loss: 0.15082094818353653, G Loss: 4.61152982711792\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4185/100000, D Loss: 0.180947408080101, G Loss: 4.458998203277588\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4186/100000, D Loss: 0.14872505515813828, G Loss: 4.841193199157715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4187/100000, D Loss: 0.1999000459909439, G Loss: 4.7036452293396\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4188/100000, D Loss: 0.2314082533121109, G Loss: 4.556788444519043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4189/100000, D Loss: 0.1796063557267189, G Loss: 4.839020252227783\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4190/100000, D Loss: 0.23574654012918472, G Loss: 4.64787483215332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4191/100000, D Loss: 0.21558986604213715, G Loss: 4.712975025177002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4192/100000, D Loss: 0.2594013959169388, G Loss: 4.5811614990234375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4193/100000, D Loss: 0.24711483716964722, G Loss: 4.912191390991211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4194/100000, D Loss: 0.24646206200122833, G Loss: 4.830050468444824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4195/100000, D Loss: 0.276958167552948, G Loss: 4.6826677322387695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4196/100000, D Loss: 0.20518626272678375, G Loss: 5.061141014099121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4197/100000, D Loss: 0.303582563996315, G Loss: 4.861344337463379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4198/100000, D Loss: 0.30034852772951126, G Loss: 4.640942573547363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4199/100000, D Loss: 0.27500683814287186, G Loss: 4.7826385498046875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4200/100000, D Loss: 0.3233794718980789, G Loss: 4.999699592590332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4201/100000, D Loss: 0.29775570333004, G Loss: 5.055510997772217\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4202/100000, D Loss: 0.3117322623729706, G Loss: 5.112032890319824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4203/100000, D Loss: 0.28665319085121155, G Loss: 5.022661209106445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4204/100000, D Loss: 0.3091001808643341, G Loss: 5.136709213256836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4205/100000, D Loss: 0.29458244144916534, G Loss: 5.117525100708008\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4206/100000, D Loss: 0.2604655921459198, G Loss: 5.520822048187256\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4207/100000, D Loss: 0.23252345621585846, G Loss: 5.8605499267578125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4208/100000, D Loss: 0.2260131761431694, G Loss: 5.4017839431762695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4209/100000, D Loss: 0.22020763903856277, G Loss: 5.1853556632995605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4210/100000, D Loss: 0.16261810064315796, G Loss: 5.915938377380371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4211/100000, D Loss: 0.1135101169347763, G Loss: 6.0850372314453125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4212/100000, D Loss: 0.12696801126003265, G Loss: 5.771519660949707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4213/100000, D Loss: 0.11646952852606773, G Loss: 5.509045600891113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4214/100000, D Loss: 0.09558477625250816, G Loss: 5.835273265838623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4215/100000, D Loss: 0.09964963048696518, G Loss: 5.913088798522949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4216/100000, D Loss: 0.07842255756258965, G Loss: 6.0266642570495605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4217/100000, D Loss: 0.09443364292383194, G Loss: 5.980422019958496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4218/100000, D Loss: 0.10012498870491982, G Loss: 6.10446834564209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4219/100000, D Loss: 0.09770791232585907, G Loss: 5.910004615783691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4220/100000, D Loss: 0.10471425950527191, G Loss: 5.940197944641113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4221/100000, D Loss: 0.09091777727007866, G Loss: 5.813356399536133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4222/100000, D Loss: 0.11283501237630844, G Loss: 5.783089637756348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4223/100000, D Loss: 0.09696922823786736, G Loss: 5.840176582336426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4224/100000, D Loss: 0.11353370547294617, G Loss: 5.819052219390869\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4225/100000, D Loss: 0.08499640598893166, G Loss: 6.01211404800415\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4226/100000, D Loss: 0.10859249904751778, G Loss: 5.586765289306641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4227/100000, D Loss: 0.11648574098944664, G Loss: 5.726119518280029\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4228/100000, D Loss: 0.10762680694460869, G Loss: 5.900053024291992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4229/100000, D Loss: 0.11487652361392975, G Loss: 5.484061241149902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4230/100000, D Loss: 0.1445971578359604, G Loss: 5.08461856842041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4231/100000, D Loss: 0.11183799803256989, G Loss: 5.735398292541504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4232/100000, D Loss: 0.11325778812170029, G Loss: 6.008551597595215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4233/100000, D Loss: 0.17243946716189384, G Loss: 5.236197471618652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4234/100000, D Loss: 0.17195551097393036, G Loss: 5.015801429748535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4235/100000, D Loss: 0.11749013513326645, G Loss: 5.907000541687012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4236/100000, D Loss: 0.16882359609007835, G Loss: 5.2588605880737305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4237/100000, D Loss: 0.19999001920223236, G Loss: 4.678104400634766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4238/100000, D Loss: 0.21626342833042145, G Loss: 5.09311580657959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4239/100000, D Loss: 0.19916309043765068, G Loss: 5.314229965209961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4240/100000, D Loss: 0.26184142380952835, G Loss: 4.267673015594482\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4241/100000, D Loss: 0.20662708580493927, G Loss: 4.943228721618652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4242/100000, D Loss: 0.2689853832125664, G Loss: 5.011983394622803\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4243/100000, D Loss: 0.27130144089460373, G Loss: 4.604539394378662\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4244/100000, D Loss: 0.260743647813797, G Loss: 5.066125869750977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4245/100000, D Loss: 0.2192847579717636, G Loss: 4.841172218322754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4246/100000, D Loss: 0.28117211163043976, G Loss: 4.315473556518555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4247/100000, D Loss: 0.2141146883368492, G Loss: 5.055473327636719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4248/100000, D Loss: 0.21109086275100708, G Loss: 5.070576190948486\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4249/100000, D Loss: 0.22395989298820496, G Loss: 4.900861740112305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4250/100000, D Loss: 0.18394307047128677, G Loss: 4.720986843109131\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4251/100000, D Loss: 0.1622164249420166, G Loss: 5.022055149078369\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4252/100000, D Loss: 0.18948404490947723, G Loss: 4.9958038330078125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4253/100000, D Loss: 0.19639796763658524, G Loss: 4.96275520324707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4254/100000, D Loss: 0.18659551441669464, G Loss: 4.950579643249512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4255/100000, D Loss: 0.1935432180762291, G Loss: 5.295373916625977\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4256/100000, D Loss: 0.21461647748947144, G Loss: 5.2288618087768555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4257/100000, D Loss: 0.18891828507184982, G Loss: 5.0449442863464355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4258/100000, D Loss: 0.15186303853988647, G Loss: 5.378268718719482\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4259/100000, D Loss: 0.17027410119771957, G Loss: 6.4737749099731445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4260/100000, D Loss: 0.21286962553858757, G Loss: 4.833247661590576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4261/100000, D Loss: 0.19527412950992584, G Loss: 5.357430458068848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4262/100000, D Loss: 0.1473706215620041, G Loss: 6.115004539489746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4263/100000, D Loss: 0.20100079104304314, G Loss: 5.046229362487793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4264/100000, D Loss: 0.2393943965435028, G Loss: 4.8068132400512695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4265/100000, D Loss: 0.15651842951774597, G Loss: 6.264749526977539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4266/100000, D Loss: 0.17261912301182747, G Loss: 5.879568576812744\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4267/100000, D Loss: 0.18682221323251724, G Loss: 5.1296000480651855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4268/100000, D Loss: 0.18384846299886703, G Loss: 5.6869001388549805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4269/100000, D Loss: 0.16048917919397354, G Loss: 5.955635070800781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4270/100000, D Loss: 0.17384233325719833, G Loss: 5.561206817626953\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4271/100000, D Loss: 0.18796827644109726, G Loss: 5.527037620544434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4272/100000, D Loss: 0.16514304280281067, G Loss: 5.613391876220703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4273/100000, D Loss: 0.2151428610086441, G Loss: 5.2060747146606445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4274/100000, D Loss: 0.19024847447872162, G Loss: 5.500388145446777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4275/100000, D Loss: 0.17476142942905426, G Loss: 5.663795471191406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4276/100000, D Loss: 0.18205932527780533, G Loss: 5.217957496643066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4277/100000, D Loss: 0.22148394584655762, G Loss: 5.101543426513672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4278/100000, D Loss: 0.21951434761285782, G Loss: 5.353817939758301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4279/100000, D Loss: 0.24735787510871887, G Loss: 5.026875972747803\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4280/100000, D Loss: 0.26372139155864716, G Loss: 5.091018199920654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4281/100000, D Loss: 0.2671087086200714, G Loss: 5.249456882476807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4282/100000, D Loss: 0.2938813641667366, G Loss: 5.419321537017822\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4283/100000, D Loss: 0.34377172589302063, G Loss: 5.120161056518555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4284/100000, D Loss: 0.38738498091697693, G Loss: 4.997919082641602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4285/100000, D Loss: 0.3277242034673691, G Loss: 5.5688557624816895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4286/100000, D Loss: 0.3049796521663666, G Loss: 5.497323989868164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4287/100000, D Loss: 0.2833859473466873, G Loss: 5.059680461883545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4288/100000, D Loss: 0.3182603269815445, G Loss: 5.454964637756348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4289/100000, D Loss: 0.22435329854488373, G Loss: 6.174378395080566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4290/100000, D Loss: 0.27043619006872177, G Loss: 5.310719013214111\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4291/100000, D Loss: 0.2752419114112854, G Loss: 5.170294284820557\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4292/100000, D Loss: 0.19850929826498032, G Loss: 6.1566691398620605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4293/100000, D Loss: 0.20659537613391876, G Loss: 5.948896408081055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4294/100000, D Loss: 0.232490174472332, G Loss: 5.576457977294922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4295/100000, D Loss: 0.20610804110765457, G Loss: 6.052758693695068\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4296/100000, D Loss: 0.18753057718276978, G Loss: 5.944714546203613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4297/100000, D Loss: 0.1486855484545231, G Loss: 5.5165815353393555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4298/100000, D Loss: 0.14474795013666153, G Loss: 5.989672660827637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4299/100000, D Loss: 0.11323439702391624, G Loss: 6.419584274291992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4300/100000, D Loss: 0.11592989414930344, G Loss: 6.330959796905518\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4301/100000, D Loss: 0.11116709187626839, G Loss: 6.347503662109375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4302/100000, D Loss: 0.11572084575891495, G Loss: 6.194113731384277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4303/100000, D Loss: 0.09793614596128464, G Loss: 6.094357490539551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4304/100000, D Loss: 0.08928068727254868, G Loss: 6.079409599304199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4305/100000, D Loss: 0.07631056010723114, G Loss: 6.339167594909668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4306/100000, D Loss: 0.11385335773229599, G Loss: 6.218543529510498\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4307/100000, D Loss: 0.10821833088994026, G Loss: 6.04005765914917\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4308/100000, D Loss: 0.11753655225038528, G Loss: 5.727949142456055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4309/100000, D Loss: 0.09499287232756615, G Loss: 5.746714115142822\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4310/100000, D Loss: 0.10997043177485466, G Loss: 5.815271377563477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4311/100000, D Loss: 0.11047210171818733, G Loss: 6.101284980773926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4312/100000, D Loss: 0.1095048226416111, G Loss: 5.698369026184082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4313/100000, D Loss: 0.11924649402499199, G Loss: 5.728731632232666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4314/100000, D Loss: 0.11847877502441406, G Loss: 5.810725212097168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4315/100000, D Loss: 0.13982505351305008, G Loss: 5.762379169464111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4316/100000, D Loss: 0.10492338985204697, G Loss: 5.804688453674316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4317/100000, D Loss: 0.09916708990931511, G Loss: 6.024425029754639\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4318/100000, D Loss: 0.14141447097063065, G Loss: 5.443281650543213\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4319/100000, D Loss: 0.1259533129632473, G Loss: 5.327701568603516\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4320/100000, D Loss: 0.13215282559394836, G Loss: 5.20285701751709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4321/100000, D Loss: 0.11973842233419418, G Loss: 5.553785800933838\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4322/100000, D Loss: 0.14079999923706055, G Loss: 5.358824729919434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4323/100000, D Loss: 0.1546959951519966, G Loss: 4.964785099029541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4324/100000, D Loss: 0.14085808396339417, G Loss: 5.030434608459473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4325/100000, D Loss: 0.14758506044745445, G Loss: 5.039659023284912\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4326/100000, D Loss: 0.16444260627031326, G Loss: 4.8969573974609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4327/100000, D Loss: 0.19089161604642868, G Loss: 4.739190101623535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4328/100000, D Loss: 0.19313105195760727, G Loss: 4.816041469573975\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4329/100000, D Loss: 0.16044088453054428, G Loss: 4.876572132110596\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4330/100000, D Loss: 0.22587956488132477, G Loss: 4.267358303070068\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4331/100000, D Loss: 0.1826922744512558, G Loss: 4.743233680725098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4332/100000, D Loss: 0.17956982553005219, G Loss: 4.93298864364624\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4333/100000, D Loss: 0.1665288656949997, G Loss: 4.608954906463623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4334/100000, D Loss: 0.16172613203525543, G Loss: 4.534987449645996\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4335/100000, D Loss: 0.1333383023738861, G Loss: 5.107966899871826\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4336/100000, D Loss: 0.16534829884767532, G Loss: 4.741756916046143\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4337/100000, D Loss: 0.18343693763017654, G Loss: 4.445735931396484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4338/100000, D Loss: 0.125453382730484, G Loss: 5.0847978591918945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4339/100000, D Loss: 0.13867153227329254, G Loss: 5.287710189819336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4340/100000, D Loss: 0.1867077574133873, G Loss: 4.608386039733887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4341/100000, D Loss: 0.14139699935913086, G Loss: 5.012446403503418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4342/100000, D Loss: 0.10733122378587723, G Loss: 5.373154640197754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4343/100000, D Loss: 0.12342339009046555, G Loss: 5.090156078338623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4344/100000, D Loss: 0.13348372280597687, G Loss: 4.815295219421387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4345/100000, D Loss: 0.11664988100528717, G Loss: 4.980319023132324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4346/100000, D Loss: 0.1026155948638916, G Loss: 5.367266654968262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4347/100000, D Loss: 0.12167894840240479, G Loss: 5.141801357269287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4348/100000, D Loss: 0.12183326855301857, G Loss: 5.054074764251709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4349/100000, D Loss: 0.16078046709299088, G Loss: 4.9721527099609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4350/100000, D Loss: 0.13272612914443016, G Loss: 5.19765567779541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4351/100000, D Loss: 0.1694050058722496, G Loss: 5.055041790008545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4352/100000, D Loss: 0.17558575421571732, G Loss: 5.101201057434082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4353/100000, D Loss: 0.1715300977230072, G Loss: 5.3649187088012695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4354/100000, D Loss: 0.14300064742565155, G Loss: 5.229042053222656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4355/100000, D Loss: 0.1233091875910759, G Loss: 5.300942420959473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4356/100000, D Loss: 0.14974790066480637, G Loss: 5.114595890045166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4357/100000, D Loss: 0.14963670074939728, G Loss: 5.391851902008057\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 4358/100000, D Loss: 0.15807713568210602, G Loss: 5.253584384918213\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4359/100000, D Loss: 0.17979521304368973, G Loss: 5.195111274719238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4360/100000, D Loss: 0.16645370423793793, G Loss: 5.559233665466309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4361/100000, D Loss: 0.1542176976799965, G Loss: 5.47299337387085\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4362/100000, D Loss: 0.1795809641480446, G Loss: 5.260471820831299\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4363/100000, D Loss: 0.1749536618590355, G Loss: 5.110672950744629\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4364/100000, D Loss: 0.14178545773029327, G Loss: 5.546841621398926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4365/100000, D Loss: 0.16618970409035683, G Loss: 5.651938438415527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4366/100000, D Loss: 0.16168644279241562, G Loss: 5.3178935050964355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4367/100000, D Loss: 0.16993217915296555, G Loss: 5.28316593170166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4368/100000, D Loss: 0.16614102572202682, G Loss: 5.7011518478393555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4369/100000, D Loss: 0.1741160973906517, G Loss: 5.820273399353027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4370/100000, D Loss: 0.1648167446255684, G Loss: 5.718047618865967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4371/100000, D Loss: 0.15790142863988876, G Loss: 5.436422824859619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4372/100000, D Loss: 0.1362961009144783, G Loss: 5.728973388671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4373/100000, D Loss: 0.12790580466389656, G Loss: 5.402370452880859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4374/100000, D Loss: 0.16065605729818344, G Loss: 5.222506523132324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4375/100000, D Loss: 0.11544015258550644, G Loss: 5.6691999435424805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4376/100000, D Loss: 0.15139322727918625, G Loss: 5.638718128204346\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4377/100000, D Loss: 0.1486179307103157, G Loss: 5.411464214324951\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4378/100000, D Loss: 0.1522444151341915, G Loss: 5.493315696716309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4379/100000, D Loss: 0.15201255679130554, G Loss: 5.364500522613525\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4380/100000, D Loss: 0.13677700236439705, G Loss: 5.637448787689209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4381/100000, D Loss: 0.14731688797473907, G Loss: 5.3718037605285645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4382/100000, D Loss: 0.14394598454236984, G Loss: 5.13746452331543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4383/100000, D Loss: 0.11622130125761032, G Loss: 5.4853997230529785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4384/100000, D Loss: 0.11811786517500877, G Loss: 5.678075790405273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4385/100000, D Loss: 0.13181410357356071, G Loss: 5.305017471313477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4386/100000, D Loss: 0.11310967057943344, G Loss: 4.972943305969238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4387/100000, D Loss: 0.13897765427827835, G Loss: 5.5230817794799805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4388/100000, D Loss: 0.13499300181865692, G Loss: 5.521762847900391\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4389/100000, D Loss: 0.1490163914859295, G Loss: 5.106178283691406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4390/100000, D Loss: 0.14117050170898438, G Loss: 4.864238739013672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4391/100000, D Loss: 0.15082904696464539, G Loss: 5.10699987411499\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4392/100000, D Loss: 0.14065365120768547, G Loss: 5.6472673416137695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4393/100000, D Loss: 0.11928091943264008, G Loss: 5.440269947052002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4394/100000, D Loss: 0.10575684905052185, G Loss: 5.261679649353027\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4395/100000, D Loss: 0.09383725374937057, G Loss: 5.352901458740234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4396/100000, D Loss: 0.08157669752836227, G Loss: 5.861663818359375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4397/100000, D Loss: 0.14087624475359917, G Loss: 5.565161228179932\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4398/100000, D Loss: 0.11355391889810562, G Loss: 5.286535263061523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4399/100000, D Loss: 0.11323939263820648, G Loss: 5.518738746643066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4400/100000, D Loss: 0.11623981222510338, G Loss: 5.409337043762207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4401/100000, D Loss: 0.11926578730344772, G Loss: 5.041844367980957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 4402/100000, D Loss: 0.12795265763998032, G Loss: 4.950135231018066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4403/100000, D Loss: 0.10884248837828636, G Loss: 5.495168209075928\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4404/100000, D Loss: 0.1478860229253769, G Loss: 5.076494216918945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4405/100000, D Loss: 0.12966106459498405, G Loss: 4.752120018005371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 4406/100000, D Loss: 0.15166743099689484, G Loss: 4.719812393188477\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4407/100000, D Loss: 0.12351047992706299, G Loss: 5.1505913734436035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4408/100000, D Loss: 0.1502220630645752, G Loss: 5.131522178649902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 4409/100000, D Loss: 0.13570310175418854, G Loss: 4.756394386291504\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 4410/100000, D Loss: 0.1451713740825653, G Loss: 4.664663314819336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4411/100000, D Loss: 0.14585426449775696, G Loss: 5.099745750427246\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4412/100000, D Loss: 0.14532522857189178, G Loss: 4.73284912109375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4413/100000, D Loss: 0.19102229177951813, G Loss: 4.225130558013916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4414/100000, D Loss: 0.15944349020719528, G Loss: 4.5658159255981445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4415/100000, D Loss: 0.1547098606824875, G Loss: 4.8353800773620605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4416/100000, D Loss: 0.15081588178873062, G Loss: 4.850967884063721\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4417/100000, D Loss: 0.16197793930768967, G Loss: 4.499240875244141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4418/100000, D Loss: 0.16261965036392212, G Loss: 4.541131973266602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4419/100000, D Loss: 0.11446963623166084, G Loss: 4.748589515686035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4420/100000, D Loss: 0.15633434429764748, G Loss: 4.3575568199157715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4421/100000, D Loss: 0.16082509607076645, G Loss: 4.468645095825195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4422/100000, D Loss: 0.12204694747924805, G Loss: 4.883267402648926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4423/100000, D Loss: 0.1446538008749485, G Loss: 4.797285556793213\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4424/100000, D Loss: 0.14481821283698082, G Loss: 4.330060005187988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4425/100000, D Loss: 0.15921377390623093, G Loss: 4.5123796463012695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4426/100000, D Loss: 0.14007582515478134, G Loss: 4.97296142578125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4427/100000, D Loss: 0.1564868539571762, G Loss: 4.585090637207031\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4428/100000, D Loss: 0.18107213079929352, G Loss: 4.325831413269043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4429/100000, D Loss: 0.15652550011873245, G Loss: 4.460422992706299\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4430/100000, D Loss: 0.1579468920826912, G Loss: 4.8407063484191895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4431/100000, D Loss: 0.20125190168619156, G Loss: 4.754719257354736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4432/100000, D Loss: 0.19958844780921936, G Loss: 4.544381141662598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 4433/100000, D Loss: 0.18159468472003937, G Loss: 4.8255615234375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4434/100000, D Loss: 0.19516818970441818, G Loss: 5.079188823699951\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4435/100000, D Loss: 0.17514101415872574, G Loss: 4.6019511222839355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4436/100000, D Loss: 0.19861552119255066, G Loss: 4.623544216156006\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4437/100000, D Loss: 0.16081449016928673, G Loss: 5.1033430099487305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4438/100000, D Loss: 0.17178036272525787, G Loss: 4.565291881561279\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4439/100000, D Loss: 0.2316117137670517, G Loss: 4.6359944343566895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4440/100000, D Loss: 0.1672510728240013, G Loss: 5.151340484619141\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4441/100000, D Loss: 0.22990062087774277, G Loss: 4.748795509338379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4442/100000, D Loss: 0.22077679634094238, G Loss: 4.4268059730529785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4443/100000, D Loss: 0.18787700682878494, G Loss: 4.835020065307617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4444/100000, D Loss: 0.20420975983142853, G Loss: 4.637839317321777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4445/100000, D Loss: 0.21065880358219147, G Loss: 4.725221633911133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4446/100000, D Loss: 0.19646164029836655, G Loss: 4.98442268371582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4447/100000, D Loss: 0.2280687466263771, G Loss: 4.790220737457275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4448/100000, D Loss: 0.26092444360256195, G Loss: 4.3941969871521\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4449/100000, D Loss: 0.20140385627746582, G Loss: 5.065153121948242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4450/100000, D Loss: 0.205013208091259, G Loss: 4.90035343170166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4451/100000, D Loss: 0.19365952908992767, G Loss: 4.654966354370117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4452/100000, D Loss: 0.15585370361804962, G Loss: 4.874276161193848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4453/100000, D Loss: 0.13326502963900566, G Loss: 5.342953205108643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4454/100000, D Loss: 0.13980907946825027, G Loss: 5.121532440185547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4455/100000, D Loss: 0.11852382868528366, G Loss: 5.191896438598633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4456/100000, D Loss: 0.10567628592252731, G Loss: 5.065271854400635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4457/100000, D Loss: 0.08778878301382065, G Loss: 5.557800769805908\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4458/100000, D Loss: 0.09593615680932999, G Loss: 5.540234565734863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4459/100000, D Loss: 0.10242364928126335, G Loss: 5.210460662841797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4460/100000, D Loss: 0.08166876435279846, G Loss: 5.300952434539795\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4461/100000, D Loss: 0.09432033076882362, G Loss: 5.196779251098633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4462/100000, D Loss: 0.0986018218100071, G Loss: 5.356436729431152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4463/100000, D Loss: 0.08804981037974358, G Loss: 5.485591411590576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4464/100000, D Loss: 0.11278729140758514, G Loss: 5.100851058959961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4465/100000, D Loss: 0.11542442440986633, G Loss: 5.128278732299805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4466/100000, D Loss: 0.11008167266845703, G Loss: 5.333949565887451\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4467/100000, D Loss: 0.12358805537223816, G Loss: 5.109151840209961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4468/100000, D Loss: 0.11768471449613571, G Loss: 4.948485374450684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4469/100000, D Loss: 0.11769554391503334, G Loss: 5.105120658874512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4470/100000, D Loss: 0.1293012872338295, G Loss: 5.178693771362305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4471/100000, D Loss: 0.13662607967853546, G Loss: 5.265585899353027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4472/100000, D Loss: 0.1301063559949398, G Loss: 5.028869152069092\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4473/100000, D Loss: 0.12679962068796158, G Loss: 4.9159955978393555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4474/100000, D Loss: 0.11778032407164574, G Loss: 5.185751914978027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4475/100000, D Loss: 0.1229129396378994, G Loss: 5.117618560791016\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4476/100000, D Loss: 0.12953730300068855, G Loss: 4.863765716552734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4477/100000, D Loss: 0.09219002723693848, G Loss: 5.016722202301025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4478/100000, D Loss: 0.0995090864598751, G Loss: 5.2274932861328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4479/100000, D Loss: 0.10416802018880844, G Loss: 5.022741317749023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4480/100000, D Loss: 0.09771475940942764, G Loss: 5.038944244384766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4481/100000, D Loss: 0.09156712144613266, G Loss: 5.127219200134277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4482/100000, D Loss: 0.08135172724723816, G Loss: 5.462254047393799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4483/100000, D Loss: 0.07932178303599358, G Loss: 5.2823638916015625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4484/100000, D Loss: 0.10153752565383911, G Loss: 4.895801544189453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4485/100000, D Loss: 0.08150067180395126, G Loss: 4.939192295074463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4486/100000, D Loss: 0.08446761965751648, G Loss: 5.291772842407227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4487/100000, D Loss: 0.08555908501148224, G Loss: 5.480018138885498\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4488/100000, D Loss: 0.10791945457458496, G Loss: 5.024462699890137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4489/100000, D Loss: 0.12550164014101028, G Loss: 4.832568168640137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4490/100000, D Loss: 0.0902106873691082, G Loss: 5.114901065826416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4491/100000, D Loss: 0.10086403042078018, G Loss: 4.968603134155273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4492/100000, D Loss: 0.13420012965798378, G Loss: 4.621943473815918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4493/100000, D Loss: 0.11667253822088242, G Loss: 4.854560375213623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4494/100000, D Loss: 0.11046123504638672, G Loss: 5.048497676849365\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4495/100000, D Loss: 0.14562252163887024, G Loss: 4.810101509094238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4496/100000, D Loss: 0.1450083702802658, G Loss: 4.8189005851745605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4497/100000, D Loss: 0.1674114093184471, G Loss: 4.84805965423584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4498/100000, D Loss: 0.19722206890583038, G Loss: 4.479865550994873\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4499/100000, D Loss: 0.18276283144950867, G Loss: 4.421562194824219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4500/100000, D Loss: 0.17348679900169373, G Loss: 4.766436576843262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4501/100000, D Loss: 0.1894482672214508, G Loss: 4.648330211639404\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4502/100000, D Loss: 0.23418675363063812, G Loss: 4.212061882019043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4503/100000, D Loss: 0.18685350567102432, G Loss: 4.603798866271973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4504/100000, D Loss: 0.1922617107629776, G Loss: 4.972712516784668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4505/100000, D Loss: 0.19068769365549088, G Loss: 4.680567741394043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4506/100000, D Loss: 0.15745249390602112, G Loss: 4.328780651092529\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4507/100000, D Loss: 0.16628511995077133, G Loss: 4.618681907653809\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4508/100000, D Loss: 0.16281958669424057, G Loss: 4.976574420928955\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4509/100000, D Loss: 0.13955779746174812, G Loss: 4.693157196044922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4510/100000, D Loss: 0.15003973245620728, G Loss: 4.736125946044922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4511/100000, D Loss: 0.11874952539801598, G Loss: 4.826370716094971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4512/100000, D Loss: 0.16291595995426178, G Loss: 4.749634742736816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4513/100000, D Loss: 0.1311844326555729, G Loss: 4.704514026641846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4514/100000, D Loss: 0.1419341266155243, G Loss: 4.687283039093018\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4515/100000, D Loss: 0.16788797825574875, G Loss: 4.6244401931762695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4516/100000, D Loss: 0.16825222969055176, G Loss: 4.739029884338379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4517/100000, D Loss: 0.1319042071700096, G Loss: 4.899715423583984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4518/100000, D Loss: 0.15630602091550827, G Loss: 4.772479057312012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4519/100000, D Loss: 0.16894618421792984, G Loss: 4.541731834411621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4520/100000, D Loss: 0.16591817140579224, G Loss: 4.553569793701172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4521/100000, D Loss: 0.20224492996931076, G Loss: 4.5755295753479\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4522/100000, D Loss: 0.21137617528438568, G Loss: 4.517282009124756\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4523/100000, D Loss: 0.2758292406797409, G Loss: 4.385507583618164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4524/100000, D Loss: 0.21121807396411896, G Loss: 4.809606552124023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4525/100000, D Loss: 0.2612892761826515, G Loss: 4.5795512199401855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4526/100000, D Loss: 0.23975052684545517, G Loss: 4.68987512588501\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4527/100000, D Loss: 0.27740751951932907, G Loss: 4.483400344848633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4528/100000, D Loss: 0.2967131584882736, G Loss: 4.3986616134643555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4529/100000, D Loss: 0.25946249812841415, G Loss: 4.541959285736084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4530/100000, D Loss: 0.29649685323238373, G Loss: 4.49174690246582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4531/100000, D Loss: 0.25463879108428955, G Loss: 4.568731784820557\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4532/100000, D Loss: 0.2566091865301132, G Loss: 4.524350643157959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4533/100000, D Loss: 0.3000161349773407, G Loss: 4.380311012268066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4534/100000, D Loss: 0.23959624022245407, G Loss: 4.547760009765625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4535/100000, D Loss: 0.2531008869409561, G Loss: 4.545621871948242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4536/100000, D Loss: 0.20219043642282486, G Loss: 4.649252891540527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4537/100000, D Loss: 0.1817193552851677, G Loss: 4.720359802246094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4538/100000, D Loss: 0.180059552192688, G Loss: 4.664756774902344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4539/100000, D Loss: 0.13718374446034431, G Loss: 4.998030662536621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4540/100000, D Loss: 0.18239958211779594, G Loss: 4.706448554992676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4541/100000, D Loss: 0.1498829945921898, G Loss: 4.799192905426025\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4542/100000, D Loss: 0.1164020374417305, G Loss: 5.270713806152344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4543/100000, D Loss: 0.13622768223285675, G Loss: 5.270158290863037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4544/100000, D Loss: 0.1237478144466877, G Loss: 4.84182596206665\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4545/100000, D Loss: 0.12422843277454376, G Loss: 5.098115921020508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4546/100000, D Loss: 0.11981049552559853, G Loss: 5.456052303314209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4547/100000, D Loss: 0.11458251625299454, G Loss: 5.531370162963867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4548/100000, D Loss: 0.12447528541088104, G Loss: 5.501447677612305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4549/100000, D Loss: 0.10117214173078537, G Loss: 5.830894947052002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4550/100000, D Loss: 0.09417684748768806, G Loss: 6.068350791931152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4551/100000, D Loss: 0.10182913020253181, G Loss: 6.000557899475098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4552/100000, D Loss: 0.11309418827295303, G Loss: 5.905838489532471\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4553/100000, D Loss: 0.11104635894298553, G Loss: 5.920629978179932\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4554/100000, D Loss: 0.1415243148803711, G Loss: 6.545955657958984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4555/100000, D Loss: 0.11662949621677399, G Loss: 6.964559555053711\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4556/100000, D Loss: 0.12534167617559433, G Loss: 6.926413536071777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4557/100000, D Loss: 0.1493283212184906, G Loss: 6.537992477416992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4558/100000, D Loss: 0.15903043001890182, G Loss: 6.691941261291504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4559/100000, D Loss: 0.16630196943879128, G Loss: 6.970916271209717\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4560/100000, D Loss: 0.16379377990961075, G Loss: 7.744448661804199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4561/100000, D Loss: 0.18791866302490234, G Loss: 7.2898993492126465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4562/100000, D Loss: 0.14028999209403992, G Loss: 7.1151909828186035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4563/100000, D Loss: 0.1481260024011135, G Loss: 6.852795600891113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4564/100000, D Loss: 0.13066886737942696, G Loss: 7.33387565612793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4565/100000, D Loss: 0.10259513929486275, G Loss: 7.436824798583984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4566/100000, D Loss: 0.11804025620222092, G Loss: 7.640305519104004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4567/100000, D Loss: 0.11994393542408943, G Loss: 7.5879645347595215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4568/100000, D Loss: 0.11673521623015404, G Loss: 7.100743293762207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4569/100000, D Loss: 0.13375317305326462, G Loss: 6.8631134033203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4570/100000, D Loss: 0.10890613496303558, G Loss: 6.913968086242676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4571/100000, D Loss: 0.1255456805229187, G Loss: 7.179715156555176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4572/100000, D Loss: 0.11572111397981644, G Loss: 7.252911567687988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4573/100000, D Loss: 0.12723011523485184, G Loss: 7.044888019561768\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4574/100000, D Loss: 0.16906923055648804, G Loss: 6.116843223571777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4575/100000, D Loss: 0.1375228837132454, G Loss: 5.784337997436523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4576/100000, D Loss: 0.1331416592001915, G Loss: 5.951054573059082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4577/100000, D Loss: 0.14830271154642105, G Loss: 5.952207565307617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4578/100000, D Loss: 0.13817589357495308, G Loss: 5.6143598556518555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4579/100000, D Loss: 0.14339866489171982, G Loss: 5.596197128295898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4580/100000, D Loss: 0.15393579006195068, G Loss: 5.484002590179443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4581/100000, D Loss: 0.1470152661204338, G Loss: 5.543394565582275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4582/100000, D Loss: 0.1670338362455368, G Loss: 5.095612049102783\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4583/100000, D Loss: 0.179407000541687, G Loss: 4.689506530761719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4584/100000, D Loss: 0.18452616035938263, G Loss: 4.705310821533203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4585/100000, D Loss: 0.1672281101346016, G Loss: 5.07391357421875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4586/100000, D Loss: 0.18470318615436554, G Loss: 5.20867919921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4587/100000, D Loss: 0.2327907383441925, G Loss: 4.617986679077148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4588/100000, D Loss: 0.24281326681375504, G Loss: 4.328395843505859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4589/100000, D Loss: 0.22341816127300262, G Loss: 4.846247673034668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4590/100000, D Loss: 0.24582669883966446, G Loss: 4.794107437133789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4591/100000, D Loss: 0.22991327941417694, G Loss: 4.695684432983398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4592/100000, D Loss: 0.2582711726427078, G Loss: 4.437972068786621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4593/100000, D Loss: 0.24458611011505127, G Loss: 4.534482955932617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4594/100000, D Loss: 0.20396288484334946, G Loss: 4.730809211730957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4595/100000, D Loss: 0.2511257454752922, G Loss: 4.518725872039795\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4596/100000, D Loss: 0.20307409763336182, G Loss: 4.764843940734863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4597/100000, D Loss: 0.19264328479766846, G Loss: 5.0773725509643555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4598/100000, D Loss: 0.18321099504828453, G Loss: 4.91508674621582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4599/100000, D Loss: 0.23073336482048035, G Loss: 4.6845550537109375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4600/100000, D Loss: 0.17826300859451294, G Loss: 4.801630973815918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4601/100000, D Loss: 0.19012319296598434, G Loss: 5.357476711273193\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4602/100000, D Loss: 0.19603999704122543, G Loss: 5.259001731872559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4603/100000, D Loss: 0.19401833415031433, G Loss: 4.6964240074157715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4604/100000, D Loss: 0.16301818192005157, G Loss: 4.688511848449707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4605/100000, D Loss: 0.15823742747306824, G Loss: 4.948396682739258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4606/100000, D Loss: 0.1840520277619362, G Loss: 5.096141815185547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4607/100000, D Loss: 0.1597956344485283, G Loss: 5.133536338806152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4608/100000, D Loss: 0.16059105843305588, G Loss: 5.166696548461914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4609/100000, D Loss: 0.13913650810718536, G Loss: 5.277650833129883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4610/100000, D Loss: 0.1726602390408516, G Loss: 5.15131950378418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4611/100000, D Loss: 0.15156376361846924, G Loss: 5.044022083282471\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4612/100000, D Loss: 0.14511078223586082, G Loss: 5.103328704833984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4613/100000, D Loss: 0.12062282860279083, G Loss: 5.31955099105835\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4614/100000, D Loss: 0.12401191145181656, G Loss: 5.45266056060791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4615/100000, D Loss: 0.15147119760513306, G Loss: 5.242412090301514\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4616/100000, D Loss: 0.14650055021047592, G Loss: 5.109396934509277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4617/100000, D Loss: 0.11279244348406792, G Loss: 5.302387237548828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4618/100000, D Loss: 0.10041290894150734, G Loss: 5.4568986892700195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4619/100000, D Loss: 0.10020487383008003, G Loss: 5.217314720153809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4620/100000, D Loss: 0.12081089988350868, G Loss: 5.285540580749512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4621/100000, D Loss: 0.12168803438544273, G Loss: 5.288872718811035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4622/100000, D Loss: 0.11083802580833435, G Loss: 5.233364105224609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4623/100000, D Loss: 0.0954929068684578, G Loss: 5.207403182983398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4624/100000, D Loss: 0.11857715994119644, G Loss: 4.959446907043457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4625/100000, D Loss: 0.13881008327007294, G Loss: 5.1031293869018555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4626/100000, D Loss: 0.16039921343326569, G Loss: 5.073461532592773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4627/100000, D Loss: 0.14601082354784012, G Loss: 4.93854284286499\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4628/100000, D Loss: 0.1651093065738678, G Loss: 4.772190570831299\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4629/100000, D Loss: 0.15986588597297668, G Loss: 4.823311805725098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4630/100000, D Loss: 0.20424794405698776, G Loss: 4.68619441986084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4631/100000, D Loss: 0.22462166845798492, G Loss: 4.5568695068359375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4632/100000, D Loss: 0.21865935623645782, G Loss: 4.609459400177002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4633/100000, D Loss: 0.20006665587425232, G Loss: 4.817398548126221\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4634/100000, D Loss: 0.25733357667922974, G Loss: 4.3645830154418945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4635/100000, D Loss: 0.2717607319355011, G Loss: 4.322699069976807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4636/100000, D Loss: 0.20933343470096588, G Loss: 4.887879371643066\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4637/100000, D Loss: 0.2195427417755127, G Loss: 4.828925609588623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4638/100000, D Loss: 0.3129589557647705, G Loss: 4.420185565948486\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4639/100000, D Loss: 0.21857093274593353, G Loss: 5.195023536682129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4640/100000, D Loss: 0.2188565656542778, G Loss: 4.826882839202881\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4641/100000, D Loss: 0.2731702923774719, G Loss: 4.397303104400635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4642/100000, D Loss: 0.18613696843385696, G Loss: 4.837012767791748\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4643/100000, D Loss: 0.2104814350605011, G Loss: 4.958689212799072\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4644/100000, D Loss: 0.2442699670791626, G Loss: 4.617611408233643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4645/100000, D Loss: 0.2048434019088745, G Loss: 4.6827006340026855\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4646/100000, D Loss: 0.2140633389353752, G Loss: 5.05644416809082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4647/100000, D Loss: 0.2139509916305542, G Loss: 4.821212291717529\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4648/100000, D Loss: 0.22493228316307068, G Loss: 4.6071343421936035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4649/100000, D Loss: 0.22864719480276108, G Loss: 4.7225847244262695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4650/100000, D Loss: 0.16932965070009232, G Loss: 5.188667297363281\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4651/100000, D Loss: 0.18625472858548164, G Loss: 4.852869033813477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4652/100000, D Loss: 0.18773112446069717, G Loss: 4.596797943115234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4653/100000, D Loss: 0.1811053454875946, G Loss: 4.586505889892578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4654/100000, D Loss: 0.1528337076306343, G Loss: 5.207005500793457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4655/100000, D Loss: 0.16469451785087585, G Loss: 4.84316349029541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4656/100000, D Loss: 0.19314809143543243, G Loss: 4.497757434844971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4657/100000, D Loss: 0.15970313549041748, G Loss: 5.096059799194336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4658/100000, D Loss: 0.13254479691386223, G Loss: 5.555478096008301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4659/100000, D Loss: 0.17507630586624146, G Loss: 4.902854919433594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4660/100000, D Loss: 0.18000346422195435, G Loss: 4.665297985076904\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4661/100000, D Loss: 0.1378931626677513, G Loss: 5.306855201721191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4662/100000, D Loss: 0.16726739704608917, G Loss: 5.013741970062256\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4663/100000, D Loss: 0.1688845008611679, G Loss: 4.499965667724609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4664/100000, D Loss: 0.1598057746887207, G Loss: 4.842776298522949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4665/100000, D Loss: 0.13380184769630432, G Loss: 5.600478172302246\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4666/100000, D Loss: 0.13988177105784416, G Loss: 5.25147819519043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4667/100000, D Loss: 0.1944475695490837, G Loss: 4.383033752441406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4668/100000, D Loss: 0.13763932511210442, G Loss: 4.69915246963501\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4669/100000, D Loss: 0.12540088221430779, G Loss: 5.307504177093506\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4670/100000, D Loss: 0.13543717563152313, G Loss: 5.143444061279297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4671/100000, D Loss: 0.17211433500051498, G Loss: 4.6987409591674805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4672/100000, D Loss: 0.171012245118618, G Loss: 4.5076799392700195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4673/100000, D Loss: 0.15335407853126526, G Loss: 5.076876163482666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4674/100000, D Loss: 0.16803563386201859, G Loss: 4.801610946655273\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4675/100000, D Loss: 0.14890377968549728, G Loss: 4.647494316101074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4676/100000, D Loss: 0.12863000482320786, G Loss: 4.68939733505249\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4677/100000, D Loss: 0.14680468291044235, G Loss: 5.112074375152588\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4678/100000, D Loss: 0.11776997521519661, G Loss: 5.129384994506836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4679/100000, D Loss: 0.13669900596141815, G Loss: 4.8352813720703125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4680/100000, D Loss: 0.14493118226528168, G Loss: 4.8767266273498535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4681/100000, D Loss: 0.12706609815359116, G Loss: 5.307831764221191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4682/100000, D Loss: 0.12981991097331047, G Loss: 5.310901165008545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4683/100000, D Loss: 0.16191284358501434, G Loss: 4.797680854797363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4684/100000, D Loss: 0.2026953026652336, G Loss: 4.646334648132324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4685/100000, D Loss: 0.18263200670480728, G Loss: 5.041341781616211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4686/100000, D Loss: 0.2669021263718605, G Loss: 4.804849624633789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4687/100000, D Loss: 0.2806825637817383, G Loss: 4.684077262878418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4688/100000, D Loss: 0.31860509514808655, G Loss: 4.717683792114258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4689/100000, D Loss: 0.3759046792984009, G Loss: 4.669212341308594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4690/100000, D Loss: 0.46671751141548157, G Loss: 4.406085014343262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4691/100000, D Loss: 0.5968515276908875, G Loss: 4.634626388549805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4692/100000, D Loss: 0.6291834712028503, G Loss: 4.48583984375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4693/100000, D Loss: 0.8726699352264404, G Loss: 3.882059097290039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4694/100000, D Loss: 0.7830017805099487, G Loss: 4.594027996063232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4695/100000, D Loss: 0.7858222424983978, G Loss: 4.337132453918457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4696/100000, D Loss: 0.7432591617107391, G Loss: 3.9009475708007812\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4697/100000, D Loss: 0.5801233351230621, G Loss: 4.642317771911621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4698/100000, D Loss: 0.40246646851301193, G Loss: 4.975419998168945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4699/100000, D Loss: 0.2886165678501129, G Loss: 4.796557426452637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4700/100000, D Loss: 0.22667692601680756, G Loss: 4.948099136352539\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4701/100000, D Loss: 0.14196699857711792, G Loss: 5.212117671966553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4702/100000, D Loss: 0.10500897839665413, G Loss: 5.554893493652344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4703/100000, D Loss: 0.09352949261665344, G Loss: 5.660437107086182\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4704/100000, D Loss: 0.09398297592997551, G Loss: 5.3409600257873535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4705/100000, D Loss: 0.08703134581446648, G Loss: 5.444469451904297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4706/100000, D Loss: 0.09083801880478859, G Loss: 5.671747207641602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4707/100000, D Loss: 0.09931899979710579, G Loss: 5.58668327331543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4708/100000, D Loss: 0.0970444492995739, G Loss: 5.727024078369141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4709/100000, D Loss: 0.0738963782787323, G Loss: 5.681504249572754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4710/100000, D Loss: 0.09906155243515968, G Loss: 5.492365837097168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4711/100000, D Loss: 0.1268354393541813, G Loss: 5.25595235824585\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4712/100000, D Loss: 0.13668477535247803, G Loss: 5.471177101135254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4713/100000, D Loss: 0.13532091677188873, G Loss: 5.50363826751709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4714/100000, D Loss: 0.18105672299861908, G Loss: 5.112667083740234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4715/100000, D Loss: 0.19562885910272598, G Loss: 4.773751258850098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4716/100000, D Loss: 0.20300374180078506, G Loss: 4.993409156799316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4717/100000, D Loss: 0.19486510008573532, G Loss: 5.052970886230469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4718/100000, D Loss: 0.21276918053627014, G Loss: 4.6051154136657715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4719/100000, D Loss: 0.22805287688970566, G Loss: 4.619941234588623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4720/100000, D Loss: 0.24213723093271255, G Loss: 4.97281551361084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4721/100000, D Loss: 0.23170962184667587, G Loss: 4.87270450592041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4722/100000, D Loss: 0.26619505882263184, G Loss: 4.230276107788086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4723/100000, D Loss: 0.21387089788913727, G Loss: 4.462188720703125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4724/100000, D Loss: 0.17343617230653763, G Loss: 5.073841094970703\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4725/100000, D Loss: 0.17484182864427567, G Loss: 5.005521774291992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4726/100000, D Loss: 0.17529847472906113, G Loss: 4.5091047286987305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4727/100000, D Loss: 0.12574423104524612, G Loss: 4.783496856689453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4728/100000, D Loss: 0.10492886230349541, G Loss: 5.263759136199951\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4729/100000, D Loss: 0.0775241106748581, G Loss: 5.6330461502075195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4730/100000, D Loss: 0.1012030839920044, G Loss: 5.135776042938232\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4731/100000, D Loss: 0.11197985708713531, G Loss: 4.694834232330322\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4732/100000, D Loss: 0.10375912860035896, G Loss: 4.876812934875488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4733/100000, D Loss: 0.09398163855075836, G Loss: 5.33265495300293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4734/100000, D Loss: 0.07648308388888836, G Loss: 5.600541591644287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4735/100000, D Loss: 0.10565628856420517, G Loss: 5.06390905380249\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4736/100000, D Loss: 0.10856731235980988, G Loss: 4.829659938812256\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4737/100000, D Loss: 0.09386486187577248, G Loss: 4.963358402252197\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4738/100000, D Loss: 0.09012510254979134, G Loss: 5.200375556945801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4739/100000, D Loss: 0.11344146728515625, G Loss: 5.150149345397949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4740/100000, D Loss: 0.14575333893299103, G Loss: 4.803428649902344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4741/100000, D Loss: 0.1319030225276947, G Loss: 4.829412460327148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4742/100000, D Loss: 0.1358824223279953, G Loss: 4.706132888793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4743/100000, D Loss: 0.1387651413679123, G Loss: 4.717315673828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4744/100000, D Loss: 0.12904834002256393, G Loss: 4.997397422790527\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4745/100000, D Loss: 0.16383086144924164, G Loss: 4.899748802185059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4746/100000, D Loss: 0.1638764813542366, G Loss: 4.57011604309082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4747/100000, D Loss: 0.19690100103616714, G Loss: 4.486198425292969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4748/100000, D Loss: 0.16938305646181107, G Loss: 5.046236515045166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4749/100000, D Loss: 0.1913100630044937, G Loss: 4.860098838806152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4750/100000, D Loss: 0.1914050430059433, G Loss: 4.574832916259766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4751/100000, D Loss: 0.17847054451704025, G Loss: 4.6759443283081055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4752/100000, D Loss: 0.16944164782762527, G Loss: 4.76517391204834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4753/100000, D Loss: 0.19760403037071228, G Loss: 4.754937171936035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4754/100000, D Loss: 0.1859709993004799, G Loss: 4.642678737640381\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4755/100000, D Loss: 0.20600571483373642, G Loss: 4.343939304351807\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4756/100000, D Loss: 0.22699455171823502, G Loss: 4.202527046203613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4757/100000, D Loss: 0.17950990796089172, G Loss: 4.637081623077393\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4758/100000, D Loss: 0.2115004062652588, G Loss: 4.631150245666504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4759/100000, D Loss: 0.21875547617673874, G Loss: 4.472228050231934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4760/100000, D Loss: 0.1963152289390564, G Loss: 4.573393821716309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4761/100000, D Loss: 0.20133443176746368, G Loss: 4.387667655944824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4762/100000, D Loss: 0.22656045109033585, G Loss: 4.479876518249512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4763/100000, D Loss: 0.22700364887714386, G Loss: 4.760873794555664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4764/100000, D Loss: 0.22142673283815384, G Loss: 4.57393217086792\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4765/100000, D Loss: 0.209669828414917, G Loss: 4.437772750854492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4766/100000, D Loss: 0.2023630365729332, G Loss: 4.85862922668457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4767/100000, D Loss: 0.20686709880828857, G Loss: 4.708076000213623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4768/100000, D Loss: 0.21942591667175293, G Loss: 4.453179836273193\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4769/100000, D Loss: 0.2095201015472412, G Loss: 4.645098686218262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4770/100000, D Loss: 0.20918818563222885, G Loss: 4.906119346618652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4771/100000, D Loss: 0.21550996601581573, G Loss: 4.681021690368652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4772/100000, D Loss: 0.2755168303847313, G Loss: 4.146001815795898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4773/100000, D Loss: 0.23921974003314972, G Loss: 4.6321916580200195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4774/100000, D Loss: 0.20209557563066483, G Loss: 5.075592517852783\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4775/100000, D Loss: 0.2209279090166092, G Loss: 4.293270111083984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4776/100000, D Loss: 0.23311391472816467, G Loss: 4.251899242401123\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4777/100000, D Loss: 0.20040593296289444, G Loss: 4.774619102478027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4778/100000, D Loss: 0.20908933877944946, G Loss: 4.46242618560791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4779/100000, D Loss: 0.24367037415504456, G Loss: 4.001473426818848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4780/100000, D Loss: 0.2310236692428589, G Loss: 4.334104061126709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4781/100000, D Loss: 0.17456840723752975, G Loss: 5.078367233276367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4782/100000, D Loss: 0.22188153117895126, G Loss: 4.5460591316223145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4783/100000, D Loss: 0.18722209334373474, G Loss: 4.189648628234863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4784/100000, D Loss: 0.18429511040449142, G Loss: 4.533064842224121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4785/100000, D Loss: 0.16131462156772614, G Loss: 5.0741167068481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4786/100000, D Loss: 0.20638766884803772, G Loss: 4.542397499084473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4787/100000, D Loss: 0.20119443535804749, G Loss: 4.2099785804748535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4788/100000, D Loss: 0.2069270834326744, G Loss: 4.480740547180176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4789/100000, D Loss: 0.17122261971235275, G Loss: 5.0555620193481445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4790/100000, D Loss: 0.16569766402244568, G Loss: 4.939027786254883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4791/100000, D Loss: 0.17438846081495285, G Loss: 4.269017219543457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4792/100000, D Loss: 0.1724083349108696, G Loss: 4.376372814178467\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4793/100000, D Loss: 0.13488298654556274, G Loss: 4.910396099090576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4794/100000, D Loss: 0.1343645416200161, G Loss: 5.2349138259887695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4795/100000, D Loss: 0.15859279036521912, G Loss: 4.5168256759643555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4796/100000, D Loss: 0.15172257274389267, G Loss: 4.502252578735352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4797/100000, D Loss: 0.13189220055937767, G Loss: 4.666729927062988\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4798/100000, D Loss: 0.18588506430387497, G Loss: 4.405055522918701\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4799/100000, D Loss: 0.16345880925655365, G Loss: 4.372984886169434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4800/100000, D Loss: 0.14154545962810516, G Loss: 4.677418231964111\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4801/100000, D Loss: 0.13728445768356323, G Loss: 4.907465934753418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4802/100000, D Loss: 0.13908074796199799, G Loss: 4.829819202423096\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4803/100000, D Loss: 0.14674603939056396, G Loss: 4.735473155975342\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4804/100000, D Loss: 0.1458965390920639, G Loss: 4.644274711608887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4805/100000, D Loss: 0.15894393622875214, G Loss: 4.536138534545898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4806/100000, D Loss: 0.15443721413612366, G Loss: 4.497034549713135\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4807/100000, D Loss: 0.12051025405526161, G Loss: 4.479840278625488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4808/100000, D Loss: 0.1491597220301628, G Loss: 4.419848442077637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4809/100000, D Loss: 0.13648457825183868, G Loss: 4.659921646118164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4810/100000, D Loss: 0.1497122049331665, G Loss: 4.575946807861328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4811/100000, D Loss: 0.1997271180152893, G Loss: 4.228238105773926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4812/100000, D Loss: 0.18381627649068832, G Loss: 4.496792316436768\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4813/100000, D Loss: 0.16744405031204224, G Loss: 4.6196417808532715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4814/100000, D Loss: 0.17027751356363297, G Loss: 4.643955707550049\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4815/100000, D Loss: 0.23232383280992508, G Loss: 4.056221961975098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4816/100000, D Loss: 0.2233019396662712, G Loss: 4.175024032592773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4817/100000, D Loss: 0.1984228417277336, G Loss: 4.708481788635254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4818/100000, D Loss: 0.20462806522846222, G Loss: 4.698657989501953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4819/100000, D Loss: 0.23705272376537323, G Loss: 4.256768703460693\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4820/100000, D Loss: 0.22553636878728867, G Loss: 4.581634521484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4821/100000, D Loss: 0.22701305150985718, G Loss: 4.84880256652832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4822/100000, D Loss: 0.26686692982912064, G Loss: 4.610067367553711\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4823/100000, D Loss: 0.32325246930122375, G Loss: 4.43009614944458\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4824/100000, D Loss: 0.2832746207714081, G Loss: 4.809107780456543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4825/100000, D Loss: 0.30078883469104767, G Loss: 4.994283676147461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4826/100000, D Loss: 0.36640819907188416, G Loss: 4.467164516448975\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4827/100000, D Loss: 0.2843010425567627, G Loss: 4.984672546386719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4828/100000, D Loss: 0.27168096601963043, G Loss: 5.364733695983887\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4829/100000, D Loss: 0.259551078081131, G Loss: 5.042572975158691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4830/100000, D Loss: 0.2679808884859085, G Loss: 4.699390411376953\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4831/100000, D Loss: 0.23387978971004486, G Loss: 4.912144660949707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4832/100000, D Loss: 0.20398204028606415, G Loss: 5.615063667297363\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4833/100000, D Loss: 0.2449217364192009, G Loss: 5.139468193054199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4834/100000, D Loss: 0.21058283001184464, G Loss: 4.787776947021484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4835/100000, D Loss: 0.20354709774255753, G Loss: 5.020803451538086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4836/100000, D Loss: 0.13964509218931198, G Loss: 5.471122741699219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4837/100000, D Loss: 0.17465950176119804, G Loss: 5.094925403594971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4838/100000, D Loss: 0.1517721265554428, G Loss: 4.888352394104004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4839/100000, D Loss: 0.15297534316778183, G Loss: 5.119924545288086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4840/100000, D Loss: 0.1401938758790493, G Loss: 5.014962196350098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4841/100000, D Loss: 0.16933094710111618, G Loss: 4.859987258911133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4842/100000, D Loss: 0.16028884053230286, G Loss: 4.688272476196289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4843/100000, D Loss: 0.1480775661766529, G Loss: 5.0296149253845215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4844/100000, D Loss: 0.1959197074174881, G Loss: 4.6852850914001465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4845/100000, D Loss: 0.18300499767065048, G Loss: 4.491891860961914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4846/100000, D Loss: 0.1812690943479538, G Loss: 4.767683029174805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4847/100000, D Loss: 0.18755589425563812, G Loss: 5.082300662994385\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4848/100000, D Loss: 0.24563679099082947, G Loss: 4.573373317718506\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4849/100000, D Loss: 0.24302075803279877, G Loss: 4.265565872192383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4850/100000, D Loss: 0.206755131483078, G Loss: 4.465579509735107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4851/100000, D Loss: 0.2060704603791237, G Loss: 4.863975524902344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4852/100000, D Loss: 0.21057774126529694, G Loss: 4.830587387084961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4853/100000, D Loss: 0.21218596398830414, G Loss: 4.4036359786987305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4854/100000, D Loss: 0.20123358070850372, G Loss: 4.29799747467041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4855/100000, D Loss: 0.2026638239622116, G Loss: 4.591758728027344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4856/100000, D Loss: 0.1549241691827774, G Loss: 4.977219581604004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4857/100000, D Loss: 0.15168964862823486, G Loss: 4.919218063354492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4858/100000, D Loss: 0.14516869187355042, G Loss: 4.752392768859863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4859/100000, D Loss: 0.16920487582683563, G Loss: 4.445749282836914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4860/100000, D Loss: 0.14914211630821228, G Loss: 4.811223983764648\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4861/100000, D Loss: 0.13173296302556992, G Loss: 5.053438663482666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4862/100000, D Loss: 0.12179369106888771, G Loss: 5.293941497802734\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4863/100000, D Loss: 0.11094171553850174, G Loss: 5.263526916503906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4864/100000, D Loss: 0.10793749988079071, G Loss: 5.2236809730529785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4865/100000, D Loss: 0.09234611690044403, G Loss: 5.426929950714111\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4866/100000, D Loss: 0.12127958983182907, G Loss: 5.395163536071777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4867/100000, D Loss: 0.11373667046427727, G Loss: 5.470608711242676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4868/100000, D Loss: 0.09174258634448051, G Loss: 5.560815811157227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4869/100000, D Loss: 0.09403210133314133, G Loss: 5.445886611938477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4870/100000, D Loss: 0.12767666950821877, G Loss: 5.016916751861572\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4871/100000, D Loss: 0.11760946363210678, G Loss: 5.271906852722168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4872/100000, D Loss: 0.10357062891125679, G Loss: 5.491957187652588\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4873/100000, D Loss: 0.12625066936016083, G Loss: 5.421412944793701\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4874/100000, D Loss: 0.17280813306570053, G Loss: 4.952110290527344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4875/100000, D Loss: 0.1528318002820015, G Loss: 4.942649841308594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4876/100000, D Loss: 0.1790565773844719, G Loss: 5.513723373413086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4877/100000, D Loss: 0.1863684505224228, G Loss: 5.87130069732666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4878/100000, D Loss: 0.26132721453905106, G Loss: 4.787045001983643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4879/100000, D Loss: 0.2992173507809639, G Loss: 4.281069278717041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4880/100000, D Loss: 0.2874319925904274, G Loss: 5.031890392303467\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4881/100000, D Loss: 0.25521818548440933, G Loss: 5.555388450622559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4882/100000, D Loss: 0.3661978244781494, G Loss: 5.089046478271484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4883/100000, D Loss: 0.3573042154312134, G Loss: 4.683347702026367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4884/100000, D Loss: 0.34287068247795105, G Loss: 5.157814025878906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4885/100000, D Loss: 0.3012041300535202, G Loss: 5.42848539352417\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4886/100000, D Loss: 0.313923180103302, G Loss: 5.269476890563965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4887/100000, D Loss: 0.27717262506484985, G Loss: 5.016611099243164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4888/100000, D Loss: 0.21475760638713837, G Loss: 5.062151908874512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4889/100000, D Loss: 0.21321380883455276, G Loss: 5.51608943939209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4890/100000, D Loss: 0.20297905057668686, G Loss: 5.46097469329834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4891/100000, D Loss: 0.17161168158054352, G Loss: 5.506552696228027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4892/100000, D Loss: 0.15368781238794327, G Loss: 5.968656539916992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4893/100000, D Loss: 0.16201770305633545, G Loss: 5.766727447509766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4894/100000, D Loss: 0.13036619126796722, G Loss: 5.6801018714904785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4895/100000, D Loss: 0.12679246813058853, G Loss: 5.6660685539245605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4896/100000, D Loss: 0.09864562749862671, G Loss: 5.844481468200684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4897/100000, D Loss: 0.09999066591262817, G Loss: 5.614723205566406\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4898/100000, D Loss: 0.09210991114377975, G Loss: 5.478300094604492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4899/100000, D Loss: 0.08922065794467926, G Loss: 5.45825719833374\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4900/100000, D Loss: 0.08463338389992714, G Loss: 5.630928039550781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4901/100000, D Loss: 0.09439486637711525, G Loss: 5.782689094543457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4902/100000, D Loss: 0.07327892258763313, G Loss: 5.720149517059326\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4903/100000, D Loss: 0.12852367386221886, G Loss: 4.983981132507324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4904/100000, D Loss: 0.08783868327736855, G Loss: 4.9924516677856445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4905/100000, D Loss: 0.07722393423318863, G Loss: 5.70314359664917\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4906/100000, D Loss: 0.08515091240406036, G Loss: 5.756424903869629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4907/100000, D Loss: 0.12558802962303162, G Loss: 4.915440559387207\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4908/100000, D Loss: 0.1070673018693924, G Loss: 4.696324825286865\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4909/100000, D Loss: 0.09618782252073288, G Loss: 5.216389179229736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4910/100000, D Loss: 0.10467314347624779, G Loss: 5.4224958419799805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4911/100000, D Loss: 0.10837218910455704, G Loss: 4.860588073730469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4912/100000, D Loss: 0.12946107238531113, G Loss: 4.532240867614746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4913/100000, D Loss: 0.10412213578820229, G Loss: 5.184397220611572\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4914/100000, D Loss: 0.099760040640831, G Loss: 5.660556793212891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4915/100000, D Loss: 0.1030612401664257, G Loss: 5.2146196365356445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4916/100000, D Loss: 0.13462276011705399, G Loss: 4.801715850830078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4917/100000, D Loss: 0.12721195071935654, G Loss: 5.058524131774902\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 4918/100000, D Loss: 0.1100843995809555, G Loss: 5.345542907714844\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4919/100000, D Loss: 0.10218758694827557, G Loss: 5.306516647338867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4920/100000, D Loss: 0.13166366517543793, G Loss: 4.973348617553711\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4921/100000, D Loss: 0.1365881711244583, G Loss: 4.8740692138671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4922/100000, D Loss: 0.11181178316473961, G Loss: 5.272217750549316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4923/100000, D Loss: 0.10070841014385223, G Loss: 5.233884811401367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4924/100000, D Loss: 0.13267098367214203, G Loss: 4.884581565856934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4925/100000, D Loss: 0.12988285720348358, G Loss: 4.719292640686035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4926/100000, D Loss: 0.14514774829149246, G Loss: 4.9548492431640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4927/100000, D Loss: 0.14165861159563065, G Loss: 4.952324867248535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4928/100000, D Loss: 0.1342773549258709, G Loss: 4.872289657592773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4929/100000, D Loss: 0.14227165281772614, G Loss: 4.6445183753967285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4930/100000, D Loss: 0.15950015932321548, G Loss: 4.8759660720825195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4931/100000, D Loss: 0.18281739950180054, G Loss: 4.986150741577148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4932/100000, D Loss: 0.16982907056808472, G Loss: 5.020831108093262\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4933/100000, D Loss: 0.1657600998878479, G Loss: 4.855094909667969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4934/100000, D Loss: 0.16455470770597458, G Loss: 4.4334869384765625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4935/100000, D Loss: 0.16929571330547333, G Loss: 4.558995246887207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4936/100000, D Loss: 0.17438745498657227, G Loss: 4.89846134185791\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4937/100000, D Loss: 0.16604655981063843, G Loss: 4.726131439208984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4938/100000, D Loss: 0.16235201805830002, G Loss: 4.633210182189941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4939/100000, D Loss: 0.20126723498106003, G Loss: 4.798282146453857\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4940/100000, D Loss: 0.15592093020677567, G Loss: 4.932290077209473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4941/100000, D Loss: 0.17279566451907158, G Loss: 4.629544258117676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4942/100000, D Loss: 0.19409847259521484, G Loss: 4.3076491355896\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4943/100000, D Loss: 0.2012767791748047, G Loss: 4.518274784088135\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4944/100000, D Loss: 0.21514204889535904, G Loss: 5.022826194763184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4945/100000, D Loss: 0.22419729828834534, G Loss: 4.334306716918945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4946/100000, D Loss: 0.26021403074264526, G Loss: 4.198649883270264\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4947/100000, D Loss: 0.21319375932216644, G Loss: 4.6214704513549805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4948/100000, D Loss: 0.22390568256378174, G Loss: 4.345199108123779\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4949/100000, D Loss: 0.2566296458244324, G Loss: 4.021977424621582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4950/100000, D Loss: 0.24598024785518646, G Loss: 4.260012626647949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4951/100000, D Loss: 0.25326792895793915, G Loss: 4.357334136962891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4952/100000, D Loss: 0.2558802664279938, G Loss: 4.101202011108398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4953/100000, D Loss: 0.24624228477478027, G Loss: 4.320296764373779\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4954/100000, D Loss: 0.21251478046178818, G Loss: 4.447622299194336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4955/100000, D Loss: 0.24653077125549316, G Loss: 4.447436809539795\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4956/100000, D Loss: 0.19817505776882172, G Loss: 4.56928825378418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4957/100000, D Loss: 0.19165410846471786, G Loss: 4.472867965698242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4958/100000, D Loss: 0.17827158421278, G Loss: 4.469776153564453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4959/100000, D Loss: 0.18160107731819153, G Loss: 4.59677791595459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4960/100000, D Loss: 0.16114287823438644, G Loss: 4.597772598266602\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4961/100000, D Loss: 0.17511405050754547, G Loss: 4.697107791900635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4962/100000, D Loss: 0.1348911076784134, G Loss: 4.930357933044434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4963/100000, D Loss: 0.1236240342259407, G Loss: 4.802453517913818\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4964/100000, D Loss: 0.15193725749850273, G Loss: 4.541224479675293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4965/100000, D Loss: 0.1391497626900673, G Loss: 4.74235725402832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4966/100000, D Loss: 0.11609084904193878, G Loss: 4.975873947143555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4967/100000, D Loss: 0.14886244758963585, G Loss: 4.679533958435059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4968/100000, D Loss: 0.15527313202619553, G Loss: 4.329525947570801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4969/100000, D Loss: 0.15963415056467056, G Loss: 4.749465465545654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4970/100000, D Loss: 0.1519773155450821, G Loss: 4.728960990905762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4971/100000, D Loss: 0.15309210121631622, G Loss: 4.6020188331604\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4972/100000, D Loss: 0.17496775835752487, G Loss: 4.4568095207214355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4973/100000, D Loss: 0.1372855305671692, G Loss: 4.578458786010742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4974/100000, D Loss: 0.15414521470665932, G Loss: 4.5075812339782715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4975/100000, D Loss: 0.14996864274144173, G Loss: 4.265372276306152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4976/100000, D Loss: 0.20323419570922852, G Loss: 4.102851390838623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4977/100000, D Loss: 0.20125173032283783, G Loss: 4.19066047668457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4978/100000, D Loss: 0.15162931755185127, G Loss: 4.3797478675842285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4979/100000, D Loss: 0.18122391402721405, G Loss: 4.295401573181152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4980/100000, D Loss: 0.16715849190950394, G Loss: 4.2605695724487305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4981/100000, D Loss: 0.23568042367696762, G Loss: 3.980581760406494\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4982/100000, D Loss: 0.2057274803519249, G Loss: 4.482783317565918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4983/100000, D Loss: 0.21206166595220566, G Loss: 4.3820600509643555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4984/100000, D Loss: 0.22085899859666824, G Loss: 3.8460874557495117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4985/100000, D Loss: 0.2338889092206955, G Loss: 3.856044054031372\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4986/100000, D Loss: 0.1856461837887764, G Loss: 4.6891679763793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4987/100000, D Loss: 0.215327687561512, G Loss: 4.148366451263428\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4988/100000, D Loss: 0.261425144970417, G Loss: 3.5588459968566895\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4989/100000, D Loss: 0.22860518097877502, G Loss: 4.132424354553223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4990/100000, D Loss: 0.19652220234274864, G Loss: 4.679551124572754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 4991/100000, D Loss: 0.23881738632917404, G Loss: 4.0215229988098145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4992/100000, D Loss: 0.2190590724349022, G Loss: 4.295381546020508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4993/100000, D Loss: 0.17809944599866867, G Loss: 5.248245716094971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4994/100000, D Loss: 0.19787508249282837, G Loss: 4.389641761779785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4995/100000, D Loss: 0.1870449036359787, G Loss: 4.383549690246582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4996/100000, D Loss: 0.16823333501815796, G Loss: 4.962607383728027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4997/100000, D Loss: 0.16122063994407654, G Loss: 5.074341773986816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4998/100000, D Loss: 0.16643325239419937, G Loss: 4.422286033630371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 4999/100000, D Loss: 0.1834132969379425, G Loss: 4.329728126525879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5000/100000, D Loss: 0.13044123351573944, G Loss: 4.918737411499023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5001/100000, D Loss: 0.14864224195480347, G Loss: 4.841939926147461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5002/100000, D Loss: 0.18918359279632568, G Loss: 4.231280326843262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5003/100000, D Loss: 0.16477297246456146, G Loss: 4.412932395935059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5004/100000, D Loss: 0.16471415758132935, G Loss: 4.83034610748291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5005/100000, D Loss: 0.1645769625902176, G Loss: 4.564824104309082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5006/100000, D Loss: 0.24510860443115234, G Loss: 3.8511881828308105\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5007/100000, D Loss: 0.15864630043506622, G Loss: 4.584079742431641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5008/100000, D Loss: 0.17466918006539345, G Loss: 4.768403053283691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5009/100000, D Loss: 0.20659884810447693, G Loss: 4.161338806152344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5010/100000, D Loss: 0.21771420538425446, G Loss: 4.144611358642578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5011/100000, D Loss: 0.16199176758527756, G Loss: 4.798945426940918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5012/100000, D Loss: 0.17994724586606026, G Loss: 4.412779808044434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5013/100000, D Loss: 0.18807236105203629, G Loss: 4.048700332641602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5014/100000, D Loss: 0.20268143713474274, G Loss: 4.144475936889648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5015/100000, D Loss: 0.16559193283319473, G Loss: 4.769299507141113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5016/100000, D Loss: 0.18271547555923462, G Loss: 4.483684539794922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5017/100000, D Loss: 0.18561618030071259, G Loss: 4.167861461639404\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5018/100000, D Loss: 0.17119435966014862, G Loss: 4.095249176025391\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5019/100000, D Loss: 0.14373011887073517, G Loss: 4.624222755432129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5020/100000, D Loss: 0.15825600177049637, G Loss: 4.621591567993164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5021/100000, D Loss: 0.12271512672305107, G Loss: 4.477781772613525\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5022/100000, D Loss: 0.1378420889377594, G Loss: 4.276839733123779\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5023/100000, D Loss: 0.13144909590482712, G Loss: 4.612364768981934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5024/100000, D Loss: 0.12345901504158974, G Loss: 4.828352928161621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5025/100000, D Loss: 0.15362130850553513, G Loss: 4.710899353027344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5026/100000, D Loss: 0.15952926874160767, G Loss: 4.271512031555176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5027/100000, D Loss: 0.13383421301841736, G Loss: 4.428471565246582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5028/100000, D Loss: 0.12975437939167023, G Loss: 4.828754425048828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5029/100000, D Loss: 0.15786835551261902, G Loss: 4.526754379272461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5030/100000, D Loss: 0.14973848313093185, G Loss: 4.265119552612305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5031/100000, D Loss: 0.14521045237779617, G Loss: 4.66414737701416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5032/100000, D Loss: 0.11924172192811966, G Loss: 4.8981523513793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5033/100000, D Loss: 0.14514486491680145, G Loss: 4.618178367614746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5034/100000, D Loss: 0.13750166445970535, G Loss: 4.387314796447754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5035/100000, D Loss: 0.1508476808667183, G Loss: 4.5985918045043945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5036/100000, D Loss: 0.09863576665520668, G Loss: 4.921712398529053\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5037/100000, D Loss: 0.14625807479023933, G Loss: 4.454739570617676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5038/100000, D Loss: 0.12821192294359207, G Loss: 4.328165531158447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5039/100000, D Loss: 0.12161974981427193, G Loss: 4.537465572357178\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5040/100000, D Loss: 0.1064261645078659, G Loss: 4.652009963989258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5041/100000, D Loss: 0.11178060621023178, G Loss: 4.857038497924805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5042/100000, D Loss: 0.12408198416233063, G Loss: 4.620281219482422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5043/100000, D Loss: 0.11942491680383682, G Loss: 4.614537239074707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5044/100000, D Loss: 0.13376020267605782, G Loss: 4.487744331359863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5045/100000, D Loss: 0.14292585104703903, G Loss: 4.79639196395874\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5046/100000, D Loss: 0.16746851801872253, G Loss: 4.5646138191223145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5047/100000, D Loss: 0.16497718542814255, G Loss: 4.713146686553955\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5048/100000, D Loss: 0.1716027855873108, G Loss: 4.370672225952148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5049/100000, D Loss: 0.22145217657089233, G Loss: 4.277912616729736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5050/100000, D Loss: 0.23068125545978546, G Loss: 4.720457077026367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5051/100000, D Loss: 0.24714292585849762, G Loss: 4.683652877807617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5052/100000, D Loss: 0.318431556224823, G Loss: 4.246188163757324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5053/100000, D Loss: 0.3042373061180115, G Loss: 4.369667053222656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5054/100000, D Loss: 0.26156412065029144, G Loss: 5.0345611572265625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5055/100000, D Loss: 0.333112433552742, G Loss: 4.729883193969727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5056/100000, D Loss: 0.3398696482181549, G Loss: 4.061054706573486\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5057/100000, D Loss: 0.2793677970767021, G Loss: 4.7582478523254395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5058/100000, D Loss: 0.2408067137002945, G Loss: 5.453056335449219\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5059/100000, D Loss: 0.29273682832717896, G Loss: 4.543132781982422\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5060/100000, D Loss: 0.23181676864624023, G Loss: 4.551996231079102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5061/100000, D Loss: 0.15534773468971252, G Loss: 5.307690620422363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5062/100000, D Loss: 0.17206116020679474, G Loss: 5.309655666351318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5063/100000, D Loss: 0.15136679261922836, G Loss: 4.97930908203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5064/100000, D Loss: 0.16706851869821548, G Loss: 4.631732940673828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5065/100000, D Loss: 0.14711681008338928, G Loss: 4.909445762634277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5066/100000, D Loss: 0.12380014359951019, G Loss: 5.260660171508789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5067/100000, D Loss: 0.11211151257157326, G Loss: 5.191294193267822\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5068/100000, D Loss: 0.16675372421741486, G Loss: 4.544205665588379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5069/100000, D Loss: 0.12152815982699394, G Loss: 4.699991226196289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5070/100000, D Loss: 0.1380985677242279, G Loss: 5.234246730804443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5071/100000, D Loss: 0.10278848931193352, G Loss: 5.627410888671875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5072/100000, D Loss: 0.17703759670257568, G Loss: 4.530485153198242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5073/100000, D Loss: 0.16392968595027924, G Loss: 3.9945807456970215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5074/100000, D Loss: 0.13393060490489006, G Loss: 4.808823585510254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5075/100000, D Loss: 0.12981776520609856, G Loss: 5.274855613708496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5076/100000, D Loss: 0.15288371592760086, G Loss: 4.876681327819824\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5077/100000, D Loss: 0.16482853144407272, G Loss: 4.104373455047607\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5078/100000, D Loss: 0.16994989663362503, G Loss: 4.354352951049805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5079/100000, D Loss: 0.13944897055625916, G Loss: 5.207670211791992\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5080/100000, D Loss: 0.1765461601316929, G Loss: 4.866702079772949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5081/100000, D Loss: 0.1815350018441677, G Loss: 4.154322624206543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5082/100000, D Loss: 0.20970625430345535, G Loss: 4.312765121459961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5083/100000, D Loss: 0.13751930743455887, G Loss: 5.145785331726074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5084/100000, D Loss: 0.18068983405828476, G Loss: 4.823871612548828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5085/100000, D Loss: 0.2054351568222046, G Loss: 4.010398864746094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5086/100000, D Loss: 0.19816508144140244, G Loss: 4.1608500480651855\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5087/100000, D Loss: 0.1652313396334648, G Loss: 4.666959762573242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5088/100000, D Loss: 0.19351806491613388, G Loss: 4.565201759338379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5089/100000, D Loss: 0.18881111592054367, G Loss: 4.5013861656188965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5090/100000, D Loss: 0.18581385165452957, G Loss: 4.5049638748168945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5091/100000, D Loss: 0.15379760786890984, G Loss: 4.565402984619141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5092/100000, D Loss: 0.22816592454910278, G Loss: 4.4281697273254395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5093/100000, D Loss: 0.16769617050886154, G Loss: 4.83796501159668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5094/100000, D Loss: 0.1887676902115345, G Loss: 4.792665958404541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5095/100000, D Loss: 0.20703726261854172, G Loss: 4.426082611083984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5096/100000, D Loss: 0.19108940660953522, G Loss: 4.733828544616699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5097/100000, D Loss: 0.14045916125178337, G Loss: 5.6520676612854\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5098/100000, D Loss: 0.17793187871575356, G Loss: 4.827651500701904\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5099/100000, D Loss: 0.17286404222249985, G Loss: 4.434142112731934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5100/100000, D Loss: 0.15655584633350372, G Loss: 5.218810558319092\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5101/100000, D Loss: 0.11028866097331047, G Loss: 5.549211502075195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5102/100000, D Loss: 0.12641733139753342, G Loss: 5.065757751464844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5103/100000, D Loss: 0.12995360791683197, G Loss: 4.520508289337158\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5104/100000, D Loss: 0.15526485443115234, G Loss: 4.81252384185791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5105/100000, D Loss: 0.11002668365836143, G Loss: 5.203652858734131\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5106/100000, D Loss: 0.1329239085316658, G Loss: 4.98772668838501\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5107/100000, D Loss: 0.11988912522792816, G Loss: 4.702714920043945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5108/100000, D Loss: 0.14269384741783142, G Loss: 4.7946367263793945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5109/100000, D Loss: 0.1283479481935501, G Loss: 4.8618974685668945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5110/100000, D Loss: 0.12942004948854446, G Loss: 4.794154167175293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5111/100000, D Loss: 0.13999693095684052, G Loss: 4.8471784591674805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5112/100000, D Loss: 0.18848950415849686, G Loss: 4.4832539558410645\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5113/100000, D Loss: 0.1839747130870819, G Loss: 4.574233055114746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5114/100000, D Loss: 0.1499408334493637, G Loss: 4.901278495788574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5115/100000, D Loss: 0.2028914988040924, G Loss: 4.626241683959961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5116/100000, D Loss: 0.2002515122294426, G Loss: 4.419759750366211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5117/100000, D Loss: 0.20457900315523148, G Loss: 4.475319862365723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5118/100000, D Loss: 0.17699258029460907, G Loss: 4.498532295227051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5119/100000, D Loss: 0.27474720776081085, G Loss: 4.174222469329834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5120/100000, D Loss: 0.23825547844171524, G Loss: 4.659806728363037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5121/100000, D Loss: 0.2531737759709358, G Loss: 4.323883056640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5122/100000, D Loss: 0.31142744421958923, G Loss: 4.191267013549805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5123/100000, D Loss: 0.27035170793533325, G Loss: 4.564348220825195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5124/100000, D Loss: 0.3015138506889343, G Loss: 4.0821967124938965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5125/100000, D Loss: 0.340043842792511, G Loss: 4.304338455200195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5126/100000, D Loss: 0.2656336575746536, G Loss: 4.840855598449707\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5127/100000, D Loss: 0.3604743033647537, G Loss: 4.354635238647461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5128/100000, D Loss: 0.2735138237476349, G Loss: 4.67874002456665\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5129/100000, D Loss: 0.28056326508522034, G Loss: 4.778092384338379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5130/100000, D Loss: 0.2325717806816101, G Loss: 5.019689559936523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5131/100000, D Loss: 0.23087716102600098, G Loss: 5.102519512176514\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5132/100000, D Loss: 0.1955435946583748, G Loss: 5.045621871948242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5133/100000, D Loss: 0.1924935281276703, G Loss: 4.82175350189209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5134/100000, D Loss: 0.19131071120500565, G Loss: 5.132896900177002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5135/100000, D Loss: 0.1491681933403015, G Loss: 5.491586685180664\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5136/100000, D Loss: 0.14498063176870346, G Loss: 5.152353286743164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5137/100000, D Loss: 0.1423858478665352, G Loss: 5.0832624435424805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5138/100000, D Loss: 0.13495755195617676, G Loss: 5.192549228668213\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5139/100000, D Loss: 0.155965156853199, G Loss: 5.22130823135376\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5140/100000, D Loss: 0.14505470544099808, G Loss: 5.101252555847168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5141/100000, D Loss: 0.12780535221099854, G Loss: 5.386948585510254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5142/100000, D Loss: 0.12662236392498016, G Loss: 5.5227556228637695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5143/100000, D Loss: 0.1344629041850567, G Loss: 4.937129974365234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5144/100000, D Loss: 0.12511659413576126, G Loss: 4.937651634216309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5145/100000, D Loss: 0.12469502538442612, G Loss: 5.015410423278809\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5146/100000, D Loss: 0.13354676216840744, G Loss: 5.032812595367432\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5147/100000, D Loss: 0.13243582472205162, G Loss: 5.208921432495117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5148/100000, D Loss: 0.17712987959384918, G Loss: 4.606167793273926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5149/100000, D Loss: 0.1789267510175705, G Loss: 4.794832229614258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5150/100000, D Loss: 0.1585780456662178, G Loss: 4.9589643478393555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5151/100000, D Loss: 0.19517315179109573, G Loss: 4.5390119552612305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5152/100000, D Loss: 0.19655396044254303, G Loss: 4.658491134643555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5153/100000, D Loss: 0.17199432104825974, G Loss: 4.850881576538086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5154/100000, D Loss: 0.2465193122625351, G Loss: 4.655713081359863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5155/100000, D Loss: 0.24024485051631927, G Loss: 4.520301818847656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5156/100000, D Loss: 0.19552507251501083, G Loss: 4.755734443664551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5157/100000, D Loss: 0.23350124806165695, G Loss: 4.752700328826904\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5158/100000, D Loss: 0.2445119172334671, G Loss: 4.410878658294678\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5159/100000, D Loss: 0.22896353155374527, G Loss: 4.510883331298828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5160/100000, D Loss: 0.2499391883611679, G Loss: 4.443408012390137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5161/100000, D Loss: 0.2678483575582504, G Loss: 4.385428428649902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5162/100000, D Loss: 0.2475094199180603, G Loss: 4.701913833618164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5163/100000, D Loss: 0.2515599653124809, G Loss: 4.4597930908203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5164/100000, D Loss: 0.25051960349082947, G Loss: 4.473647117614746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5165/100000, D Loss: 0.25146424770355225, G Loss: 4.370294094085693\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5166/100000, D Loss: 0.21395131945610046, G Loss: 4.792340278625488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5167/100000, D Loss: 0.1529691144824028, G Loss: 5.301845550537109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5168/100000, D Loss: 0.17799369245767593, G Loss: 4.948080062866211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5169/100000, D Loss: 0.18947229534387589, G Loss: 4.452507019042969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5170/100000, D Loss: 0.14758528023958206, G Loss: 4.700750827789307\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5171/100000, D Loss: 0.14465173333883286, G Loss: 4.934392929077148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5172/100000, D Loss: 0.17161495983600616, G Loss: 5.063885688781738\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5173/100000, D Loss: 0.16068806499242783, G Loss: 4.883518695831299\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5174/100000, D Loss: 0.18106994032859802, G Loss: 4.6073126792907715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5175/100000, D Loss: 0.17670921236276627, G Loss: 4.928660869598389\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5176/100000, D Loss: 0.17220056802034378, G Loss: 5.068356513977051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5177/100000, D Loss: 0.22017627954483032, G Loss: 4.372142314910889\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5178/100000, D Loss: 0.20904603600502014, G Loss: 4.521890640258789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5179/100000, D Loss: 0.18432120233774185, G Loss: 4.819816589355469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5180/100000, D Loss: 0.23965497314929962, G Loss: 4.819918632507324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5181/100000, D Loss: 0.23449493944644928, G Loss: 4.534027099609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5182/100000, D Loss: 0.23152462393045425, G Loss: 4.564157485961914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5183/100000, D Loss: 0.2379452958703041, G Loss: 4.556501388549805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5184/100000, D Loss: 0.2507987394928932, G Loss: 4.385207176208496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5185/100000, D Loss: 0.2764380872249603, G Loss: 4.3100972175598145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5186/100000, D Loss: 0.26410311460494995, G Loss: 4.702005863189697\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5187/100000, D Loss: 0.2760564610362053, G Loss: 4.6248626708984375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5188/100000, D Loss: 0.30051977187395096, G Loss: 4.019323348999023\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5189/100000, D Loss: 0.21575000137090683, G Loss: 4.3985819816589355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5190/100000, D Loss: 0.26629336178302765, G Loss: 4.5333123207092285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5191/100000, D Loss: 0.23686547577381134, G Loss: 4.213339805603027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5192/100000, D Loss: 0.22507616877555847, G Loss: 4.419156074523926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5193/100000, D Loss: 0.1936403065919876, G Loss: 4.609890937805176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5194/100000, D Loss: 0.2129620760679245, G Loss: 4.313290596008301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5195/100000, D Loss: 0.19505906105041504, G Loss: 4.397158622741699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5196/100000, D Loss: 0.24009796977043152, G Loss: 4.3455400466918945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5197/100000, D Loss: 0.2034919261932373, G Loss: 4.548519134521484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5198/100000, D Loss: 0.18400737643241882, G Loss: 4.545160293579102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5199/100000, D Loss: 0.21144778653979301, G Loss: 4.090083599090576\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5200/100000, D Loss: 0.2692888379096985, G Loss: 3.9554264545440674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5201/100000, D Loss: 0.20862115919589996, G Loss: 4.57236909866333\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5202/100000, D Loss: 0.20729777216911316, G Loss: 4.888001441955566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5203/100000, D Loss: 0.2592690512537956, G Loss: 4.277432918548584\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5204/100000, D Loss: 0.24661289155483246, G Loss: 4.17185115814209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5205/100000, D Loss: 0.16902637481689453, G Loss: 5.203368186950684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5206/100000, D Loss: 0.1484246551990509, G Loss: 5.492124557495117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5207/100000, D Loss: 0.17363563925027847, G Loss: 4.396124839782715\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5208/100000, D Loss: 0.18641500920057297, G Loss: 4.21108341217041\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5209/100000, D Loss: 0.1097300797700882, G Loss: 5.078917503356934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5210/100000, D Loss: 0.10688625276088715, G Loss: 5.469531059265137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5211/100000, D Loss: 0.12988358363509178, G Loss: 5.293848991394043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5212/100000, D Loss: 0.1286938600242138, G Loss: 4.913329124450684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5213/100000, D Loss: 0.1314704492688179, G Loss: 4.783860206604004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5214/100000, D Loss: 0.12065846472978592, G Loss: 5.004083156585693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5215/100000, D Loss: 0.11414279788732529, G Loss: 5.148067474365234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5216/100000, D Loss: 0.11369295418262482, G Loss: 4.871711730957031\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5217/100000, D Loss: 0.14356454461812973, G Loss: 4.7984514236450195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5218/100000, D Loss: 0.11461959779262543, G Loss: 4.6935014724731445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5219/100000, D Loss: 0.11042309552431107, G Loss: 5.038876533508301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5220/100000, D Loss: 0.10823862627148628, G Loss: 5.363770484924316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5221/100000, D Loss: 0.11914946138858795, G Loss: 4.938604354858398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5222/100000, D Loss: 0.1326347514986992, G Loss: 4.670234203338623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5223/100000, D Loss: 0.10677755996584892, G Loss: 4.601533889770508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5224/100000, D Loss: 0.10667088627815247, G Loss: 5.008454322814941\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5225/100000, D Loss: 0.12877339124679565, G Loss: 5.41724157333374\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5226/100000, D Loss: 0.11646851152181625, G Loss: 5.249979019165039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5227/100000, D Loss: 0.11350173875689507, G Loss: 4.849444389343262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5228/100000, D Loss: 0.11403355747461319, G Loss: 4.686961650848389\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5229/100000, D Loss: 0.11028727516531944, G Loss: 4.990813255310059\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5230/100000, D Loss: 0.10213109850883484, G Loss: 5.238814830780029\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5231/100000, D Loss: 0.11169705912470818, G Loss: 4.808872222900391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5232/100000, D Loss: 0.11810949444770813, G Loss: 4.5423736572265625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5233/100000, D Loss: 0.145815908908844, G Loss: 4.420563697814941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5234/100000, D Loss: 0.14297910034656525, G Loss: 4.813605785369873\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5235/100000, D Loss: 0.1387547180056572, G Loss: 4.675962924957275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5236/100000, D Loss: 0.16497685015201569, G Loss: 4.1688385009765625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5237/100000, D Loss: 0.18819451332092285, G Loss: 4.161832332611084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5238/100000, D Loss: 0.17007309943437576, G Loss: 4.583591938018799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5239/100000, D Loss: 0.17489300668239594, G Loss: 4.590424537658691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5240/100000, D Loss: 0.19617682695388794, G Loss: 4.253721237182617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5241/100000, D Loss: 0.22372378408908844, G Loss: 4.1623029708862305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5242/100000, D Loss: 0.16481934487819672, G Loss: 4.574212074279785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5243/100000, D Loss: 0.21212441474199295, G Loss: 4.164224624633789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5244/100000, D Loss: 0.18650871515274048, G Loss: 3.973480463027954\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5245/100000, D Loss: 0.17033137381076813, G Loss: 4.419125556945801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5246/100000, D Loss: 0.17739160731434822, G Loss: 4.690011978149414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5247/100000, D Loss: 0.16898952051997185, G Loss: 4.3454766273498535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5248/100000, D Loss: 0.19599772989749908, G Loss: 4.196172714233398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5249/100000, D Loss: 0.12439398467540741, G Loss: 4.47644567489624\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5250/100000, D Loss: 0.15934369340538979, G Loss: 4.532604217529297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5251/100000, D Loss: 0.17896155267953873, G Loss: 4.169454097747803\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5252/100000, D Loss: 0.19119465351104736, G Loss: 4.213508605957031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5253/100000, D Loss: 0.1579589992761612, G Loss: 4.593236446380615\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5254/100000, D Loss: 0.17456722259521484, G Loss: 4.374508380889893\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5255/100000, D Loss: 0.18837518244981766, G Loss: 4.436153411865234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5256/100000, D Loss: 0.16580532491207123, G Loss: 4.303895950317383\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5257/100000, D Loss: 0.1851186826825142, G Loss: 4.4412641525268555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5258/100000, D Loss: 0.17800871282815933, G Loss: 4.623523235321045\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5259/100000, D Loss: 0.19518264383077621, G Loss: 4.193019866943359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5260/100000, D Loss: 0.1911907121539116, G Loss: 4.324755668640137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5261/100000, D Loss: 0.13642869889736176, G Loss: 4.832976341247559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5262/100000, D Loss: 0.1882067397236824, G Loss: 4.566833972930908\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5263/100000, D Loss: 0.15786590427160263, G Loss: 4.398530006408691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5264/100000, D Loss: 0.21330778300762177, G Loss: 4.164308547973633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5265/100000, D Loss: 0.20423521846532822, G Loss: 4.527395725250244\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5266/100000, D Loss: 0.17348019778728485, G Loss: 4.80001974105835\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5267/100000, D Loss: 0.1785983294248581, G Loss: 4.476641654968262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5268/100000, D Loss: 0.19526077061891556, G Loss: 4.312838077545166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5269/100000, D Loss: 0.14932814240455627, G Loss: 4.739066123962402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5270/100000, D Loss: 0.16926611959934235, G Loss: 4.71415901184082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5271/100000, D Loss: 0.1508716307580471, G Loss: 4.510347366333008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5272/100000, D Loss: 0.1733379065990448, G Loss: 4.600856781005859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5273/100000, D Loss: 0.15007475018501282, G Loss: 4.794072151184082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5274/100000, D Loss: 0.14149659499526024, G Loss: 5.114540100097656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5275/100000, D Loss: 0.16968151926994324, G Loss: 4.7173261642456055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5276/100000, D Loss: 0.14677105844020844, G Loss: 4.478179931640625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5277/100000, D Loss: 0.12995696812868118, G Loss: 5.015552520751953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5278/100000, D Loss: 0.15390221774578094, G Loss: 5.120365619659424\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5279/100000, D Loss: 0.1942005753517151, G Loss: 4.622612953186035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5280/100000, D Loss: 0.17427191138267517, G Loss: 4.474431037902832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5281/100000, D Loss: 0.20677783340215683, G Loss: 4.627486228942871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5282/100000, D Loss: 0.176387719810009, G Loss: 5.135601997375488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5283/100000, D Loss: 0.22441495954990387, G Loss: 4.757946968078613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5284/100000, D Loss: 0.22499290108680725, G Loss: 4.146642684936523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5285/100000, D Loss: 0.26832181215286255, G Loss: 4.179416656494141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5286/100000, D Loss: 0.2096565216779709, G Loss: 4.904589653015137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5287/100000, D Loss: 0.21176569163799286, G Loss: 4.756891250610352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5288/100000, D Loss: 0.23578573763370514, G Loss: 4.399687767028809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5289/100000, D Loss: 0.2630654349923134, G Loss: 4.414636611938477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5290/100000, D Loss: 0.185240276157856, G Loss: 5.029910087585449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5291/100000, D Loss: 0.20408614352345467, G Loss: 4.722130298614502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5292/100000, D Loss: 0.24215390533208847, G Loss: 4.480201721191406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5293/100000, D Loss: 0.18721963465213776, G Loss: 4.806746482849121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5294/100000, D Loss: 0.17430545389652252, G Loss: 5.236692428588867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5295/100000, D Loss: 0.15289413556456566, G Loss: 5.292773246765137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5296/100000, D Loss: 0.14613929390907288, G Loss: 5.027660846710205\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5297/100000, D Loss: 0.12184953689575195, G Loss: 5.226067066192627\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5298/100000, D Loss: 0.09857970476150513, G Loss: 5.439146041870117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5299/100000, D Loss: 0.09335098788142204, G Loss: 5.4887237548828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5300/100000, D Loss: 0.10372821241617203, G Loss: 5.953186988830566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5301/100000, D Loss: 0.11635715141892433, G Loss: 5.931867599487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5302/100000, D Loss: 0.0935763344168663, G Loss: 5.693748950958252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5303/100000, D Loss: 0.09023333713412285, G Loss: 5.612614631652832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5304/100000, D Loss: 0.10545983910560608, G Loss: 5.591938018798828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5305/100000, D Loss: 0.09850117191672325, G Loss: 5.899387359619141\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5306/100000, D Loss: 0.10989433154463768, G Loss: 5.783169269561768\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5307/100000, D Loss: 0.1309344694018364, G Loss: 5.501466751098633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5308/100000, D Loss: 0.1321743167936802, G Loss: 5.638716220855713\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5309/100000, D Loss: 0.12344127893447876, G Loss: 5.834024429321289\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5310/100000, D Loss: 0.11484237760305405, G Loss: 5.82830810546875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5311/100000, D Loss: 0.09807927533984184, G Loss: 5.4898905754089355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5312/100000, D Loss: 0.10208607465028763, G Loss: 5.472216606140137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5313/100000, D Loss: 0.12614334374666214, G Loss: 5.092776298522949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5314/100000, D Loss: 0.13246098905801773, G Loss: 5.41596794128418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5315/100000, D Loss: 0.12829169631004333, G Loss: 5.633622646331787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5316/100000, D Loss: 0.12031249701976776, G Loss: 5.2637786865234375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5317/100000, D Loss: 0.14263074100017548, G Loss: 5.002933025360107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5318/100000, D Loss: 0.1200760006904602, G Loss: 4.98925256729126\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5319/100000, D Loss: 0.14449191093444824, G Loss: 5.388300895690918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5320/100000, D Loss: 0.14689073711633682, G Loss: 5.190125465393066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5321/100000, D Loss: 0.14106358587741852, G Loss: 4.8748779296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5322/100000, D Loss: 0.15449708700180054, G Loss: 4.9990692138671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5323/100000, D Loss: 0.14886372536420822, G Loss: 5.350425720214844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5324/100000, D Loss: 0.1874496340751648, G Loss: 5.185581207275391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5325/100000, D Loss: 0.17129502445459366, G Loss: 5.258700847625732\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5326/100000, D Loss: 0.1946026161313057, G Loss: 5.265873432159424\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5327/100000, D Loss: 0.2092067375779152, G Loss: 5.211385250091553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5328/100000, D Loss: 0.21597500145435333, G Loss: 5.096920967102051\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5329/100000, D Loss: 0.2733340561389923, G Loss: 5.166719436645508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5330/100000, D Loss: 0.2476176768541336, G Loss: 5.410414695739746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5331/100000, D Loss: 0.261586457490921, G Loss: 5.2096848487854\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5332/100000, D Loss: 0.2486039325594902, G Loss: 4.891858100891113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5333/100000, D Loss: 0.25637659430503845, G Loss: 5.733648300170898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5334/100000, D Loss: 0.20825006067752838, G Loss: 6.0805158615112305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5335/100000, D Loss: 0.3259618580341339, G Loss: 5.010786056518555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5336/100000, D Loss: 0.2774278298020363, G Loss: 4.702114105224609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5337/100000, D Loss: 0.2106357365846634, G Loss: 5.56031608581543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5338/100000, D Loss: 0.21581585705280304, G Loss: 5.919309139251709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5339/100000, D Loss: 0.2087371125817299, G Loss: 5.690802574157715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5340/100000, D Loss: 0.1987568885087967, G Loss: 5.0149006843566895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5341/100000, D Loss: 0.18462838232517242, G Loss: 5.261353492736816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5342/100000, D Loss: 0.16916987299919128, G Loss: 5.804790019989014\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5343/100000, D Loss: 0.17885735630989075, G Loss: 5.798051834106445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5344/100000, D Loss: 0.18254847079515457, G Loss: 5.463465213775635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5345/100000, D Loss: 0.15960551798343658, G Loss: 5.149168968200684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5346/100000, D Loss: 0.1568954437971115, G Loss: 5.429952621459961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5347/100000, D Loss: 0.16728658601641655, G Loss: 5.7347002029418945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5348/100000, D Loss: 0.16068262606859207, G Loss: 5.534358978271484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5349/100000, D Loss: 0.1841735988855362, G Loss: 5.367828369140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5350/100000, D Loss: 0.20910728722810745, G Loss: 5.125962257385254\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5351/100000, D Loss: 0.19012530148029327, G Loss: 5.315096378326416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5352/100000, D Loss: 0.1794889271259308, G Loss: 5.503859519958496\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5353/100000, D Loss: 0.2005484700202942, G Loss: 5.291728973388672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5354/100000, D Loss: 0.20922722667455673, G Loss: 5.22074031829834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5355/100000, D Loss: 0.21581922471523285, G Loss: 5.214668273925781\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5356/100000, D Loss: 0.2557350844144821, G Loss: 5.0630269050598145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5357/100000, D Loss: 0.2333863005042076, G Loss: 4.929728031158447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5358/100000, D Loss: 0.17929407209157944, G Loss: 5.149594306945801\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5359/100000, D Loss: 0.18570247292518616, G Loss: 5.359376430511475\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5360/100000, D Loss: 0.17112122848629951, G Loss: 5.2453508377075195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5361/100000, D Loss: 0.19945257902145386, G Loss: 4.738393783569336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5362/100000, D Loss: 0.19392143189907074, G Loss: 5.317389011383057\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5363/100000, D Loss: 0.17881611362099648, G Loss: 5.552511215209961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5364/100000, D Loss: 0.16698750853538513, G Loss: 5.60493278503418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5365/100000, D Loss: 0.1692075952887535, G Loss: 5.09293270111084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5366/100000, D Loss: 0.16814391314983368, G Loss: 5.278258323669434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5367/100000, D Loss: 0.13383855670690536, G Loss: 5.851673126220703\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5368/100000, D Loss: 0.14301197975873947, G Loss: 5.682590961456299\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5369/100000, D Loss: 0.13303016498684883, G Loss: 5.120572566986084\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5370/100000, D Loss: 0.15374202281236649, G Loss: 5.426871299743652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5371/100000, D Loss: 0.09850391373038292, G Loss: 6.303488731384277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5372/100000, D Loss: 0.11465010792016983, G Loss: 5.879153251647949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5373/100000, D Loss: 0.13196972012519836, G Loss: 5.199067115783691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5374/100000, D Loss: 0.15250667184591293, G Loss: 5.150585174560547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5375/100000, D Loss: 0.11487498879432678, G Loss: 5.689651966094971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5376/100000, D Loss: 0.08905636519193649, G Loss: 6.297813415527344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5377/100000, D Loss: 0.12883004918694496, G Loss: 5.730391502380371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5378/100000, D Loss: 0.13981197029352188, G Loss: 5.41107177734375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5379/100000, D Loss: 0.11796070262789726, G Loss: 5.593341827392578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5380/100000, D Loss: 0.1156185045838356, G Loss: 5.575941562652588\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5381/100000, D Loss: 0.11144920438528061, G Loss: 5.522290229797363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5382/100000, D Loss: 0.11340152844786644, G Loss: 5.397738456726074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5383/100000, D Loss: 0.11251449957489967, G Loss: 5.539250373840332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5384/100000, D Loss: 0.13471177220344543, G Loss: 5.299176216125488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5385/100000, D Loss: 0.12282579392194748, G Loss: 5.351999282836914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5386/100000, D Loss: 0.12143976613879204, G Loss: 5.674422264099121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5387/100000, D Loss: 0.11498914286494255, G Loss: 5.840188026428223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5388/100000, D Loss: 0.13136648759245872, G Loss: 5.222189903259277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5389/100000, D Loss: 0.13091151788830757, G Loss: 5.286739826202393\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5390/100000, D Loss: 0.1265256702899933, G Loss: 5.638570785522461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5391/100000, D Loss: 0.12691562250256538, G Loss: 5.759416580200195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5392/100000, D Loss: 0.13025462999939919, G Loss: 5.427813529968262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5393/100000, D Loss: 0.14718401432037354, G Loss: 5.135415077209473\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5394/100000, D Loss: 0.14227694272994995, G Loss: 5.4327850341796875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5395/100000, D Loss: 0.1526145562529564, G Loss: 5.324916839599609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5396/100000, D Loss: 0.21066219359636307, G Loss: 4.684011936187744\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5397/100000, D Loss: 0.20804695785045624, G Loss: 4.89800500869751\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5398/100000, D Loss: 0.20420962572097778, G Loss: 5.456449031829834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5399/100000, D Loss: 0.22240521758794785, G Loss: 4.967954635620117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5400/100000, D Loss: 0.24362961947917938, G Loss: 4.606175422668457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5401/100000, D Loss: 0.2555028349161148, G Loss: 4.85883903503418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5402/100000, D Loss: 0.20757637917995453, G Loss: 5.307520389556885\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5403/100000, D Loss: 0.25643882155418396, G Loss: 4.773416519165039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5404/100000, D Loss: 0.23882464319467545, G Loss: 4.789060592651367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5405/100000, D Loss: 0.26792412996292114, G Loss: 4.957681655883789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5406/100000, D Loss: 0.33327895402908325, G Loss: 4.718464374542236\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5407/100000, D Loss: 0.3167491853237152, G Loss: 4.611135482788086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5408/100000, D Loss: 0.2587529718875885, G Loss: 4.871586799621582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5409/100000, D Loss: 0.3096206337213516, G Loss: 5.047443866729736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5410/100000, D Loss: 0.27199091762304306, G Loss: 5.108501434326172\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5411/100000, D Loss: 0.2569541931152344, G Loss: 5.014797210693359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5412/100000, D Loss: 0.2783806547522545, G Loss: 4.822168350219727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5413/100000, D Loss: 0.22161587327718735, G Loss: 5.2977519035339355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5414/100000, D Loss: 0.22245285660028458, G Loss: 5.667328834533691\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5415/100000, D Loss: 0.23265200853347778, G Loss: 5.4405927658081055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5416/100000, D Loss: 0.2724694311618805, G Loss: 4.972815036773682\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5417/100000, D Loss: 0.20495682954788208, G Loss: 5.285305976867676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5418/100000, D Loss: 0.18206794559955597, G Loss: 5.654870986938477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5419/100000, D Loss: 0.21110600233078003, G Loss: 5.441745758056641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5420/100000, D Loss: 0.18564166128635406, G Loss: 5.57161808013916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5421/100000, D Loss: 0.16414201259613037, G Loss: 5.547484397888184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5422/100000, D Loss: 0.16009850800037384, G Loss: 5.746866226196289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5423/100000, D Loss: 0.18288873136043549, G Loss: 5.600408554077148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5424/100000, D Loss: 0.14690718054771423, G Loss: 5.61395263671875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5425/100000, D Loss: 0.1475619226694107, G Loss: 5.935606002807617\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5426/100000, D Loss: 0.14300353080034256, G Loss: 6.015768051147461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5427/100000, D Loss: 0.19704410433769226, G Loss: 5.666140079498291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5428/100000, D Loss: 0.17951128631830215, G Loss: 5.450484752655029\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5429/100000, D Loss: 0.1737629622220993, G Loss: 5.824206829071045\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5430/100000, D Loss: 0.16946594417095184, G Loss: 6.2722930908203125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5431/100000, D Loss: 0.1910952925682068, G Loss: 5.929670333862305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5432/100000, D Loss: 0.23968448489904404, G Loss: 5.367814064025879\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5433/100000, D Loss: 0.2081795111298561, G Loss: 5.600855827331543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5434/100000, D Loss: 0.21836131811141968, G Loss: 5.782223701477051\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5435/100000, D Loss: 0.2583394795656204, G Loss: 5.337629318237305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5436/100000, D Loss: 0.2604230046272278, G Loss: 5.245094299316406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5437/100000, D Loss: 0.26438526809215546, G Loss: 5.355381488800049\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5438/100000, D Loss: 0.2703288644552231, G Loss: 5.170616626739502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5439/100000, D Loss: 0.36535052955150604, G Loss: 4.625539302825928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5440/100000, D Loss: 0.3600742518901825, G Loss: 4.625507831573486\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5441/100000, D Loss: 0.32414405047893524, G Loss: 5.069121360778809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5442/100000, D Loss: 0.34551939368247986, G Loss: 4.878689765930176\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5443/100000, D Loss: 0.29353034496307373, G Loss: 5.122482776641846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5444/100000, D Loss: 0.2741206884384155, G Loss: 4.6669721603393555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5445/100000, D Loss: 0.2607608586549759, G Loss: 4.791985511779785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5446/100000, D Loss: 0.20040806382894516, G Loss: 5.38066291809082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5447/100000, D Loss: 0.24262617528438568, G Loss: 5.290786266326904\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5448/100000, D Loss: 0.24190492928028107, G Loss: 4.663967132568359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5449/100000, D Loss: 0.23082030564546585, G Loss: 4.988275051116943\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5450/100000, D Loss: 0.1691487953066826, G Loss: 5.5853376388549805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5451/100000, D Loss: 0.2006097175180912, G Loss: 5.348584175109863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5452/100000, D Loss: 0.21493147313594818, G Loss: 4.928060531616211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5453/100000, D Loss: 0.1595669835805893, G Loss: 5.325255393981934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5454/100000, D Loss: 0.13049545139074326, G Loss: 5.759527206420898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5455/100000, D Loss: 0.1677720546722412, G Loss: 5.740942001342773\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5456/100000, D Loss: 0.13287105038762093, G Loss: 5.489832878112793\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5457/100000, D Loss: 0.15461380034685135, G Loss: 5.238967418670654\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5458/100000, D Loss: 0.13452626019716263, G Loss: 5.376829147338867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5459/100000, D Loss: 0.12547491490840912, G Loss: 5.876560211181641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5460/100000, D Loss: 0.1517559140920639, G Loss: 5.786525726318359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5461/100000, D Loss: 0.16278838366270065, G Loss: 5.288851737976074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5462/100000, D Loss: 0.18048207461833954, G Loss: 5.256303310394287\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5463/100000, D Loss: 0.1475689634680748, G Loss: 5.67736291885376\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5464/100000, D Loss: 0.15631207823753357, G Loss: 5.4099016189575195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5465/100000, D Loss: 0.15217353403568268, G Loss: 5.16794490814209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5466/100000, D Loss: 0.17039982229471207, G Loss: 5.179740905761719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5467/100000, D Loss: 0.1793544963002205, G Loss: 5.642769813537598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5468/100000, D Loss: 0.19810357689857483, G Loss: 5.327951431274414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5469/100000, D Loss: 0.21071521937847137, G Loss: 4.967803478240967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5470/100000, D Loss: 0.18533334136009216, G Loss: 5.101455211639404\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5471/100000, D Loss: 0.2571750581264496, G Loss: 4.858458518981934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5472/100000, D Loss: 0.22640623152256012, G Loss: 5.000253677368164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5473/100000, D Loss: 0.22385426610708237, G Loss: 4.918297290802002\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5474/100000, D Loss: 0.28263820707798004, G Loss: 4.659241676330566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5475/100000, D Loss: 0.24675214290618896, G Loss: 4.912078857421875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5476/100000, D Loss: 0.2594798281788826, G Loss: 5.131536483764648\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5477/100000, D Loss: 0.27869782596826553, G Loss: 4.879405975341797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5478/100000, D Loss: 0.2867158278822899, G Loss: 4.488273620605469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5479/100000, D Loss: 0.2652715891599655, G Loss: 4.836979866027832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5480/100000, D Loss: 0.24558478593826294, G Loss: 5.204217433929443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5481/100000, D Loss: 0.3318459838628769, G Loss: 4.552688121795654\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5482/100000, D Loss: 0.27607494592666626, G Loss: 4.579504013061523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5483/100000, D Loss: 0.2351868748664856, G Loss: 4.891243934631348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5484/100000, D Loss: 0.2786838710308075, G Loss: 4.589774131774902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5485/100000, D Loss: 0.296104371547699, G Loss: 4.604539394378662\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5486/100000, D Loss: 0.2371176928281784, G Loss: 5.0113396644592285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5487/100000, D Loss: 0.2270938977599144, G Loss: 5.193678379058838\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5488/100000, D Loss: 0.22000806778669357, G Loss: 5.029594421386719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5489/100000, D Loss: 0.1737920492887497, G Loss: 4.896313667297363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5490/100000, D Loss: 0.21088790893554688, G Loss: 4.871584892272949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5491/100000, D Loss: 0.18343180418014526, G Loss: 5.254294395446777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5492/100000, D Loss: 0.16012174636125565, G Loss: 5.40912389755249\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5493/100000, D Loss: 0.18652812764048576, G Loss: 5.125401020050049\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5494/100000, D Loss: 0.18726670742034912, G Loss: 4.800746440887451\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5495/100000, D Loss: 0.16174721717834473, G Loss: 4.779401779174805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5496/100000, D Loss: 0.16961728781461716, G Loss: 5.279980659484863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5497/100000, D Loss: 0.12281659990549088, G Loss: 5.42625617980957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5498/100000, D Loss: 0.15199803560972214, G Loss: 4.940192222595215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5499/100000, D Loss: 0.16075144708156586, G Loss: 4.807936668395996\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5500/100000, D Loss: 0.15156464278697968, G Loss: 4.683279991149902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5501/100000, D Loss: 0.15636500716209412, G Loss: 5.10139274597168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5502/100000, D Loss: 0.17227686196565628, G Loss: 4.971386909484863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5503/100000, D Loss: 0.2344582974910736, G Loss: 4.806032657623291\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5504/100000, D Loss: 0.20117931813001633, G Loss: 4.790666580200195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5505/100000, D Loss: 0.2019054889678955, G Loss: 4.798642158508301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5506/100000, D Loss: 0.22958176583051682, G Loss: 4.3588547706604\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5507/100000, D Loss: 0.22665376216173172, G Loss: 4.729907989501953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5508/100000, D Loss: 0.2361130192875862, G Loss: 4.829176902770996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5509/100000, D Loss: 0.2343081310391426, G Loss: 4.500378608703613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5510/100000, D Loss: 0.18240036815404892, G Loss: 4.712671756744385\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5511/100000, D Loss: 0.19009287655353546, G Loss: 4.870086669921875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5512/100000, D Loss: 0.16848300397396088, G Loss: 4.969359874725342\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5513/100000, D Loss: 0.15711523592472076, G Loss: 4.722356796264648\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5514/100000, D Loss: 0.1685267761349678, G Loss: 4.918968677520752\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5515/100000, D Loss: 0.14358308911323547, G Loss: 5.344342231750488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5516/100000, D Loss: 0.14946886524558067, G Loss: 5.2922844886779785\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5517/100000, D Loss: 0.1698901578783989, G Loss: 4.835556983947754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5518/100000, D Loss: 0.15121475607156754, G Loss: 5.1577935218811035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5519/100000, D Loss: 0.14496375620365143, G Loss: 5.399003028869629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5520/100000, D Loss: 0.148614089936018, G Loss: 5.255722999572754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5521/100000, D Loss: 0.12674269080162048, G Loss: 5.243927001953125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5522/100000, D Loss: 0.1681303158402443, G Loss: 4.636045932769775\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5523/100000, D Loss: 0.1728046014904976, G Loss: 4.98139762878418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5524/100000, D Loss: 0.16883330047130585, G Loss: 5.278878211975098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5525/100000, D Loss: 0.18049170821905136, G Loss: 4.7204155921936035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5526/100000, D Loss: 0.20339719206094742, G Loss: 4.399636268615723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5527/100000, D Loss: 0.1860777586698532, G Loss: 4.721754550933838\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5528/100000, D Loss: 0.196072556078434, G Loss: 4.711426258087158\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5529/100000, D Loss: 0.2523297816514969, G Loss: 4.124699592590332\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5530/100000, D Loss: 0.26827116310596466, G Loss: 4.691470146179199\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5531/100000, D Loss: 0.19951298832893372, G Loss: 5.32279634475708\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5532/100000, D Loss: 0.2511918917298317, G Loss: 4.44659423828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5533/100000, D Loss: 0.2353140115737915, G Loss: 4.224800109863281\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5534/100000, D Loss: 0.16303443908691406, G Loss: 5.278433799743652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5535/100000, D Loss: 0.22832144051790237, G Loss: 4.632546901702881\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5536/100000, D Loss: 0.24187545478343964, G Loss: 4.563042163848877\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5537/100000, D Loss: 0.19492452591657639, G Loss: 5.169700622558594\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5538/100000, D Loss: 0.15702500939369202, G Loss: 5.302741050720215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5539/100000, D Loss: 0.17891638725996017, G Loss: 4.854240417480469\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5540/100000, D Loss: 0.15009991824626923, G Loss: 4.769985198974609\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5541/100000, D Loss: 0.14681077376008034, G Loss: 5.084586143493652\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5542/100000, D Loss: 0.15734925866127014, G Loss: 4.93928337097168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5543/100000, D Loss: 0.15493564307689667, G Loss: 4.893320083618164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5544/100000, D Loss: 0.18924851715564728, G Loss: 4.753009796142578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5545/100000, D Loss: 0.19967889785766602, G Loss: 4.760761260986328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5546/100000, D Loss: 0.20607607066631317, G Loss: 4.759767055511475\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5547/100000, D Loss: 0.20927010476589203, G Loss: 4.622286796569824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5548/100000, D Loss: 0.2182988077402115, G Loss: 4.6167168617248535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5549/100000, D Loss: 0.25993378460407257, G Loss: 4.555718421936035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5550/100000, D Loss: 0.2771129161119461, G Loss: 4.444573402404785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5551/100000, D Loss: 0.2675385922193527, G Loss: 4.668763160705566\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5552/100000, D Loss: 0.3150392323732376, G Loss: 4.491623878479004\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5553/100000, D Loss: 0.34606319665908813, G Loss: 4.221978187561035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5554/100000, D Loss: 0.2664259821176529, G Loss: 4.627239227294922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5555/100000, D Loss: 0.3064783737063408, G Loss: 4.365342140197754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5556/100000, D Loss: 0.3042404502630234, G Loss: 4.2361040115356445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5557/100000, D Loss: 0.27646276354789734, G Loss: 4.233068943023682\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5558/100000, D Loss: 0.2851096987724304, G Loss: 4.288418769836426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5559/100000, D Loss: 0.2820593789219856, G Loss: 4.2734808921813965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5560/100000, D Loss: 0.22842788696289062, G Loss: 4.451555252075195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5561/100000, D Loss: 0.23875071108341217, G Loss: 4.494243144989014\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5562/100000, D Loss: 0.24094632267951965, G Loss: 4.1963958740234375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5563/100000, D Loss: 0.2203780859708786, G Loss: 4.194191932678223\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5564/100000, D Loss: 0.1821587085723877, G Loss: 4.441992282867432\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5565/100000, D Loss: 0.1775113195180893, G Loss: 4.991854667663574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5566/100000, D Loss: 0.18629395216703415, G Loss: 4.681156635284424\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5567/100000, D Loss: 0.2120300680398941, G Loss: 4.345455169677734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5568/100000, D Loss: 0.16966509819030762, G Loss: 4.8474040031433105\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5569/100000, D Loss: 0.1633211076259613, G Loss: 5.5099287033081055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5570/100000, D Loss: 0.20566851645708084, G Loss: 4.971467018127441\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5571/100000, D Loss: 0.17634288221597672, G Loss: 4.58736515045166\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5572/100000, D Loss: 0.171162948012352, G Loss: 5.188105583190918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5573/100000, D Loss: 0.11322812736034393, G Loss: 5.95843505859375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5574/100000, D Loss: 0.1628740429878235, G Loss: 5.654795169830322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5575/100000, D Loss: 0.14775271341204643, G Loss: 5.147359848022461\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5576/100000, D Loss: 0.17946483194828033, G Loss: 5.139418125152588\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5577/100000, D Loss: 0.13509684056043625, G Loss: 5.887877941131592\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5578/100000, D Loss: 0.13312869891524315, G Loss: 6.030904293060303\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5579/100000, D Loss: 0.17347751557826996, G Loss: 5.7355637550354\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5580/100000, D Loss: 0.17434878647327423, G Loss: 5.500339984893799\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5581/100000, D Loss: 0.17777180671691895, G Loss: 5.76947021484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5582/100000, D Loss: 0.14758987724781036, G Loss: 6.25004768371582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5583/100000, D Loss: 0.1706300601363182, G Loss: 6.096148490905762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5584/100000, D Loss: 0.2304423525929451, G Loss: 5.408749580383301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5585/100000, D Loss: 0.2044677734375, G Loss: 5.402735710144043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5586/100000, D Loss: 0.20329870283603668, G Loss: 5.7542009353637695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5587/100000, D Loss: 0.1878182366490364, G Loss: 6.09316349029541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5588/100000, D Loss: 0.19840118661522865, G Loss: 5.717566967010498\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5589/100000, D Loss: 0.21446450054645538, G Loss: 4.992337226867676\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5590/100000, D Loss: 0.20371975749731064, G Loss: 5.266262054443359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5591/100000, D Loss: 0.23107293248176575, G Loss: 5.512435436248779\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5592/100000, D Loss: 0.19586169719696045, G Loss: 5.076328277587891\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5593/100000, D Loss: 0.21483727544546127, G Loss: 4.896595001220703\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5594/100000, D Loss: 0.271142840385437, G Loss: 4.732893943786621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5595/100000, D Loss: 0.24736055731773376, G Loss: 4.89891242980957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5596/100000, D Loss: 0.3210621178150177, G Loss: 4.73734712600708\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5597/100000, D Loss: 0.24950392544269562, G Loss: 4.887951850891113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5598/100000, D Loss: 0.30932825803756714, G Loss: 4.679508686065674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5599/100000, D Loss: 0.27911674976348877, G Loss: 4.82890510559082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5600/100000, D Loss: 0.28190480917692184, G Loss: 4.790069103240967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5601/100000, D Loss: 0.323233500123024, G Loss: 4.68593692779541\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5602/100000, D Loss: 0.2924947440624237, G Loss: 5.192978858947754\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5603/100000, D Loss: 0.30295826494693756, G Loss: 5.035024642944336\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5604/100000, D Loss: 0.28291837126016617, G Loss: 4.529177665710449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5605/100000, D Loss: 0.27983519434928894, G Loss: 4.956865310668945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5606/100000, D Loss: 0.2592317834496498, G Loss: 5.218429088592529\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5607/100000, D Loss: 0.24866163730621338, G Loss: 5.340594291687012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5608/100000, D Loss: 0.2392933964729309, G Loss: 5.018978118896484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5609/100000, D Loss: 0.20525465160608292, G Loss: 5.315093994140625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5610/100000, D Loss: 0.19518111646175385, G Loss: 5.610252857208252\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5611/100000, D Loss: 0.14479229599237442, G Loss: 5.795619010925293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5612/100000, D Loss: 0.16759958863258362, G Loss: 5.7707414627075195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5613/100000, D Loss: 0.16254892200231552, G Loss: 5.76417350769043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5614/100000, D Loss: 0.1513185203075409, G Loss: 5.693717956542969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5615/100000, D Loss: 0.12418290972709656, G Loss: 5.8882951736450195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5616/100000, D Loss: 0.12634534761309624, G Loss: 5.938738822937012\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5617/100000, D Loss: 0.1413642130792141, G Loss: 5.5506591796875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5618/100000, D Loss: 0.12102629244327545, G Loss: 5.2736406326293945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5619/100000, D Loss: 0.12652677297592163, G Loss: 5.490959167480469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5620/100000, D Loss: 0.12083162367343903, G Loss: 5.807693004608154\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5621/100000, D Loss: 0.14140943437814713, G Loss: 5.836349964141846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5622/100000, D Loss: 0.1403275728225708, G Loss: 5.514620304107666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5623/100000, D Loss: 0.15871519595384598, G Loss: 5.248104572296143\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5624/100000, D Loss: 0.16825970262289047, G Loss: 4.995515823364258\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5625/100000, D Loss: 0.15849080681800842, G Loss: 5.130209922790527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5626/100000, D Loss: 0.1426841840147972, G Loss: 5.207629203796387\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5627/100000, D Loss: 0.1693774312734604, G Loss: 4.983610153198242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5628/100000, D Loss: 0.21641532331705093, G Loss: 4.902451038360596\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5629/100000, D Loss: 0.19927217811346054, G Loss: 5.037174701690674\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5630/100000, D Loss: 0.2031852751970291, G Loss: 5.091506481170654\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5631/100000, D Loss: 0.20275255292654037, G Loss: 5.099749565124512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5632/100000, D Loss: 0.22670960426330566, G Loss: 4.98407506942749\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5633/100000, D Loss: 0.20747912675142288, G Loss: 5.27133846282959\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5634/100000, D Loss: 0.21218723058700562, G Loss: 5.112893581390381\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5635/100000, D Loss: 0.19633951783180237, G Loss: 4.943235397338867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5636/100000, D Loss: 0.17308198660612106, G Loss: 5.028812408447266\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5637/100000, D Loss: 0.1737975999712944, G Loss: 4.946005821228027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5638/100000, D Loss: 0.20950497686862946, G Loss: 4.828953266143799\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5639/100000, D Loss: 0.17928564548492432, G Loss: 4.932083606719971\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5640/100000, D Loss: 0.16936944425106049, G Loss: 4.947543621063232\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5641/100000, D Loss: 0.18771492689847946, G Loss: 4.7148542404174805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5642/100000, D Loss: 0.16208335012197495, G Loss: 4.739831924438477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5643/100000, D Loss: 0.16261348873376846, G Loss: 5.166471481323242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5644/100000, D Loss: 0.17275188118219376, G Loss: 5.089353561401367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5645/100000, D Loss: 0.18830378353595734, G Loss: 4.763736724853516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5646/100000, D Loss: 0.15458963066339493, G Loss: 4.749229907989502\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5647/100000, D Loss: 0.14852601289749146, G Loss: 5.063641548156738\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5648/100000, D Loss: 0.17784450203180313, G Loss: 4.752200603485107\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5649/100000, D Loss: 0.18908484280109406, G Loss: 4.459901332855225\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5650/100000, D Loss: 0.1640320047736168, G Loss: 4.959497451782227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5651/100000, D Loss: 0.16535406559705734, G Loss: 5.077244758605957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5652/100000, D Loss: 0.22024577856063843, G Loss: 4.484830856323242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5653/100000, D Loss: 0.1949320062994957, G Loss: 4.550392150878906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5654/100000, D Loss: 0.18988507241010666, G Loss: 5.106456756591797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5655/100000, D Loss: 0.19016728922724724, G Loss: 4.840270042419434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5656/100000, D Loss: 0.20791301131248474, G Loss: 4.422337532043457\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5657/100000, D Loss: 0.189721018075943, G Loss: 4.350725173950195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5658/100000, D Loss: 0.20697429031133652, G Loss: 5.090692043304443\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5659/100000, D Loss: 0.18553821742534637, G Loss: 5.246272087097168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5660/100000, D Loss: 0.19312750175595284, G Loss: 4.671230792999268\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5661/100000, D Loss: 0.19881417602300644, G Loss: 4.651244163513184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5662/100000, D Loss: 0.20144712179899216, G Loss: 4.895736217498779\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5663/100000, D Loss: 0.17690613865852356, G Loss: 5.255585670471191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5664/100000, D Loss: 0.2437945008277893, G Loss: 4.657811641693115\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5665/100000, D Loss: 0.21667592227458954, G Loss: 4.555220603942871\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5666/100000, D Loss: 0.2257245033979416, G Loss: 4.621905326843262\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5667/100000, D Loss: 0.21239002794027328, G Loss: 4.810142993927002\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5668/100000, D Loss: 0.2578144371509552, G Loss: 4.466382026672363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5669/100000, D Loss: 0.26799699664115906, G Loss: 4.181540012359619\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5670/100000, D Loss: 0.29511912167072296, G Loss: 4.4035234451293945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5671/100000, D Loss: 0.29283206909894943, G Loss: 4.52520751953125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5672/100000, D Loss: 0.24305719137191772, G Loss: 4.749817848205566\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5673/100000, D Loss: 0.25002890825271606, G Loss: 4.370091915130615\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5674/100000, D Loss: 0.1978711634874344, G Loss: 4.382326126098633\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5675/100000, D Loss: 0.2609362006187439, G Loss: 4.310510158538818\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5676/100000, D Loss: 0.2624244689941406, G Loss: 4.416752815246582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5677/100000, D Loss: 0.21302387863397598, G Loss: 4.654510498046875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5678/100000, D Loss: 0.22450872510671616, G Loss: 4.713191986083984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5679/100000, D Loss: 0.28399282693862915, G Loss: 4.409629821777344\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5680/100000, D Loss: 0.22644372284412384, G Loss: 4.429285049438477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5681/100000, D Loss: 0.20019898563623428, G Loss: 4.6843719482421875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5682/100000, D Loss: 0.22742176055908203, G Loss: 4.486093521118164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5683/100000, D Loss: 0.21833298355340958, G Loss: 4.389064788818359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5684/100000, D Loss: 0.2483563870191574, G Loss: 4.421288967132568\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5685/100000, D Loss: 0.1967938244342804, G Loss: 4.576078414916992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5686/100000, D Loss: 0.16664717346429825, G Loss: 5.016067028045654\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5687/100000, D Loss: 0.19873422384262085, G Loss: 4.923576831817627\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5688/100000, D Loss: 0.21949587762355804, G Loss: 4.381287097930908\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5689/100000, D Loss: 0.16063465178012848, G Loss: 4.838715076446533\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5690/100000, D Loss: 0.1747247874736786, G Loss: 5.512985706329346\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5691/100000, D Loss: 0.16203885152935982, G Loss: 5.590442657470703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5692/100000, D Loss: 0.1732713282108307, G Loss: 5.225461006164551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5693/100000, D Loss: 0.17436480522155762, G Loss: 5.441680908203125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5694/100000, D Loss: 0.16334990411996841, G Loss: 5.824716091156006\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5695/100000, D Loss: 0.2036605328321457, G Loss: 5.892199516296387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5696/100000, D Loss: 0.20005708932876587, G Loss: 5.662996292114258\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5697/100000, D Loss: 0.2209773138165474, G Loss: 5.575909614562988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5698/100000, D Loss: 0.23228532075881958, G Loss: 5.704046249389648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5699/100000, D Loss: 0.2077862098813057, G Loss: 5.893613815307617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5700/100000, D Loss: 0.27206261456012726, G Loss: 5.688609600067139\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5701/100000, D Loss: 0.1775740087032318, G Loss: 5.878310680389404\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5702/100000, D Loss: 0.21112778782844543, G Loss: 5.466708183288574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5703/100000, D Loss: 0.2032817006111145, G Loss: 5.132854461669922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5704/100000, D Loss: 0.1860451027750969, G Loss: 5.4199371337890625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5705/100000, D Loss: 0.1766064614057541, G Loss: 5.607810020446777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5706/100000, D Loss: 0.2101820483803749, G Loss: 5.443748950958252\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5707/100000, D Loss: 0.206283800303936, G Loss: 5.188309192657471\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5708/100000, D Loss: 0.19724179059267044, G Loss: 5.152854919433594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5709/100000, D Loss: 0.18230697512626648, G Loss: 5.42042350769043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5710/100000, D Loss: 0.19082214683294296, G Loss: 5.1159563064575195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5711/100000, D Loss: 0.18939397484064102, G Loss: 5.132434368133545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5712/100000, D Loss: 0.15756729245185852, G Loss: 5.500007629394531\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5713/100000, D Loss: 0.21057245135307312, G Loss: 5.179001331329346\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5714/100000, D Loss: 0.19831477105617523, G Loss: 4.975185871124268\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5715/100000, D Loss: 0.2099873572587967, G Loss: 4.910887718200684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5716/100000, D Loss: 0.18434540927410126, G Loss: 5.439913749694824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5717/100000, D Loss: 0.19972704350948334, G Loss: 5.246773719787598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5718/100000, D Loss: 0.21777638047933578, G Loss: 4.66232442855835\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5719/100000, D Loss: 0.1967259645462036, G Loss: 5.0966267585754395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5720/100000, D Loss: 0.2149524837732315, G Loss: 5.26718807220459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5721/100000, D Loss: 0.2462439090013504, G Loss: 4.8240203857421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5722/100000, D Loss: 0.27950234711170197, G Loss: 4.754444122314453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5723/100000, D Loss: 0.23896490037441254, G Loss: 4.956424236297607\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5724/100000, D Loss: 0.24805429577827454, G Loss: 4.7903642654418945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5725/100000, D Loss: 0.23371216654777527, G Loss: 4.584611892700195\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5726/100000, D Loss: 0.25660672783851624, G Loss: 4.729063987731934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5727/100000, D Loss: 0.20454737544059753, G Loss: 4.974156379699707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5728/100000, D Loss: 0.2533136159181595, G Loss: 4.674691200256348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5729/100000, D Loss: 0.2121071070432663, G Loss: 4.730937957763672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5730/100000, D Loss: 0.18856757879257202, G Loss: 5.111633777618408\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5731/100000, D Loss: 0.23839426040649414, G Loss: 4.878847122192383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5732/100000, D Loss: 0.23706316947937012, G Loss: 4.800858020782471\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 5733/100000, D Loss: 0.2210511937737465, G Loss: 4.81782341003418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5734/100000, D Loss: 0.22863689064979553, G Loss: 4.6397786140441895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5735/100000, D Loss: 0.21885232627391815, G Loss: 4.784582138061523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5736/100000, D Loss: 0.21490021795034409, G Loss: 5.010467529296875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5737/100000, D Loss: 0.26317228376865387, G Loss: 4.704115867614746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5738/100000, D Loss: 0.25337354838848114, G Loss: 4.524802207946777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5739/100000, D Loss: 0.28281232714653015, G Loss: 4.435379505157471\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5740/100000, D Loss: 0.27678944170475006, G Loss: 4.627722263336182\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5741/100000, D Loss: 0.28213924914598465, G Loss: 4.776878356933594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5742/100000, D Loss: 0.24012842774391174, G Loss: 4.41754674911499\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5743/100000, D Loss: 0.26648181676864624, G Loss: 4.281903266906738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5744/100000, D Loss: 0.257118359208107, G Loss: 4.678884506225586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5745/100000, D Loss: 0.19964368641376495, G Loss: 5.100961685180664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5746/100000, D Loss: 0.22768144309520721, G Loss: 4.856823444366455\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5747/100000, D Loss: 0.23911277204751968, G Loss: 4.451174736022949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5748/100000, D Loss: 0.15359637141227722, G Loss: 4.922800064086914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5749/100000, D Loss: 0.13986263424158096, G Loss: 4.941843509674072\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5750/100000, D Loss: 0.13102846965193748, G Loss: 4.809137344360352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5751/100000, D Loss: 0.15331735461950302, G Loss: 4.971457481384277\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5752/100000, D Loss: 0.13824854791164398, G Loss: 5.2126312255859375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5753/100000, D Loss: 0.17047133296728134, G Loss: 4.958793640136719\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5754/100000, D Loss: 0.13604583591222763, G Loss: 4.888957977294922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5755/100000, D Loss: 0.12240449711680412, G Loss: 5.298786163330078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5756/100000, D Loss: 0.15302923321723938, G Loss: 4.757859230041504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5757/100000, D Loss: 0.1514764130115509, G Loss: 4.741792678833008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5758/100000, D Loss: 0.14513248950242996, G Loss: 4.808143138885498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5759/100000, D Loss: 0.17382705211639404, G Loss: 5.082958221435547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5760/100000, D Loss: 0.17314992100000381, G Loss: 4.804838180541992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5761/100000, D Loss: 0.204291433095932, G Loss: 4.528051376342773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5762/100000, D Loss: 0.20345599204301834, G Loss: 4.47622013092041\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5763/100000, D Loss: 0.21111304312944412, G Loss: 4.715015888214111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5764/100000, D Loss: 0.20479507744312286, G Loss: 4.901364326477051\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5765/100000, D Loss: 0.22157779335975647, G Loss: 4.638428211212158\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5766/100000, D Loss: 0.2316306233406067, G Loss: 4.258388519287109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5767/100000, D Loss: 0.23884952813386917, G Loss: 4.513189315795898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5768/100000, D Loss: 0.19047491252422333, G Loss: 4.858654499053955\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5769/100000, D Loss: 0.24200066924095154, G Loss: 4.621186256408691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5770/100000, D Loss: 0.21092084795236588, G Loss: 4.459510326385498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5771/100000, D Loss: 0.20465291291475296, G Loss: 4.82997465133667\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5772/100000, D Loss: 0.21726538240909576, G Loss: 4.663163185119629\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5773/100000, D Loss: 0.19527443498373032, G Loss: 4.650661468505859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5774/100000, D Loss: 0.1983700692653656, G Loss: 5.095951080322266\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5775/100000, D Loss: 0.19070561230182648, G Loss: 5.040087699890137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5776/100000, D Loss: 0.17687664926052094, G Loss: 4.869841575622559\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5777/100000, D Loss: 0.17509903758764267, G Loss: 4.804863929748535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5778/100000, D Loss: 0.17015469074249268, G Loss: 5.028679847717285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5779/100000, D Loss: 0.14783170819282532, G Loss: 5.261003017425537\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5780/100000, D Loss: 0.17313047498464584, G Loss: 4.905762672424316\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5781/100000, D Loss: 0.18995076417922974, G Loss: 4.6467671394348145\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5782/100000, D Loss: 0.18541072309017181, G Loss: 5.171182155609131\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5783/100000, D Loss: 0.1927439197897911, G Loss: 5.047740936279297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5784/100000, D Loss: 0.2404472976922989, G Loss: 4.272670745849609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5785/100000, D Loss: 0.24895711243152618, G Loss: 4.727657794952393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5786/100000, D Loss: 0.23027656972408295, G Loss: 4.8765411376953125\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5787/100000, D Loss: 0.25569765269756317, G Loss: 4.546059608459473\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5788/100000, D Loss: 0.273849219083786, G Loss: 4.378230094909668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5789/100000, D Loss: 0.2453163117170334, G Loss: 4.462772369384766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5790/100000, D Loss: 0.29262448847293854, G Loss: 4.39371395111084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5791/100000, D Loss: 0.28974759578704834, G Loss: 4.437829971313477\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5792/100000, D Loss: 0.2845317870378494, G Loss: 4.3132452964782715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5793/100000, D Loss: 0.22866739332675934, G Loss: 4.837174415588379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5794/100000, D Loss: 0.2565750479698181, G Loss: 4.082695007324219\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5795/100000, D Loss: 0.24049484729766846, G Loss: 4.212757587432861\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5796/100000, D Loss: 0.2042381837964058, G Loss: 4.521245002746582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5797/100000, D Loss: 0.20692718029022217, G Loss: 4.731605529785156\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5798/100000, D Loss: 0.25385186076164246, G Loss: 4.186460018157959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5799/100000, D Loss: 0.17823783308267593, G Loss: 4.329585075378418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5800/100000, D Loss: 0.15748067200183868, G Loss: 4.749379634857178\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5801/100000, D Loss: 0.21390974521636963, G Loss: 4.447885990142822\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5802/100000, D Loss: 0.22083280980587006, G Loss: 4.264881610870361\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5803/100000, D Loss: 0.18837759643793106, G Loss: 4.452027320861816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5804/100000, D Loss: 0.19211692363023758, G Loss: 4.492859840393066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5805/100000, D Loss: 0.25403834879398346, G Loss: 4.405560493469238\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5806/100000, D Loss: 0.19284383207559586, G Loss: 4.7483720779418945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5807/100000, D Loss: 0.22202808409929276, G Loss: 4.338529586791992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5808/100000, D Loss: 0.2617807164788246, G Loss: 4.13426399230957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5809/100000, D Loss: 0.19978021085262299, G Loss: 4.600879192352295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5810/100000, D Loss: 0.22527925670146942, G Loss: 4.518963813781738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5811/100000, D Loss: 0.20823195576667786, G Loss: 4.492205619812012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5812/100000, D Loss: 0.25636492669582367, G Loss: 4.20566987991333\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5813/100000, D Loss: 0.26480039209127426, G Loss: 4.345506191253662\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5814/100000, D Loss: 0.2300090491771698, G Loss: 4.3097734451293945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5815/100000, D Loss: 0.24182936549186707, G Loss: 4.246365547180176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5816/100000, D Loss: 0.24627666920423508, G Loss: 4.457981109619141\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5817/100000, D Loss: 0.29192084074020386, G Loss: 4.26472282409668\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5818/100000, D Loss: 0.3231254070997238, G Loss: 4.202760219573975\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5819/100000, D Loss: 0.2814258486032486, G Loss: 4.088878154754639\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5820/100000, D Loss: 0.2816625013947487, G Loss: 4.184995651245117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5821/100000, D Loss: 0.3029628247022629, G Loss: 4.150217056274414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5822/100000, D Loss: 0.24945507943630219, G Loss: 4.356539726257324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5823/100000, D Loss: 0.2077689841389656, G Loss: 4.51045036315918\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5824/100000, D Loss: 0.2690020948648453, G Loss: 4.213834762573242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5825/100000, D Loss: 0.2185463234782219, G Loss: 4.369399070739746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5826/100000, D Loss: 0.2245730757713318, G Loss: 4.6416826248168945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5827/100000, D Loss: 0.20949330925941467, G Loss: 4.7872209548950195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5828/100000, D Loss: 0.2141404151916504, G Loss: 4.655257225036621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5829/100000, D Loss: 0.2133335918188095, G Loss: 4.441989898681641\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5830/100000, D Loss: 0.1587461531162262, G Loss: 4.843780517578125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5831/100000, D Loss: 0.17795824259519577, G Loss: 4.763716697692871\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5832/100000, D Loss: 0.20638655126094818, G Loss: 4.509647369384766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5833/100000, D Loss: 0.2494872659444809, G Loss: 4.282064437866211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5834/100000, D Loss: 0.21486621350049973, G Loss: 4.641659736633301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5835/100000, D Loss: 0.2731570452451706, G Loss: 4.382628917694092\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5836/100000, D Loss: 0.2271268367767334, G Loss: 4.445775508880615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5837/100000, D Loss: 0.22509771585464478, G Loss: 4.6785101890563965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5838/100000, D Loss: 0.214585579931736, G Loss: 4.461790084838867\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5839/100000, D Loss: 0.229349747300148, G Loss: 4.511673927307129\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5840/100000, D Loss: 0.2101573348045349, G Loss: 4.487981796264648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5841/100000, D Loss: 0.17397087067365646, G Loss: 4.734405040740967\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5842/100000, D Loss: 0.1938888356089592, G Loss: 4.550576210021973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5843/100000, D Loss: 0.20305347442626953, G Loss: 4.688294410705566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5844/100000, D Loss: 0.15712206810712814, G Loss: 5.064886093139648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5845/100000, D Loss: 0.15980979055166245, G Loss: 4.984258651733398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5846/100000, D Loss: 0.1488829404115677, G Loss: 4.765711307525635\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5847/100000, D Loss: 0.14091430604457855, G Loss: 4.654634475708008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5848/100000, D Loss: 0.09507006779313087, G Loss: 5.197659015655518\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5849/100000, D Loss: 0.10203540325164795, G Loss: 5.356359004974365\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5850/100000, D Loss: 0.12353118881583214, G Loss: 5.165050506591797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5851/100000, D Loss: 0.10856165736913681, G Loss: 4.836843967437744\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5852/100000, D Loss: 0.10697506368160248, G Loss: 5.019003868103027\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5853/100000, D Loss: 0.10731697082519531, G Loss: 5.269765853881836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5854/100000, D Loss: 0.11907820031046867, G Loss: 5.434299945831299\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5855/100000, D Loss: 0.12209612131118774, G Loss: 4.990239143371582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5856/100000, D Loss: 0.12391354516148567, G Loss: 4.9159955978393555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5857/100000, D Loss: 0.11542144417762756, G Loss: 5.052602767944336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5858/100000, D Loss: 0.12495237961411476, G Loss: 4.82790470123291\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5859/100000, D Loss: 0.14460478723049164, G Loss: 4.595302104949951\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5860/100000, D Loss: 0.17235244810581207, G Loss: 4.782204627990723\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5861/100000, D Loss: 0.17174363136291504, G Loss: 4.7637481689453125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5862/100000, D Loss: 0.18556499481201172, G Loss: 4.7825822830200195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5863/100000, D Loss: 0.23493201285600662, G Loss: 4.559595584869385\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5864/100000, D Loss: 0.2245131954550743, G Loss: 4.379190444946289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5865/100000, D Loss: 0.27046848833560944, G Loss: 4.274648666381836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5866/100000, D Loss: 0.2521212249994278, G Loss: 4.375690460205078\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5867/100000, D Loss: 0.30898091197013855, G Loss: 4.145967960357666\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5868/100000, D Loss: 0.3059959411621094, G Loss: 3.8164467811584473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5869/100000, D Loss: 0.39432159066200256, G Loss: 4.121325969696045\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5870/100000, D Loss: 0.36422598361968994, G Loss: 4.352089881896973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5871/100000, D Loss: 0.405408039689064, G Loss: 4.036588668823242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5872/100000, D Loss: 0.31997111439704895, G Loss: 4.162213325500488\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5873/100000, D Loss: 0.3494595140218735, G Loss: 4.206052780151367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5874/100000, D Loss: 0.29822948575019836, G Loss: 4.145937919616699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5875/100000, D Loss: 0.30421143770217896, G Loss: 4.206305027008057\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5876/100000, D Loss: 0.3393422067165375, G Loss: 4.3903045654296875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5877/100000, D Loss: 0.3360717371106148, G Loss: 4.203186988830566\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5878/100000, D Loss: 0.3504209816455841, G Loss: 3.9281301498413086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5879/100000, D Loss: 0.3321395516395569, G Loss: 4.228015899658203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5880/100000, D Loss: 0.29024238884449005, G Loss: 4.151778221130371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5881/100000, D Loss: 0.29734306782484055, G Loss: 4.069782257080078\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5882/100000, D Loss: 0.282641276717186, G Loss: 4.1138386726379395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5883/100000, D Loss: 0.24509839713573456, G Loss: 4.247138977050781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5884/100000, D Loss: 0.27051570266485214, G Loss: 4.067020416259766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5885/100000, D Loss: 0.24007046222686768, G Loss: 3.9903500080108643\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5886/100000, D Loss: 0.212765671312809, G Loss: 4.212569236755371\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5887/100000, D Loss: 0.1725408136844635, G Loss: 4.472304344177246\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5888/100000, D Loss: 0.1634673736989498, G Loss: 4.6987738609313965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5889/100000, D Loss: 0.14338938519358635, G Loss: 4.5030903816223145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5890/100000, D Loss: 0.1565041020512581, G Loss: 4.574954032897949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5891/100000, D Loss: 0.1300460398197174, G Loss: 4.892354965209961\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5892/100000, D Loss: 0.14009389281272888, G Loss: 4.9133429527282715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5893/100000, D Loss: 0.119381383061409, G Loss: 4.959595203399658\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5894/100000, D Loss: 0.1269637793302536, G Loss: 5.034689903259277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5895/100000, D Loss: 0.12592017278075218, G Loss: 5.117330551147461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5896/100000, D Loss: 0.12580835819244385, G Loss: 5.226774215698242\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5897/100000, D Loss: 0.14105980098247528, G Loss: 5.058312892913818\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5898/100000, D Loss: 0.14743990451097488, G Loss: 5.045619010925293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5899/100000, D Loss: 0.14477145671844482, G Loss: 5.167945861816406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5900/100000, D Loss: 0.13067984580993652, G Loss: 5.566685199737549\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5901/100000, D Loss: 0.1778511330485344, G Loss: 4.95079231262207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5902/100000, D Loss: 0.17888876795768738, G Loss: 4.772032737731934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5903/100000, D Loss: 0.18883123993873596, G Loss: 4.839316368103027\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5904/100000, D Loss: 0.21961987018585205, G Loss: 5.233187198638916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5905/100000, D Loss: 0.1628173477947712, G Loss: 5.368864059448242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5906/100000, D Loss: 0.21944938600063324, G Loss: 4.860822677612305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5907/100000, D Loss: 0.2241557389497757, G Loss: 5.074787139892578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5908/100000, D Loss: 0.1980113908648491, G Loss: 5.487247467041016\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5909/100000, D Loss: 0.1877693384885788, G Loss: 5.270404815673828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5910/100000, D Loss: 0.21856588125228882, G Loss: 4.993963718414307\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5911/100000, D Loss: 0.23799515515565872, G Loss: 5.136282920837402\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5912/100000, D Loss: 0.18413717299699783, G Loss: 5.580822467803955\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5913/100000, D Loss: 0.20380809903144836, G Loss: 5.67213249206543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5914/100000, D Loss: 0.23039034754037857, G Loss: 4.953545570373535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5915/100000, D Loss: 0.2333001047372818, G Loss: 4.829072952270508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5916/100000, D Loss: 0.1498863324522972, G Loss: 5.4101386070251465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5917/100000, D Loss: 0.20333201438188553, G Loss: 5.268156051635742\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5918/100000, D Loss: 0.17234677076339722, G Loss: 4.926324844360352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5919/100000, D Loss: 0.19298742711544037, G Loss: 4.957470893859863\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5920/100000, D Loss: 0.189936563372612, G Loss: 5.172825336456299\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5921/100000, D Loss: 0.20766982436180115, G Loss: 5.0558390617370605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5922/100000, D Loss: 0.18197990953922272, G Loss: 5.0675048828125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5923/100000, D Loss: 0.24695412814617157, G Loss: 4.932109355926514\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5924/100000, D Loss: 0.2404172718524933, G Loss: 4.803310871124268\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5925/100000, D Loss: 0.19404301792383194, G Loss: 4.951485633850098\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5926/100000, D Loss: 0.19800881296396255, G Loss: 5.090565204620361\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5927/100000, D Loss: 0.1819172352552414, G Loss: 5.019455909729004\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5928/100000, D Loss: 0.17066308110952377, G Loss: 5.027713298797607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5929/100000, D Loss: 0.1657031923532486, G Loss: 5.254327774047852\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5930/100000, D Loss: 0.163316048681736, G Loss: 5.46436882019043\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5931/100000, D Loss: 0.11334569379687309, G Loss: 5.332714080810547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5932/100000, D Loss: 0.14549852907657623, G Loss: 5.26862096786499\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5933/100000, D Loss: 0.16852784156799316, G Loss: 4.970325946807861\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5934/100000, D Loss: 0.1427372321486473, G Loss: 5.198266983032227\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5935/100000, D Loss: 0.1586223840713501, G Loss: 5.265885353088379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5936/100000, D Loss: 0.16032244265079498, G Loss: 5.066956520080566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5937/100000, D Loss: 0.1602313220500946, G Loss: 4.968692779541016\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5938/100000, D Loss: 0.12357258796691895, G Loss: 5.2288360595703125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5939/100000, D Loss: 0.15793771296739578, G Loss: 5.224623680114746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5940/100000, D Loss: 0.13693473860621452, G Loss: 4.856185436248779\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5941/100000, D Loss: 0.1395084634423256, G Loss: 4.71647834777832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5942/100000, D Loss: 0.15505066514015198, G Loss: 4.889614105224609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5943/100000, D Loss: 0.1274746209383011, G Loss: 5.513373374938965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5944/100000, D Loss: 0.14714762195944786, G Loss: 5.404839515686035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5945/100000, D Loss: 0.1487913355231285, G Loss: 4.700156211853027\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5946/100000, D Loss: 0.16566017270088196, G Loss: 4.776597499847412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5947/100000, D Loss: 0.13884544372558594, G Loss: 5.4969329833984375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5948/100000, D Loss: 0.13912305980920792, G Loss: 5.464852333068848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5949/100000, D Loss: 0.1900435909628868, G Loss: 4.940159797668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5950/100000, D Loss: 0.16449852287769318, G Loss: 4.632676601409912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5951/100000, D Loss: 0.1723662167787552, G Loss: 5.273922443389893\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5952/100000, D Loss: 0.15631313249468803, G Loss: 5.528923988342285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5953/100000, D Loss: 0.20991045236587524, G Loss: 4.9157819747924805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5954/100000, D Loss: 0.22825585305690765, G Loss: 4.425539493560791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5955/100000, D Loss: 0.1839936077594757, G Loss: 4.908838272094727\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5956/100000, D Loss: 0.17319399863481522, G Loss: 5.501964569091797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5957/100000, D Loss: 0.20797882974147797, G Loss: 5.0360188484191895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5958/100000, D Loss: 0.233475461602211, G Loss: 4.666835784912109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5959/100000, D Loss: 0.18654462695121765, G Loss: 4.679406642913818\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5960/100000, D Loss: 0.1593027114868164, G Loss: 5.092508316040039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5961/100000, D Loss: 0.22286677360534668, G Loss: 5.01045560836792\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5962/100000, D Loss: 0.17298029363155365, G Loss: 4.864130973815918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5963/100000, D Loss: 0.19665978848934174, G Loss: 4.975491523742676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5964/100000, D Loss: 0.1748020052909851, G Loss: 5.119997024536133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5965/100000, D Loss: 0.17636509239673615, G Loss: 5.152758598327637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5966/100000, D Loss: 0.17911000549793243, G Loss: 4.9733123779296875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5967/100000, D Loss: 0.15535318106412888, G Loss: 4.861352920532227\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5968/100000, D Loss: 0.1544424518942833, G Loss: 5.126150131225586\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5969/100000, D Loss: 0.17689554393291473, G Loss: 4.804491996765137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 5970/100000, D Loss: 0.19139928370714188, G Loss: 4.960670471191406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5971/100000, D Loss: 0.17255927622318268, G Loss: 5.198927879333496\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5972/100000, D Loss: 0.1814158633351326, G Loss: 5.077304840087891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5973/100000, D Loss: 0.15304171293973923, G Loss: 4.8701171875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5974/100000, D Loss: 0.13628315925598145, G Loss: 5.080717086791992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 5975/100000, D Loss: 0.16362373530864716, G Loss: 4.918047904968262\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5976/100000, D Loss: 0.18894989788532257, G Loss: 4.5712056159973145\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5977/100000, D Loss: 0.16021975874900818, G Loss: 5.087869167327881\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5978/100000, D Loss: 0.15177028626203537, G Loss: 4.997320175170898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5979/100000, D Loss: 0.19738369435071945, G Loss: 4.521495342254639\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5980/100000, D Loss: 0.19325244426727295, G Loss: 4.773580074310303\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5981/100000, D Loss: 0.15209275484085083, G Loss: 5.118471145629883\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 5982/100000, D Loss: 0.21621223539113998, G Loss: 4.411238193511963\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 5983/100000, D Loss: 0.20629844814538956, G Loss: 4.290087699890137\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5984/100000, D Loss: 0.18186382949352264, G Loss: 4.867616653442383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5985/100000, D Loss: 0.20701192319393158, G Loss: 4.816826820373535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5986/100000, D Loss: 0.21511871367692947, G Loss: 4.276435375213623\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 5987/100000, D Loss: 0.2147875726222992, G Loss: 4.731346130371094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5988/100000, D Loss: 0.19981543719768524, G Loss: 4.910358428955078\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5989/100000, D Loss: 0.26772769540548325, G Loss: 4.26605224609375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5990/100000, D Loss: 0.2381742000579834, G Loss: 4.496540069580078\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5991/100000, D Loss: 0.201373890042305, G Loss: 4.77812385559082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5992/100000, D Loss: 0.23464074730873108, G Loss: 4.391855716705322\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5993/100000, D Loss: 0.24548743665218353, G Loss: 4.365922927856445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5994/100000, D Loss: 0.2240760326385498, G Loss: 4.778090476989746\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 5995/100000, D Loss: 0.2523116320371628, G Loss: 4.501688480377197\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5996/100000, D Loss: 0.2822108864784241, G Loss: 4.120089530944824\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 5997/100000, D Loss: 0.25813575088977814, G Loss: 4.3362226486206055\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 5998/100000, D Loss: 0.19824456423521042, G Loss: 4.893831253051758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 5999/100000, D Loss: 0.27023746073246, G Loss: 4.358003616333008\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6000/100000, D Loss: 0.28559456765651703, G Loss: 4.1414031982421875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6001/100000, D Loss: 0.23959649354219437, G Loss: 4.668651580810547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6002/100000, D Loss: 0.25152692943811417, G Loss: 4.566005706787109\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6003/100000, D Loss: 0.28399691730737686, G Loss: 3.9940006732940674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6004/100000, D Loss: 0.30324992537498474, G Loss: 3.975874185562134\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6005/100000, D Loss: 0.264945887029171, G Loss: 4.505090713500977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6006/100000, D Loss: 0.27660298347473145, G Loss: 4.39849853515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6007/100000, D Loss: 0.327581524848938, G Loss: 4.056192398071289\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6008/100000, D Loss: 0.2621161937713623, G Loss: 4.460638523101807\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6009/100000, D Loss: 0.24581144005060196, G Loss: 4.545859336853027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6010/100000, D Loss: 0.31386661529541016, G Loss: 3.7057156562805176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6011/100000, D Loss: 0.2603791505098343, G Loss: 4.277704238891602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6012/100000, D Loss: 0.2563883811235428, G Loss: 4.715150356292725\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6013/100000, D Loss: 0.24304988980293274, G Loss: 4.243818283081055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6014/100000, D Loss: 0.2748570293188095, G Loss: 3.8019893169403076\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6015/100000, D Loss: 0.23397980630397797, G Loss: 4.3262152671813965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6016/100000, D Loss: 0.21708201617002487, G Loss: 4.771226406097412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6017/100000, D Loss: 0.2154201790690422, G Loss: 4.332489967346191\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6018/100000, D Loss: 0.20144310593605042, G Loss: 4.358798027038574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6019/100000, D Loss: 0.15832939743995667, G Loss: 4.898319244384766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6020/100000, D Loss: 0.1749369278550148, G Loss: 4.733646869659424\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6021/100000, D Loss: 0.1997462511062622, G Loss: 4.276766300201416\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6022/100000, D Loss: 0.1646115630865097, G Loss: 4.824527740478516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6023/100000, D Loss: 0.1477145403623581, G Loss: 5.307600021362305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6024/100000, D Loss: 0.20549148321151733, G Loss: 4.464993476867676\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6025/100000, D Loss: 0.19203084707260132, G Loss: 4.231822967529297\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6026/100000, D Loss: 0.16786647588014603, G Loss: 4.8008317947387695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6027/100000, D Loss: 0.17448798194527626, G Loss: 4.865540981292725\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6028/100000, D Loss: 0.24054008722305298, G Loss: 4.124109268188477\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6029/100000, D Loss: 0.21965083479881287, G Loss: 4.142196178436279\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6030/100000, D Loss: 0.18210449069738388, G Loss: 4.531102657318115\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6031/100000, D Loss: 0.22175809741020203, G Loss: 4.3990583419799805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6032/100000, D Loss: 0.246366485953331, G Loss: 4.003115653991699\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6033/100000, D Loss: 0.24505114555358887, G Loss: 4.27298641204834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6034/100000, D Loss: 0.2619999349117279, G Loss: 4.228189945220947\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6035/100000, D Loss: 0.29424695670604706, G Loss: 4.02064847946167\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6036/100000, D Loss: 0.2593945413827896, G Loss: 4.192797660827637\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6037/100000, D Loss: 0.27638906240463257, G Loss: 4.341084957122803\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6038/100000, D Loss: 0.3588469475507736, G Loss: 4.152404308319092\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6039/100000, D Loss: 0.3513825982809067, G Loss: 3.8652477264404297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6040/100000, D Loss: 0.29760435223579407, G Loss: 4.2124223709106445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6041/100000, D Loss: 0.2709023952484131, G Loss: 4.404058933258057\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6042/100000, D Loss: 0.2985031306743622, G Loss: 4.057994842529297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6043/100000, D Loss: 0.277026891708374, G Loss: 4.043410301208496\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6044/100000, D Loss: 0.235014408826828, G Loss: 4.403735160827637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6045/100000, D Loss: 0.2971339300274849, G Loss: 4.01140022277832\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6046/100000, D Loss: 0.25880444049835205, G Loss: 4.16224479675293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6047/100000, D Loss: 0.24094805121421814, G Loss: 4.3642168045043945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6048/100000, D Loss: 0.238606795668602, G Loss: 4.497424125671387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6049/100000, D Loss: 0.2803911864757538, G Loss: 3.8630661964416504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6050/100000, D Loss: 0.2586444243788719, G Loss: 4.135241508483887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6051/100000, D Loss: 0.20613808929920197, G Loss: 4.374779224395752\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6052/100000, D Loss: 0.2726197987794876, G Loss: 4.240664958953857\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6053/100000, D Loss: 0.21830570697784424, G Loss: 4.061502933502197\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6054/100000, D Loss: 0.2199556827545166, G Loss: 4.299670219421387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6055/100000, D Loss: 0.20683980733156204, G Loss: 4.284689903259277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6056/100000, D Loss: 0.24089551717042923, G Loss: 4.107623100280762\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6057/100000, D Loss: 0.21457388997077942, G Loss: 4.552326202392578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6058/100000, D Loss: 0.20865285396575928, G Loss: 4.7300944328308105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6059/100000, D Loss: 0.18634933233261108, G Loss: 4.426403522491455\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6060/100000, D Loss: 0.24303144216537476, G Loss: 4.022116661071777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6061/100000, D Loss: 0.21867632865905762, G Loss: 4.693608283996582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6062/100000, D Loss: 0.20711368322372437, G Loss: 4.882224082946777\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6063/100000, D Loss: 0.22202245146036148, G Loss: 4.216054916381836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6064/100000, D Loss: 0.2355002537369728, G Loss: 4.2775750160217285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6065/100000, D Loss: 0.19997192174196243, G Loss: 5.065583229064941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6066/100000, D Loss: 0.21970415860414505, G Loss: 4.70097017288208\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6067/100000, D Loss: 0.24134483933448792, G Loss: 4.389077663421631\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6068/100000, D Loss: 0.20568835735321045, G Loss: 4.88388204574585\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6069/100000, D Loss: 0.19907817244529724, G Loss: 5.1063032150268555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6070/100000, D Loss: 0.20455525815486908, G Loss: 4.725592613220215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6071/100000, D Loss: 0.2129564881324768, G Loss: 4.582742691040039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6072/100000, D Loss: 0.17536920309066772, G Loss: 4.939305305480957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6073/100000, D Loss: 0.2130327895283699, G Loss: 5.049962043762207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6074/100000, D Loss: 0.17948470264673233, G Loss: 4.933826923370361\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6075/100000, D Loss: 0.171917624771595, G Loss: 5.109185695648193\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6076/100000, D Loss: 0.1929088532924652, G Loss: 4.882744789123535\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6077/100000, D Loss: 0.19174794107675552, G Loss: 5.094233512878418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6078/100000, D Loss: 0.20133042335510254, G Loss: 5.13817024230957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6079/100000, D Loss: 0.22334794700145721, G Loss: 4.973737716674805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6080/100000, D Loss: 0.22536171972751617, G Loss: 5.22912073135376\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6081/100000, D Loss: 0.21893547475337982, G Loss: 5.244723320007324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6082/100000, D Loss: 0.22667868435382843, G Loss: 4.913315773010254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6083/100000, D Loss: 0.2243012934923172, G Loss: 4.811361789703369\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6084/100000, D Loss: 0.23138853162527084, G Loss: 5.0328216552734375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6085/100000, D Loss: 0.21803030371665955, G Loss: 4.985352516174316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6086/100000, D Loss: 0.24256472289562225, G Loss: 4.613376617431641\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6087/100000, D Loss: 0.23444639891386032, G Loss: 4.521224021911621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6088/100000, D Loss: 0.23515845090150833, G Loss: 4.949099540710449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6089/100000, D Loss: 0.21167127788066864, G Loss: 5.035564422607422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6090/100000, D Loss: 0.2791707515716553, G Loss: 4.457859992980957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6091/100000, D Loss: 0.24687300622463226, G Loss: 4.829164028167725\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6092/100000, D Loss: 0.19987443834543228, G Loss: 5.2318854331970215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6093/100000, D Loss: 0.201555535197258, G Loss: 4.687777996063232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6094/100000, D Loss: 0.23218399286270142, G Loss: 4.559225082397461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6095/100000, D Loss: 0.19706270098686218, G Loss: 5.29515266418457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6096/100000, D Loss: 0.1896221935749054, G Loss: 5.297819137573242\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6097/100000, D Loss: 0.2181067317724228, G Loss: 4.832798957824707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6098/100000, D Loss: 0.20569949597120285, G Loss: 4.685120582580566\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6099/100000, D Loss: 0.18576259911060333, G Loss: 4.955893516540527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6100/100000, D Loss: 0.15100806206464767, G Loss: 5.336823463439941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6101/100000, D Loss: 0.1495557576417923, G Loss: 5.2305073738098145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6102/100000, D Loss: 0.16302673518657684, G Loss: 4.684636116027832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6103/100000, D Loss: 0.18444303423166275, G Loss: 4.671411514282227\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6104/100000, D Loss: 0.16303714364767075, G Loss: 5.17672872543335\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 6105/100000, D Loss: 0.17347542941570282, G Loss: 5.021815299987793\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6106/100000, D Loss: 0.19846908748149872, G Loss: 4.638228893280029\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6107/100000, D Loss: 0.17424916476011276, G Loss: 5.026671409606934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6108/100000, D Loss: 0.1904202550649643, G Loss: 5.079708576202393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6109/100000, D Loss: 0.1920151263475418, G Loss: 5.012161731719971\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6110/100000, D Loss: 0.2018827646970749, G Loss: 4.737504005432129\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6111/100000, D Loss: 0.17167381942272186, G Loss: 5.069432735443115\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6112/100000, D Loss: 0.21328023821115494, G Loss: 4.846549034118652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6113/100000, D Loss: 0.16940242052078247, G Loss: 4.8347392082214355\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6114/100000, D Loss: 0.17799429595470428, G Loss: 4.970302104949951\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6115/100000, D Loss: 0.18128080666065216, G Loss: 5.270052433013916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6116/100000, D Loss: 0.19475695490837097, G Loss: 5.232343673706055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6117/100000, D Loss: 0.1747359335422516, G Loss: 4.875367641448975\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6118/100000, D Loss: 0.22884730994701385, G Loss: 4.94565486907959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6119/100000, D Loss: 0.188923642039299, G Loss: 5.497567176818848\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6120/100000, D Loss: 0.194516621530056, G Loss: 5.507300853729248\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6121/100000, D Loss: 0.22328335046768188, G Loss: 4.89640998840332\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6122/100000, D Loss: 0.23480357229709625, G Loss: 5.234601020812988\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6123/100000, D Loss: 0.199268139898777, G Loss: 6.089289665222168\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6124/100000, D Loss: 0.25244922935962677, G Loss: 5.508667945861816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6125/100000, D Loss: 0.2663559764623642, G Loss: 5.046712875366211\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6126/100000, D Loss: 0.2353268787264824, G Loss: 5.636211395263672\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "Epoch 6127/100000, D Loss: 0.2342865988612175, G Loss: 5.946086883544922\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6128/100000, D Loss: 0.25571057200431824, G Loss: 5.2168474197387695\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6129/100000, D Loss: 0.2633603438735008, G Loss: 4.947281837463379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6130/100000, D Loss: 0.20745772123336792, G Loss: 5.567082405090332\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6131/100000, D Loss: 0.27998270094394684, G Loss: 5.38033390045166\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6132/100000, D Loss: 0.24404875934123993, G Loss: 5.362695217132568\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6133/100000, D Loss: 0.25970957428216934, G Loss: 5.3350090980529785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6134/100000, D Loss: 0.2828262448310852, G Loss: 5.306541919708252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6135/100000, D Loss: 0.24225834012031555, G Loss: 5.4653730392456055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6136/100000, D Loss: 0.25966382026672363, G Loss: 5.481623649597168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6137/100000, D Loss: 0.19354869425296783, G Loss: 5.898739814758301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6138/100000, D Loss: 0.18113106489181519, G Loss: 5.553074836730957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6139/100000, D Loss: 0.16041886061429977, G Loss: 5.485703468322754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6140/100000, D Loss: 0.1735275760293007, G Loss: 5.5390520095825195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6141/100000, D Loss: 0.1391768679022789, G Loss: 5.645204544067383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6142/100000, D Loss: 0.13031313568353653, G Loss: 5.886590957641602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6143/100000, D Loss: 0.1476127654314041, G Loss: 5.725085258483887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6144/100000, D Loss: 0.1324383094906807, G Loss: 5.452299118041992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6145/100000, D Loss: 0.14820677042007446, G Loss: 5.349219799041748\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6146/100000, D Loss: 0.13540318608283997, G Loss: 5.619222164154053\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6147/100000, D Loss: 0.14875483512878418, G Loss: 5.80659294128418\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6148/100000, D Loss: 0.1431712657213211, G Loss: 5.697315216064453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6149/100000, D Loss: 0.1582769677042961, G Loss: 5.387757301330566\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6150/100000, D Loss: 0.16264578700065613, G Loss: 5.452136039733887\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6151/100000, D Loss: 0.18663597851991653, G Loss: 5.004645347595215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6152/100000, D Loss: 0.20398156344890594, G Loss: 4.8146653175354\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6153/100000, D Loss: 0.19137991219758987, G Loss: 5.090576171875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6154/100000, D Loss: 0.18823134154081345, G Loss: 5.111124038696289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6155/100000, D Loss: 0.22156956046819687, G Loss: 4.830772399902344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6156/100000, D Loss: 0.23294613510370255, G Loss: 4.566217422485352\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6157/100000, D Loss: 0.2250409796833992, G Loss: 4.940431594848633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6158/100000, D Loss: 0.23801599442958832, G Loss: 4.671414375305176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6159/100000, D Loss: 0.21036356687545776, G Loss: 4.465513706207275\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6160/100000, D Loss: 0.22410735487937927, G Loss: 4.482341766357422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6161/100000, D Loss: 0.2898883521556854, G Loss: 4.5848212242126465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6162/100000, D Loss: 0.2611180543899536, G Loss: 4.559959411621094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6163/100000, D Loss: 0.33301711082458496, G Loss: 4.240124702453613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6164/100000, D Loss: 0.2985815554857254, G Loss: 4.480832576751709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6165/100000, D Loss: 0.31333211064338684, G Loss: 4.386394500732422\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6166/100000, D Loss: 0.3109687566757202, G Loss: 4.520462989807129\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6167/100000, D Loss: 0.27180736511945724, G Loss: 4.360868453979492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6168/100000, D Loss: 0.32561343908309937, G Loss: 4.098982810974121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6169/100000, D Loss: 0.30680394172668457, G Loss: 4.288276195526123\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6170/100000, D Loss: 0.25243546813726425, G Loss: 4.46942663192749\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6171/100000, D Loss: 0.2740680128335953, G Loss: 4.804811477661133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6172/100000, D Loss: 0.2990652024745941, G Loss: 4.467429161071777\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6173/100000, D Loss: 0.27284738421440125, G Loss: 4.189976215362549\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6174/100000, D Loss: 0.22911354899406433, G Loss: 4.6014838218688965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6175/100000, D Loss: 0.23014673590660095, G Loss: 4.592112064361572\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6176/100000, D Loss: 0.2064661905169487, G Loss: 4.632162570953369\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6177/100000, D Loss: 0.19729681313037872, G Loss: 4.530897617340088\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6178/100000, D Loss: 0.18918564170598984, G Loss: 4.941869258880615\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6179/100000, D Loss: 0.1918695792555809, G Loss: 4.935413837432861\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6180/100000, D Loss: 0.17867328971624374, G Loss: 4.617574214935303\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6181/100000, D Loss: 0.15985067188739777, G Loss: 4.672030448913574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6182/100000, D Loss: 0.16599398106336594, G Loss: 4.9086012840271\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6183/100000, D Loss: 0.14433062076568604, G Loss: 5.145279884338379\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6184/100000, D Loss: 0.1468166448175907, G Loss: 4.950234413146973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6185/100000, D Loss: 0.15438340604305267, G Loss: 4.926082134246826\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6186/100000, D Loss: 0.14051882922649384, G Loss: 4.805644989013672\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6187/100000, D Loss: 0.1714150607585907, G Loss: 4.791819095611572\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6188/100000, D Loss: 0.16025685518980026, G Loss: 4.818457126617432\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6189/100000, D Loss: 0.18914348632097244, G Loss: 4.755139350891113\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6190/100000, D Loss: 0.1728036254644394, G Loss: 4.844494819641113\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6191/100000, D Loss: 0.19377101212739944, G Loss: 4.823671817779541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6192/100000, D Loss: 0.20446817576885223, G Loss: 4.348872184753418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6193/100000, D Loss: 0.18343861401081085, G Loss: 4.616953372955322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6194/100000, D Loss: 0.18239830434322357, G Loss: 4.860269546508789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6195/100000, D Loss: 0.16632185876369476, G Loss: 4.975323677062988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6196/100000, D Loss: 0.22387242317199707, G Loss: 4.456904411315918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6197/100000, D Loss: 0.1861795410513878, G Loss: 4.911418914794922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6198/100000, D Loss: 0.15937089174985886, G Loss: 5.249564170837402\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6199/100000, D Loss: 0.22061553597450256, G Loss: 4.4727888107299805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6200/100000, D Loss: 0.20835503190755844, G Loss: 4.391691207885742\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6201/100000, D Loss: 0.17479213327169418, G Loss: 5.361630916595459\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6202/100000, D Loss: 0.20015612617135048, G Loss: 5.156886577606201\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6203/100000, D Loss: 0.23266685009002686, G Loss: 4.363253593444824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6204/100000, D Loss: 0.18951039016246796, G Loss: 4.678912162780762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6205/100000, D Loss: 0.14798900857567787, G Loss: 5.15395450592041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6206/100000, D Loss: 0.1613297164440155, G Loss: 5.037077903747559\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6207/100000, D Loss: 0.2058914750814438, G Loss: 4.521135330200195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6208/100000, D Loss: 0.19434680044651031, G Loss: 4.955180644989014\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6209/100000, D Loss: 0.15737741440534592, G Loss: 5.124659061431885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6210/100000, D Loss: 0.1754118949174881, G Loss: 4.593729019165039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6211/100000, D Loss: 0.21388623863458633, G Loss: 4.526416778564453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6212/100000, D Loss: 0.16609099507331848, G Loss: 4.674481391906738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6213/100000, D Loss: 0.19925622642040253, G Loss: 4.656244277954102\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6214/100000, D Loss: 0.19251607358455658, G Loss: 4.575716972351074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6215/100000, D Loss: 0.18680383265018463, G Loss: 4.8027777671813965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6216/100000, D Loss: 0.19762904942035675, G Loss: 4.937934875488281\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6217/100000, D Loss: 0.2220076471567154, G Loss: 4.441287994384766\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6218/100000, D Loss: 0.21773867309093475, G Loss: 4.311389446258545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6219/100000, D Loss: 0.21156196296215057, G Loss: 4.227249622344971\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6220/100000, D Loss: 0.2607613429427147, G Loss: 4.2587714195251465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6221/100000, D Loss: 0.2896876856684685, G Loss: 4.081842422485352\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6222/100000, D Loss: 0.3221745789051056, G Loss: 3.7544360160827637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6223/100000, D Loss: 0.3499010503292084, G Loss: 4.032063961029053\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6224/100000, D Loss: 0.27522506564855576, G Loss: 4.534587383270264\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6225/100000, D Loss: 0.3467808812856674, G Loss: 3.880362033843994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6226/100000, D Loss: 0.36776313185691833, G Loss: 3.986837148666382\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6227/100000, D Loss: 0.3433925658464432, G Loss: 4.151318073272705\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6228/100000, D Loss: 0.37738654017448425, G Loss: 3.774526357650757\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6229/100000, D Loss: 0.3889326751232147, G Loss: 3.6183459758758545\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6230/100000, D Loss: 0.28337429463863373, G Loss: 4.416106224060059\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6231/100000, D Loss: 0.3148365020751953, G Loss: 3.863842487335205\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6232/100000, D Loss: 0.3402832895517349, G Loss: 3.6905412673950195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6233/100000, D Loss: 0.3050491362810135, G Loss: 4.300346374511719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6234/100000, D Loss: 0.27233852446079254, G Loss: 4.380664825439453\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6235/100000, D Loss: 0.272295244038105, G Loss: 4.132962226867676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6236/100000, D Loss: 0.26999180763959885, G Loss: 4.113990783691406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6237/100000, D Loss: 0.22879472374916077, G Loss: 4.2640180587768555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6238/100000, D Loss: 0.22995150089263916, G Loss: 4.2832183837890625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6239/100000, D Loss: 0.2118656039237976, G Loss: 4.563070297241211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6240/100000, D Loss: 0.1837848722934723, G Loss: 4.338561058044434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6241/100000, D Loss: 0.20689738541841507, G Loss: 3.931428909301758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6242/100000, D Loss: 0.17368287593126297, G Loss: 4.520987510681152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6243/100000, D Loss: 0.155280202627182, G Loss: 4.706817150115967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6244/100000, D Loss: 0.16032643616199493, G Loss: 4.277308464050293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6245/100000, D Loss: 0.17655853927135468, G Loss: 4.15891170501709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6246/100000, D Loss: 0.16086912155151367, G Loss: 4.410653114318848\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6247/100000, D Loss: 0.144122626632452, G Loss: 4.722752571105957\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6248/100000, D Loss: 0.1765391230583191, G Loss: 4.3438401222229\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6249/100000, D Loss: 0.1731824353337288, G Loss: 4.096687316894531\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6250/100000, D Loss: 0.1413556933403015, G Loss: 4.602264404296875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6251/100000, D Loss: 0.1315687745809555, G Loss: 4.7310791015625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6252/100000, D Loss: 0.16258249804377556, G Loss: 4.2144775390625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6253/100000, D Loss: 0.21017443388700485, G Loss: 3.8598670959472656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6254/100000, D Loss: 0.1580599546432495, G Loss: 4.555241107940674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6255/100000, D Loss: 0.1777670457959175, G Loss: 4.692347526550293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6256/100000, D Loss: 0.2381715178489685, G Loss: 4.001338005065918\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6257/100000, D Loss: 0.2339271381497383, G Loss: 3.902198314666748\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6258/100000, D Loss: 0.21422312408685684, G Loss: 4.405433177947998\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6259/100000, D Loss: 0.21293698996305466, G Loss: 4.465847492218018\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6260/100000, D Loss: 0.28080321848392487, G Loss: 3.767271041870117\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6261/100000, D Loss: 0.27390412986278534, G Loss: 3.7915916442871094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6262/100000, D Loss: 0.2208351194858551, G Loss: 4.49041748046875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6263/100000, D Loss: 0.2474736124277115, G Loss: 4.353729248046875\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6264/100000, D Loss: 0.2746657431125641, G Loss: 3.6925437450408936\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6265/100000, D Loss: 0.25316401571035385, G Loss: 4.046629428863525\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6266/100000, D Loss: 0.23691260814666748, G Loss: 4.2834577560424805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6267/100000, D Loss: 0.32566653192043304, G Loss: 3.795956611633301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6268/100000, D Loss: 0.28411969542503357, G Loss: 3.990839719772339\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6269/100000, D Loss: 0.31536467373371124, G Loss: 4.235299110412598\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6270/100000, D Loss: 0.2948789745569229, G Loss: 4.020449161529541\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6271/100000, D Loss: 0.32144807279109955, G Loss: 3.924593448638916\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6272/100000, D Loss: 0.26349741965532303, G Loss: 4.178770542144775\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6273/100000, D Loss: 0.334681399166584, G Loss: 3.759540319442749\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6274/100000, D Loss: 0.2967699468135834, G Loss: 3.901432991027832\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6275/100000, D Loss: 0.2797218859195709, G Loss: 4.332728385925293\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6276/100000, D Loss: 0.24843322485685349, G Loss: 4.348170757293701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6277/100000, D Loss: 0.3145419657230377, G Loss: 3.784278631210327\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6278/100000, D Loss: 0.31989434361457825, G Loss: 3.579293966293335\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6279/100000, D Loss: 0.2349374145269394, G Loss: 4.39826774597168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6280/100000, D Loss: 0.2760442793369293, G Loss: 3.9238784313201904\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6281/100000, D Loss: 0.26836663484573364, G Loss: 3.7653279304504395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6282/100000, D Loss: 0.18551792204380035, G Loss: 4.268161773681641\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6283/100000, D Loss: 0.1856975555419922, G Loss: 4.423152446746826\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6284/100000, D Loss: 0.1911812648177147, G Loss: 4.116101264953613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6285/100000, D Loss: 0.1886265128850937, G Loss: 3.9394936561584473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6286/100000, D Loss: 0.14803840965032578, G Loss: 4.3312482833862305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6287/100000, D Loss: 0.13432402908802032, G Loss: 4.665676593780518\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6288/100000, D Loss: 0.14092852547764778, G Loss: 4.625972747802734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6289/100000, D Loss: 0.14075439050793648, G Loss: 4.3528032302856445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6290/100000, D Loss: 0.15897352993488312, G Loss: 4.2812042236328125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6291/100000, D Loss: 0.12714502215385437, G Loss: 4.596095085144043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6292/100000, D Loss: 0.11633610725402832, G Loss: 4.707710266113281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6293/100000, D Loss: 0.15346947312355042, G Loss: 4.653040885925293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6294/100000, D Loss: 0.1461772844195366, G Loss: 4.381278038024902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6295/100000, D Loss: 0.14249975234270096, G Loss: 4.4108686447143555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6296/100000, D Loss: 0.1463208645582199, G Loss: 4.46508264541626\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6297/100000, D Loss: 0.12844721227884293, G Loss: 4.483597278594971\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6298/100000, D Loss: 0.1768932342529297, G Loss: 4.243995666503906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6299/100000, D Loss: 0.18073242902755737, G Loss: 4.420456886291504\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6300/100000, D Loss: 0.18736953288316727, G Loss: 4.702267646789551\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6301/100000, D Loss: 0.2239776998758316, G Loss: 4.29301643371582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6302/100000, D Loss: 0.17980340868234634, G Loss: 4.174699783325195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6303/100000, D Loss: 0.19718009233474731, G Loss: 4.257740020751953\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6304/100000, D Loss: 0.23128706216812134, G Loss: 4.471488952636719\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6305/100000, D Loss: 0.22719058394432068, G Loss: 4.438809394836426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6306/100000, D Loss: 0.24468883126974106, G Loss: 4.253932952880859\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6307/100000, D Loss: 0.19683218747377396, G Loss: 4.606795310974121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6308/100000, D Loss: 0.20980007946491241, G Loss: 4.586312294006348\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6309/100000, D Loss: 0.2418612688779831, G Loss: 4.127365589141846\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6310/100000, D Loss: 0.19993183761835098, G Loss: 4.434499263763428\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6311/100000, D Loss: 0.19621504843235016, G Loss: 4.421996116638184\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6312/100000, D Loss: 0.2373545542359352, G Loss: 3.9916129112243652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6313/100000, D Loss: 0.2807285189628601, G Loss: 4.12054967880249\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6314/100000, D Loss: 0.21259703487157822, G Loss: 4.51601505279541\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6315/100000, D Loss: 0.2538771852850914, G Loss: 3.909593343734741\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6316/100000, D Loss: 0.3150186985731125, G Loss: 3.7138657569885254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6317/100000, D Loss: 0.30672694742679596, G Loss: 4.056542873382568\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6318/100000, D Loss: 0.29629407823085785, G Loss: 4.103015899658203\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6319/100000, D Loss: 0.33600735664367676, G Loss: 3.701725482940674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6320/100000, D Loss: 0.31125451624393463, G Loss: 3.871715545654297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6321/100000, D Loss: 0.3190610259771347, G Loss: 4.095164775848389\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6322/100000, D Loss: 0.33227574825286865, G Loss: 3.85098934173584\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6323/100000, D Loss: 0.30874812602996826, G Loss: 4.163290023803711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6324/100000, D Loss: 0.32959191501140594, G Loss: 4.063295364379883\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6325/100000, D Loss: 0.3274566978216171, G Loss: 3.8290088176727295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6326/100000, D Loss: 0.35609130561351776, G Loss: 3.8774657249450684\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6327/100000, D Loss: 0.2736757770180702, G Loss: 4.320274829864502\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6328/100000, D Loss: 0.26600316911935806, G Loss: 4.236243724822998\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6329/100000, D Loss: 0.2869827300310135, G Loss: 4.00846004486084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6330/100000, D Loss: 0.22894331812858582, G Loss: 4.309752464294434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6331/100000, D Loss: 0.20345379412174225, G Loss: 4.589250087738037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6332/100000, D Loss: 0.2032179906964302, G Loss: 4.683739185333252\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6333/100000, D Loss: 0.20864447951316833, G Loss: 4.386263847351074\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6334/100000, D Loss: 0.17311588674783707, G Loss: 4.798852443695068\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6335/100000, D Loss: 0.1627371609210968, G Loss: 5.058417320251465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6336/100000, D Loss: 0.19311371445655823, G Loss: 4.366908550262451\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6337/100000, D Loss: 0.17343153804540634, G Loss: 4.450901031494141\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6338/100000, D Loss: 0.15482081472873688, G Loss: 4.8105621337890625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6339/100000, D Loss: 0.13378184288740158, G Loss: 5.0121989250183105\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6340/100000, D Loss: 0.14847318828105927, G Loss: 4.695318698883057\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6341/100000, D Loss: 0.14850208163261414, G Loss: 4.653823375701904\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6342/100000, D Loss: 0.1599697694182396, G Loss: 5.02971076965332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6343/100000, D Loss: 0.10502134263515472, G Loss: 5.418062210083008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6344/100000, D Loss: 0.1423470377922058, G Loss: 4.9236955642700195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6345/100000, D Loss: 0.15261580795049667, G Loss: 4.308405876159668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6346/100000, D Loss: 0.15536999702453613, G Loss: 4.45755672454834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6347/100000, D Loss: 0.1258586272597313, G Loss: 5.060743808746338\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6348/100000, D Loss: 0.12897715345025063, G Loss: 4.918414115905762\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6349/100000, D Loss: 0.12874041497707367, G Loss: 4.595817565917969\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6350/100000, D Loss: 0.12769660726189613, G Loss: 4.598248481750488\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6351/100000, D Loss: 0.11857753619551659, G Loss: 4.73441219329834\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6352/100000, D Loss: 0.13791333884000778, G Loss: 4.736455917358398\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6353/100000, D Loss: 0.13075125962495804, G Loss: 4.833581447601318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6354/100000, D Loss: 0.1485305279493332, G Loss: 4.700359344482422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6355/100000, D Loss: 0.15114090591669083, G Loss: 4.554685592651367\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6356/100000, D Loss: 0.1772587150335312, G Loss: 4.466906547546387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6357/100000, D Loss: 0.17474952340126038, G Loss: 4.53475284576416\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6358/100000, D Loss: 0.18442486226558685, G Loss: 4.2303571701049805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6359/100000, D Loss: 0.217605859041214, G Loss: 4.300580024719238\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6360/100000, D Loss: 0.17975743860006332, G Loss: 4.582163333892822\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6361/100000, D Loss: 0.21016251295804977, G Loss: 4.4382429122924805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6362/100000, D Loss: 0.23246090859174728, G Loss: 4.3066205978393555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6363/100000, D Loss: 0.23294781893491745, G Loss: 4.1938862800598145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6364/100000, D Loss: 0.18546855449676514, G Loss: 4.427155494689941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6365/100000, D Loss: 0.2675049602985382, G Loss: 4.112165927886963\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6366/100000, D Loss: 0.2543255314230919, G Loss: 4.244863510131836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6367/100000, D Loss: 0.21381241083145142, G Loss: 4.52568244934082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6368/100000, D Loss: 0.2660493850708008, G Loss: 4.006021499633789\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6369/100000, D Loss: 0.28670288622379303, G Loss: 4.209638595581055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6370/100000, D Loss: 0.22180526703596115, G Loss: 4.542007923126221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6371/100000, D Loss: 0.27093505859375, G Loss: 4.172293663024902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6372/100000, D Loss: 0.26434358954429626, G Loss: 3.970381736755371\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6373/100000, D Loss: 0.2096318081021309, G Loss: 4.389359474182129\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6374/100000, D Loss: 0.2518809139728546, G Loss: 4.260526657104492\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6375/100000, D Loss: 0.22929342091083527, G Loss: 4.0906453132629395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6376/100000, D Loss: 0.18542595207691193, G Loss: 4.530177116394043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6377/100000, D Loss: 0.18876101076602936, G Loss: 4.464827537536621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6378/100000, D Loss: 0.18999997526407242, G Loss: 4.473731994628906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6379/100000, D Loss: 0.16647909581661224, G Loss: 4.474506378173828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6380/100000, D Loss: 0.1757633239030838, G Loss: 4.357520580291748\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6381/100000, D Loss: 0.15379544347524643, G Loss: 4.456064701080322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6382/100000, D Loss: 0.14199020713567734, G Loss: 4.725711345672607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6383/100000, D Loss: 0.1403678022325039, G Loss: 4.9675164222717285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6384/100000, D Loss: 0.14950575679540634, G Loss: 4.776271820068359\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6385/100000, D Loss: 0.13910603523254395, G Loss: 4.787247180938721\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6386/100000, D Loss: 0.14796415716409683, G Loss: 4.7935404777526855\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6387/100000, D Loss: 0.16290593892335892, G Loss: 4.7109174728393555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6388/100000, D Loss: 0.14870940148830414, G Loss: 4.5962605476379395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6389/100000, D Loss: 0.16680415719747543, G Loss: 4.527070045471191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6390/100000, D Loss: 0.16903238743543625, G Loss: 4.437768936157227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6391/100000, D Loss: 0.19469860941171646, G Loss: 4.7248992919921875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6392/100000, D Loss: 0.18134213984012604, G Loss: 4.703161239624023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6393/100000, D Loss: 0.18906092643737793, G Loss: 4.740621566772461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6394/100000, D Loss: 0.19943232834339142, G Loss: 4.768122673034668\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6395/100000, D Loss: 0.1955912485718727, G Loss: 4.424861907958984\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6396/100000, D Loss: 0.2121170163154602, G Loss: 4.539273262023926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6397/100000, D Loss: 0.19067592173814774, G Loss: 4.800286293029785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6398/100000, D Loss: 0.23235242813825607, G Loss: 4.593112945556641\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6399/100000, D Loss: 0.20843295007944107, G Loss: 4.66712760925293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6400/100000, D Loss: 0.2382316291332245, G Loss: 4.659267425537109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6401/100000, D Loss: 0.19123877584934235, G Loss: 4.916749477386475\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6402/100000, D Loss: 0.24227696657180786, G Loss: 4.515204429626465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6403/100000, D Loss: 0.21206354349851608, G Loss: 4.707416534423828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6404/100000, D Loss: 0.19103074818849564, G Loss: 4.934508323669434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6405/100000, D Loss: 0.20328184217214584, G Loss: 4.859247207641602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6406/100000, D Loss: 0.2021823599934578, G Loss: 4.74854850769043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6407/100000, D Loss: 0.2143169716000557, G Loss: 4.715976715087891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6408/100000, D Loss: 0.1832270324230194, G Loss: 4.839240550994873\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6409/100000, D Loss: 0.18457980453968048, G Loss: 4.925695896148682\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6410/100000, D Loss: 0.15591546893119812, G Loss: 4.807444095611572\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6411/100000, D Loss: 0.18584062159061432, G Loss: 4.886826038360596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6412/100000, D Loss: 0.18056116998195648, G Loss: 4.771416187286377\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6413/100000, D Loss: 0.14348874241113663, G Loss: 5.181977272033691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6414/100000, D Loss: 0.1310349814593792, G Loss: 5.213525772094727\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6415/100000, D Loss: 0.13518024235963821, G Loss: 5.12152099609375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6416/100000, D Loss: 0.1523008495569229, G Loss: 4.75338077545166\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6417/100000, D Loss: 0.1576085239648819, G Loss: 5.061744689941406\n",
      "32/32 [==============================] - 0s 11ms/step\n",
      "Epoch 6418/100000, D Loss: 0.11674537137150764, G Loss: 5.4377522468566895\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6419/100000, D Loss: 0.12527434155344963, G Loss: 5.231280326843262\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6420/100000, D Loss: 0.1215384192764759, G Loss: 4.97409725189209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6421/100000, D Loss: 0.12567750737071037, G Loss: 4.8047261238098145\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6422/100000, D Loss: 0.11535453423857689, G Loss: 5.008876800537109\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6423/100000, D Loss: 0.11923745647072792, G Loss: 5.067853927612305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6424/100000, D Loss: 0.10036913305521011, G Loss: 5.174410820007324\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6425/100000, D Loss: 0.12151535227894783, G Loss: 4.6748223304748535\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6426/100000, D Loss: 0.12398732453584671, G Loss: 5.122418403625488\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6427/100000, D Loss: 0.09852873533964157, G Loss: 5.306353569030762\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 6428/100000, D Loss: 0.12297976762056351, G Loss: 5.08372688293457\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6429/100000, D Loss: 0.1176551878452301, G Loss: 4.7851691246032715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6430/100000, D Loss: 0.12990987300872803, G Loss: 4.844540596008301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6431/100000, D Loss: 0.1436469927430153, G Loss: 5.132246971130371\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6432/100000, D Loss: 0.12770268321037292, G Loss: 5.216932773590088\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6433/100000, D Loss: 0.17795205116271973, G Loss: 4.7876482009887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6434/100000, D Loss: 0.1685456931591034, G Loss: 4.892765045166016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6435/100000, D Loss: 0.15737871825695038, G Loss: 4.92170524597168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6436/100000, D Loss: 0.17442567646503448, G Loss: 5.004644393920898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6437/100000, D Loss: 0.17811669409275055, G Loss: 4.750453948974609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6438/100000, D Loss: 0.2103935331106186, G Loss: 4.696847438812256\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6439/100000, D Loss: 0.21322817355394363, G Loss: 4.743748664855957\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6440/100000, D Loss: 0.18746024370193481, G Loss: 5.037210464477539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6441/100000, D Loss: 0.21818189322948456, G Loss: 4.9136762619018555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6442/100000, D Loss: 0.22727235406637192, G Loss: 4.872879505157471\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6443/100000, D Loss: 0.22856315970420837, G Loss: 4.902933120727539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6444/100000, D Loss: 0.234762541949749, G Loss: 5.111428260803223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6445/100000, D Loss: 0.25667157769203186, G Loss: 4.604026794433594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6446/100000, D Loss: 0.22174230217933655, G Loss: 5.107548713684082\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6447/100000, D Loss: 0.23183012008666992, G Loss: 5.317722320556641\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6448/100000, D Loss: 0.2745400071144104, G Loss: 4.874526023864746\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 6449/100000, D Loss: 0.25848983973264694, G Loss: 4.900315284729004\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6450/100000, D Loss: 0.2139185070991516, G Loss: 5.128041744232178\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6451/100000, D Loss: 0.28734801709651947, G Loss: 4.94956111907959\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6452/100000, D Loss: 0.2502581924200058, G Loss: 5.264352798461914\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6453/100000, D Loss: 0.23033495247364044, G Loss: 5.313539028167725\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6454/100000, D Loss: 0.2515784204006195, G Loss: 4.743747711181641\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6455/100000, D Loss: 0.22204216569662094, G Loss: 4.743263244628906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6456/100000, D Loss: 0.20936761796474457, G Loss: 5.1991376876831055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6457/100000, D Loss: 0.20207179337739944, G Loss: 5.396324157714844\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6458/100000, D Loss: 0.22764912247657776, G Loss: 4.846592426300049\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6459/100000, D Loss: 0.1810348778963089, G Loss: 4.741583824157715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6460/100000, D Loss: 0.18639686703681946, G Loss: 5.142003059387207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6461/100000, D Loss: 0.15931617468595505, G Loss: 5.363600730895996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6462/100000, D Loss: 0.18203246593475342, G Loss: 5.02116584777832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6463/100000, D Loss: 0.1725025549530983, G Loss: 4.82961368560791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6464/100000, D Loss: 0.15457818657159805, G Loss: 5.096938133239746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6465/100000, D Loss: 0.18610725551843643, G Loss: 5.064554214477539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6466/100000, D Loss: 0.14999253302812576, G Loss: 4.984158039093018\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6467/100000, D Loss: 0.15023910999298096, G Loss: 4.871567249298096\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6468/100000, D Loss: 0.18344790488481522, G Loss: 4.703725814819336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6469/100000, D Loss: 0.16119830310344696, G Loss: 4.928285598754883\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6470/100000, D Loss: 0.15055925771594048, G Loss: 4.9364013671875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6471/100000, D Loss: 0.1795487254858017, G Loss: 4.522988319396973\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6472/100000, D Loss: 0.19522792845964432, G Loss: 4.480316162109375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6473/100000, D Loss: 0.1623631715774536, G Loss: 4.886419296264648\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6474/100000, D Loss: 0.18314655870199203, G Loss: 4.979260444641113\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6475/100000, D Loss: 0.16123229265213013, G Loss: 4.671477794647217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6476/100000, D Loss: 0.20200280100107193, G Loss: 4.3956499099731445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6477/100000, D Loss: 0.17681895941495895, G Loss: 4.608037948608398\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6478/100000, D Loss: 0.15698587149381638, G Loss: 4.645327091217041\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6479/100000, D Loss: 0.1845095157623291, G Loss: 4.577085494995117\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6480/100000, D Loss: 0.2031267210841179, G Loss: 4.422746658325195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6481/100000, D Loss: 0.20189619809389114, G Loss: 4.418164253234863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6482/100000, D Loss: 0.16403307020664215, G Loss: 4.733073711395264\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6483/100000, D Loss: 0.18590163439512253, G Loss: 4.460522651672363\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6484/100000, D Loss: 0.18733488768339157, G Loss: 4.115964412689209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6485/100000, D Loss: 0.18288570642471313, G Loss: 4.389591217041016\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6486/100000, D Loss: 0.14329485595226288, G Loss: 4.825071334838867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6487/100000, D Loss: 0.21984951198101044, G Loss: 4.056893825531006\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6488/100000, D Loss: 0.19715570658445358, G Loss: 3.871835708618164\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6489/100000, D Loss: 0.1991359442472458, G Loss: 4.319520950317383\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6490/100000, D Loss: 0.20768144726753235, G Loss: 4.452761650085449\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6491/100000, D Loss: 0.221017524600029, G Loss: 4.146533012390137\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6492/100000, D Loss: 0.20267769694328308, G Loss: 4.293181419372559\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6493/100000, D Loss: 0.23166106641292572, G Loss: 4.325053691864014\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6494/100000, D Loss: 0.2607945576310158, G Loss: 4.088578701019287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6495/100000, D Loss: 0.266773521900177, G Loss: 4.464852809906006\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6496/100000, D Loss: 0.26195141673088074, G Loss: 4.307162284851074\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6497/100000, D Loss: 0.238593690097332, G Loss: 4.175910949707031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6498/100000, D Loss: 0.2690160423517227, G Loss: 4.287873268127441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6499/100000, D Loss: 0.24673031270503998, G Loss: 4.475313186645508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6500/100000, D Loss: 0.2680415213108063, G Loss: 4.453903675079346\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6501/100000, D Loss: 0.24993494153022766, G Loss: 4.4136152267456055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6502/100000, D Loss: 0.22093796730041504, G Loss: 4.349816799163818\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6503/100000, D Loss: 0.24471884965896606, G Loss: 4.493446350097656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6504/100000, D Loss: 0.22394917905330658, G Loss: 4.726736068725586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6505/100000, D Loss: 0.2672101706266403, G Loss: 4.659915924072266\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6506/100000, D Loss: 0.20896855741739273, G Loss: 4.687860488891602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6507/100000, D Loss: 0.22874192148447037, G Loss: 4.709927082061768\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6508/100000, D Loss: 0.24514023214578629, G Loss: 4.882607460021973\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6509/100000, D Loss: 0.2660503685474396, G Loss: 4.9190263748168945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6510/100000, D Loss: 0.233462892472744, G Loss: 4.902822494506836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6511/100000, D Loss: 0.23414425551891327, G Loss: 4.953798770904541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6512/100000, D Loss: 0.241620734333992, G Loss: 5.174835205078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6513/100000, D Loss: 0.2655259296298027, G Loss: 4.738472938537598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6514/100000, D Loss: 0.27842479944229126, G Loss: 4.952423095703125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6515/100000, D Loss: 0.29326796531677246, G Loss: 5.242995738983154\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6516/100000, D Loss: 0.24699880182743073, G Loss: 5.345009803771973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6517/100000, D Loss: 0.2724434584379196, G Loss: 4.876928329467773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6518/100000, D Loss: 0.3135688602924347, G Loss: 4.7375688552856445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6519/100000, D Loss: 0.27125126123428345, G Loss: 5.47298526763916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6520/100000, D Loss: 0.23026806861162186, G Loss: 5.548252582550049\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6521/100000, D Loss: 0.27644000947475433, G Loss: 4.698174953460693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6522/100000, D Loss: 0.2222406268119812, G Loss: 4.442300796508789\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6523/100000, D Loss: 0.21653582155704498, G Loss: 4.797237873077393\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6524/100000, D Loss: 0.20310012251138687, G Loss: 5.226530075073242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6525/100000, D Loss: 0.17137886583805084, G Loss: 5.073614120483398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6526/100000, D Loss: 0.20414899289608002, G Loss: 4.74594783782959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6527/100000, D Loss: 0.16575530171394348, G Loss: 4.701536655426025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6528/100000, D Loss: 0.17031657695770264, G Loss: 4.842364311218262\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6529/100000, D Loss: 0.14770133793354034, G Loss: 5.024890899658203\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6530/100000, D Loss: 0.16174251586198807, G Loss: 5.095966339111328\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6531/100000, D Loss: 0.1432739645242691, G Loss: 4.70213508605957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6532/100000, D Loss: 0.16237721592187881, G Loss: 4.635734558105469\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6533/100000, D Loss: 0.18246781826019287, G Loss: 4.597869873046875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6534/100000, D Loss: 0.17391341924667358, G Loss: 4.715288162231445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6535/100000, D Loss: 0.16031859815120697, G Loss: 5.040281295776367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6536/100000, D Loss: 0.16808124631643295, G Loss: 4.74440860748291\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6537/100000, D Loss: 0.16101136803627014, G Loss: 4.478415012359619\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6538/100000, D Loss: 0.19499871879816055, G Loss: 4.366934776306152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6539/100000, D Loss: 0.15771256387233734, G Loss: 4.82166051864624\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6540/100000, D Loss: 0.17112760618329048, G Loss: 4.95783805847168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6541/100000, D Loss: 0.1746329739689827, G Loss: 4.3264241218566895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6542/100000, D Loss: 0.17119452357292175, G Loss: 4.1796159744262695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6543/100000, D Loss: 0.17944253981113434, G Loss: 4.833152770996094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6544/100000, D Loss: 0.16220436990261078, G Loss: 5.001918792724609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6545/100000, D Loss: 0.18104364350438118, G Loss: 4.505743026733398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6546/100000, D Loss: 0.18937058746814728, G Loss: 4.480771064758301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6547/100000, D Loss: 0.15524864196777344, G Loss: 4.903021812438965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6548/100000, D Loss: 0.19371122121810913, G Loss: 4.782651424407959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6549/100000, D Loss: 0.169310562312603, G Loss: 4.781292915344238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6550/100000, D Loss: 0.19706018269062042, G Loss: 4.762141227722168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6551/100000, D Loss: 0.17791373282670975, G Loss: 5.076186180114746\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6552/100000, D Loss: 0.18763960152864456, G Loss: 4.695526599884033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6553/100000, D Loss: 0.16258075088262558, G Loss: 4.996344566345215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6554/100000, D Loss: 0.1733686849474907, G Loss: 5.024307727813721\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6555/100000, D Loss: 0.16659096628427505, G Loss: 4.828856945037842\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6556/100000, D Loss: 0.1494763046503067, G Loss: 4.715070724487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6557/100000, D Loss: 0.1654471829533577, G Loss: 4.893807411193848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6558/100000, D Loss: 0.1611102968454361, G Loss: 4.821657180786133\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6559/100000, D Loss: 0.2004273757338524, G Loss: 4.748654842376709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6560/100000, D Loss: 0.25882506370544434, G Loss: 4.652678489685059\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6561/100000, D Loss: 0.18667953461408615, G Loss: 4.708813667297363\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6562/100000, D Loss: 0.22929465770721436, G Loss: 4.832621097564697\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6563/100000, D Loss: 0.23493896424770355, G Loss: 4.438631057739258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6564/100000, D Loss: 0.3119029551744461, G Loss: 4.04698371887207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6565/100000, D Loss: 0.2533099055290222, G Loss: 4.509819984436035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6566/100000, D Loss: 0.3037088140845299, G Loss: 4.4417405128479\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6567/100000, D Loss: 0.3368888646364212, G Loss: 4.032907485961914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6568/100000, D Loss: 0.3220018148422241, G Loss: 4.256059646606445\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6569/100000, D Loss: 0.3059404715895653, G Loss: 4.070610046386719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6570/100000, D Loss: 0.3448297530412674, G Loss: 3.8954086303710938\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6571/100000, D Loss: 0.36031821370124817, G Loss: 4.10134220123291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6572/100000, D Loss: 0.3634769916534424, G Loss: 4.627455711364746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6573/100000, D Loss: 0.38356563448905945, G Loss: 4.506595611572266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6574/100000, D Loss: 0.376256063580513, G Loss: 4.319689750671387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6575/100000, D Loss: 0.36840009689331055, G Loss: 4.4609880447387695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6576/100000, D Loss: 0.36375413835048676, G Loss: 4.610886573791504\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6577/100000, D Loss: 0.3079157620668411, G Loss: 4.463793754577637\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6578/100000, D Loss: 0.3533419668674469, G Loss: 4.23094367980957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6579/100000, D Loss: 0.31160254776477814, G Loss: 4.575067043304443\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6580/100000, D Loss: 0.27847258746623993, G Loss: 4.435920715332031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6581/100000, D Loss: 0.3100973963737488, G Loss: 4.235766410827637\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6582/100000, D Loss: 0.24767853319644928, G Loss: 4.38575553894043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6583/100000, D Loss: 0.29497716575860977, G Loss: 4.464534282684326\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6584/100000, D Loss: 0.27629807591438293, G Loss: 4.2567667961120605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6585/100000, D Loss: 0.22543669492006302, G Loss: 4.4531683921813965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6586/100000, D Loss: 0.2217865139245987, G Loss: 4.734164714813232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6587/100000, D Loss: 0.2695298045873642, G Loss: 4.105630874633789\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6588/100000, D Loss: 0.24973534792661667, G Loss: 4.334311008453369\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6589/100000, D Loss: 0.25410158932209015, G Loss: 4.694190979003906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6590/100000, D Loss: 0.24828163534402847, G Loss: 4.699278831481934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6591/100000, D Loss: 0.2675458565354347, G Loss: 4.348857402801514\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6592/100000, D Loss: 0.26811933517456055, G Loss: 4.489439487457275\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6593/100000, D Loss: 0.25971484184265137, G Loss: 4.496098041534424\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6594/100000, D Loss: 0.23912450671195984, G Loss: 4.377803802490234\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6595/100000, D Loss: 0.24223938584327698, G Loss: 4.382077693939209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6596/100000, D Loss: 0.221065491437912, G Loss: 4.474816799163818\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6597/100000, D Loss: 0.22817471623420715, G Loss: 4.542690277099609\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6598/100000, D Loss: 0.2394118756055832, G Loss: 4.5973124504089355\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6599/100000, D Loss: 0.2585056871175766, G Loss: 4.620359420776367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6600/100000, D Loss: 0.1866232380270958, G Loss: 4.894325256347656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6601/100000, D Loss: 0.21554034948349, G Loss: 4.4494781494140625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6602/100000, D Loss: 0.22707700729370117, G Loss: 4.2821245193481445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6603/100000, D Loss: 0.18723181635141373, G Loss: 4.812401294708252\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6604/100000, D Loss: 0.18702277168631554, G Loss: 5.018738746643066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6605/100000, D Loss: 0.1810452938079834, G Loss: 4.744561672210693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6606/100000, D Loss: 0.2037298008799553, G Loss: 4.560777187347412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6607/100000, D Loss: 0.1519749015569687, G Loss: 4.91909646987915\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6608/100000, D Loss: 0.14623036980628967, G Loss: 5.1256890296936035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6609/100000, D Loss: 0.18909341096878052, G Loss: 4.546902179718018\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6610/100000, D Loss: 0.15262174606323242, G Loss: 4.61254358291626\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6611/100000, D Loss: 0.17981507629156113, G Loss: 4.746902942657471\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6612/100000, D Loss: 0.13210280984640121, G Loss: 5.065597057342529\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6613/100000, D Loss: 0.21174076199531555, G Loss: 4.6167893409729\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6614/100000, D Loss: 0.18879598379135132, G Loss: 4.562339782714844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6615/100000, D Loss: 0.17520324885845184, G Loss: 4.614802360534668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6616/100000, D Loss: 0.19529476016759872, G Loss: 4.6082658767700195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6617/100000, D Loss: 0.15427374094724655, G Loss: 4.960024356842041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6618/100000, D Loss: 0.1349647119641304, G Loss: 4.967619895935059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6619/100000, D Loss: 0.18919731676578522, G Loss: 4.640682697296143\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6620/100000, D Loss: 0.18055333942174911, G Loss: 4.431432723999023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6621/100000, D Loss: 0.15159976482391357, G Loss: 4.681432247161865\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6622/100000, D Loss: 0.16518649458885193, G Loss: 4.9029693603515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6623/100000, D Loss: 0.18576596677303314, G Loss: 4.529835224151611\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6624/100000, D Loss: 0.21012397855520248, G Loss: 4.133310317993164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6625/100000, D Loss: 0.22023984789848328, G Loss: 4.479084014892578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6626/100000, D Loss: 0.23504874855279922, G Loss: 4.41883659362793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6627/100000, D Loss: 0.25137220323085785, G Loss: 3.9218759536743164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6628/100000, D Loss: 0.25380079448223114, G Loss: 4.087754726409912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6629/100000, D Loss: 0.22368116676807404, G Loss: 4.67591667175293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6630/100000, D Loss: 0.2785080671310425, G Loss: 4.140913009643555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6631/100000, D Loss: 0.3477995693683624, G Loss: 3.7469558715820312\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6632/100000, D Loss: 0.2700704038143158, G Loss: 4.070764541625977\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6633/100000, D Loss: 0.315824955701828, G Loss: 4.276819705963135\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6634/100000, D Loss: 0.30315838754177094, G Loss: 3.5688912868499756\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6635/100000, D Loss: 0.3349195718765259, G Loss: 3.7210888862609863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6636/100000, D Loss: 0.22993792593479156, G Loss: 4.500555038452148\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6637/100000, D Loss: 0.24586369097232819, G Loss: 4.228282928466797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6638/100000, D Loss: 0.2959679961204529, G Loss: 3.612722396850586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6639/100000, D Loss: 0.23955176770687103, G Loss: 3.964503049850464\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6640/100000, D Loss: 0.27007146179676056, G Loss: 4.216228485107422\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6641/100000, D Loss: 0.24085231125354767, G Loss: 4.174402713775635\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6642/100000, D Loss: 0.23274291306734085, G Loss: 4.033355712890625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6643/100000, D Loss: 0.2333180159330368, G Loss: 3.9963457584381104\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6644/100000, D Loss: 0.2386423796415329, G Loss: 4.19891357421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6645/100000, D Loss: 0.18462835252285004, G Loss: 4.569802284240723\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6646/100000, D Loss: 0.20604732632637024, G Loss: 4.42234992980957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6647/100000, D Loss: 0.25134871155023575, G Loss: 4.238175868988037\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6648/100000, D Loss: 0.20713497698307037, G Loss: 4.698508262634277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6649/100000, D Loss: 0.2203558385372162, G Loss: 4.525262832641602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6650/100000, D Loss: 0.20306424796581268, G Loss: 4.468650817871094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6651/100000, D Loss: 0.26290176808834076, G Loss: 4.48939323425293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6652/100000, D Loss: 0.24811388552188873, G Loss: 4.353257179260254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6653/100000, D Loss: 0.2391812652349472, G Loss: 4.609642028808594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6654/100000, D Loss: 0.24571649730205536, G Loss: 4.703473091125488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6655/100000, D Loss: 0.24600526690483093, G Loss: 4.585719585418701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6656/100000, D Loss: 0.25012753903865814, G Loss: 4.408137321472168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6657/100000, D Loss: 0.23003844916820526, G Loss: 4.473648548126221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6658/100000, D Loss: 0.2259708270430565, G Loss: 4.838710784912109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6659/100000, D Loss: 0.248402439057827, G Loss: 4.805192947387695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6660/100000, D Loss: 0.21168313920497894, G Loss: 4.550246238708496\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6661/100000, D Loss: 0.2228977382183075, G Loss: 4.436661243438721\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6662/100000, D Loss: 0.20683080703020096, G Loss: 4.665342330932617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6663/100000, D Loss: 0.18612104654312134, G Loss: 4.918193817138672\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6664/100000, D Loss: 0.19762801378965378, G Loss: 4.724992752075195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6665/100000, D Loss: 0.18111125379800797, G Loss: 4.581504821777344\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6666/100000, D Loss: 0.15732017159461975, G Loss: 4.7292280197143555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6667/100000, D Loss: 0.17660072445869446, G Loss: 4.599094390869141\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6668/100000, D Loss: 0.2016725391149521, G Loss: 4.52590799331665\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6669/100000, D Loss: 0.17786775529384613, G Loss: 4.571613788604736\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6670/100000, D Loss: 0.1926002949476242, G Loss: 4.887258529663086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6671/100000, D Loss: 0.1762372925877571, G Loss: 4.6325836181640625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6672/100000, D Loss: 0.1974584385752678, G Loss: 4.175551414489746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6673/100000, D Loss: 0.2007385790348053, G Loss: 4.370174407958984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6674/100000, D Loss: 0.1663711816072464, G Loss: 4.4821929931640625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6675/100000, D Loss: 0.16814543679356575, G Loss: 4.925305366516113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6676/100000, D Loss: 0.17822949588298798, G Loss: 4.7045488357543945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6677/100000, D Loss: 0.22267284244298935, G Loss: 4.01961612701416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6678/100000, D Loss: 0.2050534039735794, G Loss: 4.296187877655029\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6679/100000, D Loss: 0.17862683534622192, G Loss: 4.677274227142334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6680/100000, D Loss: 0.15930892154574394, G Loss: 5.0296430587768555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6681/100000, D Loss: 0.184873316437006, G Loss: 4.211453914642334\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6682/100000, D Loss: 0.19435640424489975, G Loss: 4.227993965148926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6683/100000, D Loss: 0.17798103392124176, G Loss: 4.693925857543945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6684/100000, D Loss: 0.16942232847213745, G Loss: 4.814897537231445\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6685/100000, D Loss: 0.17315199971199036, G Loss: 4.669782638549805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6686/100000, D Loss: 0.20842140913009644, G Loss: 4.191303253173828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6687/100000, D Loss: 0.16829654574394226, G Loss: 4.522154808044434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6688/100000, D Loss: 0.13951293006539345, G Loss: 4.872866630554199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6689/100000, D Loss: 0.17916173487901688, G Loss: 4.878356456756592\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6690/100000, D Loss: 0.20773282647132874, G Loss: 3.883601188659668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6691/100000, D Loss: 0.17709548026323318, G Loss: 4.203727722167969\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6692/100000, D Loss: 0.16204903274774551, G Loss: 5.012753009796143\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6693/100000, D Loss: 0.17365537211298943, G Loss: 4.912696838378906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6694/100000, D Loss: 0.17316821962594986, G Loss: 4.346078872680664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6695/100000, D Loss: 0.17656534165143967, G Loss: 4.11055850982666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6696/100000, D Loss: 0.1799410581588745, G Loss: 4.399290561676025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6697/100000, D Loss: 0.1536482870578766, G Loss: 4.748595237731934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6698/100000, D Loss: 0.2111927792429924, G Loss: 4.571023941040039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6699/100000, D Loss: 0.19796089082956314, G Loss: 4.100953578948975\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6700/100000, D Loss: 0.18769700825214386, G Loss: 4.103092670440674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6701/100000, D Loss: 0.22939090430736542, G Loss: 4.321309566497803\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6702/100000, D Loss: 0.2370949387550354, G Loss: 4.338359832763672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6703/100000, D Loss: 0.21642234176397324, G Loss: 4.335109710693359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6704/100000, D Loss: 0.22264370322227478, G Loss: 4.62238883972168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6705/100000, D Loss: 0.25587188452482224, G Loss: 4.38409948348999\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6706/100000, D Loss: 0.2679806053638458, G Loss: 4.152237892150879\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6707/100000, D Loss: 0.27409905195236206, G Loss: 4.5783586502075195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6708/100000, D Loss: 0.2554961293935776, G Loss: 4.635798931121826\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6709/100000, D Loss: 0.28264372795820236, G Loss: 4.55887508392334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6710/100000, D Loss: 0.32014399766921997, G Loss: 4.365094184875488\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6711/100000, D Loss: 0.3056703209877014, G Loss: 4.774768829345703\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6712/100000, D Loss: 0.2951933890581131, G Loss: 4.540336608886719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6713/100000, D Loss: 0.315167173743248, G Loss: 4.399529457092285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6714/100000, D Loss: 0.31140466034412384, G Loss: 4.62088680267334\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6715/100000, D Loss: 0.2567574083805084, G Loss: 4.777769088745117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6716/100000, D Loss: 0.2477933093905449, G Loss: 4.981904983520508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6717/100000, D Loss: 0.22254985570907593, G Loss: 5.053555011749268\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6718/100000, D Loss: 0.20616912841796875, G Loss: 5.179782390594482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6719/100000, D Loss: 0.2042861208319664, G Loss: 5.154094696044922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6720/100000, D Loss: 0.1774912104010582, G Loss: 5.1615753173828125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6721/100000, D Loss: 0.15386737138032913, G Loss: 5.407652378082275\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6722/100000, D Loss: 0.16432860493659973, G Loss: 5.339914321899414\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6723/100000, D Loss: 0.1861279234290123, G Loss: 5.143870830535889\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6724/100000, D Loss: 0.1633850485086441, G Loss: 5.192791938781738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6725/100000, D Loss: 0.16195861995220184, G Loss: 5.3734259605407715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6726/100000, D Loss: 0.15969859808683395, G Loss: 5.3913164138793945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6727/100000, D Loss: 0.1559123396873474, G Loss: 4.969128131866455\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6728/100000, D Loss: 0.15094854682683945, G Loss: 4.620457649230957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6729/100000, D Loss: 0.1593402996659279, G Loss: 4.886801719665527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6730/100000, D Loss: 0.15733730792999268, G Loss: 5.261373519897461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6731/100000, D Loss: 0.1725548803806305, G Loss: 4.983954906463623\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6732/100000, D Loss: 0.19563210755586624, G Loss: 4.465590476989746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6733/100000, D Loss: 0.1531156599521637, G Loss: 4.693315029144287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6734/100000, D Loss: 0.15495403110980988, G Loss: 5.05799674987793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6735/100000, D Loss: 0.21806520968675613, G Loss: 4.683549404144287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6736/100000, D Loss: 0.1763443425297737, G Loss: 4.6546478271484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6737/100000, D Loss: 0.1967233493924141, G Loss: 4.743917465209961\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6738/100000, D Loss: 0.20284856110811234, G Loss: 4.583245754241943\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6739/100000, D Loss: 0.20579584687948227, G Loss: 4.2990264892578125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6740/100000, D Loss: 0.17828311771154404, G Loss: 4.655388832092285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6741/100000, D Loss: 0.2033364400267601, G Loss: 4.763259410858154\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6742/100000, D Loss: 0.22154181450605392, G Loss: 4.429970741271973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6743/100000, D Loss: 0.21140630543231964, G Loss: 4.402757167816162\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6744/100000, D Loss: 0.2254001647233963, G Loss: 4.658984661102295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6745/100000, D Loss: 0.21545259654521942, G Loss: 4.299023628234863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6746/100000, D Loss: 0.24439486861228943, G Loss: 4.09928035736084\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6747/100000, D Loss: 0.2030637264251709, G Loss: 4.420112133026123\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6748/100000, D Loss: 0.21626678109169006, G Loss: 4.514812469482422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6749/100000, D Loss: 0.22381028532981873, G Loss: 4.4033403396606445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6750/100000, D Loss: 0.21405483037233353, G Loss: 4.368404388427734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6751/100000, D Loss: 0.20527829229831696, G Loss: 4.665271282196045\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6752/100000, D Loss: 0.21036861091852188, G Loss: 4.488225936889648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6753/100000, D Loss: 0.2178947478532791, G Loss: 4.166380405426025\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6754/100000, D Loss: 0.24768933653831482, G Loss: 4.174015522003174\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6755/100000, D Loss: 0.19795415550470352, G Loss: 4.710650444030762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6756/100000, D Loss: 0.2390238717198372, G Loss: 4.499797821044922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6757/100000, D Loss: 0.27064523100852966, G Loss: 3.9281108379364014\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6758/100000, D Loss: 0.2664823532104492, G Loss: 4.186248779296875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6759/100000, D Loss: 0.2545836716890335, G Loss: 4.466392517089844\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6760/100000, D Loss: 0.26073046773672104, G Loss: 4.530587673187256\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6761/100000, D Loss: 0.2912173643708229, G Loss: 4.178497314453125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6762/100000, D Loss: 0.3033133000135422, G Loss: 4.145736217498779\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6763/100000, D Loss: 0.25273651629686356, G Loss: 4.346222877502441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6764/100000, D Loss: 0.27635155618190765, G Loss: 4.045784950256348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6765/100000, D Loss: 0.2923528850078583, G Loss: 4.129422187805176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6766/100000, D Loss: 0.275238499045372, G Loss: 4.326389312744141\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6767/100000, D Loss: 0.25534452497959137, G Loss: 4.129188537597656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6768/100000, D Loss: 0.26392874121665955, G Loss: 4.000406265258789\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6769/100000, D Loss: 0.2091061994433403, G Loss: 4.272021293640137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6770/100000, D Loss: 0.18820714205503464, G Loss: 4.483246803283691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6771/100000, D Loss: 0.18580450862646103, G Loss: 4.254891395568848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6772/100000, D Loss: 0.18892954289913177, G Loss: 4.188372611999512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6773/100000, D Loss: 0.1784631833434105, G Loss: 4.402981758117676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6774/100000, D Loss: 0.17963143438100815, G Loss: 4.338904857635498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6775/100000, D Loss: 0.17772305011749268, G Loss: 4.215373516082764\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6776/100000, D Loss: 0.17177830636501312, G Loss: 4.460793495178223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6777/100000, D Loss: 0.11864160001277924, G Loss: 4.946202278137207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6778/100000, D Loss: 0.1532500647008419, G Loss: 4.554358959197998\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6779/100000, D Loss: 0.16273540258407593, G Loss: 4.416688442230225\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6780/100000, D Loss: 0.1374480277299881, G Loss: 4.781315326690674\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6781/100000, D Loss: 0.12499510124325752, G Loss: 4.872238636016846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6782/100000, D Loss: 0.14861498400568962, G Loss: 4.594539642333984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6783/100000, D Loss: 0.1423662230372429, G Loss: 4.4481635093688965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6784/100000, D Loss: 0.12704043090343475, G Loss: 4.904825687408447\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6785/100000, D Loss: 0.11723266169428825, G Loss: 5.272196292877197\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6786/100000, D Loss: 0.15623756498098373, G Loss: 4.722116470336914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6787/100000, D Loss: 0.1435970440506935, G Loss: 4.348178863525391\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6788/100000, D Loss: 0.13594339042901993, G Loss: 4.719099998474121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6789/100000, D Loss: 0.14376699924468994, G Loss: 5.203158855438232\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6790/100000, D Loss: 0.1647341139614582, G Loss: 4.691161632537842\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6791/100000, D Loss: 0.20151882618665695, G Loss: 4.249177932739258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6792/100000, D Loss: 0.22160054743289948, G Loss: 4.541054725646973\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6793/100000, D Loss: 0.1854366734623909, G Loss: 4.790290832519531\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6794/100000, D Loss: 0.228045254945755, G Loss: 4.454333305358887\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6795/100000, D Loss: 0.26095908880233765, G Loss: 4.175382614135742\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6796/100000, D Loss: 0.26200346648693085, G Loss: 4.315241813659668\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6797/100000, D Loss: 0.2690521478652954, G Loss: 4.291414737701416\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 6798/100000, D Loss: 0.31962017714977264, G Loss: 4.119696617126465\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 6799/100000, D Loss: 0.26956069469451904, G Loss: 4.205645561218262\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6800/100000, D Loss: 0.3107456564903259, G Loss: 4.211888313293457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6801/100000, D Loss: 0.3144511580467224, G Loss: 4.203202724456787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6802/100000, D Loss: 0.2839176058769226, G Loss: 4.329023361206055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6803/100000, D Loss: 0.28557877242565155, G Loss: 4.050717353820801\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6804/100000, D Loss: 0.3140847384929657, G Loss: 4.372921466827393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6805/100000, D Loss: 0.2624192610383034, G Loss: 4.6107330322265625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6806/100000, D Loss: 0.3345003128051758, G Loss: 4.160069465637207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6807/100000, D Loss: 0.29616451263427734, G Loss: 4.283870697021484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6808/100000, D Loss: 0.2674025893211365, G Loss: 4.249958515167236\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6809/100000, D Loss: 0.3540477007627487, G Loss: 3.7938976287841797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6810/100000, D Loss: 0.3001914471387863, G Loss: 4.422472953796387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6811/100000, D Loss: 0.28722744435071945, G Loss: 4.454202175140381\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6812/100000, D Loss: 0.32990480959415436, G Loss: 4.100012302398682\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6813/100000, D Loss: 0.29594650864601135, G Loss: 4.0744218826293945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6814/100000, D Loss: 0.262489914894104, G Loss: 4.572685241699219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6815/100000, D Loss: 0.2503553330898285, G Loss: 4.588746070861816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6816/100000, D Loss: 0.26055172085762024, G Loss: 4.324741363525391\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6817/100000, D Loss: 0.22912150621414185, G Loss: 4.722177505493164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6818/100000, D Loss: 0.23182469606399536, G Loss: 5.048842430114746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6819/100000, D Loss: 0.19365663826465607, G Loss: 5.021043300628662\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6820/100000, D Loss: 0.2418098971247673, G Loss: 4.807262420654297\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 6821/100000, D Loss: 0.19462759792804718, G Loss: 4.964494705200195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6822/100000, D Loss: 0.18871049582958221, G Loss: 5.478234767913818\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6823/100000, D Loss: 0.17469769716262817, G Loss: 5.161457538604736\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6824/100000, D Loss: 0.2003265991806984, G Loss: 4.63362979888916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6825/100000, D Loss: 0.18624381721019745, G Loss: 4.813064098358154\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6826/100000, D Loss: 0.19475268572568893, G Loss: 5.358529090881348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6827/100000, D Loss: 0.19676385819911957, G Loss: 5.26397180557251\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6828/100000, D Loss: 0.20296867936849594, G Loss: 5.1231369972229\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6829/100000, D Loss: 0.18717309087514877, G Loss: 5.259762763977051\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6830/100000, D Loss: 0.1912505254149437, G Loss: 5.105782985687256\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6831/100000, D Loss: 0.16443461924791336, G Loss: 5.1642045974731445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6832/100000, D Loss: 0.1712300255894661, G Loss: 5.074138641357422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6833/100000, D Loss: 0.16468770802021027, G Loss: 5.135507583618164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6834/100000, D Loss: 0.1366788148880005, G Loss: 5.3287835121154785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6835/100000, D Loss: 0.14119989797472954, G Loss: 5.21781063079834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6836/100000, D Loss: 0.16584698855876923, G Loss: 5.2916436195373535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6837/100000, D Loss: 0.1625676080584526, G Loss: 5.396923542022705\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6838/100000, D Loss: 0.14445094391703606, G Loss: 5.2723822593688965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6839/100000, D Loss: 0.16710130870342255, G Loss: 5.0381364822387695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6840/100000, D Loss: 0.18896406143903732, G Loss: 4.600186347961426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6841/100000, D Loss: 0.1743953600525856, G Loss: 5.044679164886475\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6842/100000, D Loss: 0.18726297467947006, G Loss: 5.270733833312988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6843/100000, D Loss: 0.21166785061359406, G Loss: 4.920340538024902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6844/100000, D Loss: 0.19135835021734238, G Loss: 4.8307976722717285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6845/100000, D Loss: 0.17525848746299744, G Loss: 4.876070976257324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6846/100000, D Loss: 0.20518864691257477, G Loss: 4.796754837036133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6847/100000, D Loss: 0.1632542535662651, G Loss: 5.202558517456055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6848/100000, D Loss: 0.21474772691726685, G Loss: 4.655345916748047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6849/100000, D Loss: 0.2347651645541191, G Loss: 4.699612617492676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6850/100000, D Loss: 0.19493308663368225, G Loss: 4.66009521484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6851/100000, D Loss: 0.21866752207279205, G Loss: 4.874157905578613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6852/100000, D Loss: 0.23126399517059326, G Loss: 4.77100133895874\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6853/100000, D Loss: 0.24439619481563568, G Loss: 4.347572326660156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6854/100000, D Loss: 0.2803301364183426, G Loss: 4.195413589477539\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6855/100000, D Loss: 0.2856992483139038, G Loss: 4.631302356719971\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6856/100000, D Loss: 0.27610984444618225, G Loss: 4.634906768798828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6857/100000, D Loss: 0.30839698016643524, G Loss: 4.0415215492248535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6858/100000, D Loss: 0.3079109787940979, G Loss: 4.147255897521973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6859/100000, D Loss: 0.22650735080242157, G Loss: 4.781647205352783\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6860/100000, D Loss: 0.27552687376737595, G Loss: 4.573002815246582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6861/100000, D Loss: 0.27830158919095993, G Loss: 4.125985622406006\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6862/100000, D Loss: 0.3204866051673889, G Loss: 4.2402729988098145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6863/100000, D Loss: 0.24210990220308304, G Loss: 4.844816207885742\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6864/100000, D Loss: 0.2233678326010704, G Loss: 5.019084453582764\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6865/100000, D Loss: 0.2510421872138977, G Loss: 4.2503156661987305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6866/100000, D Loss: 0.25938719511032104, G Loss: 4.495749473571777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6867/100000, D Loss: 0.19347239285707474, G Loss: 4.97337532043457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6868/100000, D Loss: 0.23363831639289856, G Loss: 4.533580780029297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6869/100000, D Loss: 0.22467486560344696, G Loss: 4.523421287536621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6870/100000, D Loss: 0.2092939242720604, G Loss: 4.76531982421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6871/100000, D Loss: 0.17403734102845192, G Loss: 4.894671440124512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6872/100000, D Loss: 0.2418236881494522, G Loss: 4.586005687713623\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6873/100000, D Loss: 0.17682310193777084, G Loss: 4.959332466125488\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6874/100000, D Loss: 0.16923922300338745, G Loss: 5.07415771484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6875/100000, D Loss: 0.1717141829431057, G Loss: 4.638886451721191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6876/100000, D Loss: 0.1954301968216896, G Loss: 4.7570648193359375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6877/100000, D Loss: 0.15462087094783783, G Loss: 5.174774169921875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6878/100000, D Loss: 0.15676183626055717, G Loss: 5.326174736022949\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6879/100000, D Loss: 0.14366695284843445, G Loss: 5.031118392944336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6880/100000, D Loss: 0.1861875355243683, G Loss: 4.709549903869629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6881/100000, D Loss: 0.16463547199964523, G Loss: 4.768056869506836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6882/100000, D Loss: 0.15857118368148804, G Loss: 5.150091171264648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6883/100000, D Loss: 0.20109478384256363, G Loss: 4.968484878540039\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6884/100000, D Loss: 0.21403605490922928, G Loss: 4.803193092346191\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6885/100000, D Loss: 0.23388753086328506, G Loss: 4.572544574737549\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6886/100000, D Loss: 0.23306705057621002, G Loss: 4.959650039672852\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6887/100000, D Loss: 0.23230547457933426, G Loss: 5.077065944671631\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6888/100000, D Loss: 0.22048446536064148, G Loss: 5.019205093383789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6889/100000, D Loss: 0.2519803047180176, G Loss: 4.5967864990234375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6890/100000, D Loss: 0.265177458524704, G Loss: 4.819605827331543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6891/100000, D Loss: 0.2382713109254837, G Loss: 5.097952842712402\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6892/100000, D Loss: 0.2466176673769951, G Loss: 4.925236701965332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6893/100000, D Loss: 0.2008265107870102, G Loss: 5.073246955871582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6894/100000, D Loss: 0.17044740915298462, G Loss: 5.196895599365234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6895/100000, D Loss: 0.21643894910812378, G Loss: 5.216666221618652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6896/100000, D Loss: 0.18751728534698486, G Loss: 4.8223748207092285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6897/100000, D Loss: 0.16413473337888718, G Loss: 5.112884521484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6898/100000, D Loss: 0.19276828318834305, G Loss: 4.866148471832275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6899/100000, D Loss: 0.19975019991397858, G Loss: 4.644547462463379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6900/100000, D Loss: 0.19621489197015762, G Loss: 4.617067337036133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6901/100000, D Loss: 0.20479966700077057, G Loss: 4.774100303649902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6902/100000, D Loss: 0.20380425453186035, G Loss: 4.6597514152526855\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6903/100000, D Loss: 0.1714286208152771, G Loss: 4.6525068283081055\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6904/100000, D Loss: 0.1617618352174759, G Loss: 4.823543548583984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6905/100000, D Loss: 0.17741703242063522, G Loss: 4.651217937469482\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6906/100000, D Loss: 0.17971394211053848, G Loss: 4.413477420806885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6907/100000, D Loss: 0.13044776767492294, G Loss: 4.542969703674316\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6908/100000, D Loss: 0.14898233860731125, G Loss: 4.520718574523926\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6909/100000, D Loss: 0.14232080802321434, G Loss: 4.773406982421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6910/100000, D Loss: 0.1388094201683998, G Loss: 4.827908992767334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6911/100000, D Loss: 0.1720755249261856, G Loss: 4.703672409057617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6912/100000, D Loss: 0.17586629837751389, G Loss: 4.576169490814209\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6913/100000, D Loss: 0.15942710638046265, G Loss: 4.388664245605469\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6914/100000, D Loss: 0.14860093593597412, G Loss: 4.618853569030762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6915/100000, D Loss: 0.15572357177734375, G Loss: 4.713072776794434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6916/100000, D Loss: 0.20715761184692383, G Loss: 4.500629901885986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6917/100000, D Loss: 0.17473536729812622, G Loss: 4.473848819732666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6918/100000, D Loss: 0.20628701895475388, G Loss: 4.40528678894043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6919/100000, D Loss: 0.22236265987157822, G Loss: 4.135960578918457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6920/100000, D Loss: 0.2578044906258583, G Loss: 4.147383213043213\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6921/100000, D Loss: 0.21133867651224136, G Loss: 4.491619110107422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6922/100000, D Loss: 0.24334368109703064, G Loss: 4.317965507507324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6923/100000, D Loss: 0.25880687683820724, G Loss: 4.20026969909668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6924/100000, D Loss: 0.3066053241491318, G Loss: 4.454089164733887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6925/100000, D Loss: 0.31717048585414886, G Loss: 4.182453155517578\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6926/100000, D Loss: 0.27557677030563354, G Loss: 4.283206939697266\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6927/100000, D Loss: 0.2741639316082001, G Loss: 4.409361362457275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6928/100000, D Loss: 0.3140564113855362, G Loss: 4.0192952156066895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6929/100000, D Loss: 0.3090037554502487, G Loss: 3.8541359901428223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6930/100000, D Loss: 0.24671008437871933, G Loss: 4.193214416503906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6931/100000, D Loss: 0.2735195606946945, G Loss: 4.316399097442627\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6932/100000, D Loss: 0.30433139204978943, G Loss: 4.053717613220215\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6933/100000, D Loss: 0.2754054293036461, G Loss: 4.323502063751221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6934/100000, D Loss: 0.2728482782840729, G Loss: 4.510488986968994\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6935/100000, D Loss: 0.2022947445511818, G Loss: 4.67807149887085\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6936/100000, D Loss: 0.2195504531264305, G Loss: 4.501713752746582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6937/100000, D Loss: 0.19801539182662964, G Loss: 4.28752326965332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6938/100000, D Loss: 0.22106802463531494, G Loss: 4.543785095214844\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6939/100000, D Loss: 0.1467302218079567, G Loss: 5.028373718261719\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6940/100000, D Loss: 0.19431458786129951, G Loss: 4.489102363586426\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6941/100000, D Loss: 0.20067832618951797, G Loss: 4.3257646560668945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6942/100000, D Loss: 0.16003265976905823, G Loss: 4.799988269805908\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6943/100000, D Loss: 0.14549436420202255, G Loss: 5.189050197601318\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6944/100000, D Loss: 0.1796414777636528, G Loss: 4.986114025115967\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6945/100000, D Loss: 0.18357552587985992, G Loss: 4.352406978607178\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6946/100000, D Loss: 0.20596012473106384, G Loss: 4.264358043670654\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6947/100000, D Loss: 0.2156808078289032, G Loss: 4.60448694229126\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6948/100000, D Loss: 0.23580822348594666, G Loss: 4.597044467926025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6949/100000, D Loss: 0.27356913685798645, G Loss: 4.204451084136963\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6950/100000, D Loss: 0.24748903512954712, G Loss: 4.3318681716918945\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6951/100000, D Loss: 0.23646466434001923, G Loss: 4.379087924957275\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6952/100000, D Loss: 0.285954087972641, G Loss: 4.061471939086914\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6953/100000, D Loss: 0.27991484105587006, G Loss: 4.30980920791626\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6954/100000, D Loss: 0.21074531227350235, G Loss: 4.543882369995117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6955/100000, D Loss: 0.20762833952903748, G Loss: 4.623348236083984\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6956/100000, D Loss: 0.2608996704220772, G Loss: 3.9959943294525146\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6957/100000, D Loss: 0.24746569246053696, G Loss: 4.115725040435791\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6958/100000, D Loss: 0.21040865778923035, G Loss: 4.480441570281982\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6959/100000, D Loss: 0.1920410320162773, G Loss: 4.7166032791137695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6960/100000, D Loss: 0.20911218225955963, G Loss: 4.3722944259643555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6961/100000, D Loss: 0.26393162459135056, G Loss: 3.9246397018432617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6962/100000, D Loss: 0.20019496977329254, G Loss: 4.785584926605225\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6963/100000, D Loss: 0.2371194213628769, G Loss: 4.858833312988281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6964/100000, D Loss: 0.22326373308897018, G Loss: 4.120115280151367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6965/100000, D Loss: 0.23714429140090942, G Loss: 3.775057792663574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6966/100000, D Loss: 0.22173453867435455, G Loss: 4.520057678222656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6967/100000, D Loss: 0.21348590403795242, G Loss: 4.890183448791504\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6968/100000, D Loss: 0.24376727640628815, G Loss: 4.046102523803711\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6969/100000, D Loss: 0.2272242307662964, G Loss: 3.756150960922241\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6970/100000, D Loss: 0.15334630012512207, G Loss: 4.785308837890625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6971/100000, D Loss: 0.1455167643725872, G Loss: 5.083349704742432\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6972/100000, D Loss: 0.21469873189926147, G Loss: 4.309394836425781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6973/100000, D Loss: 0.16108331084251404, G Loss: 4.171459197998047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6974/100000, D Loss: 0.13155677169561386, G Loss: 5.07547664642334\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6975/100000, D Loss: 0.13526082783937454, G Loss: 5.304696559906006\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6976/100000, D Loss: 0.1415913663804531, G Loss: 4.503143787384033\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6977/100000, D Loss: 0.1414206624031067, G Loss: 4.569055080413818\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6978/100000, D Loss: 0.12721693515777588, G Loss: 4.977367401123047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6979/100000, D Loss: 0.13266725838184357, G Loss: 5.325336456298828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6980/100000, D Loss: 0.1475224643945694, G Loss: 4.6359405517578125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6981/100000, D Loss: 0.16481970995664597, G Loss: 4.474021911621094\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6982/100000, D Loss: 0.14130444079637527, G Loss: 4.633471965789795\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6983/100000, D Loss: 0.15355613455176353, G Loss: 4.762584686279297\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6984/100000, D Loss: 0.18295664340257645, G Loss: 4.365200042724609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6985/100000, D Loss: 0.20132357627153397, G Loss: 4.45767879486084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6986/100000, D Loss: 0.1662379577755928, G Loss: 4.923560619354248\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 6987/100000, D Loss: 0.20700769126415253, G Loss: 4.685899257659912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6988/100000, D Loss: 0.1854034811258316, G Loss: 4.415217399597168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6989/100000, D Loss: 0.1916208118200302, G Loss: 4.408251762390137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6990/100000, D Loss: 0.24474149197340012, G Loss: 4.384795665740967\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6991/100000, D Loss: 0.23978130519390106, G Loss: 4.152007102966309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6992/100000, D Loss: 0.25377681851387024, G Loss: 4.275542259216309\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6993/100000, D Loss: 0.28697017580270767, G Loss: 4.258983612060547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 6994/100000, D Loss: 0.2683420479297638, G Loss: 4.289458274841309\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6995/100000, D Loss: 0.2503007650375366, G Loss: 4.543856620788574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6996/100000, D Loss: 0.27351095527410507, G Loss: 4.530716896057129\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6997/100000, D Loss: 0.27996835857629776, G Loss: 4.179200172424316\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6998/100000, D Loss: 0.2270393893122673, G Loss: 4.3692827224731445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 6999/100000, D Loss: 0.24736324697732925, G Loss: 4.776978015899658\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7000/100000, D Loss: 0.22788115590810776, G Loss: 4.847134590148926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7001/100000, D Loss: 0.26065997779369354, G Loss: 4.472308158874512\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7002/100000, D Loss: 0.24418029189109802, G Loss: 4.494837760925293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7003/100000, D Loss: 0.20277474075555801, G Loss: 4.766695022583008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7004/100000, D Loss: 0.1821076050400734, G Loss: 5.200351238250732\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7005/100000, D Loss: 0.18091998994350433, G Loss: 4.959542751312256\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7006/100000, D Loss: 0.23179107904434204, G Loss: 4.741279125213623\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7007/100000, D Loss: 0.19623946398496628, G Loss: 4.879223823547363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7008/100000, D Loss: 0.20261826366186142, G Loss: 4.8815412521362305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7009/100000, D Loss: 0.21395330876111984, G Loss: 4.490560531616211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7010/100000, D Loss: 0.18125253915786743, G Loss: 4.8612871170043945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7011/100000, D Loss: 0.16742858290672302, G Loss: 5.117239952087402\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7012/100000, D Loss: 0.21386582404375076, G Loss: 4.80460786819458\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7013/100000, D Loss: 0.22266043722629547, G Loss: 4.410235404968262\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7014/100000, D Loss: 0.21225771307945251, G Loss: 4.627028465270996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7015/100000, D Loss: 0.17829415202140808, G Loss: 4.907666206359863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7016/100000, D Loss: 0.17090018093585968, G Loss: 4.721457481384277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7017/100000, D Loss: 0.20510871708393097, G Loss: 4.400320053100586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7018/100000, D Loss: 0.2083425596356392, G Loss: 4.462752342224121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7019/100000, D Loss: 0.16142721474170685, G Loss: 4.678594589233398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7020/100000, D Loss: 0.15869947522878647, G Loss: 4.850257396697998\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7021/100000, D Loss: 0.15721166133880615, G Loss: 4.574926376342773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7022/100000, D Loss: 0.1821461170911789, G Loss: 4.336682319641113\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7023/100000, D Loss: 0.19805105030536652, G Loss: 4.6728692054748535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7024/100000, D Loss: 0.1634952314198017, G Loss: 4.835258483886719\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7025/100000, D Loss: 0.21042127162218094, G Loss: 4.5755414962768555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7026/100000, D Loss: 0.19694101810455322, G Loss: 4.511683464050293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7027/100000, D Loss: 0.1802787259221077, G Loss: 4.901073455810547\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7028/100000, D Loss: 0.17731570452451706, G Loss: 4.914377212524414\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7029/100000, D Loss: 0.18855205923318863, G Loss: 4.654513835906982\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7030/100000, D Loss: 0.1574029177427292, G Loss: 4.772294998168945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7031/100000, D Loss: 0.18537984788417816, G Loss: 4.646023750305176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7032/100000, D Loss: 0.1653381511569023, G Loss: 4.835616588592529\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7033/100000, D Loss: 0.17548353224992752, G Loss: 4.869784832000732\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7034/100000, D Loss: 0.1855316460132599, G Loss: 4.727003574371338\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7035/100000, D Loss: 0.17941731214523315, G Loss: 4.8151679039001465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7036/100000, D Loss: 0.15293597429990768, G Loss: 4.976789474487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7037/100000, D Loss: 0.1741771399974823, G Loss: 5.138084411621094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7038/100000, D Loss: 0.17555012553930283, G Loss: 4.60228157043457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7039/100000, D Loss: 0.1639721766114235, G Loss: 4.960668563842773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7040/100000, D Loss: 0.14956600964069366, G Loss: 5.073725700378418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7041/100000, D Loss: 0.20646947622299194, G Loss: 4.941960334777832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7042/100000, D Loss: 0.18565316498279572, G Loss: 4.548599720001221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7043/100000, D Loss: 0.16765549778938293, G Loss: 4.903705596923828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7044/100000, D Loss: 0.1570648029446602, G Loss: 5.062726974487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7045/100000, D Loss: 0.17952972650527954, G Loss: 4.718456745147705\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7046/100000, D Loss: 0.1598915532231331, G Loss: 4.5114827156066895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7047/100000, D Loss: 0.16148287057876587, G Loss: 4.681134223937988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7048/100000, D Loss: 0.1624801903963089, G Loss: 4.771906852722168\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7049/100000, D Loss: 0.1832726150751114, G Loss: 4.5693888664245605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7050/100000, D Loss: 0.1629239171743393, G Loss: 4.62370491027832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7051/100000, D Loss: 0.1857389658689499, G Loss: 4.80526065826416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7052/100000, D Loss: 0.16775992512702942, G Loss: 4.751757621765137\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7053/100000, D Loss: 0.1478790044784546, G Loss: 4.54334831237793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7054/100000, D Loss: 0.19474930316209793, G Loss: 4.355806350708008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7055/100000, D Loss: 0.16853731125593185, G Loss: 4.629164695739746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7056/100000, D Loss: 0.20873495191335678, G Loss: 4.618827819824219\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7057/100000, D Loss: 0.22951793670654297, G Loss: 4.28569221496582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7058/100000, D Loss: 0.20408009737730026, G Loss: 4.183349609375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7059/100000, D Loss: 0.22411953657865524, G Loss: 4.554337501525879\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7060/100000, D Loss: 0.21875320374965668, G Loss: 4.717101097106934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7061/100000, D Loss: 0.21052837371826172, G Loss: 4.48452615737915\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7062/100000, D Loss: 0.2548961117863655, G Loss: 4.175914287567139\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7063/100000, D Loss: 0.22802071273326874, G Loss: 4.564885139465332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7064/100000, D Loss: 0.27059078216552734, G Loss: 4.4158124923706055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7065/100000, D Loss: 0.23818489909172058, G Loss: 4.498094081878662\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7066/100000, D Loss: 0.25442054867744446, G Loss: 4.441725730895996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7067/100000, D Loss: 0.22412078827619553, G Loss: 4.640755653381348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7068/100000, D Loss: 0.2679810971021652, G Loss: 4.489818572998047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7069/100000, D Loss: 0.2383342906832695, G Loss: 4.395869255065918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7070/100000, D Loss: 0.19952335953712463, G Loss: 5.110858917236328\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7071/100000, D Loss: 0.18815682083368301, G Loss: 5.215001583099365\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7072/100000, D Loss: 0.22836285829544067, G Loss: 4.374789237976074\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7073/100000, D Loss: 0.2109607756137848, G Loss: 4.091747283935547\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7074/100000, D Loss: 0.16286983713507652, G Loss: 5.0038371086120605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7075/100000, D Loss: 0.1565343290567398, G Loss: 5.586141109466553\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7076/100000, D Loss: 0.17062538489699364, G Loss: 5.0850725173950195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7077/100000, D Loss: 0.176692895591259, G Loss: 4.590348243713379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7078/100000, D Loss: 0.178144633769989, G Loss: 4.750370979309082\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7079/100000, D Loss: 0.16190601885318756, G Loss: 5.350039482116699\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7080/100000, D Loss: 0.1932830512523651, G Loss: 5.335707664489746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7081/100000, D Loss: 0.21824565529823303, G Loss: 5.012956619262695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7082/100000, D Loss: 0.2314557209610939, G Loss: 4.861712455749512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7083/100000, D Loss: 0.25304388999938965, G Loss: 4.9277191162109375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7084/100000, D Loss: 0.24556522071361542, G Loss: 4.769414901733398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7085/100000, D Loss: 0.2642402648925781, G Loss: 4.886066436767578\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7086/100000, D Loss: 0.26468034088611603, G Loss: 5.031779766082764\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7087/100000, D Loss: 0.2551245465874672, G Loss: 4.93597936630249\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7088/100000, D Loss: 0.26556791365146637, G Loss: 4.804821968078613\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7089/100000, D Loss: 0.2713055983185768, G Loss: 4.7574052810668945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7090/100000, D Loss: 0.18109415471553802, G Loss: 5.455399513244629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7091/100000, D Loss: 0.18836940824985504, G Loss: 5.760844707489014\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7092/100000, D Loss: 0.18181631714105606, G Loss: 5.365621566772461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7093/100000, D Loss: 0.17834705114364624, G Loss: 5.259201526641846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7094/100000, D Loss: 0.13576387986540794, G Loss: 5.504103660583496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7095/100000, D Loss: 0.13924837112426758, G Loss: 5.888358116149902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7096/100000, D Loss: 0.15839629247784615, G Loss: 5.5366973876953125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7097/100000, D Loss: 0.15769801288843155, G Loss: 5.375715255737305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7098/100000, D Loss: 0.15210577845573425, G Loss: 5.428238391876221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7099/100000, D Loss: 0.13893841952085495, G Loss: 5.511218547821045\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7100/100000, D Loss: 0.12083609774708748, G Loss: 5.322929382324219\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7101/100000, D Loss: 0.12887119501829147, G Loss: 5.368658542633057\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7102/100000, D Loss: 0.15305916219949722, G Loss: 4.967203617095947\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7103/100000, D Loss: 0.12849537283182144, G Loss: 4.929100513458252\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7104/100000, D Loss: 0.11874151229858398, G Loss: 5.4632039070129395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7105/100000, D Loss: 0.14356734603643417, G Loss: 4.9665093421936035\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7106/100000, D Loss: 0.1607593223452568, G Loss: 4.571636199951172\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7107/100000, D Loss: 0.15121295303106308, G Loss: 4.8688201904296875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7108/100000, D Loss: 0.1503278911113739, G Loss: 5.01099967956543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7109/100000, D Loss: 0.13738875836133957, G Loss: 4.83819580078125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7110/100000, D Loss: 0.16124768555164337, G Loss: 4.333347797393799\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7111/100000, D Loss: 0.17794321477413177, G Loss: 4.491403579711914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7112/100000, D Loss: 0.17862488329410553, G Loss: 4.668784141540527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7113/100000, D Loss: 0.19795574247837067, G Loss: 4.507573127746582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7114/100000, D Loss: 0.1651807278394699, G Loss: 4.511942386627197\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7115/100000, D Loss: 0.18455100804567337, G Loss: 4.377154350280762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7116/100000, D Loss: 0.2115069404244423, G Loss: 4.492922306060791\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7117/100000, D Loss: 0.20089253783226013, G Loss: 4.557320594787598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7118/100000, D Loss: 0.20141810923814774, G Loss: 4.310839653015137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7119/100000, D Loss: 0.2206856533885002, G Loss: 4.501505374908447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7120/100000, D Loss: 0.19727665185928345, G Loss: 4.422250270843506\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7121/100000, D Loss: 0.24442113935947418, G Loss: 4.125624656677246\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7122/100000, D Loss: 0.2501025125384331, G Loss: 4.456019401550293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7123/100000, D Loss: 0.27004915475845337, G Loss: 4.413716793060303\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7124/100000, D Loss: 0.25799710303545, G Loss: 4.227569580078125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7125/100000, D Loss: 0.3595508486032486, G Loss: 3.933382272720337\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7126/100000, D Loss: 0.32500188052654266, G Loss: 4.219977378845215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7127/100000, D Loss: 0.2769964784383774, G Loss: 4.246553421020508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7128/100000, D Loss: 0.3491128087043762, G Loss: 4.3459882736206055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7129/100000, D Loss: 0.24948354810476303, G Loss: 4.631942272186279\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7130/100000, D Loss: 0.2769303619861603, G Loss: 4.008108615875244\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7131/100000, D Loss: 0.29851144552230835, G Loss: 3.786796808242798\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7132/100000, D Loss: 0.271403431892395, G Loss: 4.216536521911621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7133/100000, D Loss: 0.19791214913129807, G Loss: 4.770883560180664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7134/100000, D Loss: 0.21601098030805588, G Loss: 4.258037567138672\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7135/100000, D Loss: 0.23644022643566132, G Loss: 4.168815612792969\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7136/100000, D Loss: 0.15877578407526016, G Loss: 4.496099472045898\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7137/100000, D Loss: 0.15368370711803436, G Loss: 4.79271125793457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7138/100000, D Loss: 0.14359143376350403, G Loss: 4.665838241577148\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7139/100000, D Loss: 0.13356871902942657, G Loss: 4.585751533508301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7140/100000, D Loss: 0.14733144640922546, G Loss: 4.611804008483887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7141/100000, D Loss: 0.12855829298496246, G Loss: 4.639862060546875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7142/100000, D Loss: 0.1409224048256874, G Loss: 4.664244651794434\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7143/100000, D Loss: 0.1333421915769577, G Loss: 4.921600818634033\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7144/100000, D Loss: 0.12593642622232437, G Loss: 4.837179660797119\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7145/100000, D Loss: 0.12438513338565826, G Loss: 4.604564666748047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7146/100000, D Loss: 0.13251705467700958, G Loss: 4.4566850662231445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7147/100000, D Loss: 0.14364559203386307, G Loss: 4.743646621704102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7148/100000, D Loss: 0.16805289685726166, G Loss: 4.713972091674805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7149/100000, D Loss: 0.1757541224360466, G Loss: 4.571854591369629\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7150/100000, D Loss: 0.1792728751897812, G Loss: 4.254968166351318\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7151/100000, D Loss: 0.1867748126387596, G Loss: 4.23722505569458\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7152/100000, D Loss: 0.18451891839504242, G Loss: 4.519316673278809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7153/100000, D Loss: 0.19360729306936264, G Loss: 4.442620277404785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7154/100000, D Loss: 0.23127669095993042, G Loss: 3.9573922157287598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7155/100000, D Loss: 0.21994126588106155, G Loss: 4.2693071365356445\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7156/100000, D Loss: 0.19493651390075684, G Loss: 4.793980598449707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7157/100000, D Loss: 0.2417140081524849, G Loss: 4.376055717468262\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7158/100000, D Loss: 0.2587352991104126, G Loss: 3.975140333175659\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7159/100000, D Loss: 0.17567209154367447, G Loss: 4.388892650604248\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7160/100000, D Loss: 0.23232512921094894, G Loss: 4.36320686340332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7161/100000, D Loss: 0.22911188006401062, G Loss: 4.090672492980957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7162/100000, D Loss: 0.24568121880292892, G Loss: 4.467426300048828\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7163/100000, D Loss: 0.18586498498916626, G Loss: 4.876367568969727\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7164/100000, D Loss: 0.19068294018507004, G Loss: 4.712950229644775\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7165/100000, D Loss: 0.20387568324804306, G Loss: 4.429989814758301\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7166/100000, D Loss: 0.1806740164756775, G Loss: 4.641759872436523\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7167/100000, D Loss: 0.13517331704497337, G Loss: 5.527424335479736\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7168/100000, D Loss: 0.16455086320638657, G Loss: 5.397139549255371\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7169/100000, D Loss: 0.18592850863933563, G Loss: 4.435530185699463\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7170/100000, D Loss: 0.22130727022886276, G Loss: 4.3576741218566895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7171/100000, D Loss: 0.16771183162927628, G Loss: 5.442617416381836\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7172/100000, D Loss: 0.11763187497854233, G Loss: 5.899155139923096\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7173/100000, D Loss: 0.2325192093849182, G Loss: 4.588459014892578\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7174/100000, D Loss: 0.21300652623176575, G Loss: 4.047632217407227\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7175/100000, D Loss: 0.15216322988271713, G Loss: 5.096086502075195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7176/100000, D Loss: 0.20197118818759918, G Loss: 5.279629230499268\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7177/100000, D Loss: 0.22040902078151703, G Loss: 4.539521217346191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7178/100000, D Loss: 0.2213873490691185, G Loss: 4.358988285064697\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7179/100000, D Loss: 0.152370385825634, G Loss: 5.3478312492370605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7180/100000, D Loss: 0.19647832587361336, G Loss: 5.314881801605225\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7181/100000, D Loss: 0.23772411048412323, G Loss: 4.66047477722168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7182/100000, D Loss: 0.2033824920654297, G Loss: 4.754249572753906\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7183/100000, D Loss: 0.1812135875225067, G Loss: 5.1070990562438965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7184/100000, D Loss: 0.19671639055013657, G Loss: 4.960741996765137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7185/100000, D Loss: 0.2278556525707245, G Loss: 4.540074348449707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7186/100000, D Loss: 0.22623919695615768, G Loss: 4.801444053649902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7187/100000, D Loss: 0.17770278453826904, G Loss: 5.023498058319092\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7188/100000, D Loss: 0.2027963101863861, G Loss: 4.986388206481934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7189/100000, D Loss: 0.24115554988384247, G Loss: 4.37369441986084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7190/100000, D Loss: 0.21644078195095062, G Loss: 4.741427421569824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7191/100000, D Loss: 0.23615891486406326, G Loss: 5.049109935760498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7192/100000, D Loss: 0.24309812486171722, G Loss: 4.964358806610107\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7193/100000, D Loss: 0.2796606123447418, G Loss: 4.4197821617126465\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7194/100000, D Loss: 0.24445097893476486, G Loss: 4.404909133911133\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7195/100000, D Loss: 0.30069035291671753, G Loss: 4.44237756729126\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7196/100000, D Loss: 0.23837315291166306, G Loss: 4.763354778289795\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7197/100000, D Loss: 0.26638472080230713, G Loss: 4.528736114501953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7198/100000, D Loss: 0.3000050038099289, G Loss: 4.1653523445129395\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7199/100000, D Loss: 0.27573931217193604, G Loss: 4.196573734283447\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7200/100000, D Loss: 0.32231855392456055, G Loss: 4.536006927490234\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7201/100000, D Loss: 0.27033621072769165, G Loss: 4.437423229217529\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7202/100000, D Loss: 0.31643885374069214, G Loss: 4.066535949707031\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7203/100000, D Loss: 0.29403991997241974, G Loss: 4.614754676818848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7204/100000, D Loss: 0.2772964611649513, G Loss: 4.474358558654785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7205/100000, D Loss: 0.27694110572338104, G Loss: 4.373120307922363\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7206/100000, D Loss: 0.27777189761400223, G Loss: 4.29609489440918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7207/100000, D Loss: 0.2544074207544327, G Loss: 4.4051947593688965\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7208/100000, D Loss: 0.2398408278822899, G Loss: 4.754321098327637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7209/100000, D Loss: 0.2056439109146595, G Loss: 4.523997783660889\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7210/100000, D Loss: 0.23862726986408234, G Loss: 3.9479422569274902\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7211/100000, D Loss: 0.20763246715068817, G Loss: 4.509181976318359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7212/100000, D Loss: 0.156947523355484, G Loss: 5.0895795822143555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7213/100000, D Loss: 0.18699576705694199, G Loss: 4.782576560974121\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7214/100000, D Loss: 0.21756426990032196, G Loss: 4.458982944488525\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7215/100000, D Loss: 0.18205838650465012, G Loss: 4.536983489990234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7216/100000, D Loss: 0.15872564166784286, G Loss: 4.736827373504639\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7217/100000, D Loss: 0.17933597415685654, G Loss: 4.466440677642822\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7218/100000, D Loss: 0.20616362243890762, G Loss: 4.558333396911621\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7219/100000, D Loss: 0.1508498713374138, G Loss: 4.8889031410217285\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7220/100000, D Loss: 0.17431293055415154, G Loss: 4.851805686950684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7221/100000, D Loss: 0.1987653151154518, G Loss: 4.371894836425781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7222/100000, D Loss: 0.17060552537441254, G Loss: 4.403172492980957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7223/100000, D Loss: 0.1705668643116951, G Loss: 4.743239402770996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7224/100000, D Loss: 0.16135024279356003, G Loss: 5.0795578956604\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7225/100000, D Loss: 0.1418461725115776, G Loss: 4.998262405395508\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7226/100000, D Loss: 0.15536177158355713, G Loss: 4.719970703125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7227/100000, D Loss: 0.1294580101966858, G Loss: 4.966235637664795\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7228/100000, D Loss: 0.13669344037771225, G Loss: 4.920910358428955\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7229/100000, D Loss: 0.1563963145017624, G Loss: 4.810468673706055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7230/100000, D Loss: 0.14071035385131836, G Loss: 4.739588737487793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7231/100000, D Loss: 0.15567253530025482, G Loss: 4.572521209716797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7232/100000, D Loss: 0.14124171435832977, G Loss: 4.735591888427734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7233/100000, D Loss: 0.13342827558517456, G Loss: 5.014931678771973\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7234/100000, D Loss: 0.14842302352190018, G Loss: 4.9101362228393555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7235/100000, D Loss: 0.1564432755112648, G Loss: 4.492366790771484\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7236/100000, D Loss: 0.15670114755630493, G Loss: 4.5609636306762695\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7237/100000, D Loss: 0.137625303119421, G Loss: 4.873766899108887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7238/100000, D Loss: 0.1346196047961712, G Loss: 5.100083827972412\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7239/100000, D Loss: 0.15658168122172356, G Loss: 4.603081703186035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7240/100000, D Loss: 0.16765481233596802, G Loss: 4.386435508728027\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7241/100000, D Loss: 0.1655280441045761, G Loss: 4.598189830780029\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7242/100000, D Loss: 0.17519189417362213, G Loss: 5.069135665893555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7243/100000, D Loss: 0.20702426135540009, G Loss: 4.4648613929748535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7244/100000, D Loss: 0.21088414639234543, G Loss: 4.08668327331543\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7245/100000, D Loss: 0.17790458351373672, G Loss: 4.372023582458496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7246/100000, D Loss: 0.18375302106142044, G Loss: 4.705347061157227\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7247/100000, D Loss: 0.19392834603786469, G Loss: 4.471750736236572\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7248/100000, D Loss: 0.2161225900053978, G Loss: 4.3233489990234375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7249/100000, D Loss: 0.21838686615228653, G Loss: 4.215863227844238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7250/100000, D Loss: 0.19740141183137894, G Loss: 4.441500663757324\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7251/100000, D Loss: 0.23870766907930374, G Loss: 4.222531795501709\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7252/100000, D Loss: 0.25499964505434036, G Loss: 4.156070709228516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7253/100000, D Loss: 0.23596029728651047, G Loss: 4.389944076538086\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7254/100000, D Loss: 0.26983774453401566, G Loss: 4.402525424957275\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7255/100000, D Loss: 0.25899282842874527, G Loss: 4.248232841491699\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7256/100000, D Loss: 0.2732681781053543, G Loss: 4.2501301765441895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7257/100000, D Loss: 0.30770038068294525, G Loss: 4.271116256713867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7258/100000, D Loss: 0.2676505073904991, G Loss: 4.29841423034668\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7259/100000, D Loss: 0.28385328501462936, G Loss: 4.275335311889648\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7260/100000, D Loss: 0.24863845109939575, G Loss: 4.507322788238525\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7261/100000, D Loss: 0.27149226516485214, G Loss: 4.331329345703125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7262/100000, D Loss: 0.3260648250579834, G Loss: 4.040894508361816\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7263/100000, D Loss: 0.2709661275148392, G Loss: 4.352297782897949\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7264/100000, D Loss: 0.2758106291294098, G Loss: 4.542945861816406\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7265/100000, D Loss: 0.2769164815545082, G Loss: 4.501496315002441\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7266/100000, D Loss: 0.3047259598970413, G Loss: 4.179192066192627\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7267/100000, D Loss: 0.3280307352542877, G Loss: 4.3776655197143555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7268/100000, D Loss: 0.28677625209093094, G Loss: 4.713846683502197\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7269/100000, D Loss: 0.2906242907047272, G Loss: 4.232510089874268\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7270/100000, D Loss: 0.29426583647727966, G Loss: 4.166813850402832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7271/100000, D Loss: 0.26776282489299774, G Loss: 4.370283126831055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7272/100000, D Loss: 0.34743596613407135, G Loss: 4.232090950012207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7273/100000, D Loss: 0.24247083067893982, G Loss: 4.345269203186035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7274/100000, D Loss: 0.24366053938865662, G Loss: 4.437841415405273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7275/100000, D Loss: 0.24644017219543457, G Loss: 4.441758155822754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7276/100000, D Loss: 0.20673146843910217, G Loss: 4.66246223449707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7277/100000, D Loss: 0.18555143475532532, G Loss: 4.7422404289245605\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7278/100000, D Loss: 0.15291515737771988, G Loss: 4.938780784606934\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7279/100000, D Loss: 0.14076782763004303, G Loss: 4.942618370056152\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7280/100000, D Loss: 0.12079557031393051, G Loss: 5.093221664428711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7281/100000, D Loss: 0.11275333538651466, G Loss: 5.079868793487549\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7282/100000, D Loss: 0.10775304585695267, G Loss: 5.131341934204102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7283/100000, D Loss: 0.09823036566376686, G Loss: 4.848507881164551\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7284/100000, D Loss: 0.11341044306755066, G Loss: 5.146456718444824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7285/100000, D Loss: 0.10038022696971893, G Loss: 5.122372627258301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7286/100000, D Loss: 0.0979188084602356, G Loss: 5.051599502563477\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7287/100000, D Loss: 0.11789947375655174, G Loss: 5.190006732940674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7288/100000, D Loss: 0.11944340914487839, G Loss: 5.095949172973633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7289/100000, D Loss: 0.12394325062632561, G Loss: 4.998943328857422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7290/100000, D Loss: 0.13994062691926956, G Loss: 4.604377746582031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7291/100000, D Loss: 0.15418174862861633, G Loss: 4.913438320159912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7292/100000, D Loss: 0.1307171918451786, G Loss: 5.180651664733887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7293/100000, D Loss: 0.17059413343667984, G Loss: 4.672170162200928\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7294/100000, D Loss: 0.18752848356962204, G Loss: 4.412992477416992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7295/100000, D Loss: 0.140372596681118, G Loss: 4.721922397613525\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7296/100000, D Loss: 0.161385677754879, G Loss: 4.6079301834106445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7297/100000, D Loss: 0.18212641775608063, G Loss: 4.520046234130859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7298/100000, D Loss: 0.19321762025356293, G Loss: 4.661434173583984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7299/100000, D Loss: 0.18129733204841614, G Loss: 4.7425923347473145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7300/100000, D Loss: 0.24007799476385117, G Loss: 4.404101848602295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7301/100000, D Loss: 0.23233158141374588, G Loss: 4.3547210693359375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7302/100000, D Loss: 0.19749602675437927, G Loss: 5.154308319091797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7303/100000, D Loss: 0.2148309201002121, G Loss: 4.900629997253418\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7304/100000, D Loss: 0.2578330487012863, G Loss: 4.384917259216309\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7305/100000, D Loss: 0.25690731406211853, G Loss: 4.607790946960449\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7306/100000, D Loss: 0.21703987568616867, G Loss: 4.939364433288574\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7307/100000, D Loss: 0.2595718055963516, G Loss: 4.412221431732178\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7308/100000, D Loss: 0.27216963469982147, G Loss: 4.328990459442139\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7309/100000, D Loss: 0.23050571978092194, G Loss: 5.035626411437988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7310/100000, D Loss: 0.27182188630104065, G Loss: 4.5208587646484375\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7311/100000, D Loss: 0.2818547785282135, G Loss: 4.374095439910889\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7312/100000, D Loss: 0.25310516357421875, G Loss: 4.415126800537109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7313/100000, D Loss: 0.28695616126060486, G Loss: 4.431922435760498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7314/100000, D Loss: 0.28276199102401733, G Loss: 4.554994106292725\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7315/100000, D Loss: 0.30214936286211014, G Loss: 4.246601581573486\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7316/100000, D Loss: 0.28911125659942627, G Loss: 4.393874168395996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7317/100000, D Loss: 0.24638064205646515, G Loss: 4.490213394165039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7318/100000, D Loss: 0.3120761811733246, G Loss: 4.293691158294678\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7319/100000, D Loss: 0.27800023555755615, G Loss: 4.324345588684082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7320/100000, D Loss: 0.30383650958538055, G Loss: 4.450478553771973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7321/100000, D Loss: 0.2564935013651848, G Loss: 4.709506988525391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7322/100000, D Loss: 0.22722788900136948, G Loss: 4.397960662841797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7323/100000, D Loss: 0.21145302802324295, G Loss: 4.334480285644531\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7324/100000, D Loss: 0.2283664345741272, G Loss: 4.421574592590332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7325/100000, D Loss: 0.16951553523540497, G Loss: 4.711597442626953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7326/100000, D Loss: 0.1788736656308174, G Loss: 4.715937614440918\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7327/100000, D Loss: 0.15620124340057373, G Loss: 4.562678337097168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7328/100000, D Loss: 0.14012624323368073, G Loss: 4.771474361419678\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7329/100000, D Loss: 0.12802935019135475, G Loss: 4.86201810836792\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7330/100000, D Loss: 0.1603606715798378, G Loss: 4.832721710205078\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7331/100000, D Loss: 0.16001571714878082, G Loss: 4.669687747955322\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7332/100000, D Loss: 0.13465793430805206, G Loss: 4.93707799911499\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7333/100000, D Loss: 0.12335152924060822, G Loss: 5.048530101776123\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7334/100000, D Loss: 0.16035949811339378, G Loss: 4.670405864715576\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7335/100000, D Loss: 0.13457994163036346, G Loss: 4.81393575668335\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7336/100000, D Loss: 0.1760200522840023, G Loss: 4.793229103088379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7337/100000, D Loss: 0.1308659166097641, G Loss: 4.82136344909668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7338/100000, D Loss: 0.13524651527404785, G Loss: 4.6674604415893555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7339/100000, D Loss: 0.1619786024093628, G Loss: 4.644867420196533\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7340/100000, D Loss: 0.14136697351932526, G Loss: 4.694889068603516\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7341/100000, D Loss: 0.14161987602710724, G Loss: 4.844507217407227\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7342/100000, D Loss: 0.14090482145547867, G Loss: 4.520747661590576\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7343/100000, D Loss: 0.1768108308315277, G Loss: 4.3742475509643555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7344/100000, D Loss: 0.19345606863498688, G Loss: 4.483794689178467\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7345/100000, D Loss: 0.15511712804436684, G Loss: 5.086371898651123\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7346/100000, D Loss: 0.1685827262699604, G Loss: 4.578563690185547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7347/100000, D Loss: 0.19059770554304123, G Loss: 4.0828657150268555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7348/100000, D Loss: 0.1613195240497589, G Loss: 4.430185317993164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7349/100000, D Loss: 0.15839751809835434, G Loss: 4.986931800842285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7350/100000, D Loss: 0.16839895397424698, G Loss: 4.68966007232666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7351/100000, D Loss: 0.19632137566804886, G Loss: 3.9713799953460693\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7352/100000, D Loss: 0.20987935364246368, G Loss: 4.422609329223633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7353/100000, D Loss: 0.1643478274345398, G Loss: 4.933527946472168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7354/100000, D Loss: 0.22241565585136414, G Loss: 4.425779342651367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7355/100000, D Loss: 0.23657619953155518, G Loss: 3.8660061359405518\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7356/100000, D Loss: 0.20350946485996246, G Loss: 4.313802242279053\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7357/100000, D Loss: 0.20845141261816025, G Loss: 4.6034955978393555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7358/100000, D Loss: 0.24759067595005035, G Loss: 4.036272048950195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7359/100000, D Loss: 0.24110420048236847, G Loss: 4.086263179779053\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7360/100000, D Loss: 0.1701950505375862, G Loss: 4.784255027770996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7361/100000, D Loss: 0.2454107701778412, G Loss: 4.227620601654053\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7362/100000, D Loss: 0.2596531808376312, G Loss: 3.788018226623535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7363/100000, D Loss: 0.23097197711467743, G Loss: 4.135212421417236\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7364/100000, D Loss: 0.2080589383840561, G Loss: 4.373456954956055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7365/100000, D Loss: 0.2518107444047928, G Loss: 4.196474552154541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7366/100000, D Loss: 0.20467650890350342, G Loss: 4.057821273803711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7367/100000, D Loss: 0.2236630916595459, G Loss: 4.168498992919922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7368/100000, D Loss: 0.1993444338440895, G Loss: 4.432307243347168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7369/100000, D Loss: 0.20050828158855438, G Loss: 4.3985276222229\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7370/100000, D Loss: 0.1863551363348961, G Loss: 4.329857349395752\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7371/100000, D Loss: 0.18742735683918, G Loss: 4.549136638641357\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7372/100000, D Loss: 0.19073965400457382, G Loss: 4.508281707763672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7373/100000, D Loss: 0.1701999306678772, G Loss: 4.356528282165527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7374/100000, D Loss: 0.18262960761785507, G Loss: 4.387126922607422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7375/100000, D Loss: 0.17506995052099228, G Loss: 4.500301837921143\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7376/100000, D Loss: 0.1775270774960518, G Loss: 4.656858921051025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7377/100000, D Loss: 0.17737478762865067, G Loss: 4.624467372894287\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7378/100000, D Loss: 0.17477939277887344, G Loss: 4.596893787384033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7379/100000, D Loss: 0.17451179027557373, G Loss: 4.464722633361816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7380/100000, D Loss: 0.21629921346902847, G Loss: 4.341187477111816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7381/100000, D Loss: 0.14301691949367523, G Loss: 4.652495384216309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7382/100000, D Loss: 0.19741403311491013, G Loss: 4.549739837646484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7383/100000, D Loss: 0.23111920058727264, G Loss: 4.423651218414307\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7384/100000, D Loss: 0.16825219988822937, G Loss: 4.367013931274414\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7385/100000, D Loss: 0.20478440821170807, G Loss: 4.61357307434082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7386/100000, D Loss: 0.18829485028982162, G Loss: 4.761439800262451\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7387/100000, D Loss: 0.22030946612358093, G Loss: 4.612131118774414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7388/100000, D Loss: 0.16703124344348907, G Loss: 4.624417781829834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7389/100000, D Loss: 0.16838140785694122, G Loss: 4.495011329650879\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7390/100000, D Loss: 0.167850062251091, G Loss: 4.718622207641602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7391/100000, D Loss: 0.14901867508888245, G Loss: 4.518399238586426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7392/100000, D Loss: 0.1746814250946045, G Loss: 4.479053497314453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7393/100000, D Loss: 0.18248970806598663, G Loss: 4.633218765258789\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7394/100000, D Loss: 0.18788158893585205, G Loss: 4.652101516723633\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7395/100000, D Loss: 0.18818364292383194, G Loss: 4.623984336853027\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7396/100000, D Loss: 0.17435616999864578, G Loss: 4.305367469787598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7397/100000, D Loss: 0.19146728515625, G Loss: 4.342106819152832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7398/100000, D Loss: 0.1770026683807373, G Loss: 4.3450212478637695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7399/100000, D Loss: 0.1929675117135048, G Loss: 4.392374038696289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7400/100000, D Loss: 0.18382078409194946, G Loss: 4.608504772186279\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7401/100000, D Loss: 0.17955800890922546, G Loss: 4.556224822998047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7402/100000, D Loss: 0.1953536793589592, G Loss: 4.347181797027588\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7403/100000, D Loss: 0.1699511706829071, G Loss: 4.464633941650391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7404/100000, D Loss: 0.16662446409463882, G Loss: 4.709207534790039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7405/100000, D Loss: 0.17601358890533447, G Loss: 4.3644609451293945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7406/100000, D Loss: 0.18895593285560608, G Loss: 4.34058952331543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7407/100000, D Loss: 0.18129543960094452, G Loss: 4.597324371337891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7408/100000, D Loss: 0.16655417531728745, G Loss: 4.653115272521973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7409/100000, D Loss: 0.17903009802103043, G Loss: 4.466342926025391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7410/100000, D Loss: 0.16722629219293594, G Loss: 4.530145645141602\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7411/100000, D Loss: 0.17554671317338943, G Loss: 4.637717247009277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7412/100000, D Loss: 0.15873268246650696, G Loss: 4.730264663696289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7413/100000, D Loss: 0.17892275750637054, G Loss: 4.636728763580322\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7414/100000, D Loss: 0.16579756140708923, G Loss: 4.595972061157227\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7415/100000, D Loss: 0.1654309332370758, G Loss: 4.869317054748535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7416/100000, D Loss: 0.15106619894504547, G Loss: 4.976940155029297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7417/100000, D Loss: 0.1757919266819954, G Loss: 4.94383430480957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7418/100000, D Loss: 0.19486504048109055, G Loss: 4.713608741760254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7419/100000, D Loss: 0.18126491457223892, G Loss: 4.8287248611450195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7420/100000, D Loss: 0.18656735867261887, G Loss: 4.930776596069336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7421/100000, D Loss: 0.18562840670347214, G Loss: 4.823688507080078\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7422/100000, D Loss: 0.17991884797811508, G Loss: 5.098836898803711\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7423/100000, D Loss: 0.17504394054412842, G Loss: 4.994685173034668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7424/100000, D Loss: 0.1735941395163536, G Loss: 5.092077255249023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7425/100000, D Loss: 0.1773814558982849, G Loss: 5.22210168838501\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7426/100000, D Loss: 0.15986273437738419, G Loss: 5.165002822875977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7427/100000, D Loss: 0.1824559047818184, G Loss: 4.912919998168945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7428/100000, D Loss: 0.19829006493091583, G Loss: 4.820116996765137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7429/100000, D Loss: 0.1827748417854309, G Loss: 5.135494232177734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7430/100000, D Loss: 0.1952858343720436, G Loss: 5.136563301086426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7431/100000, D Loss: 0.20297759771347046, G Loss: 4.725849151611328\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7432/100000, D Loss: 0.24558264762163162, G Loss: 4.608857154846191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7433/100000, D Loss: 0.20501583814620972, G Loss: 4.924112796783447\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7434/100000, D Loss: 0.20826318860054016, G Loss: 4.903330326080322\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7435/100000, D Loss: 0.25632520765066147, G Loss: 4.747223854064941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7436/100000, D Loss: 0.218690425157547, G Loss: 5.134283065795898\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7437/100000, D Loss: 0.2040264829993248, G Loss: 5.253375053405762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7438/100000, D Loss: 0.21359889209270477, G Loss: 5.287813186645508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7439/100000, D Loss: 0.23158209770917892, G Loss: 5.052169322967529\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7440/100000, D Loss: 0.2677931785583496, G Loss: 4.899420738220215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7441/100000, D Loss: 0.20226583629846573, G Loss: 5.446599006652832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7442/100000, D Loss: 0.24632403999567032, G Loss: 5.14445161819458\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7443/100000, D Loss: 0.2538207992911339, G Loss: 4.677734851837158\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7444/100000, D Loss: 0.21055320650339127, G Loss: 5.131878852844238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7445/100000, D Loss: 0.20570868998765945, G Loss: 5.624853610992432\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7446/100000, D Loss: 0.2285689264535904, G Loss: 5.148931503295898\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7447/100000, D Loss: 0.23762734234333038, G Loss: 4.460865020751953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7448/100000, D Loss: 0.21440282464027405, G Loss: 4.94041633605957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7449/100000, D Loss: 0.22713899612426758, G Loss: 5.327648162841797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7450/100000, D Loss: 0.23112554848194122, G Loss: 4.855473518371582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7451/100000, D Loss: 0.27751610428094864, G Loss: 4.609930992126465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7452/100000, D Loss: 0.20748752355575562, G Loss: 4.927655220031738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7453/100000, D Loss: 0.22555600851774216, G Loss: 5.221482753753662\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7454/100000, D Loss: 0.1603604443371296, G Loss: 5.059222221374512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7455/100000, D Loss: 0.23887547850608826, G Loss: 4.236122131347656\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7456/100000, D Loss: 0.21430954337120056, G Loss: 4.4359235763549805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7457/100000, D Loss: 0.21172606199979782, G Loss: 5.067807674407959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7458/100000, D Loss: 0.21307332068681717, G Loss: 4.909909248352051\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7459/100000, D Loss: 0.2440364584326744, G Loss: 4.159382343292236\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7460/100000, D Loss: 0.21896522492170334, G Loss: 4.238603115081787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7461/100000, D Loss: 0.159147247672081, G Loss: 4.610292434692383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7462/100000, D Loss: 0.20525666326284409, G Loss: 4.647562026977539\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7463/100000, D Loss: 0.16279026865959167, G Loss: 4.780450344085693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7464/100000, D Loss: 0.1735595241189003, G Loss: 4.714513301849365\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7465/100000, D Loss: 0.15996365249156952, G Loss: 4.852621078491211\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7466/100000, D Loss: 0.14561496302485466, G Loss: 4.931213855743408\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7467/100000, D Loss: 0.1290336176753044, G Loss: 4.669681549072266\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7468/100000, D Loss: 0.13381467014551163, G Loss: 4.982210159301758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7469/100000, D Loss: 0.1320059709250927, G Loss: 5.075803279876709\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7470/100000, D Loss: 0.1271965578198433, G Loss: 5.104170799255371\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7471/100000, D Loss: 0.1271979883313179, G Loss: 5.105056285858154\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7472/100000, D Loss: 0.11896120756864548, G Loss: 4.791813373565674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7473/100000, D Loss: 0.14297562465071678, G Loss: 5.058972358703613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7474/100000, D Loss: 0.13246170431375504, G Loss: 5.242214202880859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7475/100000, D Loss: 0.15664539858698845, G Loss: 4.97719669342041\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7476/100000, D Loss: 0.1707264855504036, G Loss: 4.6307830810546875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7477/100000, D Loss: 0.19908872991800308, G Loss: 4.2544403076171875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7478/100000, D Loss: 0.15869659185409546, G Loss: 4.889208793640137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7479/100000, D Loss: 0.14888432249426842, G Loss: 5.246528148651123\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7480/100000, D Loss: 0.2148124948143959, G Loss: 4.606712341308594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7481/100000, D Loss: 0.2396770343184471, G Loss: 4.188387870788574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7482/100000, D Loss: 0.2195277065038681, G Loss: 4.477151393890381\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7483/100000, D Loss: 0.20552107691764832, G Loss: 4.928256034851074\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7484/100000, D Loss: 0.26272280514240265, G Loss: 4.364400386810303\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7485/100000, D Loss: 0.28405648469924927, G Loss: 4.098537921905518\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7486/100000, D Loss: 0.2400057688355446, G Loss: 4.297497272491455\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7487/100000, D Loss: 0.254271924495697, G Loss: 4.54168701171875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7488/100000, D Loss: 0.2460600659251213, G Loss: 4.398058891296387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7489/100000, D Loss: 0.23542968928813934, G Loss: 4.453876972198486\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7490/100000, D Loss: 0.19331245869398117, G Loss: 5.036506175994873\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7491/100000, D Loss: 0.18594902753829956, G Loss: 5.054661750793457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7492/100000, D Loss: 0.22072288393974304, G Loss: 4.594020843505859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7493/100000, D Loss: 0.21047788113355637, G Loss: 4.531825065612793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7494/100000, D Loss: 0.2029864266514778, G Loss: 4.824585437774658\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7495/100000, D Loss: 0.16316330432891846, G Loss: 5.188521862030029\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7496/100000, D Loss: 0.1890777125954628, G Loss: 4.695686340332031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7497/100000, D Loss: 0.247129887342453, G Loss: 4.211188793182373\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7498/100000, D Loss: 0.22769120335578918, G Loss: 4.540575981140137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7499/100000, D Loss: 0.2237137258052826, G Loss: 4.739508152008057\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7500/100000, D Loss: 0.2665211856365204, G Loss: 4.310728073120117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7501/100000, D Loss: 0.27439945936203003, G Loss: 4.318213939666748\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7502/100000, D Loss: 0.30020947754383087, G Loss: 4.329136848449707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7503/100000, D Loss: 0.3247084468603134, G Loss: 4.343695640563965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7504/100000, D Loss: 0.2965843081474304, G Loss: 4.484785079956055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7505/100000, D Loss: 0.3046901524066925, G Loss: 4.239906311035156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7506/100000, D Loss: 0.2788223773241043, G Loss: 4.219654083251953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7507/100000, D Loss: 0.25581688433885574, G Loss: 4.643908977508545\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7508/100000, D Loss: 0.200266033411026, G Loss: 5.084628105163574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7509/100000, D Loss: 0.2247239127755165, G Loss: 4.425163269042969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7510/100000, D Loss: 0.20754767954349518, G Loss: 4.434233665466309\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7511/100000, D Loss: 0.17198070883750916, G Loss: 4.973832130432129\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7512/100000, D Loss: 0.13486584275960922, G Loss: 5.4108991622924805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7513/100000, D Loss: 0.12930728122591972, G Loss: 5.404114723205566\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7514/100000, D Loss: 0.172377310693264, G Loss: 4.716626167297363\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7515/100000, D Loss: 0.14835722371935844, G Loss: 4.972657680511475\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7516/100000, D Loss: 0.11765481531620026, G Loss: 5.576674461364746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7517/100000, D Loss: 0.14290359616279602, G Loss: 5.399221420288086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7518/100000, D Loss: 0.15390633046627045, G Loss: 5.0902018547058105\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7519/100000, D Loss: 0.15764471888542175, G Loss: 5.035186767578125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7520/100000, D Loss: 0.14395881444215775, G Loss: 5.376229286193848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7521/100000, D Loss: 0.14171507209539413, G Loss: 5.5248565673828125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7522/100000, D Loss: 0.1578298956155777, G Loss: 5.010997295379639\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7523/100000, D Loss: 0.16669956594705582, G Loss: 4.840451717376709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7524/100000, D Loss: 0.18087683618068695, G Loss: 4.881954193115234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7525/100000, D Loss: 0.1935453563928604, G Loss: 5.054420471191406\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7526/100000, D Loss: 0.18526962399482727, G Loss: 5.215559959411621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7527/100000, D Loss: 0.18869858980178833, G Loss: 5.10367488861084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7528/100000, D Loss: 0.1733381152153015, G Loss: 4.782947063446045\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7529/100000, D Loss: 0.18851883709430695, G Loss: 4.411127090454102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7530/100000, D Loss: 0.18370148539543152, G Loss: 4.759060859680176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7531/100000, D Loss: 0.1999053731560707, G Loss: 5.181192874908447\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7532/100000, D Loss: 0.21093104779720306, G Loss: 5.068757057189941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7533/100000, D Loss: 0.25852228701114655, G Loss: 4.5440263748168945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7534/100000, D Loss: 0.2561589479446411, G Loss: 4.579572677612305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7535/100000, D Loss: 0.19118638336658478, G Loss: 5.116267681121826\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7536/100000, D Loss: 0.24304375052452087, G Loss: 4.850149631500244\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7537/100000, D Loss: 0.3089112341403961, G Loss: 4.281971454620361\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7538/100000, D Loss: 0.2733980640769005, G Loss: 4.542064666748047\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7539/100000, D Loss: 0.22636361420154572, G Loss: 4.847253799438477\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7540/100000, D Loss: 0.3043174147605896, G Loss: 4.398715972900391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7541/100000, D Loss: 0.27083293348550797, G Loss: 4.461614608764648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7542/100000, D Loss: 0.2523231506347656, G Loss: 4.629211902618408\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7543/100000, D Loss: 0.29675786197185516, G Loss: 4.487688064575195\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7544/100000, D Loss: 0.256934255361557, G Loss: 4.316579818725586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7545/100000, D Loss: 0.3027959167957306, G Loss: 4.440471649169922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7546/100000, D Loss: 0.25553686916828156, G Loss: 4.639659881591797\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7547/100000, D Loss: 0.2202717587351799, G Loss: 4.730847358703613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7548/100000, D Loss: 0.20513181388378143, G Loss: 4.256976127624512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7549/100000, D Loss: 0.22293119132518768, G Loss: 4.285297870635986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7550/100000, D Loss: 0.20664732158184052, G Loss: 4.864166259765625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7551/100000, D Loss: 0.23331549763679504, G Loss: 4.704245567321777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7552/100000, D Loss: 0.2492348849773407, G Loss: 4.23526668548584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7553/100000, D Loss: 0.2315780594944954, G Loss: 4.708562850952148\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7554/100000, D Loss: 0.15834563225507736, G Loss: 5.478394985198975\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7555/100000, D Loss: 0.2037024386227131, G Loss: 4.962334632873535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7556/100000, D Loss: 0.18045534193515778, G Loss: 4.623964309692383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7557/100000, D Loss: 0.12717563658952713, G Loss: 5.00043249130249\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7558/100000, D Loss: 0.11815003678202629, G Loss: 5.443710803985596\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7559/100000, D Loss: 0.13996824622154236, G Loss: 5.383059024810791\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7560/100000, D Loss: 0.1370692066848278, G Loss: 4.775294303894043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7561/100000, D Loss: 0.11752793192863464, G Loss: 4.974668502807617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7562/100000, D Loss: 0.122111476957798, G Loss: 5.112090587615967\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7563/100000, D Loss: 0.10899528861045837, G Loss: 5.343581199645996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7564/100000, D Loss: 0.1162612996995449, G Loss: 5.270782947540283\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7565/100000, D Loss: 0.13845081254839897, G Loss: 4.897685527801514\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7566/100000, D Loss: 0.1140359491109848, G Loss: 4.91313362121582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7567/100000, D Loss: 0.13244591653347015, G Loss: 5.130683422088623\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7568/100000, D Loss: 0.1491691991686821, G Loss: 5.207688331604004\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7569/100000, D Loss: 0.1583988294005394, G Loss: 5.0227766036987305\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7570/100000, D Loss: 0.1449660323560238, G Loss: 4.734452724456787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7571/100000, D Loss: 0.17415517568588257, G Loss: 4.511824607849121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7572/100000, D Loss: 0.16731539368629456, G Loss: 4.870820045471191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7573/100000, D Loss: 0.13303175568580627, G Loss: 5.165104866027832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7574/100000, D Loss: 0.17584951221942902, G Loss: 4.699556350708008\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7575/100000, D Loss: 0.2204899936914444, G Loss: 4.563721179962158\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7576/100000, D Loss: 0.18169333785772324, G Loss: 4.828029632568359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7577/100000, D Loss: 0.21063193678855896, G Loss: 4.561056137084961\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7578/100000, D Loss: 0.2543896436691284, G Loss: 4.1522626876831055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7579/100000, D Loss: 0.24236392974853516, G Loss: 4.537328243255615\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7580/100000, D Loss: 0.2559114396572113, G Loss: 4.530264854431152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7581/100000, D Loss: 0.3636571913957596, G Loss: 3.867953300476074\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7582/100000, D Loss: 0.38660354912281036, G Loss: 4.128293514251709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7583/100000, D Loss: 0.3299361914396286, G Loss: 4.553434371948242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7584/100000, D Loss: 0.367121085524559, G Loss: 4.1202311515808105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7585/100000, D Loss: 0.3431619852781296, G Loss: 4.2320051193237305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7586/100000, D Loss: 0.35011571645736694, G Loss: 4.112557888031006\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7587/100000, D Loss: 0.3804546445608139, G Loss: 4.139676094055176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7588/100000, D Loss: 0.3309473693370819, G Loss: 4.441460132598877\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7589/100000, D Loss: 0.3248545378446579, G Loss: 4.200404167175293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7590/100000, D Loss: 0.3343598544597626, G Loss: 4.326422691345215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7591/100000, D Loss: 0.3019949719309807, G Loss: 4.14365291595459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7592/100000, D Loss: 0.2706279456615448, G Loss: 4.432492256164551\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7593/100000, D Loss: 0.2151055932044983, G Loss: 4.607999324798584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7594/100000, D Loss: 0.2551840990781784, G Loss: 4.495506286621094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7595/100000, D Loss: 0.28840988874435425, G Loss: 4.088346004486084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7596/100000, D Loss: 0.21851031482219696, G Loss: 4.561819553375244\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7597/100000, D Loss: 0.24268703162670135, G Loss: 4.625711917877197\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7598/100000, D Loss: 0.2626260668039322, G Loss: 4.412647247314453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7599/100000, D Loss: 0.21418941020965576, G Loss: 4.43067741394043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7600/100000, D Loss: 0.17098210006952286, G Loss: 4.8655686378479\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7601/100000, D Loss: 0.24231435358524323, G Loss: 4.289463996887207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7602/100000, D Loss: 0.1886594519019127, G Loss: 4.380146026611328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7603/100000, D Loss: 0.19362132251262665, G Loss: 4.7162933349609375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7604/100000, D Loss: 0.1875830888748169, G Loss: 4.69019079208374\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7605/100000, D Loss: 0.18449123203754425, G Loss: 4.244997978210449\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7606/100000, D Loss: 0.20095331221818924, G Loss: 4.361617565155029\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7607/100000, D Loss: 0.17744813859462738, G Loss: 4.5876078605651855\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7608/100000, D Loss: 0.19699176400899887, G Loss: 4.414496421813965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7609/100000, D Loss: 0.17088142037391663, G Loss: 4.68531608581543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7610/100000, D Loss: 0.19890502095222473, G Loss: 4.231837749481201\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7611/100000, D Loss: 0.18066518008708954, G Loss: 4.248517036437988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7612/100000, D Loss: 0.1754978746175766, G Loss: 4.365919589996338\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7613/100000, D Loss: 0.17887714505195618, G Loss: 4.599351406097412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7614/100000, D Loss: 0.17803777009248734, G Loss: 4.432892799377441\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7615/100000, D Loss: 0.21945367008447647, G Loss: 4.070582866668701\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7616/100000, D Loss: 0.22514895349740982, G Loss: 4.2602996826171875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7617/100000, D Loss: 0.19786305725574493, G Loss: 4.765771865844727\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7618/100000, D Loss: 0.21707714721560478, G Loss: 4.166694641113281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7619/100000, D Loss: 0.21055449545383453, G Loss: 4.0922040939331055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7620/100000, D Loss: 0.2189699485898018, G Loss: 4.370521545410156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7621/100000, D Loss: 0.1993626207113266, G Loss: 4.282334327697754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7622/100000, D Loss: 0.2671816200017929, G Loss: 3.894711494445801\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7623/100000, D Loss: 0.2347312718629837, G Loss: 4.225914001464844\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7624/100000, D Loss: 0.23839979618787766, G Loss: 4.521803855895996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7625/100000, D Loss: 0.2700868397951126, G Loss: 4.039770126342773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7626/100000, D Loss: 0.24435360729694366, G Loss: 3.999159574508667\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7627/100000, D Loss: 0.24289020895957947, G Loss: 4.096348285675049\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7628/100000, D Loss: 0.2648773044347763, G Loss: 4.099409580230713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7629/100000, D Loss: 0.28325675427913666, G Loss: 4.029073715209961\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7630/100000, D Loss: 0.26614274084568024, G Loss: 4.140605449676514\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7631/100000, D Loss: 0.30075450241565704, G Loss: 4.274043083190918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7632/100000, D Loss: 0.24965057522058487, G Loss: 4.087161064147949\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7633/100000, D Loss: 0.29015278816223145, G Loss: 3.9071342945098877\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7634/100000, D Loss: 0.2215839847922325, G Loss: 4.249733924865723\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7635/100000, D Loss: 0.21794479340314865, G Loss: 4.386852264404297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7636/100000, D Loss: 0.22920966893434525, G Loss: 4.123354911804199\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7637/100000, D Loss: 0.27524325251579285, G Loss: 3.919820785522461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7638/100000, D Loss: 0.22670119255781174, G Loss: 4.103235244750977\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7639/100000, D Loss: 0.23322489857673645, G Loss: 4.2785844802856445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7640/100000, D Loss: 0.23276247829198837, G Loss: 4.332996845245361\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7641/100000, D Loss: 0.27877648174762726, G Loss: 4.127596855163574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7642/100000, D Loss: 0.26884666085243225, G Loss: 4.249794006347656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7643/100000, D Loss: 0.23433973640203476, G Loss: 4.527013778686523\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7644/100000, D Loss: 0.23243331909179688, G Loss: 4.604568004608154\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7645/100000, D Loss: 0.281005822122097, G Loss: 4.143704414367676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7646/100000, D Loss: 0.30091944336891174, G Loss: 4.001397609710693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7647/100000, D Loss: 0.25473418831825256, G Loss: 4.479414939880371\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7648/100000, D Loss: 0.2514065057039261, G Loss: 4.851159572601318\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7649/100000, D Loss: 0.34005074203014374, G Loss: 4.042454719543457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7650/100000, D Loss: 0.29482097923755646, G Loss: 4.220130920410156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7651/100000, D Loss: 0.24725548923015594, G Loss: 4.740762710571289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7652/100000, D Loss: 0.27426768839359283, G Loss: 4.551860809326172\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7653/100000, D Loss: 0.29139767587184906, G Loss: 3.9841246604919434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7654/100000, D Loss: 0.33609361946582794, G Loss: 3.965696334838867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7655/100000, D Loss: 0.27342984080314636, G Loss: 4.618943214416504\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7656/100000, D Loss: 0.3105507791042328, G Loss: 4.503702163696289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7657/100000, D Loss: 0.34124167263507843, G Loss: 3.9903225898742676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7658/100000, D Loss: 0.2956492006778717, G Loss: 4.292802333831787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7659/100000, D Loss: 0.21654777228832245, G Loss: 5.120750904083252\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7660/100000, D Loss: 0.23906616121530533, G Loss: 4.880202293395996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7661/100000, D Loss: 0.2737627923488617, G Loss: 4.195865631103516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7662/100000, D Loss: 0.2369016781449318, G Loss: 4.325430393218994\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7663/100000, D Loss: 0.19022338092327118, G Loss: 4.9942169189453125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7664/100000, D Loss: 0.1916171982884407, G Loss: 5.115537166595459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7665/100000, D Loss: 0.20711006224155426, G Loss: 4.575830936431885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7666/100000, D Loss: 0.22129803895950317, G Loss: 4.314857482910156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7667/100000, D Loss: 0.2053830400109291, G Loss: 4.653090476989746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7668/100000, D Loss: 0.18765170127153397, G Loss: 5.138106346130371\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7669/100000, D Loss: 0.23493288457393646, G Loss: 4.616702079772949\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7670/100000, D Loss: 0.23434671759605408, G Loss: 4.5504937171936035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7671/100000, D Loss: 0.19513488560914993, G Loss: 4.647459983825684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7672/100000, D Loss: 0.17663969099521637, G Loss: 5.092721939086914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7673/100000, D Loss: 0.21143276989459991, G Loss: 4.723446369171143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7674/100000, D Loss: 0.2246507629752159, G Loss: 4.593898773193359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7675/100000, D Loss: 0.18809623271226883, G Loss: 4.9462690353393555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7676/100000, D Loss: 0.19874124228954315, G Loss: 5.189959526062012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7677/100000, D Loss: 0.17819367349147797, G Loss: 5.06143856048584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7678/100000, D Loss: 0.23341402411460876, G Loss: 4.661320686340332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7679/100000, D Loss: 0.22131624072790146, G Loss: 4.583187103271484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7680/100000, D Loss: 0.16681918501853943, G Loss: 5.055946350097656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7681/100000, D Loss: 0.2177300825715065, G Loss: 4.9656662940979\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7682/100000, D Loss: 0.24070358276367188, G Loss: 4.4552903175354\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7683/100000, D Loss: 0.17193778604269028, G Loss: 4.737666130065918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7684/100000, D Loss: 0.20191195607185364, G Loss: 5.252686023712158\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 7685/100000, D Loss: 0.2084486484527588, G Loss: 4.862926483154297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7686/100000, D Loss: 0.22399716079235077, G Loss: 4.572739124298096\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7687/100000, D Loss: 0.2356361225247383, G Loss: 4.742238998413086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7688/100000, D Loss: 0.20750517398118973, G Loss: 4.956698417663574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7689/100000, D Loss: 0.2501174435019493, G Loss: 4.605073928833008\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7690/100000, D Loss: 0.28885021805763245, G Loss: 4.38523006439209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7691/100000, D Loss: 0.2684907093644142, G Loss: 4.556631088256836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7692/100000, D Loss: 0.2673966586589813, G Loss: 4.6941752433776855\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7693/100000, D Loss: 0.27498970925807953, G Loss: 4.552778244018555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7694/100000, D Loss: 0.2711758092045784, G Loss: 4.237001419067383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7695/100000, D Loss: 0.2780718207359314, G Loss: 4.185759544372559\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7696/100000, D Loss: 0.2808275818824768, G Loss: 4.198094844818115\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7697/100000, D Loss: 0.31217363476753235, G Loss: 4.312801361083984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7698/100000, D Loss: 0.26335500180721283, G Loss: 4.390098571777344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7699/100000, D Loss: 0.3426576256752014, G Loss: 4.0419111251831055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7700/100000, D Loss: 0.35049842298030853, G Loss: 4.273656368255615\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7701/100000, D Loss: 0.2965487986803055, G Loss: 4.6139326095581055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7702/100000, D Loss: 0.3314971923828125, G Loss: 4.502730369567871\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7703/100000, D Loss: 0.3191179037094116, G Loss: 4.024324417114258\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7704/100000, D Loss: 0.3313920199871063, G Loss: 4.389805316925049\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7705/100000, D Loss: 0.24613240361213684, G Loss: 4.967155456542969\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7706/100000, D Loss: 0.27707668393850327, G Loss: 4.52790641784668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7707/100000, D Loss: 0.3095655143260956, G Loss: 4.090020179748535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7708/100000, D Loss: 0.30284179747104645, G Loss: 4.420208930969238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7709/100000, D Loss: 0.2766449451446533, G Loss: 4.7530317306518555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7710/100000, D Loss: 0.2925676256418228, G Loss: 4.365621566772461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7711/100000, D Loss: 0.29037629067897797, G Loss: 4.258737087249756\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7712/100000, D Loss: 0.2938275933265686, G Loss: 4.231332778930664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7713/100000, D Loss: 0.28082653880119324, G Loss: 4.493623733520508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7714/100000, D Loss: 0.28710344433784485, G Loss: 4.378056526184082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7715/100000, D Loss: 0.27594348788261414, G Loss: 4.199461936950684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7716/100000, D Loss: 0.26779377460479736, G Loss: 4.332672595977783\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7717/100000, D Loss: 0.23103072494268417, G Loss: 4.471713066101074\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7718/100000, D Loss: 0.2345077469944954, G Loss: 4.530798435211182\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7719/100000, D Loss: 0.20575229823589325, G Loss: 4.305658340454102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7720/100000, D Loss: 0.21011851727962494, G Loss: 4.537147521972656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7721/100000, D Loss: 0.162030927836895, G Loss: 4.479321002960205\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7722/100000, D Loss: 0.16866283118724823, G Loss: 4.680492401123047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7723/100000, D Loss: 0.1711190789937973, G Loss: 4.631772041320801\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7724/100000, D Loss: 0.15943819284439087, G Loss: 4.716048240661621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7725/100000, D Loss: 0.14411523193120956, G Loss: 4.987577438354492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7726/100000, D Loss: 0.15573783218860626, G Loss: 4.7326531410217285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7727/100000, D Loss: 0.170102059841156, G Loss: 4.247075080871582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7728/100000, D Loss: 0.1738608032464981, G Loss: 4.607952117919922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7729/100000, D Loss: 0.13372477144002914, G Loss: 5.0314621925354\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7730/100000, D Loss: 0.17171784490346909, G Loss: 4.443548202514648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7731/100000, D Loss: 0.1831623762845993, G Loss: 4.462461948394775\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7732/100000, D Loss: 0.17227154970169067, G Loss: 4.687647342681885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7733/100000, D Loss: 0.16372091323137283, G Loss: 4.947759628295898\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7734/100000, D Loss: 0.2241733819246292, G Loss: 4.446589469909668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7735/100000, D Loss: 0.22498217225074768, G Loss: 4.235563278198242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7736/100000, D Loss: 0.16906297206878662, G Loss: 4.719508171081543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7737/100000, D Loss: 0.2068692445755005, G Loss: 4.711231708526611\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7738/100000, D Loss: 0.23160656541585922, G Loss: 4.334988594055176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7739/100000, D Loss: 0.26903101801872253, G Loss: 4.194851875305176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7740/100000, D Loss: 0.20893080532550812, G Loss: 4.846155643463135\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7741/100000, D Loss: 0.26504021883010864, G Loss: 4.636996746063232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7742/100000, D Loss: 0.30845123529434204, G Loss: 3.993129014968872\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7743/100000, D Loss: 0.2761140614748001, G Loss: 4.25227165222168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7744/100000, D Loss: 0.2751757428050041, G Loss: 4.452893257141113\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7745/100000, D Loss: 0.35899896919727325, G Loss: 3.991586446762085\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7746/100000, D Loss: 0.3447139263153076, G Loss: 4.069737911224365\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7747/100000, D Loss: 0.3635280579328537, G Loss: 4.538068771362305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7748/100000, D Loss: 0.28141307085752487, G Loss: 4.248002529144287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7749/100000, D Loss: 0.38520464301109314, G Loss: 3.9227917194366455\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7750/100000, D Loss: 0.4016048014163971, G Loss: 3.9904277324676514\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7751/100000, D Loss: 0.2898763343691826, G Loss: 4.391707420349121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7752/100000, D Loss: 0.2703703045845032, G Loss: 4.462393760681152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7753/100000, D Loss: 0.280799463391304, G Loss: 4.204120635986328\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7754/100000, D Loss: 0.2585712894797325, G Loss: 4.42067813873291\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7755/100000, D Loss: 0.19959384202957153, G Loss: 4.645170211791992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7756/100000, D Loss: 0.2287670597434044, G Loss: 4.7215895652771\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7757/100000, D Loss: 0.20804854482412338, G Loss: 4.829442977905273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7758/100000, D Loss: 0.16732501983642578, G Loss: 5.144691467285156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7759/100000, D Loss: 0.1621764823794365, G Loss: 4.85698127746582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7760/100000, D Loss: 0.1615137904882431, G Loss: 4.965104103088379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7761/100000, D Loss: 0.14240343868732452, G Loss: 4.990069389343262\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7762/100000, D Loss: 0.13222131878137589, G Loss: 5.285658359527588\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7763/100000, D Loss: 0.131276935338974, G Loss: 5.318822383880615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7764/100000, D Loss: 0.13914309442043304, G Loss: 4.971556186676025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7765/100000, D Loss: 0.1648731380701065, G Loss: 4.918925762176514\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7766/100000, D Loss: 0.15010905265808105, G Loss: 5.174088001251221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7767/100000, D Loss: 0.16449570655822754, G Loss: 5.343080043792725\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7768/100000, D Loss: 0.1755651757121086, G Loss: 5.404645919799805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7769/100000, D Loss: 0.17510027438402176, G Loss: 4.918191909790039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7770/100000, D Loss: 0.2265726998448372, G Loss: 4.889379501342773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7771/100000, D Loss: 0.20571613311767578, G Loss: 5.351222515106201\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7772/100000, D Loss: 0.22847093641757965, G Loss: 5.456693649291992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7773/100000, D Loss: 0.25946715474128723, G Loss: 5.084814071655273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7774/100000, D Loss: 0.24381162226200104, G Loss: 5.001466751098633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7775/100000, D Loss: 0.261761911213398, G Loss: 5.486888885498047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7776/100000, D Loss: 0.23202718794345856, G Loss: 5.384886741638184\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7777/100000, D Loss: 0.24157391488552094, G Loss: 4.869936943054199\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7778/100000, D Loss: 0.30303530395030975, G Loss: 4.806660175323486\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7779/100000, D Loss: 0.29288288950920105, G Loss: 5.121565818786621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7780/100000, D Loss: 0.27212080359458923, G Loss: 5.383114814758301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7781/100000, D Loss: 0.3079110234975815, G Loss: 4.618112564086914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7782/100000, D Loss: 0.28358201682567596, G Loss: 4.730644226074219\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7783/100000, D Loss: 0.28567881882190704, G Loss: 5.053631782531738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7784/100000, D Loss: 0.2899399399757385, G Loss: 5.161343574523926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7785/100000, D Loss: 0.2674340754747391, G Loss: 4.939522743225098\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7786/100000, D Loss: 0.28400540351867676, G Loss: 4.544691562652588\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7787/100000, D Loss: 0.2654290646314621, G Loss: 4.705075740814209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7788/100000, D Loss: 0.23054183274507523, G Loss: 4.9261579513549805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7789/100000, D Loss: 0.25315551459789276, G Loss: 4.936835289001465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7790/100000, D Loss: 0.23918119817972183, G Loss: 4.6168742179870605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7791/100000, D Loss: 0.24058552086353302, G Loss: 4.800912857055664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7792/100000, D Loss: 0.20526883006095886, G Loss: 5.373405456542969\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7793/100000, D Loss: 0.22210165858268738, G Loss: 4.867867469787598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7794/100000, D Loss: 0.24629026651382446, G Loss: 4.2838544845581055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 7795/100000, D Loss: 0.2223615050315857, G Loss: 4.850130558013916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7796/100000, D Loss: 0.21555174887180328, G Loss: 5.410807132720947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7797/100000, D Loss: 0.28640538454055786, G Loss: 4.846790313720703\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7798/100000, D Loss: 0.21625235676765442, G Loss: 4.7759199142456055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7799/100000, D Loss: 0.22361142933368683, G Loss: 4.895226001739502\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7800/100000, D Loss: 0.2982735335826874, G Loss: 4.7182159423828125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7801/100000, D Loss: 0.2998330295085907, G Loss: 4.513004302978516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7802/100000, D Loss: 0.2683546245098114, G Loss: 4.749671936035156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7803/100000, D Loss: 0.26339635998010635, G Loss: 4.467691421508789\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7804/100000, D Loss: 0.32183922827243805, G Loss: 4.246519088745117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7805/100000, D Loss: 0.2818107157945633, G Loss: 4.56056022644043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7806/100000, D Loss: 0.3088057115674019, G Loss: 4.7393598556518555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7807/100000, D Loss: 0.3168376535177231, G Loss: 4.224881172180176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7808/100000, D Loss: 0.31596481800079346, G Loss: 4.514196872711182\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7809/100000, D Loss: 0.31992003321647644, G Loss: 4.504819869995117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7810/100000, D Loss: 0.3069562315940857, G Loss: 4.6615400314331055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7811/100000, D Loss: 0.3987679034471512, G Loss: 4.250362396240234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7812/100000, D Loss: 0.3527799993753433, G Loss: 4.479708671569824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7813/100000, D Loss: 0.3035205602645874, G Loss: 4.730278015136719\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7814/100000, D Loss: 0.3283950909972191, G Loss: 4.215100288391113\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7815/100000, D Loss: 0.32771727442741394, G Loss: 4.287538528442383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7816/100000, D Loss: 0.31980445981025696, G Loss: 4.706075668334961\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7817/100000, D Loss: 0.27130620181560516, G Loss: 4.864576816558838\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7818/100000, D Loss: 0.2776203379034996, G Loss: 4.328383445739746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7819/100000, D Loss: 0.27059564739465714, G Loss: 4.048978328704834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7820/100000, D Loss: 0.2492475062608719, G Loss: 4.613687515258789\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7821/100000, D Loss: 0.21178880333900452, G Loss: 5.13077449798584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7822/100000, D Loss: 0.23571018874645233, G Loss: 4.580252647399902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7823/100000, D Loss: 0.23939573764801025, G Loss: 4.2116618156433105\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7824/100000, D Loss: 0.22353820502758026, G Loss: 4.523369789123535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7825/100000, D Loss: 0.18798063695430756, G Loss: 5.145656585693359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7826/100000, D Loss: 0.20699597895145416, G Loss: 4.892269134521484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7827/100000, D Loss: 0.2166227400302887, G Loss: 4.560749053955078\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7828/100000, D Loss: 0.2082419991493225, G Loss: 4.439268112182617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7829/100000, D Loss: 0.1929878368973732, G Loss: 4.741891860961914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7830/100000, D Loss: 0.2289981096982956, G Loss: 4.903531074523926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7831/100000, D Loss: 0.25557587295770645, G Loss: 4.852224826812744\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7832/100000, D Loss: 0.2642635628581047, G Loss: 4.939053535461426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7833/100000, D Loss: 0.2360060214996338, G Loss: 4.871740818023682\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7834/100000, D Loss: 0.32128244638442993, G Loss: 4.504665851593018\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7835/100000, D Loss: 0.24621330201625824, G Loss: 4.8130340576171875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7836/100000, D Loss: 0.2330208122730255, G Loss: 5.198073387145996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7837/100000, D Loss: 0.26364945620298386, G Loss: 4.985730171203613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7838/100000, D Loss: 0.3240143954753876, G Loss: 4.639822006225586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7839/100000, D Loss: 0.2543480172753334, G Loss: 5.200730323791504\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7840/100000, D Loss: 0.2813258394598961, G Loss: 5.029226303100586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7841/100000, D Loss: 0.26327235996723175, G Loss: 4.738224983215332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7842/100000, D Loss: 0.24532566964626312, G Loss: 4.885890960693359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7843/100000, D Loss: 0.22117656469345093, G Loss: 5.034340858459473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7844/100000, D Loss: 0.2400912046432495, G Loss: 5.154706954956055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7845/100000, D Loss: 0.2649105191230774, G Loss: 5.041158199310303\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7846/100000, D Loss: 0.2653353661298752, G Loss: 4.583741188049316\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7847/100000, D Loss: 0.22542455047369003, G Loss: 4.750472068786621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7848/100000, D Loss: 0.23574083298444748, G Loss: 5.284717559814453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7849/100000, D Loss: 0.2382771149277687, G Loss: 4.956261157989502\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7850/100000, D Loss: 0.23033040761947632, G Loss: 4.484490394592285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7851/100000, D Loss: 0.1927499622106552, G Loss: 4.752836227416992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7852/100000, D Loss: 0.2101285755634308, G Loss: 4.964076042175293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7853/100000, D Loss: 0.21373040974140167, G Loss: 4.902575969696045\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7854/100000, D Loss: 0.2357533797621727, G Loss: 4.558713912963867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7855/100000, D Loss: 0.24622463434934616, G Loss: 4.3465447425842285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7856/100000, D Loss: 0.22326265275478363, G Loss: 4.66376256942749\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7857/100000, D Loss: 0.22917061299085617, G Loss: 5.135796546936035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7858/100000, D Loss: 0.19987211376428604, G Loss: 5.042139053344727\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7859/100000, D Loss: 0.2246064841747284, G Loss: 4.689496040344238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7860/100000, D Loss: 0.17952960729599, G Loss: 4.916437149047852\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7861/100000, D Loss: 0.2090415582060814, G Loss: 4.981902599334717\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7862/100000, D Loss: 0.17817248404026031, G Loss: 5.063301086425781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7863/100000, D Loss: 0.19008661806583405, G Loss: 4.7442145347595215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7864/100000, D Loss: 0.20720616728067398, G Loss: 4.706238746643066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7865/100000, D Loss: 0.1753988340497017, G Loss: 4.990568161010742\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7866/100000, D Loss: 0.18793033808469772, G Loss: 5.044023513793945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7867/100000, D Loss: 0.19822777062654495, G Loss: 4.620379447937012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7868/100000, D Loss: 0.18711189925670624, G Loss: 4.523589134216309\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7869/100000, D Loss: 0.2064322829246521, G Loss: 4.611835956573486\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7870/100000, D Loss: 0.18638131767511368, G Loss: 4.637981414794922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7871/100000, D Loss: 0.21546777337789536, G Loss: 4.329376220703125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7872/100000, D Loss: 0.2547750324010849, G Loss: 4.280929088592529\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7873/100000, D Loss: 0.24154629558324814, G Loss: 4.516755104064941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7874/100000, D Loss: 0.2662810757756233, G Loss: 4.296684741973877\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7875/100000, D Loss: 0.30347180366516113, G Loss: 4.068386077880859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7876/100000, D Loss: 0.3221176862716675, G Loss: 4.17908239364624\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7877/100000, D Loss: 0.35444869101047516, G Loss: 4.164536952972412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7878/100000, D Loss: 0.32947462797164917, G Loss: 4.139021873474121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7879/100000, D Loss: 0.3718825876712799, G Loss: 3.9564363956451416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7880/100000, D Loss: 0.3490688353776932, G Loss: 3.97003436088562\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7881/100000, D Loss: 0.3540703356266022, G Loss: 4.1297736167907715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7882/100000, D Loss: 0.41076189279556274, G Loss: 3.7488107681274414\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7883/100000, D Loss: 0.43598572909832, G Loss: 3.63165283203125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7884/100000, D Loss: 0.385637104511261, G Loss: 3.994752883911133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7885/100000, D Loss: 0.38444656133651733, G Loss: 4.133065223693848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7886/100000, D Loss: 0.44063884019851685, G Loss: 3.687401294708252\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7887/100000, D Loss: 0.38490207493305206, G Loss: 3.630345344543457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7888/100000, D Loss: 0.2982208579778671, G Loss: 4.103457927703857\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7889/100000, D Loss: 0.30190080404281616, G Loss: 4.037145614624023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7890/100000, D Loss: 0.2629487216472626, G Loss: 4.121916770935059\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7891/100000, D Loss: 0.2358141392469406, G Loss: 4.32259464263916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7892/100000, D Loss: 0.25019440054893494, G Loss: 4.268125534057617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7893/100000, D Loss: 0.1996258944272995, G Loss: 4.421934604644775\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7894/100000, D Loss: 0.17675933986902237, G Loss: 4.743494033813477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7895/100000, D Loss: 0.17598062753677368, G Loss: 4.45610237121582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7896/100000, D Loss: 0.1651584804058075, G Loss: 4.475164413452148\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7897/100000, D Loss: 0.19199036806821823, G Loss: 4.457426071166992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7898/100000, D Loss: 0.15596993267536163, G Loss: 4.622603416442871\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7899/100000, D Loss: 0.13628125563263893, G Loss: 5.094965934753418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7900/100000, D Loss: 0.15461058169603348, G Loss: 4.817310810089111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7901/100000, D Loss: 0.15299025177955627, G Loss: 4.523768424987793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7902/100000, D Loss: 0.14614849537611008, G Loss: 4.615955352783203\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7903/100000, D Loss: 0.14947263896465302, G Loss: 4.834381103515625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7904/100000, D Loss: 0.13916343823075294, G Loss: 5.120858192443848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7905/100000, D Loss: 0.1864381544291973, G Loss: 4.5122294425964355\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7906/100000, D Loss: 0.18236901611089706, G Loss: 4.3579301834106445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7907/100000, D Loss: 0.1725446805357933, G Loss: 4.48155403137207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7908/100000, D Loss: 0.15694332122802734, G Loss: 4.876125335693359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7909/100000, D Loss: 0.1998850703239441, G Loss: 4.499332904815674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7910/100000, D Loss: 0.19722430408000946, G Loss: 4.152370452880859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7911/100000, D Loss: 0.15919306874275208, G Loss: 4.481445789337158\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7912/100000, D Loss: 0.20198281854391098, G Loss: 4.60392951965332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7913/100000, D Loss: 0.21250136196613312, G Loss: 4.389729976654053\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7914/100000, D Loss: 0.1887282058596611, G Loss: 4.104018211364746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7915/100000, D Loss: 0.20884570479393005, G Loss: 4.3737616539001465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7916/100000, D Loss: 0.21506600826978683, G Loss: 4.517815589904785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7917/100000, D Loss: 0.23898866772651672, G Loss: 4.037922382354736\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7918/100000, D Loss: 0.23787885904312134, G Loss: 4.183356285095215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7919/100000, D Loss: 0.2157333716750145, G Loss: 4.5132856369018555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7920/100000, D Loss: 0.2616998553276062, G Loss: 4.167593002319336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7921/100000, D Loss: 0.2456047236919403, G Loss: 4.162487030029297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7922/100000, D Loss: 0.23808255046606064, G Loss: 4.197546005249023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7923/100000, D Loss: 0.24437084048986435, G Loss: 4.352924823760986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7924/100000, D Loss: 0.25078417360782623, G Loss: 4.238161087036133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7925/100000, D Loss: 0.2677004635334015, G Loss: 3.9073739051818848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7926/100000, D Loss: 0.326201468706131, G Loss: 3.669408082962036\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7927/100000, D Loss: 0.27962350845336914, G Loss: 4.282351970672607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7928/100000, D Loss: 0.31936484575271606, G Loss: 4.029869079589844\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7929/100000, D Loss: 0.3318389654159546, G Loss: 3.6267898082733154\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7930/100000, D Loss: 0.30923205614089966, G Loss: 3.7962827682495117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7931/100000, D Loss: 0.2727586030960083, G Loss: 4.120282173156738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7932/100000, D Loss: 0.3406449109315872, G Loss: 3.632563829421997\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7933/100000, D Loss: 0.3470112532377243, G Loss: 3.632617950439453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7934/100000, D Loss: 0.2778255343437195, G Loss: 4.225787162780762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7935/100000, D Loss: 0.2618556097149849, G Loss: 4.3645920753479\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7936/100000, D Loss: 0.2638273686170578, G Loss: 3.8091163635253906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7937/100000, D Loss: 0.2818654775619507, G Loss: 3.8821661472320557\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7938/100000, D Loss: 0.22370757162570953, G Loss: 4.276322841644287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7939/100000, D Loss: 0.20233533531427383, G Loss: 4.774895668029785\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7940/100000, D Loss: 0.20363307744264603, G Loss: 4.503204345703125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7941/100000, D Loss: 0.2394918128848076, G Loss: 4.144745349884033\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7942/100000, D Loss: 0.1928042620420456, G Loss: 4.176745414733887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7943/100000, D Loss: 0.18832778930664062, G Loss: 4.390841960906982\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7944/100000, D Loss: 0.2023956999182701, G Loss: 4.614537239074707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7945/100000, D Loss: 0.20196274667978287, G Loss: 4.735545635223389\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7946/100000, D Loss: 0.17373383045196533, G Loss: 4.8355512619018555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7947/100000, D Loss: 0.19884148240089417, G Loss: 4.585516929626465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7948/100000, D Loss: 0.22513052821159363, G Loss: 4.333905220031738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7949/100000, D Loss: 0.20709278434515, G Loss: 4.504491806030273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7950/100000, D Loss: 0.19592875242233276, G Loss: 4.757220268249512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7951/100000, D Loss: 0.19979997724294662, G Loss: 4.840452194213867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7952/100000, D Loss: 0.22592580318450928, G Loss: 4.773560523986816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7953/100000, D Loss: 0.25890249013900757, G Loss: 4.425067901611328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7954/100000, D Loss: 0.24234283715486526, G Loss: 4.487062454223633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7955/100000, D Loss: 0.18588699400424957, G Loss: 4.791595458984375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7956/100000, D Loss: 0.18820159882307053, G Loss: 4.87706184387207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7957/100000, D Loss: 0.2053014561533928, G Loss: 4.349973201751709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7958/100000, D Loss: 0.24295129626989365, G Loss: 3.782034158706665\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7959/100000, D Loss: 0.21061444282531738, G Loss: 4.61151123046875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7960/100000, D Loss: 0.207413449883461, G Loss: 5.146043300628662\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7961/100000, D Loss: 0.23155442625284195, G Loss: 4.603305339813232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7962/100000, D Loss: 0.2731578201055527, G Loss: 4.3554816246032715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7963/100000, D Loss: 0.2671567052602768, G Loss: 4.594332695007324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7964/100000, D Loss: 0.20075632259249687, G Loss: 4.771823883056641\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7965/100000, D Loss: 0.2980823367834091, G Loss: 3.9592132568359375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7966/100000, D Loss: 0.2760257124900818, G Loss: 4.155659198760986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7967/100000, D Loss: 0.2575315609574318, G Loss: 4.725693225860596\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7968/100000, D Loss: 0.28260206431150436, G Loss: 4.286940574645996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7969/100000, D Loss: 0.3942999094724655, G Loss: 3.511767864227295\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7970/100000, D Loss: 0.3509998768568039, G Loss: 4.178255081176758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7971/100000, D Loss: 0.36033254116773605, G Loss: 4.325424671173096\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7972/100000, D Loss: 0.3862834721803665, G Loss: 3.946805000305176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7973/100000, D Loss: 0.3790716677904129, G Loss: 3.866809368133545\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7974/100000, D Loss: 0.3058747947216034, G Loss: 4.327047348022461\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7975/100000, D Loss: 0.3201138824224472, G Loss: 4.11482048034668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7976/100000, D Loss: 0.36298954486846924, G Loss: 3.609281539916992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7977/100000, D Loss: 0.34250618517398834, G Loss: 4.183946132659912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7978/100000, D Loss: 0.2365134283900261, G Loss: 4.762529373168945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7979/100000, D Loss: 0.27413833141326904, G Loss: 4.255683898925781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7980/100000, D Loss: 0.2692890167236328, G Loss: 3.771484613418579\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7981/100000, D Loss: 0.2521890252828598, G Loss: 4.08348274230957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7982/100000, D Loss: 0.20614693313837051, G Loss: 4.742031574249268\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7983/100000, D Loss: 0.2209768146276474, G Loss: 4.614112854003906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7984/100000, D Loss: 0.26312293857336044, G Loss: 3.6788339614868164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7985/100000, D Loss: 0.21411043405532837, G Loss: 4.204314231872559\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7986/100000, D Loss: 0.17405128479003906, G Loss: 4.638078689575195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7987/100000, D Loss: 0.2110414057970047, G Loss: 4.27824592590332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7988/100000, D Loss: 0.22641637921333313, G Loss: 3.7124385833740234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7989/100000, D Loss: 0.2084098979830742, G Loss: 4.24024772644043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7990/100000, D Loss: 0.1813017874956131, G Loss: 4.8057661056518555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7991/100000, D Loss: 0.1931413859128952, G Loss: 4.640767574310303\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7992/100000, D Loss: 0.20974332094192505, G Loss: 4.014077186584473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7993/100000, D Loss: 0.21999717503786087, G Loss: 4.211556434631348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7994/100000, D Loss: 0.17698192596435547, G Loss: 4.912723064422607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7995/100000, D Loss: 0.18913474678993225, G Loss: 4.939467430114746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7996/100000, D Loss: 0.22544262558221817, G Loss: 4.070477485656738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7997/100000, D Loss: 0.23004645854234695, G Loss: 4.09621524810791\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 7998/100000, D Loss: 0.1611659899353981, G Loss: 4.60111141204834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 7999/100000, D Loss: 0.1849392205476761, G Loss: 4.773738384246826\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8000/100000, D Loss: 0.20006196200847626, G Loss: 4.222945213317871\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8001/100000, D Loss: 0.2130102515220642, G Loss: 4.1696577072143555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8002/100000, D Loss: 0.1777515411376953, G Loss: 4.400241851806641\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8003/100000, D Loss: 0.2057042196393013, G Loss: 4.374916076660156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8004/100000, D Loss: 0.22192170470952988, G Loss: 4.248302936553955\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8005/100000, D Loss: 0.21924499422311783, G Loss: 4.227481842041016\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8006/100000, D Loss: 0.23546190559864044, G Loss: 4.305268287658691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8007/100000, D Loss: 0.23591667413711548, G Loss: 4.518021583557129\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8008/100000, D Loss: 0.2265126332640648, G Loss: 4.223117828369141\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8009/100000, D Loss: 0.2304331213235855, G Loss: 4.339828014373779\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8010/100000, D Loss: 0.2352420836687088, G Loss: 4.349338054656982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8011/100000, D Loss: 0.25860870629549026, G Loss: 4.31812858581543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8012/100000, D Loss: 0.25377681851387024, G Loss: 4.249380111694336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8013/100000, D Loss: 0.2802126556634903, G Loss: 4.4037933349609375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8014/100000, D Loss: 0.23220781981945038, G Loss: 4.347371578216553\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8015/100000, D Loss: 0.27252212166786194, G Loss: 4.220424652099609\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8016/100000, D Loss: 0.23602834343910217, G Loss: 4.603793621063232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8017/100000, D Loss: 0.17349739372730255, G Loss: 4.769227981567383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8018/100000, D Loss: 0.23532405495643616, G Loss: 4.573113441467285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8019/100000, D Loss: 0.196082204580307, G Loss: 4.634056568145752\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8020/100000, D Loss: 0.14869945496320724, G Loss: 5.180620193481445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8021/100000, D Loss: 0.127994567155838, G Loss: 5.153497695922852\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8022/100000, D Loss: 0.13839509338140488, G Loss: 4.72157096862793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8023/100000, D Loss: 0.13372983783483505, G Loss: 4.521953582763672\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8024/100000, D Loss: 0.13126300275325775, G Loss: 4.725050926208496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8025/100000, D Loss: 0.12724069878458977, G Loss: 5.013222694396973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8026/100000, D Loss: 0.14652705192565918, G Loss: 4.73703670501709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8027/100000, D Loss: 0.15199564397335052, G Loss: 4.449239730834961\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8028/100000, D Loss: 0.1434032917022705, G Loss: 4.58856201171875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8029/100000, D Loss: 0.15832094103097916, G Loss: 4.799869060516357\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8030/100000, D Loss: 0.1577782854437828, G Loss: 4.715415954589844\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8031/100000, D Loss: 0.15843790024518967, G Loss: 4.74996280670166\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8032/100000, D Loss: 0.18262886255979538, G Loss: 4.627748489379883\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8033/100000, D Loss: 0.16370683163404465, G Loss: 4.779494285583496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8034/100000, D Loss: 0.17652767896652222, G Loss: 4.594304084777832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8035/100000, D Loss: 0.21250931173563004, G Loss: 4.514687538146973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8036/100000, D Loss: 0.19243000447750092, G Loss: 4.638221740722656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8037/100000, D Loss: 0.19501446932554245, G Loss: 4.376701354980469\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8038/100000, D Loss: 0.1905548870563507, G Loss: 4.42490291595459\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8039/100000, D Loss: 0.22898492217063904, G Loss: 4.366991996765137\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8040/100000, D Loss: 0.21380946040153503, G Loss: 4.657523155212402\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8041/100000, D Loss: 0.20838592946529388, G Loss: 4.730726718902588\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8042/100000, D Loss: 0.2085437849164009, G Loss: 4.419069290161133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8043/100000, D Loss: 0.2265797108411789, G Loss: 4.427422523498535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8044/100000, D Loss: 0.17027172446250916, G Loss: 4.7784504890441895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8045/100000, D Loss: 0.1956372633576393, G Loss: 4.758058547973633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8046/100000, D Loss: 0.17246156930923462, G Loss: 4.627931594848633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8047/100000, D Loss: 0.19680793583393097, G Loss: 4.563746452331543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8048/100000, D Loss: 0.18574835360050201, G Loss: 4.589200019836426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8049/100000, D Loss: 0.18403876572847366, G Loss: 4.842063903808594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8050/100000, D Loss: 0.16591617465019226, G Loss: 5.132948875427246\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8051/100000, D Loss: 0.1843031868338585, G Loss: 4.654863357543945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8052/100000, D Loss: 0.16460292786359787, G Loss: 4.624892711639404\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8053/100000, D Loss: 0.16663949191570282, G Loss: 4.857539176940918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8054/100000, D Loss: 0.13910702243447304, G Loss: 4.943008899688721\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8055/100000, D Loss: 0.1798122525215149, G Loss: 4.322104454040527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8056/100000, D Loss: 0.17772451788187027, G Loss: 4.5981035232543945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8057/100000, D Loss: 0.1400539055466652, G Loss: 5.014626502990723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8058/100000, D Loss: 0.17720264941453934, G Loss: 4.795456409454346\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8059/100000, D Loss: 0.1657702475786209, G Loss: 4.489476203918457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8060/100000, D Loss: 0.17680518329143524, G Loss: 4.759317398071289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8061/100000, D Loss: 0.2091127410531044, G Loss: 4.7533278465271\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8062/100000, D Loss: 0.16919758170843124, G Loss: 4.529200077056885\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8063/100000, D Loss: 0.20227044820785522, G Loss: 4.3844146728515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8064/100000, D Loss: 0.16847191751003265, G Loss: 4.733939170837402\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8065/100000, D Loss: 0.202532097697258, G Loss: 4.650267124176025\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8066/100000, D Loss: 0.21891404688358307, G Loss: 4.220229625701904\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8067/100000, D Loss: 0.20954781770706177, G Loss: 4.473875999450684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8068/100000, D Loss: 0.16593872755765915, G Loss: 4.702849388122559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8069/100000, D Loss: 0.21642343699932098, G Loss: 4.274051666259766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8070/100000, D Loss: 0.2650092840194702, G Loss: 3.840651750564575\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8071/100000, D Loss: 0.2261211797595024, G Loss: 4.151207447052002\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8072/100000, D Loss: 0.22744830697774887, G Loss: 4.681286334991455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8073/100000, D Loss: 0.2902712821960449, G Loss: 4.174046516418457\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8074/100000, D Loss: 0.3060789108276367, G Loss: 3.871352195739746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8075/100000, D Loss: 0.2478122115135193, G Loss: 4.163361549377441\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8076/100000, D Loss: 0.2521214038133621, G Loss: 4.349493980407715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8077/100000, D Loss: 0.29549092799425125, G Loss: 4.063669204711914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8078/100000, D Loss: 0.2558254078030586, G Loss: 4.034712791442871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8079/100000, D Loss: 0.25063978880643845, G Loss: 4.302278518676758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8080/100000, D Loss: 0.24877217411994934, G Loss: 4.508552551269531\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8081/100000, D Loss: 0.21738480776548386, G Loss: 4.799951076507568\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8082/100000, D Loss: 0.2502250522375107, G Loss: 4.598239421844482\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8083/100000, D Loss: 0.21860570460557938, G Loss: 4.285350799560547\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8084/100000, D Loss: 0.1898350790143013, G Loss: 4.688950538635254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8085/100000, D Loss: 0.18434284627437592, G Loss: 5.051883697509766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8086/100000, D Loss: 0.1716836616396904, G Loss: 5.0589728355407715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8087/100000, D Loss: 0.1787821277976036, G Loss: 4.704958915710449\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8088/100000, D Loss: 0.18165657669305801, G Loss: 4.7226667404174805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8089/100000, D Loss: 0.14774668961763382, G Loss: 4.984543323516846\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8090/100000, D Loss: 0.1524730622768402, G Loss: 5.150668621063232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8091/100000, D Loss: 0.17036481201648712, G Loss: 4.8117876052856445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8092/100000, D Loss: 0.1742517128586769, G Loss: 4.769263744354248\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 8093/100000, D Loss: 0.18334977328777313, G Loss: 4.849410057067871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8094/100000, D Loss: 0.15557730942964554, G Loss: 4.905861854553223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8095/100000, D Loss: 0.14397642016410828, G Loss: 4.836138725280762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8096/100000, D Loss: 0.18213875591754913, G Loss: 4.596277236938477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8097/100000, D Loss: 0.19989357888698578, G Loss: 4.49306583404541\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8098/100000, D Loss: 0.1474168747663498, G Loss: 4.962680816650391\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8099/100000, D Loss: 0.16197320073843002, G Loss: 4.933853626251221\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8100/100000, D Loss: 0.1873301938176155, G Loss: 4.463444709777832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8101/100000, D Loss: 0.1751358062028885, G Loss: 4.528783798217773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8102/100000, D Loss: 0.15496914833784103, G Loss: 4.777620315551758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8103/100000, D Loss: 0.1804087981581688, G Loss: 4.676547527313232\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8104/100000, D Loss: 0.16626311093568802, G Loss: 4.485408782958984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8105/100000, D Loss: 0.17668849974870682, G Loss: 4.142969608306885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8106/100000, D Loss: 0.17766061425209045, G Loss: 4.548246383666992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8107/100000, D Loss: 0.16754156351089478, G Loss: 4.9940409660339355\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8108/100000, D Loss: 0.18382760882377625, G Loss: 4.567930221557617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8109/100000, D Loss: 0.19394828379154205, G Loss: 4.4121294021606445\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 8110/100000, D Loss: 0.1518201231956482, G Loss: 4.400936603546143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8111/100000, D Loss: 0.15280098468065262, G Loss: 4.557777404785156\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8112/100000, D Loss: 0.1648741029202938, G Loss: 4.588701248168945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8113/100000, D Loss: 0.19574832171201706, G Loss: 4.342695713043213\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8114/100000, D Loss: 0.20046481490135193, G Loss: 4.170056343078613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8115/100000, D Loss: 0.19212079793214798, G Loss: 4.2800774574279785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8116/100000, D Loss: 0.1846063956618309, G Loss: 4.436708450317383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8117/100000, D Loss: 0.2040802240371704, G Loss: 4.296860694885254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8118/100000, D Loss: 0.21035850048065186, G Loss: 3.997770071029663\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8119/100000, D Loss: 0.2044132798910141, G Loss: 4.224606037139893\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8120/100000, D Loss: 0.16748745739459991, G Loss: 4.492932319641113\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8121/100000, D Loss: 0.23911721259355545, G Loss: 4.246642112731934\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8122/100000, D Loss: 0.18572643399238586, G Loss: 4.06494140625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8123/100000, D Loss: 0.1823764443397522, G Loss: 4.2861785888671875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8124/100000, D Loss: 0.19667037576436996, G Loss: 4.212553024291992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8125/100000, D Loss: 0.20296549797058105, G Loss: 3.93641996383667\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8126/100000, D Loss: 0.20816026628017426, G Loss: 4.093337535858154\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8127/100000, D Loss: 0.18966378271579742, G Loss: 4.352429389953613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8128/100000, D Loss: 0.22731124609708786, G Loss: 4.21986198425293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8129/100000, D Loss: 0.20002489537000656, G Loss: 4.257562160491943\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8130/100000, D Loss: 0.22137956321239471, G Loss: 4.22680139541626\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8131/100000, D Loss: 0.19307614117860794, G Loss: 4.210919380187988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8132/100000, D Loss: 0.26223620772361755, G Loss: 3.798147678375244\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8133/100000, D Loss: 0.26330817490816116, G Loss: 4.078103542327881\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8134/100000, D Loss: 0.24641600251197815, G Loss: 4.4098639488220215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8135/100000, D Loss: 0.35105037689208984, G Loss: 3.5705106258392334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8136/100000, D Loss: 0.30915792286396027, G Loss: 4.045055866241455\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8137/100000, D Loss: 0.2437966838479042, G Loss: 4.707851409912109\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8138/100000, D Loss: 0.3707052320241928, G Loss: 3.805590867996216\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8139/100000, D Loss: 0.3390861004590988, G Loss: 3.704932928085327\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8140/100000, D Loss: 0.2443932369351387, G Loss: 4.532681465148926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8141/100000, D Loss: 0.2978663295507431, G Loss: 4.3669753074646\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8142/100000, D Loss: 0.3155631795525551, G Loss: 3.8313441276550293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8143/100000, D Loss: 0.24394454807043076, G Loss: 4.181848526000977\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8144/100000, D Loss: 0.22499321401119232, G Loss: 4.9127607345581055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8145/100000, D Loss: 0.2792538106441498, G Loss: 4.418473243713379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8146/100000, D Loss: 0.2420598268508911, G Loss: 4.203094005584717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8147/100000, D Loss: 0.1708521470427513, G Loss: 4.679888725280762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8148/100000, D Loss: 0.19404339790344238, G Loss: 4.9036712646484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8149/100000, D Loss: 0.23240354657173157, G Loss: 4.2225871086120605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8150/100000, D Loss: 0.20662995427846909, G Loss: 4.125541687011719\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8151/100000, D Loss: 0.16887987405061722, G Loss: 4.690564155578613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8152/100000, D Loss: 0.1604955866932869, G Loss: 5.075007438659668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8153/100000, D Loss: 0.20133021473884583, G Loss: 4.761355876922607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8154/100000, D Loss: 0.21696951985359192, G Loss: 4.187923431396484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8155/100000, D Loss: 0.1929943561553955, G Loss: 4.410138130187988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8156/100000, D Loss: 0.17714014649391174, G Loss: 4.6416521072387695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8157/100000, D Loss: 0.19130007922649384, G Loss: 4.99065637588501\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8158/100000, D Loss: 0.20794623345136642, G Loss: 4.466628074645996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8159/100000, D Loss: 0.2006128653883934, G Loss: 4.291315078735352\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8160/100000, D Loss: 0.18039659410715103, G Loss: 4.673707008361816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8161/100000, D Loss: 0.17942718788981438, G Loss: 4.788506031036377\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8162/100000, D Loss: 0.20479626208543777, G Loss: 4.443277835845947\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8163/100000, D Loss: 0.2000671848654747, G Loss: 4.486956596374512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8164/100000, D Loss: 0.24368074536323547, G Loss: 4.320160865783691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8165/100000, D Loss: 0.2546939328312874, G Loss: 4.272919654846191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8166/100000, D Loss: 0.22284036874771118, G Loss: 4.545459747314453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8167/100000, D Loss: 0.22449462115764618, G Loss: 4.507949352264404\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8168/100000, D Loss: 0.2360754758119583, G Loss: 4.198040008544922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8169/100000, D Loss: 0.2584845572710037, G Loss: 4.19748592376709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8170/100000, D Loss: 0.2454892098903656, G Loss: 4.596828460693359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8171/100000, D Loss: 0.23439359664916992, G Loss: 4.294376373291016\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8172/100000, D Loss: 0.2919842153787613, G Loss: 3.9843626022338867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8173/100000, D Loss: 0.2838297188282013, G Loss: 4.3664350509643555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8174/100000, D Loss: 0.22286711633205414, G Loss: 4.850994110107422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8175/100000, D Loss: 0.28504374623298645, G Loss: 4.186539649963379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8176/100000, D Loss: 0.2771777808666229, G Loss: 4.0155229568481445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8177/100000, D Loss: 0.23755396157503128, G Loss: 4.536838531494141\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8178/100000, D Loss: 0.2508547008037567, G Loss: 4.6657609939575195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8179/100000, D Loss: 0.2680174335837364, G Loss: 4.379583358764648\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 8180/100000, D Loss: 0.25625669211149216, G Loss: 4.1960649490356445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8181/100000, D Loss: 0.266629695892334, G Loss: 4.664671421051025\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8182/100000, D Loss: 0.24857237935066223, G Loss: 4.634037017822266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8183/100000, D Loss: 0.3013312369585037, G Loss: 4.152151584625244\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8184/100000, D Loss: 0.31464746594429016, G Loss: 4.436388969421387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8185/100000, D Loss: 0.3757808655500412, G Loss: 4.496062278747559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8186/100000, D Loss: 0.33169345557689667, G Loss: 4.496657371520996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8187/100000, D Loss: 0.39120636880397797, G Loss: 4.274519920349121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8188/100000, D Loss: 0.3578326404094696, G Loss: 4.404855728149414\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8189/100000, D Loss: 0.33628982305526733, G Loss: 4.350283622741699\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8190/100000, D Loss: 0.3361099064350128, G Loss: 4.2263898849487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8191/100000, D Loss: 0.337726891040802, G Loss: 4.212207317352295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8192/100000, D Loss: 0.33762364089488983, G Loss: 4.2949957847595215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8193/100000, D Loss: 0.26477061212062836, G Loss: 4.169669151306152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8194/100000, D Loss: 0.24389386177062988, G Loss: 4.408689022064209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8195/100000, D Loss: 0.21151525527238846, G Loss: 4.61344051361084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8196/100000, D Loss: 0.21493034809827805, G Loss: 4.925922870635986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8197/100000, D Loss: 0.23513292521238327, G Loss: 4.834291934967041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8198/100000, D Loss: 0.177288256585598, G Loss: 4.730105876922607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8199/100000, D Loss: 0.17858897894620895, G Loss: 4.797114849090576\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8200/100000, D Loss: 0.18561141192913055, G Loss: 5.024384498596191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8201/100000, D Loss: 0.1761418730020523, G Loss: 4.891916275024414\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8202/100000, D Loss: 0.16526799649000168, G Loss: 4.802129745483398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8203/100000, D Loss: 0.18064401298761368, G Loss: 4.499330043792725\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8204/100000, D Loss: 0.20229628682136536, G Loss: 4.594550132751465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8205/100000, D Loss: 0.17929384857416153, G Loss: 4.9139485359191895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8206/100000, D Loss: 0.2032889574766159, G Loss: 4.809491157531738\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8207/100000, D Loss: 0.23327109217643738, G Loss: 4.353869438171387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8208/100000, D Loss: 0.21053031086921692, G Loss: 4.409846305847168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8209/100000, D Loss: 0.19490856677293777, G Loss: 4.654417991638184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8210/100000, D Loss: 0.19662993401288986, G Loss: 4.5349931716918945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8211/100000, D Loss: 0.2335391417145729, G Loss: 4.100302696228027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8212/100000, D Loss: 0.22197842597961426, G Loss: 4.218348026275635\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8213/100000, D Loss: 0.2296236827969551, G Loss: 4.625795364379883\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8214/100000, D Loss: 0.2662545442581177, G Loss: 4.2425947189331055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8215/100000, D Loss: 0.26995979249477386, G Loss: 4.171252250671387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8216/100000, D Loss: 0.27322372794151306, G Loss: 4.4056854248046875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8217/100000, D Loss: 0.2608025372028351, G Loss: 4.5231547355651855\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8218/100000, D Loss: 0.24363955855369568, G Loss: 4.474658489227295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8219/100000, D Loss: 0.24335692822933197, G Loss: 4.228118896484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8220/100000, D Loss: 0.24318179488182068, G Loss: 4.289343357086182\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8221/100000, D Loss: 0.24916192889213562, G Loss: 4.409452438354492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8222/100000, D Loss: 0.23903468251228333, G Loss: 4.696317672729492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8223/100000, D Loss: 0.24614156037569046, G Loss: 4.303247928619385\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8224/100000, D Loss: 0.25624848902225494, G Loss: 4.1734619140625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8225/100000, D Loss: 0.23715484887361526, G Loss: 4.409176826477051\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8226/100000, D Loss: 0.2696762979030609, G Loss: 4.347138404846191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8227/100000, D Loss: 0.3181964159011841, G Loss: 4.118374824523926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8228/100000, D Loss: 0.2727027088403702, G Loss: 4.112140655517578\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8229/100000, D Loss: 0.2608915865421295, G Loss: 4.239347457885742\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8230/100000, D Loss: 0.3075018674135208, G Loss: 4.336076736450195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8231/100000, D Loss: 0.30349594354629517, G Loss: 4.085232734680176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8232/100000, D Loss: 0.33135010302066803, G Loss: 4.06933069229126\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8233/100000, D Loss: 0.3299129009246826, G Loss: 4.024439334869385\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8234/100000, D Loss: 0.34785614907741547, G Loss: 4.02693510055542\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8235/100000, D Loss: 0.315805122256279, G Loss: 3.923638343811035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8236/100000, D Loss: 0.291377454996109, G Loss: 3.998892307281494\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8237/100000, D Loss: 0.2852552980184555, G Loss: 4.202938079833984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8238/100000, D Loss: 0.32767458260059357, G Loss: 3.9558398723602295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8239/100000, D Loss: 0.31931300461292267, G Loss: 3.7233898639678955\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8240/100000, D Loss: 0.25293225049972534, G Loss: 4.255030155181885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8241/100000, D Loss: 0.2192297726869583, G Loss: 4.636992454528809\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8242/100000, D Loss: 0.21824408322572708, G Loss: 4.404266357421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8243/100000, D Loss: 0.2520333603024483, G Loss: 3.936953544616699\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8244/100000, D Loss: 0.18378514051437378, G Loss: 4.405150890350342\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8245/100000, D Loss: 0.18320661783218384, G Loss: 4.52974796295166\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8246/100000, D Loss: 0.19852004200220108, G Loss: 4.2348127365112305\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 8247/100000, D Loss: 0.18603414297103882, G Loss: 4.3718767166137695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8248/100000, D Loss: 0.19437071681022644, G Loss: 4.5347771644592285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8249/100000, D Loss: 0.1789776161313057, G Loss: 4.496420860290527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8250/100000, D Loss: 0.18063073605298996, G Loss: 4.328185558319092\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8251/100000, D Loss: 0.19733743369579315, G Loss: 4.325318336486816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8252/100000, D Loss: 0.18685179203748703, G Loss: 4.275163173675537\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8253/100000, D Loss: 0.1885291114449501, G Loss: 4.322683334350586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8254/100000, D Loss: 0.20200206339359283, G Loss: 4.264392852783203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8255/100000, D Loss: 0.16973578184843063, G Loss: 4.556519508361816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8256/100000, D Loss: 0.1928466111421585, G Loss: 4.335698127746582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8257/100000, D Loss: 0.1999819651246071, G Loss: 4.082541465759277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8258/100000, D Loss: 0.20964177697896957, G Loss: 3.8096961975097656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8259/100000, D Loss: 0.19711358845233917, G Loss: 4.236807823181152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8260/100000, D Loss: 0.1943640410900116, G Loss: 4.656486988067627\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8261/100000, D Loss: 0.19761888682842255, G Loss: 4.286717414855957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8262/100000, D Loss: 0.265288770198822, G Loss: 3.8710267543792725\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8263/100000, D Loss: 0.2665908709168434, G Loss: 4.085015296936035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8264/100000, D Loss: 0.21868915855884552, G Loss: 4.4752984046936035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8265/100000, D Loss: 0.2704474925994873, G Loss: 3.89229679107666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8266/100000, D Loss: 0.3341619074344635, G Loss: 3.721585512161255\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8267/100000, D Loss: 0.21836573630571365, G Loss: 4.393790245056152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8268/100000, D Loss: 0.28604012727737427, G Loss: 4.113809585571289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8269/100000, D Loss: 0.273007795214653, G Loss: 3.7775254249572754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8270/100000, D Loss: 0.3014068752527237, G Loss: 4.115073204040527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8271/100000, D Loss: 0.2638247013092041, G Loss: 4.07872200012207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8272/100000, D Loss: 0.2805773392319679, G Loss: 4.050171375274658\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8273/100000, D Loss: 0.28467799723148346, G Loss: 3.834399700164795\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8274/100000, D Loss: 0.31350207328796387, G Loss: 3.9073781967163086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8275/100000, D Loss: 0.27437666058540344, G Loss: 4.082637310028076\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8276/100000, D Loss: 0.2881599962711334, G Loss: 4.136284351348877\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8277/100000, D Loss: 0.2509143576025963, G Loss: 4.242782115936279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8278/100000, D Loss: 0.2683635801076889, G Loss: 3.9667797088623047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8279/100000, D Loss: 0.27391327917575836, G Loss: 3.935415267944336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8280/100000, D Loss: 0.28021320700645447, G Loss: 4.008156776428223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8281/100000, D Loss: 0.24610597640275955, G Loss: 4.065454483032227\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8282/100000, D Loss: 0.28477058559656143, G Loss: 4.057487487792969\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8283/100000, D Loss: 0.2442587986588478, G Loss: 4.308197975158691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8284/100000, D Loss: 0.23352375626564026, G Loss: 4.549457550048828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8285/100000, D Loss: 0.22541502118110657, G Loss: 4.490160942077637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8286/100000, D Loss: 0.21860898286104202, G Loss: 3.980142831802368\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8287/100000, D Loss: 0.18967506289482117, G Loss: 4.178350448608398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8288/100000, D Loss: 0.16960367560386658, G Loss: 4.523951530456543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8289/100000, D Loss: 0.1958378702402115, G Loss: 4.6761794090271\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8290/100000, D Loss: 0.19017992913722992, G Loss: 4.1851396560668945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8291/100000, D Loss: 0.19931845366954803, G Loss: 4.01357889175415\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8292/100000, D Loss: 0.1813921108841896, G Loss: 4.462732791900635\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8293/100000, D Loss: 0.16207797825336456, G Loss: 4.685294151306152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8294/100000, D Loss: 0.23656728863716125, G Loss: 4.050981521606445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8295/100000, D Loss: 0.21482767909765244, G Loss: 4.067922115325928\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8296/100000, D Loss: 0.17388557642698288, G Loss: 4.670320987701416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8297/100000, D Loss: 0.1713198684155941, G Loss: 4.781188011169434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8298/100000, D Loss: 0.19110475108027458, G Loss: 4.264505386352539\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8299/100000, D Loss: 0.20122873038053513, G Loss: 4.000923156738281\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8300/100000, D Loss: 0.1693117767572403, G Loss: 4.540740013122559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8301/100000, D Loss: 0.19229967892169952, G Loss: 4.701634883880615\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8302/100000, D Loss: 0.20252832770347595, G Loss: 4.432158470153809\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8303/100000, D Loss: 0.18765295296907425, G Loss: 4.414165019989014\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8304/100000, D Loss: 0.17476920038461685, G Loss: 4.36842155456543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8305/100000, D Loss: 0.1817997395992279, G Loss: 4.563476085662842\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8306/100000, D Loss: 0.20576806366443634, G Loss: 4.514267444610596\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8307/100000, D Loss: 0.18699848651885986, G Loss: 4.485787391662598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8308/100000, D Loss: 0.17266112565994263, G Loss: 4.5172271728515625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8309/100000, D Loss: 0.1943473517894745, G Loss: 4.542876720428467\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8310/100000, D Loss: 0.21161723881959915, G Loss: 4.427972793579102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8311/100000, D Loss: 0.19273001700639725, G Loss: 4.534050941467285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8312/100000, D Loss: 0.18253332376480103, G Loss: 4.573306083679199\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8313/100000, D Loss: 0.23523327708244324, G Loss: 4.178473949432373\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8314/100000, D Loss: 0.2749737799167633, G Loss: 3.9619791507720947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8315/100000, D Loss: 0.20120205730199814, G Loss: 4.329983711242676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8316/100000, D Loss: 0.231094092130661, G Loss: 4.577486991882324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8317/100000, D Loss: 0.31299257278442383, G Loss: 3.9191694259643555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8318/100000, D Loss: 0.2721119821071625, G Loss: 3.9279377460479736\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8319/100000, D Loss: 0.25278275460004807, G Loss: 4.620405197143555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8320/100000, D Loss: 0.2664676457643509, G Loss: 4.495478630065918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8321/100000, D Loss: 0.347371369600296, G Loss: 3.4577860832214355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8322/100000, D Loss: 0.2840307950973511, G Loss: 4.227191925048828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8323/100000, D Loss: 0.2466108351945877, G Loss: 4.3930583000183105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8324/100000, D Loss: 0.2961217314004898, G Loss: 3.8803763389587402\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8325/100000, D Loss: 0.3263546973466873, G Loss: 3.6795217990875244\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8326/100000, D Loss: 0.2829047739505768, G Loss: 4.433216571807861\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8327/100000, D Loss: 0.2631423771381378, G Loss: 4.472294807434082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8328/100000, D Loss: 0.28696706891059875, G Loss: 3.910094738006592\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8329/100000, D Loss: 0.28842777013778687, G Loss: 3.9501278400421143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8330/100000, D Loss: 0.23376941680908203, G Loss: 4.490933418273926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8331/100000, D Loss: 0.291486456990242, G Loss: 4.375940799713135\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8332/100000, D Loss: 0.2853463292121887, G Loss: 3.782790184020996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8333/100000, D Loss: 0.27366891503334045, G Loss: 4.300040245056152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8334/100000, D Loss: 0.25558631867170334, G Loss: 4.267475128173828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8335/100000, D Loss: 0.293059304356575, G Loss: 3.8292489051818848\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8336/100000, D Loss: 0.3086075037717819, G Loss: 3.8427233695983887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8337/100000, D Loss: 0.22804367542266846, G Loss: 4.658303737640381\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8338/100000, D Loss: 0.31375449150800705, G Loss: 3.8803305625915527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8339/100000, D Loss: 0.31995145976543427, G Loss: 3.51780366897583\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8340/100000, D Loss: 0.2539149671792984, G Loss: 4.0165181159973145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8341/100000, D Loss: 0.2565050944685936, G Loss: 4.248262405395508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8342/100000, D Loss: 0.3020354434847832, G Loss: 3.830895185470581\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8343/100000, D Loss: 0.3071850836277008, G Loss: 3.7686920166015625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8344/100000, D Loss: 0.2621311992406845, G Loss: 4.263248443603516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8345/100000, D Loss: 0.27149808406829834, G Loss: 4.258426189422607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8346/100000, D Loss: 0.30788494646549225, G Loss: 4.148018836975098\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8347/100000, D Loss: 0.295339398086071, G Loss: 4.055627346038818\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8348/100000, D Loss: 0.276552677154541, G Loss: 4.353669166564941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8349/100000, D Loss: 0.24900683760643005, G Loss: 4.296273231506348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8350/100000, D Loss: 0.2748345509171486, G Loss: 4.154570579528809\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8351/100000, D Loss: 0.23968929052352905, G Loss: 4.135268688201904\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8352/100000, D Loss: 0.22027621418237686, G Loss: 4.25347900390625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8353/100000, D Loss: 0.19207406044006348, G Loss: 4.303542137145996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8354/100000, D Loss: 0.21191295236349106, G Loss: 4.082555770874023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8355/100000, D Loss: 0.1722472906112671, G Loss: 4.2445068359375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8356/100000, D Loss: 0.21093779802322388, G Loss: 4.246913909912109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8357/100000, D Loss: 0.1984216421842575, G Loss: 4.529016017913818\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8358/100000, D Loss: 0.2159213349223137, G Loss: 4.3805365562438965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8359/100000, D Loss: 0.18608500063419342, G Loss: 4.5909576416015625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8360/100000, D Loss: 0.19990023970603943, G Loss: 4.495719909667969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8361/100000, D Loss: 0.2041396126151085, G Loss: 4.173707008361816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8362/100000, D Loss: 0.22314460575580597, G Loss: 4.525418281555176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8363/100000, D Loss: 0.1984100118279457, G Loss: 4.652691841125488\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8364/100000, D Loss: 0.1888665035367012, G Loss: 4.567794322967529\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8365/100000, D Loss: 0.19538423418998718, G Loss: 4.734529495239258\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8366/100000, D Loss: 0.1742214858531952, G Loss: 4.669970989227295\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8367/100000, D Loss: 0.20059144496917725, G Loss: 4.7476348876953125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8368/100000, D Loss: 0.1996542066335678, G Loss: 4.635395526885986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8369/100000, D Loss: 0.192153662443161, G Loss: 4.703983306884766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8370/100000, D Loss: 0.1956283301115036, G Loss: 4.713324546813965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8371/100000, D Loss: 0.18356186151504517, G Loss: 4.591518402099609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8372/100000, D Loss: 0.18032753467559814, G Loss: 4.569287300109863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8373/100000, D Loss: 0.1735546514391899, G Loss: 4.748300552368164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8374/100000, D Loss: 0.19960807263851166, G Loss: 4.6404829025268555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8375/100000, D Loss: 0.20805564522743225, G Loss: 4.426304340362549\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8376/100000, D Loss: 0.1938467174768448, G Loss: 4.627718925476074\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8377/100000, D Loss: 0.19834356755018234, G Loss: 4.569521903991699\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8378/100000, D Loss: 0.19138173013925552, G Loss: 4.507721900939941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8379/100000, D Loss: 0.2179180234670639, G Loss: 4.578317165374756\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8380/100000, D Loss: 0.170754075050354, G Loss: 4.888641357421875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8381/100000, D Loss: 0.20364827662706375, G Loss: 5.062397480010986\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8382/100000, D Loss: 0.20905736088752747, G Loss: 4.639686584472656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8383/100000, D Loss: 0.2063138708472252, G Loss: 4.778615951538086\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8384/100000, D Loss: 0.182810477912426, G Loss: 4.825906753540039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8385/100000, D Loss: 0.2042972892522812, G Loss: 4.90661096572876\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8386/100000, D Loss: 0.20048008859157562, G Loss: 4.49418830871582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8387/100000, D Loss: 0.24796009063720703, G Loss: 4.667464733123779\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8388/100000, D Loss: 0.2285449206829071, G Loss: 4.497439861297607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8389/100000, D Loss: 0.2610553503036499, G Loss: 4.2435407638549805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8390/100000, D Loss: 0.25778043270111084, G Loss: 4.3088579177856445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8391/100000, D Loss: 0.25580430030822754, G Loss: 4.283092021942139\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8392/100000, D Loss: 0.32325349748134613, G Loss: 3.8133718967437744\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8393/100000, D Loss: 0.3644602298736572, G Loss: 3.969881534576416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8394/100000, D Loss: 0.30819350481033325, G Loss: 4.422085762023926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8395/100000, D Loss: 0.38640235364437103, G Loss: 3.9337687492370605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8396/100000, D Loss: 0.39361271262168884, G Loss: 3.9507412910461426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8397/100000, D Loss: 0.3558449000120163, G Loss: 4.218923091888428\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8398/100000, D Loss: 0.3601311296224594, G Loss: 3.7689380645751953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8399/100000, D Loss: 0.3802066445350647, G Loss: 3.653886318206787\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8400/100000, D Loss: 0.29055531322956085, G Loss: 4.046932220458984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8401/100000, D Loss: 0.32971950620412827, G Loss: 4.304399490356445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8402/100000, D Loss: 0.3155721202492714, G Loss: 3.9197371006011963\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8403/100000, D Loss: 0.34557273983955383, G Loss: 4.023505687713623\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8404/100000, D Loss: 0.22050762921571732, G Loss: 4.632911682128906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8405/100000, D Loss: 0.19989275187253952, G Loss: 4.774683475494385\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8406/100000, D Loss: 0.20025481283664703, G Loss: 4.464486122131348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8407/100000, D Loss: 0.18674538284540176, G Loss: 4.3901214599609375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8408/100000, D Loss: 0.17336292564868927, G Loss: 4.650425434112549\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8409/100000, D Loss: 0.12474017962813377, G Loss: 5.322519779205322\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8410/100000, D Loss: 0.15073080733418465, G Loss: 5.0006256103515625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8411/100000, D Loss: 0.15627405792474747, G Loss: 4.750389099121094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8412/100000, D Loss: 0.14912857115268707, G Loss: 5.025582313537598\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8413/100000, D Loss: 0.12043450027704239, G Loss: 5.165675163269043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8414/100000, D Loss: 0.12947584688663483, G Loss: 5.061084747314453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8415/100000, D Loss: 0.12433379888534546, G Loss: 4.989044189453125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8416/100000, D Loss: 0.1798131763935089, G Loss: 4.61749792098999\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8417/100000, D Loss: 0.17796329408884048, G Loss: 4.702457427978516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8418/100000, D Loss: 0.14777658134698868, G Loss: 4.76643705368042\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8419/100000, D Loss: 0.20731928944587708, G Loss: 4.891283988952637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8420/100000, D Loss: 0.178813599050045, G Loss: 4.694147109985352\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8421/100000, D Loss: 0.21419260650873184, G Loss: 4.3599677085876465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8422/100000, D Loss: 0.2107550948858261, G Loss: 4.481987953186035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8423/100000, D Loss: 0.22844874113798141, G Loss: 4.627353191375732\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8424/100000, D Loss: 0.24886665493249893, G Loss: 4.472661018371582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8425/100000, D Loss: 0.31103767454624176, G Loss: 4.077467441558838\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8426/100000, D Loss: 0.3020002394914627, G Loss: 4.109193801879883\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8427/100000, D Loss: 0.30903585255146027, G Loss: 4.4715776443481445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8428/100000, D Loss: 0.2842845171689987, G Loss: 4.295429229736328\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8429/100000, D Loss: 0.38858629763126373, G Loss: 3.8083488941192627\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8430/100000, D Loss: 0.3569463789463043, G Loss: 4.251159191131592\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8431/100000, D Loss: 0.3275901675224304, G Loss: 4.3208417892456055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8432/100000, D Loss: 0.41502290964126587, G Loss: 3.91005277633667\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8433/100000, D Loss: 0.34000933170318604, G Loss: 3.9085206985473633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8434/100000, D Loss: 0.35754460096359253, G Loss: 4.0986833572387695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8435/100000, D Loss: 0.3148605525493622, G Loss: 4.280252456665039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8436/100000, D Loss: 0.37208832800388336, G Loss: 3.820394277572632\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8437/100000, D Loss: 0.35233163833618164, G Loss: 3.836543083190918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8438/100000, D Loss: 0.29994477331638336, G Loss: 4.444956302642822\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8439/100000, D Loss: 0.31377018988132477, G Loss: 4.406483173370361\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8440/100000, D Loss: 0.321320578455925, G Loss: 3.8049092292785645\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8441/100000, D Loss: 0.29864293336868286, G Loss: 4.179730415344238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8442/100000, D Loss: 0.1949019730091095, G Loss: 4.890683174133301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8443/100000, D Loss: 0.2413356751203537, G Loss: 4.587876319885254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8444/100000, D Loss: 0.2947539836168289, G Loss: 4.112532615661621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8445/100000, D Loss: 0.17900827527046204, G Loss: 4.573044300079346\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8446/100000, D Loss: 0.18444177508354187, G Loss: 4.905535697937012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8447/100000, D Loss: 0.18131496757268906, G Loss: 4.564173698425293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8448/100000, D Loss: 0.19049926847219467, G Loss: 4.386183738708496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8449/100000, D Loss: 0.1603936180472374, G Loss: 4.31000280380249\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8450/100000, D Loss: 0.14249201118946075, G Loss: 4.663361549377441\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8451/100000, D Loss: 0.17118819057941437, G Loss: 4.818978309631348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8452/100000, D Loss: 0.157984159886837, G Loss: 4.838891506195068\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8453/100000, D Loss: 0.14878537133336067, G Loss: 4.63813591003418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8454/100000, D Loss: 0.1698802262544632, G Loss: 4.62952184677124\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8455/100000, D Loss: 0.16375092417001724, G Loss: 4.807741641998291\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8456/100000, D Loss: 0.13807447627186775, G Loss: 4.85914421081543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8457/100000, D Loss: 0.16717667877674103, G Loss: 4.69748592376709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8458/100000, D Loss: 0.1938008815050125, G Loss: 4.446896553039551\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8459/100000, D Loss: 0.1622546836733818, G Loss: 4.498273849487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8460/100000, D Loss: 0.1786215826869011, G Loss: 4.535890579223633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8461/100000, D Loss: 0.17348001897335052, G Loss: 4.527358055114746\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8462/100000, D Loss: 0.16649649292230606, G Loss: 4.701536178588867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8463/100000, D Loss: 0.1617511473596096, G Loss: 4.597043037414551\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8464/100000, D Loss: 0.18847787380218506, G Loss: 4.219245910644531\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8465/100000, D Loss: 0.18947415053844452, G Loss: 4.442646503448486\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8466/100000, D Loss: 0.16517861187458038, G Loss: 4.751164436340332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8467/100000, D Loss: 0.20142199099063873, G Loss: 4.746453762054443\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8468/100000, D Loss: 0.1905612349510193, G Loss: 4.43756103515625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8469/100000, D Loss: 0.1900765523314476, G Loss: 4.133872032165527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8470/100000, D Loss: 0.21846069395542145, G Loss: 4.1971893310546875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8471/100000, D Loss: 0.18006447702646255, G Loss: 4.700381278991699\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8472/100000, D Loss: 0.1683165431022644, G Loss: 4.553342342376709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8473/100000, D Loss: 0.18965600430965424, G Loss: 4.355557918548584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8474/100000, D Loss: 0.19688651710748672, G Loss: 4.3177385330200195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8475/100000, D Loss: 0.20618581026792526, G Loss: 4.337540626525879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8476/100000, D Loss: 0.19429679214954376, G Loss: 4.677090644836426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8477/100000, D Loss: 0.1766943857073784, G Loss: 4.726395606994629\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8478/100000, D Loss: 0.1724839210510254, G Loss: 4.384768486022949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8479/100000, D Loss: 0.19126659631729126, G Loss: 4.408855438232422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8480/100000, D Loss: 0.215329609811306, G Loss: 4.45578670501709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8481/100000, D Loss: 0.16875335574150085, G Loss: 4.574103355407715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8482/100000, D Loss: 0.18042255192995071, G Loss: 4.82944393157959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8483/100000, D Loss: 0.151919636875391, G Loss: 4.8254475593566895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8484/100000, D Loss: 0.18572376668453217, G Loss: 4.326085090637207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8485/100000, D Loss: 0.1479191929101944, G Loss: 4.447555065155029\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8486/100000, D Loss: 0.15923155844211578, G Loss: 4.830798149108887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8487/100000, D Loss: 0.1794697642326355, G Loss: 4.746798515319824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8488/100000, D Loss: 0.1920999139547348, G Loss: 4.488071441650391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8489/100000, D Loss: 0.182191401720047, G Loss: 4.480750560760498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8490/100000, D Loss: 0.16541605442762375, G Loss: 4.576786994934082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8491/100000, D Loss: 0.19686530530452728, G Loss: 4.588772773742676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8492/100000, D Loss: 0.2122606337070465, G Loss: 4.257050037384033\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8493/100000, D Loss: 0.1795872300863266, G Loss: 4.47352933883667\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8494/100000, D Loss: 0.20751383155584335, G Loss: 4.412549018859863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8495/100000, D Loss: 0.20069971680641174, G Loss: 4.307768821716309\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8496/100000, D Loss: 0.19893402606248856, G Loss: 4.290017127990723\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8497/100000, D Loss: 0.24322789162397385, G Loss: 4.139122009277344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8498/100000, D Loss: 0.22532019019126892, G Loss: 4.3508687019348145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8499/100000, D Loss: 0.18530651926994324, G Loss: 4.564178466796875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8500/100000, D Loss: 0.21341388672590256, G Loss: 4.292189598083496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8501/100000, D Loss: 0.24501121044158936, G Loss: 3.9214205741882324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8502/100000, D Loss: 0.24176503717899323, G Loss: 4.180119514465332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8503/100000, D Loss: 0.20980606228113174, G Loss: 4.545164585113525\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8504/100000, D Loss: 0.21996331214904785, G Loss: 4.289663314819336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8505/100000, D Loss: 0.24852301180362701, G Loss: 4.040148735046387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8506/100000, D Loss: 0.23237085342407227, G Loss: 4.206290245056152\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8507/100000, D Loss: 0.2132159173488617, G Loss: 4.434057235717773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8508/100000, D Loss: 0.24530202895402908, G Loss: 4.1988348960876465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8509/100000, D Loss: 0.2645605653524399, G Loss: 4.271832466125488\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8510/100000, D Loss: 0.23671141266822815, G Loss: 4.378988742828369\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8511/100000, D Loss: 0.25794580578804016, G Loss: 4.341767311096191\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8512/100000, D Loss: 0.2614787146449089, G Loss: 4.073227882385254\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8513/100000, D Loss: 0.2629961669445038, G Loss: 4.232938766479492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8514/100000, D Loss: 0.29067063331604004, G Loss: 4.170418739318848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8515/100000, D Loss: 0.26640306413173676, G Loss: 4.182789325714111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8516/100000, D Loss: 0.31234945356845856, G Loss: 3.8631038665771484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8517/100000, D Loss: 0.31282860040664673, G Loss: 3.9742777347564697\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8518/100000, D Loss: 0.3076407462358475, G Loss: 4.287841796875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8519/100000, D Loss: 0.22484201192855835, G Loss: 4.446497917175293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8520/100000, D Loss: 0.34369957447052, G Loss: 3.818110466003418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8521/100000, D Loss: 0.315342053771019, G Loss: 3.804189682006836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8522/100000, D Loss: 0.24438510090112686, G Loss: 4.629472732543945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8523/100000, D Loss: 0.2704250067472458, G Loss: 4.492008209228516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8524/100000, D Loss: 0.28157056123018265, G Loss: 4.179479598999023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8525/100000, D Loss: 0.24866367876529694, G Loss: 4.080734729766846\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8526/100000, D Loss: 0.2655673176050186, G Loss: 4.428780555725098\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8527/100000, D Loss: 0.2751530557870865, G Loss: 4.521254539489746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8528/100000, D Loss: 0.24864404648542404, G Loss: 4.5638322830200195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8529/100000, D Loss: 0.2667418271303177, G Loss: 4.1915483474731445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8530/100000, D Loss: 0.3038288801908493, G Loss: 4.0417890548706055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8531/100000, D Loss: 0.2928219884634018, G Loss: 4.335872650146484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8532/100000, D Loss: 0.28374244272708893, G Loss: 4.3422088623046875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8533/100000, D Loss: 0.32452186942100525, G Loss: 4.186651706695557\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8534/100000, D Loss: 0.30692996084690094, G Loss: 4.149023056030273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8535/100000, D Loss: 0.282000333070755, G Loss: 4.429782390594482\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8536/100000, D Loss: 0.3240487426519394, G Loss: 4.313783645629883\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8537/100000, D Loss: 0.2892310470342636, G Loss: 4.041365623474121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8538/100000, D Loss: 0.31739500164985657, G Loss: 3.9591174125671387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8539/100000, D Loss: 0.30572202801704407, G Loss: 4.636890411376953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8540/100000, D Loss: 0.2412649467587471, G Loss: 4.913039207458496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8541/100000, D Loss: 0.30709028244018555, G Loss: 4.114145278930664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8542/100000, D Loss: 0.24412698298692703, G Loss: 3.880862236022949\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8543/100000, D Loss: 0.24974852055311203, G Loss: 4.45702600479126\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8544/100000, D Loss: 0.21738124638795853, G Loss: 4.946380615234375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8545/100000, D Loss: 0.2867201715707779, G Loss: 4.446371078491211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8546/100000, D Loss: 0.31017209589481354, G Loss: 3.8991897106170654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8547/100000, D Loss: 0.23768571764230728, G Loss: 4.308778762817383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8548/100000, D Loss: 0.1865752786397934, G Loss: 4.691575527191162\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8549/100000, D Loss: 0.1861630491912365, G Loss: 4.624234199523926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8550/100000, D Loss: 0.22725574672222137, G Loss: 4.27756404876709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8551/100000, D Loss: 0.21527068316936493, G Loss: 4.468969345092773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8552/100000, D Loss: 0.18460723012685776, G Loss: 4.780755519866943\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8553/100000, D Loss: 0.197248212993145, G Loss: 4.670080661773682\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8554/100000, D Loss: 0.21745014190673828, G Loss: 4.047120094299316\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8555/100000, D Loss: 0.22528555244207382, G Loss: 4.327092170715332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8556/100000, D Loss: 0.17182929813861847, G Loss: 4.874817848205566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8557/100000, D Loss: 0.19233478605747223, G Loss: 4.640069007873535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8558/100000, D Loss: 0.19392793625593185, G Loss: 4.226565361022949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8559/100000, D Loss: 0.2136925905942917, G Loss: 4.347434997558594\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8560/100000, D Loss: 0.21170775592327118, G Loss: 4.801652908325195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8561/100000, D Loss: 0.1890024021267891, G Loss: 4.793385028839111\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8562/100000, D Loss: 0.2312387228012085, G Loss: 4.108354091644287\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8563/100000, D Loss: 0.2152697592973709, G Loss: 4.148512840270996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8564/100000, D Loss: 0.1505759060382843, G Loss: 4.745977878570557\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8565/100000, D Loss: 0.17338356003165245, G Loss: 4.706974029541016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8566/100000, D Loss: 0.20001474022865295, G Loss: 4.519405364990234\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8567/100000, D Loss: 0.17615443468093872, G Loss: 4.111482620239258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8568/100000, D Loss: 0.1965045928955078, G Loss: 4.373603343963623\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8569/100000, D Loss: 0.19068937003612518, G Loss: 4.833550453186035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8570/100000, D Loss: 0.18649320304393768, G Loss: 4.808040618896484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8571/100000, D Loss: 0.2446753978729248, G Loss: 4.207431793212891\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8572/100000, D Loss: 0.21748769283294678, G Loss: 4.30687952041626\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 8573/100000, D Loss: 0.20818549394607544, G Loss: 4.6681623458862305\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 8574/100000, D Loss: 0.2656608521938324, G Loss: 4.468596458435059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8575/100000, D Loss: 0.27108342945575714, G Loss: 4.258782863616943\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8576/100000, D Loss: 0.2652260661125183, G Loss: 4.384938716888428\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8577/100000, D Loss: 0.24750712513923645, G Loss: 4.277039527893066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8578/100000, D Loss: 0.28675659000873566, G Loss: 4.139077186584473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8579/100000, D Loss: 0.19966178387403488, G Loss: 4.630791187286377\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8580/100000, D Loss: 0.19164106249809265, G Loss: 4.865664482116699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8581/100000, D Loss: 0.24190876632928848, G Loss: 4.525619029998779\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8582/100000, D Loss: 0.23624379187822342, G Loss: 4.358802795410156\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8583/100000, D Loss: 0.22135823965072632, G Loss: 4.632938861846924\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8584/100000, D Loss: 0.19530996680259705, G Loss: 5.030967712402344\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8585/100000, D Loss: 0.1763768047094345, G Loss: 5.225395679473877\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8586/100000, D Loss: 0.20670968294143677, G Loss: 4.80051326751709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8587/100000, D Loss: 0.19398324191570282, G Loss: 4.541802406311035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8588/100000, D Loss: 0.21423785388469696, G Loss: 4.970541954040527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8589/100000, D Loss: 0.1687742993235588, G Loss: 5.343011379241943\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8590/100000, D Loss: 0.21038731932640076, G Loss: 4.994668006896973\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8591/100000, D Loss: 0.23774739354848862, G Loss: 4.657983779907227\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8592/100000, D Loss: 0.2561589404940605, G Loss: 4.202116966247559\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8593/100000, D Loss: 0.24285240471363068, G Loss: 4.737196445465088\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8594/100000, D Loss: 0.2481480911374092, G Loss: 4.831470966339111\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 8595/100000, D Loss: 0.2986944541335106, G Loss: 4.459892749786377\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8596/100000, D Loss: 0.2869330942630768, G Loss: 4.184230804443359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8597/100000, D Loss: 0.2731200009584427, G Loss: 4.662165641784668\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8598/100000, D Loss: 0.2508695423603058, G Loss: 4.873613357543945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8599/100000, D Loss: 0.2977313846349716, G Loss: 4.113931655883789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8600/100000, D Loss: 0.3330671042203903, G Loss: 4.025091171264648\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8601/100000, D Loss: 0.2329413741827011, G Loss: 4.771124839782715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8602/100000, D Loss: 0.2968636006116867, G Loss: 4.509934425354004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8603/100000, D Loss: 0.2539121061563492, G Loss: 4.210158824920654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8604/100000, D Loss: 0.2419080138206482, G Loss: 4.723965644836426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8605/100000, D Loss: 0.31923360377550125, G Loss: 4.4974284172058105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8606/100000, D Loss: 0.3154529929161072, G Loss: 4.326678276062012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8607/100000, D Loss: 0.24392755329608917, G Loss: 4.381845951080322\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8608/100000, D Loss: 0.28643110394477844, G Loss: 4.4603471755981445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8609/100000, D Loss: 0.27805158495903015, G Loss: 4.6399383544921875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8610/100000, D Loss: 0.27719417214393616, G Loss: 4.326061248779297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8611/100000, D Loss: 0.30916672945022583, G Loss: 4.283687591552734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8612/100000, D Loss: 0.24447943270206451, G Loss: 5.0626935958862305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8613/100000, D Loss: 0.28580474108457565, G Loss: 4.662286281585693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8614/100000, D Loss: 0.23861178755760193, G Loss: 4.587054252624512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8615/100000, D Loss: 0.2586118057370186, G Loss: 4.606650352478027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8616/100000, D Loss: 0.2239132672548294, G Loss: 4.736169815063477\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8617/100000, D Loss: 0.22857022285461426, G Loss: 4.87210750579834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8618/100000, D Loss: 0.2656032666563988, G Loss: 4.597089767456055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8619/100000, D Loss: 0.25393854081630707, G Loss: 4.418390274047852\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8620/100000, D Loss: 0.22074901312589645, G Loss: 4.74548864364624\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8621/100000, D Loss: 0.2358548790216446, G Loss: 4.74763298034668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8622/100000, D Loss: 0.2606087327003479, G Loss: 4.667159080505371\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8623/100000, D Loss: 0.2999523654580116, G Loss: 4.393777370452881\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8624/100000, D Loss: 0.3187197148799896, G Loss: 4.214503765106201\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8625/100000, D Loss: 0.29741232097148895, G Loss: 4.766565799713135\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8626/100000, D Loss: 0.29124945402145386, G Loss: 4.730573654174805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8627/100000, D Loss: 0.35787028074264526, G Loss: 4.048467636108398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8628/100000, D Loss: 0.3231523931026459, G Loss: 4.309380054473877\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8629/100000, D Loss: 0.2796034961938858, G Loss: 4.777505874633789\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8630/100000, D Loss: 0.2634553387761116, G Loss: 4.678199768066406\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8631/100000, D Loss: 0.27239061892032623, G Loss: 4.223748683929443\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8632/100000, D Loss: 0.2724003940820694, G Loss: 4.484325408935547\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8633/100000, D Loss: 0.23300182819366455, G Loss: 4.805346488952637\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8634/100000, D Loss: 0.19202589243650436, G Loss: 4.9994964599609375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8635/100000, D Loss: 0.18604014068841934, G Loss: 4.86456298828125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8636/100000, D Loss: 0.1707356721162796, G Loss: 4.874302864074707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8637/100000, D Loss: 0.17530404031276703, G Loss: 4.705806732177734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8638/100000, D Loss: 0.16463494300842285, G Loss: 4.991025447845459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8639/100000, D Loss: 0.17261835932731628, G Loss: 5.257935523986816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8640/100000, D Loss: 0.18157567083835602, G Loss: 4.78471565246582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8641/100000, D Loss: 0.1566258892416954, G Loss: 4.763371467590332\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8642/100000, D Loss: 0.14908207952976227, G Loss: 5.014303207397461\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 8643/100000, D Loss: 0.1473420299589634, G Loss: 5.247014999389648\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 8644/100000, D Loss: 0.19186627119779587, G Loss: 4.7343316078186035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8645/100000, D Loss: 0.18643680959939957, G Loss: 4.598041534423828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8646/100000, D Loss: 0.16466760635375977, G Loss: 4.70797872543335\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8647/100000, D Loss: 0.15904071927070618, G Loss: 4.883593559265137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8648/100000, D Loss: 0.1792459934949875, G Loss: 4.996058940887451\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8649/100000, D Loss: 0.1961309239268303, G Loss: 4.717835903167725\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8650/100000, D Loss: 0.17192038893699646, G Loss: 4.549455165863037\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8651/100000, D Loss: 0.19160563498735428, G Loss: 4.59194278717041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8652/100000, D Loss: 0.18777380883693695, G Loss: 4.716341495513916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8653/100000, D Loss: 0.2371039241552353, G Loss: 4.547883987426758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8654/100000, D Loss: 0.24257032573223114, G Loss: 4.52928352355957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8655/100000, D Loss: 0.21375398337841034, G Loss: 4.412048816680908\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8656/100000, D Loss: 0.2643764615058899, G Loss: 4.244931697845459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8657/100000, D Loss: 0.2741560637950897, G Loss: 4.180004119873047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8658/100000, D Loss: 0.2489636242389679, G Loss: 4.111927509307861\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8659/100000, D Loss: 0.26868054270744324, G Loss: 4.208577632904053\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8660/100000, D Loss: 0.28333769738674164, G Loss: 4.042060852050781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8661/100000, D Loss: 0.28807175159454346, G Loss: 4.1252970695495605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8662/100000, D Loss: 0.31471961736679077, G Loss: 3.7384958267211914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8663/100000, D Loss: 0.32923945784568787, G Loss: 4.130145072937012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8664/100000, D Loss: 0.3797236979007721, G Loss: 3.996495008468628\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8665/100000, D Loss: 0.3190065026283264, G Loss: 3.9301581382751465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8666/100000, D Loss: 0.37654413282871246, G Loss: 3.6716787815093994\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8667/100000, D Loss: 0.39207032322883606, G Loss: 4.061655044555664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8668/100000, D Loss: 0.41458216309547424, G Loss: 3.912604808807373\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8669/100000, D Loss: 0.42374187707901, G Loss: 4.026532173156738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8670/100000, D Loss: 0.3676440119743347, G Loss: 3.7337136268615723\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8671/100000, D Loss: 0.42702437937259674, G Loss: 3.7469582557678223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8672/100000, D Loss: 0.3993642181158066, G Loss: 3.801063060760498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8673/100000, D Loss: 0.3690868616104126, G Loss: 3.8747658729553223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8674/100000, D Loss: 0.3791399896144867, G Loss: 3.738878011703491\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8675/100000, D Loss: 0.393623486161232, G Loss: 3.7733218669891357\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8676/100000, D Loss: 0.3604595363140106, G Loss: 3.9860894680023193\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8677/100000, D Loss: 0.350161150097847, G Loss: 3.841153144836426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8678/100000, D Loss: 0.30199840664863586, G Loss: 3.9838719367980957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8679/100000, D Loss: 0.3071219325065613, G Loss: 3.950571060180664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8680/100000, D Loss: 0.27453529834747314, G Loss: 4.198451042175293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8681/100000, D Loss: 0.22929536551237106, G Loss: 4.277682304382324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8682/100000, D Loss: 0.22648368775844574, G Loss: 4.414007186889648\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8683/100000, D Loss: 0.19301177561283112, G Loss: 4.688987731933594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8684/100000, D Loss: 0.16195861995220184, G Loss: 4.852216720581055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8685/100000, D Loss: 0.15251541510224342, G Loss: 4.973093509674072\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8686/100000, D Loss: 0.1540166661143303, G Loss: 4.659604072570801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8687/100000, D Loss: 0.15891818702220917, G Loss: 4.857983589172363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8688/100000, D Loss: 0.12716145813465118, G Loss: 5.192741394042969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8689/100000, D Loss: 0.14619416743516922, G Loss: 5.214681625366211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8690/100000, D Loss: 0.1446758359670639, G Loss: 4.55623722076416\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8691/100000, D Loss: 0.15797193348407745, G Loss: 4.6132402420043945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8692/100000, D Loss: 0.14506684988737106, G Loss: 4.927489280700684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8693/100000, D Loss: 0.15124968439340591, G Loss: 5.120384216308594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8694/100000, D Loss: 0.18327417969703674, G Loss: 4.72084379196167\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8695/100000, D Loss: 0.21641232073307037, G Loss: 4.355090141296387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8696/100000, D Loss: 0.22569306194782257, G Loss: 4.47836971282959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8697/100000, D Loss: 0.18881553411483765, G Loss: 5.23701810836792\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8698/100000, D Loss: 0.22049085795879364, G Loss: 4.832707405090332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8699/100000, D Loss: 0.2725088745355606, G Loss: 3.9543280601501465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8700/100000, D Loss: 0.2624531164765358, G Loss: 4.2332658767700195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8701/100000, D Loss: 0.1996643990278244, G Loss: 5.131483554840088\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8702/100000, D Loss: 0.24164561927318573, G Loss: 4.760157108306885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8703/100000, D Loss: 0.2736358195543289, G Loss: 3.897709369659424\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8704/100000, D Loss: 0.3311643600463867, G Loss: 4.085414886474609\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8705/100000, D Loss: 0.2634039968252182, G Loss: 5.10205078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8706/100000, D Loss: 0.34891898185014725, G Loss: 4.664439678192139\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8707/100000, D Loss: 0.35422998666763306, G Loss: 3.9785690307617188\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8708/100000, D Loss: 0.35559235513210297, G Loss: 4.201452255249023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8709/100000, D Loss: 0.3460080474615097, G Loss: 4.454824447631836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8710/100000, D Loss: 0.47376610338687897, G Loss: 3.832941770553589\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8711/100000, D Loss: 0.45426225662231445, G Loss: 3.859739065170288\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8712/100000, D Loss: 0.37504255771636963, G Loss: 4.3859758377075195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8713/100000, D Loss: 0.4070236533880234, G Loss: 4.258945941925049\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8714/100000, D Loss: 0.6010919213294983, G Loss: 3.3417298793792725\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8715/100000, D Loss: 0.481372132897377, G Loss: 3.962125778198242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8716/100000, D Loss: 0.4105708748102188, G Loss: 4.464232444763184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8717/100000, D Loss: 0.43264254927635193, G Loss: 3.782655715942383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8718/100000, D Loss: 0.517691045999527, G Loss: 3.4660582542419434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8719/100000, D Loss: 0.3024580478668213, G Loss: 4.590225696563721\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8720/100000, D Loss: 0.3315560296177864, G Loss: 4.660946369171143\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8721/100000, D Loss: 0.29557301104068756, G Loss: 4.00919771194458\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8722/100000, D Loss: 0.25099436938762665, G Loss: 4.236518383026123\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8723/100000, D Loss: 0.21536363661289215, G Loss: 4.640496253967285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8724/100000, D Loss: 0.1673012413084507, G Loss: 4.82663631439209\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8725/100000, D Loss: 0.22037900984287262, G Loss: 4.500972270965576\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8726/100000, D Loss: 0.20023925602436066, G Loss: 4.362525939941406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8727/100000, D Loss: 0.15639032423496246, G Loss: 4.654671669006348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8728/100000, D Loss: 0.1321779489517212, G Loss: 4.916342735290527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8729/100000, D Loss: 0.14736055210232735, G Loss: 4.664695739746094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8730/100000, D Loss: 0.1654236614704132, G Loss: 4.486082553863525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8731/100000, D Loss: 0.1588059663772583, G Loss: 4.701853275299072\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8732/100000, D Loss: 0.13126135617494583, G Loss: 4.9631476402282715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8733/100000, D Loss: 0.1516750529408455, G Loss: 4.9015889167785645\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8734/100000, D Loss: 0.15867702662944794, G Loss: 4.5904083251953125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8735/100000, D Loss: 0.14921622723340988, G Loss: 4.654172420501709\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8736/100000, D Loss: 0.15527397394180298, G Loss: 4.932023525238037\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8737/100000, D Loss: 0.16888854652643204, G Loss: 4.789308071136475\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8738/100000, D Loss: 0.14126936718821526, G Loss: 4.683934211730957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8739/100000, D Loss: 0.18014311790466309, G Loss: 4.657809734344482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8740/100000, D Loss: 0.1899137794971466, G Loss: 4.451639175415039\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8741/100000, D Loss: 0.16982318460941315, G Loss: 4.641980171203613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8742/100000, D Loss: 0.19477977603673935, G Loss: 4.7123260498046875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8743/100000, D Loss: 0.20139314979314804, G Loss: 4.574191570281982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8744/100000, D Loss: 0.23585550487041473, G Loss: 4.121828079223633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8745/100000, D Loss: 0.17952995002269745, G Loss: 4.343771934509277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8746/100000, D Loss: 0.20584912598133087, G Loss: 4.399884223937988\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8747/100000, D Loss: 0.24039226770401, G Loss: 4.044408798217773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8748/100000, D Loss: 0.23232901096343994, G Loss: 3.9992403984069824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8749/100000, D Loss: 0.2417590469121933, G Loss: 4.361288070678711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8750/100000, D Loss: 0.24435987323522568, G Loss: 4.242974758148193\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8751/100000, D Loss: 0.30759575963020325, G Loss: 4.01210880279541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8752/100000, D Loss: 0.2767910957336426, G Loss: 3.868605613708496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8753/100000, D Loss: 0.30641062557697296, G Loss: 4.024262428283691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8754/100000, D Loss: 0.3532046675682068, G Loss: 4.107440948486328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8755/100000, D Loss: 0.31501419842243195, G Loss: 4.1136322021484375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8756/100000, D Loss: 0.37066785991191864, G Loss: 3.951528787612915\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8757/100000, D Loss: 0.29155807197093964, G Loss: 4.096492767333984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8758/100000, D Loss: 0.33456021547317505, G Loss: 3.9695816040039062\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8759/100000, D Loss: 0.3421475440263748, G Loss: 3.7372303009033203\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8760/100000, D Loss: 0.27729713916778564, G Loss: 3.941765785217285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8761/100000, D Loss: 0.23301541060209274, G Loss: 4.578161716461182\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8762/100000, D Loss: 0.23177995532751083, G Loss: 4.424938201904297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8763/100000, D Loss: 0.2504582405090332, G Loss: 4.063009738922119\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8764/100000, D Loss: 0.2592935860157013, G Loss: 4.168334484100342\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8765/100000, D Loss: 0.1851116567850113, G Loss: 4.794865608215332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8766/100000, D Loss: 0.2203509584069252, G Loss: 4.684471130371094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8767/100000, D Loss: 0.23360705375671387, G Loss: 4.312955856323242\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8768/100000, D Loss: 0.23753353208303452, G Loss: 4.201728820800781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8769/100000, D Loss: 0.1997605338692665, G Loss: 4.738686561584473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8770/100000, D Loss: 0.21408158540725708, G Loss: 4.57034969329834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8771/100000, D Loss: 0.2482132837176323, G Loss: 4.333139419555664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8772/100000, D Loss: 0.2332962080836296, G Loss: 4.462914943695068\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8773/100000, D Loss: 0.24018440395593643, G Loss: 4.66483736038208\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8774/100000, D Loss: 0.18896252661943436, G Loss: 4.861208915710449\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8775/100000, D Loss: 0.2297118455171585, G Loss: 4.5825910568237305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8776/100000, D Loss: 0.18561743199825287, G Loss: 4.562857627868652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8777/100000, D Loss: 0.172053262591362, G Loss: 4.609548568725586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8778/100000, D Loss: 0.2083657681941986, G Loss: 4.485300064086914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8779/100000, D Loss: 0.18131060153245926, G Loss: 4.777551651000977\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8780/100000, D Loss: 0.1435374766588211, G Loss: 4.655574798583984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8781/100000, D Loss: 0.16989009827375412, G Loss: 4.642332553863525\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8782/100000, D Loss: 0.15851758792996407, G Loss: 4.78481388092041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8783/100000, D Loss: 0.18241874873638153, G Loss: 4.514565467834473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8784/100000, D Loss: 0.14144589006900787, G Loss: 4.874973773956299\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8785/100000, D Loss: 0.14076289534568787, G Loss: 4.870136260986328\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8786/100000, D Loss: 0.15446923673152924, G Loss: 4.762319564819336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8787/100000, D Loss: 0.16538161039352417, G Loss: 4.62775993347168\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8788/100000, D Loss: 0.17627649754285812, G Loss: 4.697964668273926\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8789/100000, D Loss: 0.12972836196422577, G Loss: 5.23192834854126\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8790/100000, D Loss: 0.17223887890577316, G Loss: 5.222803115844727\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8791/100000, D Loss: 0.18140146136283875, G Loss: 4.697494029998779\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8792/100000, D Loss: 0.19035479426383972, G Loss: 4.531893730163574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8793/100000, D Loss: 0.18021881580352783, G Loss: 5.041133880615234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8794/100000, D Loss: 0.14356498420238495, G Loss: 5.0927734375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8795/100000, D Loss: 0.19729218631982803, G Loss: 4.747505187988281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8796/100000, D Loss: 0.2647641897201538, G Loss: 4.457548141479492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8797/100000, D Loss: 0.24673186987638474, G Loss: 4.6238837242126465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8798/100000, D Loss: 0.21792227029800415, G Loss: 5.027928352355957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8799/100000, D Loss: 0.281147263944149, G Loss: 4.6539306640625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8800/100000, D Loss: 0.28959451615810394, G Loss: 4.5587358474731445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8801/100000, D Loss: 0.21985863149166107, G Loss: 5.168495178222656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8802/100000, D Loss: 0.2822168469429016, G Loss: 4.666545867919922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8803/100000, D Loss: 0.3545403331518173, G Loss: 4.159280776977539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8804/100000, D Loss: 0.3402276635169983, G Loss: 4.712610721588135\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8805/100000, D Loss: 0.2353230118751526, G Loss: 5.784917831420898\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8806/100000, D Loss: 0.35175593197345734, G Loss: 4.444521903991699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8807/100000, D Loss: 0.3415524512529373, G Loss: 4.208397388458252\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8808/100000, D Loss: 0.2715820297598839, G Loss: 4.875375747680664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8809/100000, D Loss: 0.25116869807243347, G Loss: 5.351634979248047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8810/100000, D Loss: 0.28076910972595215, G Loss: 4.862016677856445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8811/100000, D Loss: 0.3015584498643875, G Loss: 4.466068267822266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8812/100000, D Loss: 0.2635824829339981, G Loss: 5.0970988273620605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8813/100000, D Loss: 0.2734510526061058, G Loss: 5.226645469665527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8814/100000, D Loss: 0.31353165209293365, G Loss: 4.629587173461914\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8815/100000, D Loss: 0.27313216030597687, G Loss: 4.530946731567383\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8816/100000, D Loss: 0.2870424687862396, G Loss: 4.979860305786133\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8817/100000, D Loss: 0.21697770059108734, G Loss: 5.164259910583496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8818/100000, D Loss: 0.23542601615190506, G Loss: 4.738112449645996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8819/100000, D Loss: 0.2864735797047615, G Loss: 4.1171555519104\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8820/100000, D Loss: 0.22292417287826538, G Loss: 4.325767993927002\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8821/100000, D Loss: 0.2619175910949707, G Loss: 4.998913764953613\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8822/100000, D Loss: 0.22909891605377197, G Loss: 4.9028120040893555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8823/100000, D Loss: 0.2980397865176201, G Loss: 4.305201053619385\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8824/100000, D Loss: 0.29449811577796936, G Loss: 4.12345027923584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8825/100000, D Loss: 0.239406019449234, G Loss: 4.726595401763916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8826/100000, D Loss: 0.250950388610363, G Loss: 4.969388008117676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8827/100000, D Loss: 0.2938580960035324, G Loss: 4.5217790603637695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8828/100000, D Loss: 0.3051688075065613, G Loss: 4.093503952026367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8829/100000, D Loss: 0.2466716319322586, G Loss: 4.555648326873779\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8830/100000, D Loss: 0.2804289907217026, G Loss: 4.718855857849121\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8831/100000, D Loss: 0.3300105780363083, G Loss: 4.49367618560791\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8832/100000, D Loss: 0.2791515737771988, G Loss: 4.114604473114014\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8833/100000, D Loss: 0.280729740858078, G Loss: 4.339132785797119\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8834/100000, D Loss: 0.2948351055383682, G Loss: 4.21699857711792\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8835/100000, D Loss: 0.3111112713813782, G Loss: 4.293247222900391\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8836/100000, D Loss: 0.3208550214767456, G Loss: 4.31371545791626\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8837/100000, D Loss: 0.3225807845592499, G Loss: 4.302476406097412\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8838/100000, D Loss: 0.37182649970054626, G Loss: 4.264500617980957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8839/100000, D Loss: 0.3381366431713104, G Loss: 4.465982437133789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8840/100000, D Loss: 0.32145215570926666, G Loss: 4.481113910675049\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8841/100000, D Loss: 0.2987665385007858, G Loss: 4.170382976531982\n",
      "32/32 [==============================] - 1s 17ms/step\n",
      "Epoch 8842/100000, D Loss: 0.26212991774082184, G Loss: 4.6581926345825195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8843/100000, D Loss: 0.221519336104393, G Loss: 5.230819225311279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8844/100000, D Loss: 0.2418433427810669, G Loss: 5.094363212585449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8845/100000, D Loss: 0.22242803126573563, G Loss: 4.862759590148926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8846/100000, D Loss: 0.17493480443954468, G Loss: 4.799400329589844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8847/100000, D Loss: 0.136612668633461, G Loss: 5.7230401039123535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8848/100000, D Loss: 0.15232138708233833, G Loss: 5.970677852630615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8849/100000, D Loss: 0.15229269862174988, G Loss: 5.49312162399292\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8850/100000, D Loss: 0.16017818450927734, G Loss: 5.133251190185547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8851/100000, D Loss: 0.1668020784854889, G Loss: 4.998319625854492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8852/100000, D Loss: 0.16731306165456772, G Loss: 5.340181827545166\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8853/100000, D Loss: 0.17226746678352356, G Loss: 5.23355770111084\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8854/100000, D Loss: 0.212617389857769, G Loss: 5.06222677230835\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8855/100000, D Loss: 0.2333829328417778, G Loss: 4.452657699584961\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8856/100000, D Loss: 0.2594187259674072, G Loss: 4.756643772125244\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8857/100000, D Loss: 0.2503828704357147, G Loss: 5.077304363250732\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8858/100000, D Loss: 0.28993619978427887, G Loss: 4.865298271179199\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8859/100000, D Loss: 0.31567807495594025, G Loss: 4.174935340881348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8860/100000, D Loss: 0.3072735518217087, G Loss: 4.402317523956299\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8861/100000, D Loss: 0.2782572954893112, G Loss: 4.747846603393555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8862/100000, D Loss: 0.31582455337047577, G Loss: 4.509335517883301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8863/100000, D Loss: 0.3151020407676697, G Loss: 4.085309028625488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8864/100000, D Loss: 0.3283321410417557, G Loss: 4.0559258460998535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8865/100000, D Loss: 0.2840493321418762, G Loss: 4.587618827819824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8866/100000, D Loss: 0.2596200406551361, G Loss: 4.635473251342773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8867/100000, D Loss: 0.24875593185424805, G Loss: 4.469905853271484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8868/100000, D Loss: 0.2486473247408867, G Loss: 4.355557441711426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8869/100000, D Loss: 0.21915826946496964, G Loss: 4.529292106628418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8870/100000, D Loss: 0.2241746038198471, G Loss: 4.89215612411499\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8871/100000, D Loss: 0.2737670987844467, G Loss: 4.444038391113281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8872/100000, D Loss: 0.2419023960828781, G Loss: 4.3524394035339355\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8873/100000, D Loss: 0.23250170797109604, G Loss: 4.538522243499756\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8874/100000, D Loss: 0.19375842809677124, G Loss: 4.827539920806885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8875/100000, D Loss: 0.24882227182388306, G Loss: 4.394344806671143\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8876/100000, D Loss: 0.2436068281531334, G Loss: 4.340584754943848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8877/100000, D Loss: 0.20689328759908676, G Loss: 4.720884799957275\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8878/100000, D Loss: 0.24517406523227692, G Loss: 4.605238437652588\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8879/100000, D Loss: 0.25412582606077194, G Loss: 4.398921966552734\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8880/100000, D Loss: 0.2752864509820938, G Loss: 4.136529445648193\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8881/100000, D Loss: 0.21921062469482422, G Loss: 4.436944007873535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8882/100000, D Loss: 0.25693026930093765, G Loss: 4.299198627471924\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8883/100000, D Loss: 0.24088110029697418, G Loss: 4.023495674133301\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8884/100000, D Loss: 0.24954751133918762, G Loss: 4.177001953125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8885/100000, D Loss: 0.26759782433509827, G Loss: 4.1785359382629395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8886/100000, D Loss: 0.28019388765096664, G Loss: 4.034407615661621\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8887/100000, D Loss: 0.3074674755334854, G Loss: 3.9851467609405518\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8888/100000, D Loss: 0.2782151401042938, G Loss: 4.368151664733887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8889/100000, D Loss: 0.29489245265722275, G Loss: 4.283871173858643\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8890/100000, D Loss: 0.2507367208600044, G Loss: 4.205417633056641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8891/100000, D Loss: 0.2444796860218048, G Loss: 4.276946544647217\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8892/100000, D Loss: 0.23359455168247223, G Loss: 4.200130939483643\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8893/100000, D Loss: 0.2007225900888443, G Loss: 4.387545108795166\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8894/100000, D Loss: 0.19894489645957947, G Loss: 4.751128673553467\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8895/100000, D Loss: 0.22359514981508255, G Loss: 4.399123191833496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8896/100000, D Loss: 0.23495950549840927, G Loss: 4.31821346282959\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8897/100000, D Loss: 0.1865488439798355, G Loss: 4.800081253051758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8898/100000, D Loss: 0.1866687685251236, G Loss: 4.804833889007568\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8899/100000, D Loss: 0.2294926717877388, G Loss: 4.488706588745117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8900/100000, D Loss: 0.2184220850467682, G Loss: 4.343968868255615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8901/100000, D Loss: 0.1783624067902565, G Loss: 4.468026161193848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8902/100000, D Loss: 0.18080655485391617, G Loss: 4.743792533874512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8903/100000, D Loss: 0.22241678088903427, G Loss: 4.552225112915039\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8904/100000, D Loss: 0.17894302308559418, G Loss: 4.717964172363281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8905/100000, D Loss: 0.1896626129746437, G Loss: 4.801649570465088\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8906/100000, D Loss: 0.18631480634212494, G Loss: 4.662120819091797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8907/100000, D Loss: 0.22916901856660843, G Loss: 4.91422176361084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8908/100000, D Loss: 0.2017921581864357, G Loss: 4.944127082824707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8909/100000, D Loss: 0.19222001731395721, G Loss: 4.612407684326172\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8910/100000, D Loss: 0.20610647648572922, G Loss: 4.423028945922852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8911/100000, D Loss: 0.18203575164079666, G Loss: 4.397243499755859\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8912/100000, D Loss: 0.21583378314971924, G Loss: 4.396440505981445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8913/100000, D Loss: 0.2114693894982338, G Loss: 4.379324436187744\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8914/100000, D Loss: 0.19466843456029892, G Loss: 4.549654960632324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8915/100000, D Loss: 0.18733899295330048, G Loss: 4.744767189025879\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8916/100000, D Loss: 0.2544027417898178, G Loss: 4.3881988525390625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8917/100000, D Loss: 0.25303326547145844, G Loss: 4.452038288116455\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8918/100000, D Loss: 0.19103150814771652, G Loss: 4.6263508796691895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8919/100000, D Loss: 0.2440849393606186, G Loss: 4.5797224044799805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8920/100000, D Loss: 0.24138674139976501, G Loss: 4.20884895324707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8921/100000, D Loss: 0.2534806430339813, G Loss: 4.0296125411987305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8922/100000, D Loss: 0.27167629450559616, G Loss: 3.989745616912842\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8923/100000, D Loss: 0.3069761097431183, G Loss: 3.977163553237915\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8924/100000, D Loss: 0.3249889463186264, G Loss: 3.995871067047119\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8925/100000, D Loss: 0.31787319481372833, G Loss: 4.061558723449707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8926/100000, D Loss: 0.3253406435251236, G Loss: 4.051389217376709\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8927/100000, D Loss: 0.32119905948638916, G Loss: 4.085477828979492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8928/100000, D Loss: 0.34711146354675293, G Loss: 4.070798873901367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8929/100000, D Loss: 0.32708799839019775, G Loss: 4.099518299102783\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8930/100000, D Loss: 0.27674632519483566, G Loss: 4.363380432128906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8931/100000, D Loss: 0.3068481385707855, G Loss: 4.194984436035156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8932/100000, D Loss: 0.2765503525733948, G Loss: 4.076692581176758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8933/100000, D Loss: 0.2648875415325165, G Loss: 4.344595432281494\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8934/100000, D Loss: 0.25948113203048706, G Loss: 4.493110656738281\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8935/100000, D Loss: 0.2523687407374382, G Loss: 4.32796573638916\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8936/100000, D Loss: 0.25726965069770813, G Loss: 4.152857780456543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8937/100000, D Loss: 0.20925576239824295, G Loss: 4.467418670654297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8938/100000, D Loss: 0.21330106258392334, G Loss: 4.3566975593566895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8939/100000, D Loss: 0.27107471227645874, G Loss: 4.282999038696289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8940/100000, D Loss: 0.19646631926298141, G Loss: 4.472562789916992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8941/100000, D Loss: 0.18050897121429443, G Loss: 4.880995273590088\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8942/100000, D Loss: 0.19767747819423676, G Loss: 4.882712364196777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8943/100000, D Loss: 0.2070356085896492, G Loss: 4.749463081359863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 8944/100000, D Loss: 0.17197149991989136, G Loss: 4.632776260375977\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8945/100000, D Loss: 0.18108726292848587, G Loss: 4.511192798614502\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8946/100000, D Loss: 0.1503075286746025, G Loss: 4.685011863708496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8947/100000, D Loss: 0.15422435104846954, G Loss: 4.9478759765625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8948/100000, D Loss: 0.15843003243207932, G Loss: 4.721130847930908\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8949/100000, D Loss: 0.1922304481267929, G Loss: 4.484233856201172\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8950/100000, D Loss: 0.18367312103509903, G Loss: 4.433971405029297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8951/100000, D Loss: 0.20345710217952728, G Loss: 4.627612113952637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8952/100000, D Loss: 0.1952260360121727, G Loss: 4.697203159332275\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8953/100000, D Loss: 0.22390197962522507, G Loss: 4.537012577056885\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8954/100000, D Loss: 0.20255034416913986, G Loss: 4.206783294677734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8955/100000, D Loss: 0.24769259989261627, G Loss: 4.020597457885742\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8956/100000, D Loss: 0.2522597312927246, G Loss: 4.41107177734375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8957/100000, D Loss: 0.20960833132266998, G Loss: 4.712427139282227\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8958/100000, D Loss: 0.25492551922798157, G Loss: 4.4713850021362305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8959/100000, D Loss: 0.24809545278549194, G Loss: 3.8717222213745117\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8960/100000, D Loss: 0.27394913136959076, G Loss: 4.1962385177612305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8961/100000, D Loss: 0.23278187960386276, G Loss: 4.668216705322266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8962/100000, D Loss: 0.2580145299434662, G Loss: 4.706470489501953\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8963/100000, D Loss: 0.239283949136734, G Loss: 4.345974922180176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8964/100000, D Loss: 0.26183196902275085, G Loss: 4.118821620941162\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8965/100000, D Loss: 0.3210560381412506, G Loss: 4.18618631362915\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8966/100000, D Loss: 0.2809329777956009, G Loss: 4.633894443511963\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8967/100000, D Loss: 0.29339106380939484, G Loss: 4.725763320922852\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8968/100000, D Loss: 0.31548812985420227, G Loss: 4.065451622009277\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8969/100000, D Loss: 0.2892913222312927, G Loss: 4.287718772888184\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8970/100000, D Loss: 0.3077647089958191, G Loss: 4.610837936401367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8971/100000, D Loss: 0.3060489371418953, G Loss: 4.426789283752441\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8972/100000, D Loss: 0.2848512977361679, G Loss: 4.386509895324707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8973/100000, D Loss: 0.2585361748933792, G Loss: 4.64811897277832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8974/100000, D Loss: 0.215669684112072, G Loss: 4.5688796043396\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8975/100000, D Loss: 0.17938479781150818, G Loss: 4.473804950714111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8976/100000, D Loss: 0.19266056269407272, G Loss: 4.687916278839111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8977/100000, D Loss: 0.2002595216035843, G Loss: 4.802308082580566\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8978/100000, D Loss: 0.16923420131206512, G Loss: 4.880260467529297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8979/100000, D Loss: 0.163589708507061, G Loss: 4.82004976272583\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8980/100000, D Loss: 0.15479669719934464, G Loss: 4.972849369049072\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8981/100000, D Loss: 0.15912649035453796, G Loss: 4.873357772827148\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8982/100000, D Loss: 0.126522496342659, G Loss: 4.930553436279297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8983/100000, D Loss: 0.1398751512169838, G Loss: 4.862558841705322\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8984/100000, D Loss: 0.15457233786582947, G Loss: 4.7506184577941895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8985/100000, D Loss: 0.16357019543647766, G Loss: 5.01495361328125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8986/100000, D Loss: 0.16994011402130127, G Loss: 4.835004806518555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8987/100000, D Loss: 0.18047234416007996, G Loss: 4.57945442199707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8988/100000, D Loss: 0.15312416851520538, G Loss: 4.512444972991943\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8989/100000, D Loss: 0.18379436433315277, G Loss: 4.698515892028809\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8990/100000, D Loss: 0.2114323228597641, G Loss: 4.921213626861572\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8991/100000, D Loss: 0.2024334967136383, G Loss: 4.661405563354492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8992/100000, D Loss: 0.21764009445905685, G Loss: 4.3709716796875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8993/100000, D Loss: 0.2590683698654175, G Loss: 4.257340908050537\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8994/100000, D Loss: 0.25517550855875015, G Loss: 4.350912094116211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8995/100000, D Loss: 0.2483280599117279, G Loss: 4.457674503326416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8996/100000, D Loss: 0.24068428575992584, G Loss: 4.271084308624268\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8997/100000, D Loss: 0.2633609175682068, G Loss: 4.234262943267822\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 8998/100000, D Loss: 0.21650074422359467, G Loss: 4.520002841949463\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 8999/100000, D Loss: 0.2425191029906273, G Loss: 4.196539402008057\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9000/100000, D Loss: 0.2549052760004997, G Loss: 4.143170356750488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9001/100000, D Loss: 0.26366885751485825, G Loss: 4.083527565002441\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9002/100000, D Loss: 0.22556771337985992, G Loss: 4.441606521606445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9003/100000, D Loss: 0.22895758599042892, G Loss: 4.424233913421631\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9004/100000, D Loss: 0.23918680846691132, G Loss: 4.3280439376831055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9005/100000, D Loss: 0.21893242746591568, G Loss: 4.333293914794922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9006/100000, D Loss: 0.23574542254209518, G Loss: 4.390418529510498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9007/100000, D Loss: 0.23029206693172455, G Loss: 4.357754707336426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9008/100000, D Loss: 0.20960471779108047, G Loss: 4.218530654907227\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9009/100000, D Loss: 0.26637642085552216, G Loss: 4.0791802406311035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9010/100000, D Loss: 0.20461902022361755, G Loss: 4.185280799865723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9011/100000, D Loss: 0.20066215097904205, G Loss: 4.464169979095459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9012/100000, D Loss: 0.22570636868476868, G Loss: 4.233320236206055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9013/100000, D Loss: 0.2693687975406647, G Loss: 4.174039840698242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9014/100000, D Loss: 0.22447272390127182, G Loss: 4.148015022277832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9015/100000, D Loss: 0.2776121348142624, G Loss: 4.106939315795898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9016/100000, D Loss: 0.24132873862981796, G Loss: 4.202023506164551\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9017/100000, D Loss: 0.2613285332918167, G Loss: 3.9930429458618164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9018/100000, D Loss: 0.2517317682504654, G Loss: 4.084586143493652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9019/100000, D Loss: 0.2761654704809189, G Loss: 4.14699125289917\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9020/100000, D Loss: 0.22331997007131577, G Loss: 4.364386558532715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9021/100000, D Loss: 0.2486780881881714, G Loss: 4.403703689575195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9022/100000, D Loss: 0.2691049426794052, G Loss: 4.217772483825684\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9023/100000, D Loss: 0.2551659047603607, G Loss: 4.272660732269287\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9024/100000, D Loss: 0.21269682794809341, G Loss: 4.488461017608643\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9025/100000, D Loss: 0.2503478527069092, G Loss: 4.427579879760742\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9026/100000, D Loss: 0.2411426529288292, G Loss: 4.179944038391113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9027/100000, D Loss: 0.22672544419765472, G Loss: 4.211193084716797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9028/100000, D Loss: 0.23655178397893906, G Loss: 4.264780521392822\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9029/100000, D Loss: 0.21980367600917816, G Loss: 4.446956634521484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9030/100000, D Loss: 0.21320383250713348, G Loss: 4.572697639465332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9031/100000, D Loss: 0.2274397611618042, G Loss: 4.202786445617676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9032/100000, D Loss: 0.19064342975616455, G Loss: 4.40875768661499\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9033/100000, D Loss: 0.2038189098238945, G Loss: 4.425746440887451\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9034/100000, D Loss: 0.19612116366624832, G Loss: 4.350961685180664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9035/100000, D Loss: 0.18027247488498688, G Loss: 4.432690620422363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9036/100000, D Loss: 0.21505378186702728, G Loss: 4.356646537780762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9037/100000, D Loss: 0.1997690424323082, G Loss: 4.276480674743652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9038/100000, D Loss: 0.17570732533931732, G Loss: 4.458388328552246\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9039/100000, D Loss: 0.17192796617746353, G Loss: 4.762310981750488\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9040/100000, D Loss: 0.19814543426036835, G Loss: 4.476747989654541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9041/100000, D Loss: 0.18682754039764404, G Loss: 4.186826705932617\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9042/100000, D Loss: 0.18252186477184296, G Loss: 4.339338779449463\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9043/100000, D Loss: 0.16608725488185883, G Loss: 4.703065872192383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9044/100000, D Loss: 0.183171346783638, G Loss: 4.694548606872559\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9045/100000, D Loss: 0.2370632290840149, G Loss: 4.230561256408691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9046/100000, D Loss: 0.22661972045898438, G Loss: 4.403972625732422\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9047/100000, D Loss: 0.19931825995445251, G Loss: 4.452609062194824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9048/100000, D Loss: 0.19634132087230682, G Loss: 4.599365234375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9049/100000, D Loss: 0.21174243092536926, G Loss: 4.229708194732666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9050/100000, D Loss: 0.16872325539588928, G Loss: 4.51467227935791\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9051/100000, D Loss: 0.2001652643084526, G Loss: 4.422307014465332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9052/100000, D Loss: 0.21721971780061722, G Loss: 4.351962089538574\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9053/100000, D Loss: 0.1921515315771103, G Loss: 4.218406677246094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9054/100000, D Loss: 0.20595592260360718, G Loss: 3.9021739959716797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9055/100000, D Loss: 0.21154411882162094, G Loss: 4.062434673309326\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9056/100000, D Loss: 0.2319183424115181, G Loss: 4.484500408172607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9057/100000, D Loss: 0.21852093935012817, G Loss: 4.5063982009887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9058/100000, D Loss: 0.251458540558815, G Loss: 4.1338958740234375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9059/100000, D Loss: 0.2742287814617157, G Loss: 3.8010716438293457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9060/100000, D Loss: 0.24105790257453918, G Loss: 4.349746227264404\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9061/100000, D Loss: 0.21226094663143158, G Loss: 4.453631401062012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9062/100000, D Loss: 0.25559742003679276, G Loss: 4.20436954498291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9063/100000, D Loss: 0.2361152470111847, G Loss: 4.019887924194336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9064/100000, D Loss: 0.26050058007240295, G Loss: 4.138744354248047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9065/100000, D Loss: 0.23276081681251526, G Loss: 4.111336708068848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9066/100000, D Loss: 0.20633472502231598, G Loss: 4.251152515411377\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9067/100000, D Loss: 0.2305493727326393, G Loss: 4.192917346954346\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9068/100000, D Loss: 0.2663756161928177, G Loss: 3.9316062927246094\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9069/100000, D Loss: 0.26908987760543823, G Loss: 4.003002166748047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9070/100000, D Loss: 0.24852018058300018, G Loss: 4.001222610473633\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9071/100000, D Loss: 0.2682180851697922, G Loss: 4.003323078155518\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9072/100000, D Loss: 0.31904318928718567, G Loss: 3.8899784088134766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9073/100000, D Loss: 0.3365875780582428, G Loss: 3.784738302230835\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9074/100000, D Loss: 0.2983105033636093, G Loss: 3.769414186477661\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9075/100000, D Loss: 0.34721195697784424, G Loss: 3.7340946197509766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9076/100000, D Loss: 0.2810432240366936, G Loss: 3.797273635864258\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9077/100000, D Loss: 0.34106725454330444, G Loss: 3.655212879180908\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9078/100000, D Loss: 0.30391447246074677, G Loss: 3.8315203189849854\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9079/100000, D Loss: 0.29081787168979645, G Loss: 3.9080986976623535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9080/100000, D Loss: 0.29231541603803635, G Loss: 3.864304542541504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9081/100000, D Loss: 0.31752297282218933, G Loss: 3.875452995300293\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9082/100000, D Loss: 0.283090278506279, G Loss: 3.775339365005493\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9083/100000, D Loss: 0.22261886298656464, G Loss: 4.181556701660156\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9084/100000, D Loss: 0.24809753894805908, G Loss: 4.136755466461182\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9085/100000, D Loss: 0.25771497189998627, G Loss: 3.7883877754211426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9086/100000, D Loss: 0.22075245529413223, G Loss: 4.05141544342041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9087/100000, D Loss: 0.21686877310276031, G Loss: 4.579069137573242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9088/100000, D Loss: 0.22931358218193054, G Loss: 4.4147748947143555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9089/100000, D Loss: 0.2504331171512604, G Loss: 4.0631608963012695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9090/100000, D Loss: 0.2092832252383232, G Loss: 4.2513813972473145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9091/100000, D Loss: 0.20951887965202332, G Loss: 4.439814567565918\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9092/100000, D Loss: 0.21402433514595032, G Loss: 4.43695068359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9093/100000, D Loss: 0.2427028864622116, G Loss: 3.9655067920684814\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9094/100000, D Loss: 0.21338265389204025, G Loss: 4.084812164306641\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9095/100000, D Loss: 0.24352005124092102, G Loss: 4.29440975189209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9096/100000, D Loss: 0.2019686996936798, G Loss: 4.325551986694336\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9097/100000, D Loss: 0.28547772765159607, G Loss: 3.8892722129821777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9098/100000, D Loss: 0.2889987379312515, G Loss: 4.0352373123168945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9099/100000, D Loss: 0.2155856341123581, G Loss: 4.370484352111816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9100/100000, D Loss: 0.3116009309887886, G Loss: 4.214367866516113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9101/100000, D Loss: 0.29122494161129, G Loss: 3.608494758605957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9102/100000, D Loss: 0.3147241473197937, G Loss: 3.897710084915161\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9103/100000, D Loss: 0.2411683201789856, G Loss: 4.424360275268555\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9104/100000, D Loss: 0.24022455513477325, G Loss: 4.459936141967773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9105/100000, D Loss: 0.2911030054092407, G Loss: 3.844754457473755\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9106/100000, D Loss: 0.22938411682844162, G Loss: 4.095964431762695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9107/100000, D Loss: 0.20567099004983902, G Loss: 4.509836673736572\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9108/100000, D Loss: 0.2277832329273224, G Loss: 4.355866432189941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9109/100000, D Loss: 0.22895286977291107, G Loss: 3.9920830726623535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9110/100000, D Loss: 0.22068923711776733, G Loss: 4.2740373611450195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9111/100000, D Loss: 0.1970324069261551, G Loss: 4.588018417358398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9112/100000, D Loss: 0.2061142921447754, G Loss: 4.52560567855835\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9113/100000, D Loss: 0.2181537002325058, G Loss: 4.271288871765137\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 9114/100000, D Loss: 0.1893753483891487, G Loss: 4.208083152770996\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9115/100000, D Loss: 0.19268152862787247, G Loss: 4.347018241882324\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9116/100000, D Loss: 0.16920943558216095, G Loss: 4.329996109008789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9117/100000, D Loss: 0.20184601098299026, G Loss: 4.303096771240234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9118/100000, D Loss: 0.20619642734527588, G Loss: 4.277358055114746\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9119/100000, D Loss: 0.22853562235832214, G Loss: 4.088043212890625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9120/100000, D Loss: 0.2543025314807892, G Loss: 3.974911689758301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9121/100000, D Loss: 0.2608969882130623, G Loss: 4.33303165435791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9122/100000, D Loss: 0.2568109631538391, G Loss: 4.190188407897949\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9123/100000, D Loss: 0.27000726759433746, G Loss: 3.8978161811828613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9124/100000, D Loss: 0.28790415823459625, G Loss: 3.9410362243652344\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9125/100000, D Loss: 0.2641710042953491, G Loss: 4.198156356811523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9126/100000, D Loss: 0.26778365671634674, G Loss: 4.358159065246582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9127/100000, D Loss: 0.26688040792942047, G Loss: 4.117606163024902\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9128/100000, D Loss: 0.2688973695039749, G Loss: 4.119935989379883\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9129/100000, D Loss: 0.28874145448207855, G Loss: 4.004619598388672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9130/100000, D Loss: 0.24685906618833542, G Loss: 4.140650749206543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9131/100000, D Loss: 0.29251091182231903, G Loss: 4.35071325302124\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9132/100000, D Loss: 0.26775334775447845, G Loss: 4.13725471496582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9133/100000, D Loss: 0.24026545882225037, G Loss: 4.179985046386719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9134/100000, D Loss: 0.25673700124025345, G Loss: 4.390237808227539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9135/100000, D Loss: 0.27484893798828125, G Loss: 4.436704158782959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9136/100000, D Loss: 0.2592744380235672, G Loss: 4.224585056304932\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9137/100000, D Loss: 0.2737196460366249, G Loss: 4.11155891418457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9138/100000, D Loss: 0.25618620961904526, G Loss: 4.385220527648926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9139/100000, D Loss: 0.2189338654279709, G Loss: 4.58112907409668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9140/100000, D Loss: 0.30244576930999756, G Loss: 4.2198381423950195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9141/100000, D Loss: 0.2581181600689888, G Loss: 4.1839752197265625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9142/100000, D Loss: 0.24851267039775848, G Loss: 4.223630905151367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9143/100000, D Loss: 0.2273809015750885, G Loss: 4.531220436096191\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9144/100000, D Loss: 0.24998974800109863, G Loss: 4.1460862159729\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9145/100000, D Loss: 0.25600823760032654, G Loss: 4.0285186767578125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9146/100000, D Loss: 0.28001219034194946, G Loss: 4.28229284286499\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9147/100000, D Loss: 0.25520825386047363, G Loss: 4.501996040344238\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9148/100000, D Loss: 0.22167810797691345, G Loss: 4.731463432312012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9149/100000, D Loss: 0.2674325332045555, G Loss: 4.1491217613220215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9150/100000, D Loss: 0.2215985506772995, G Loss: 4.008905410766602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9151/100000, D Loss: 0.24243516474962234, G Loss: 4.32457971572876\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9152/100000, D Loss: 0.22318678349256516, G Loss: 4.543928146362305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9153/100000, D Loss: 0.24752095341682434, G Loss: 4.318892002105713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9154/100000, D Loss: 0.21637460589408875, G Loss: 4.131612777709961\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9155/100000, D Loss: 0.2181076854467392, G Loss: 4.261937141418457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9156/100000, D Loss: 0.2543792128562927, G Loss: 4.512777328491211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9157/100000, D Loss: 0.20184346288442612, G Loss: 4.258950233459473\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9158/100000, D Loss: 0.23037868738174438, G Loss: 4.378665924072266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9159/100000, D Loss: 0.29547756910324097, G Loss: 3.9633822441101074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9160/100000, D Loss: 0.2504489868879318, G Loss: 4.225417137145996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9161/100000, D Loss: 0.24733814597129822, G Loss: 4.239532947540283\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9162/100000, D Loss: 0.26658325642347336, G Loss: 4.125356197357178\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9163/100000, D Loss: 0.27151212096214294, G Loss: 4.245944976806641\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9164/100000, D Loss: 0.2666037455201149, G Loss: 3.9372663497924805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9165/100000, D Loss: 0.23015622794628143, G Loss: 4.102620601654053\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9166/100000, D Loss: 0.23999463021755219, G Loss: 4.2936882972717285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9167/100000, D Loss: 0.26819370687007904, G Loss: 3.7557454109191895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9168/100000, D Loss: 0.2905755341053009, G Loss: 3.8344838619232178\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9169/100000, D Loss: 0.23367305099964142, G Loss: 4.166023254394531\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9170/100000, D Loss: 0.22076191008090973, G Loss: 4.325301170349121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9171/100000, D Loss: 0.2084573283791542, G Loss: 4.072859287261963\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9172/100000, D Loss: 0.2927439957857132, G Loss: 3.7069413661956787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9173/100000, D Loss: 0.23678681999444962, G Loss: 3.902373790740967\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9174/100000, D Loss: 0.2345869466662407, G Loss: 4.295464992523193\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9175/100000, D Loss: 0.23821903765201569, G Loss: 4.170833110809326\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9176/100000, D Loss: 0.27067285776138306, G Loss: 3.8479137420654297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9177/100000, D Loss: 0.24187041819095612, G Loss: 3.9911131858825684\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9178/100000, D Loss: 0.27449823170900345, G Loss: 3.874149799346924\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9179/100000, D Loss: 0.2969902604818344, G Loss: 3.6359872817993164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9180/100000, D Loss: 0.25410421192646027, G Loss: 3.854938268661499\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9181/100000, D Loss: 0.25367913395166397, G Loss: 4.1523661613464355\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9182/100000, D Loss: 0.26773781329393387, G Loss: 4.0178375244140625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9183/100000, D Loss: 0.2749779522418976, G Loss: 3.914337158203125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9184/100000, D Loss: 0.2775789648294449, G Loss: 3.917361259460449\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9185/100000, D Loss: 0.23687605559825897, G Loss: 4.33541202545166\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9186/100000, D Loss: 0.2436741590499878, G Loss: 4.26242733001709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9187/100000, D Loss: 0.22660597413778305, G Loss: 4.216026306152344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9188/100000, D Loss: 0.22845599055290222, G Loss: 4.089807510375977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9189/100000, D Loss: 0.21602578461170197, G Loss: 4.499702453613281\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9190/100000, D Loss: 0.19777009636163712, G Loss: 4.6216654777526855\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9191/100000, D Loss: 0.23231009393930435, G Loss: 4.413862228393555\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9192/100000, D Loss: 0.19132711738348007, G Loss: 4.271983623504639\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9193/100000, D Loss: 0.173738032579422, G Loss: 4.437755584716797\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9194/100000, D Loss: 0.20632198452949524, G Loss: 4.299907207489014\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9195/100000, D Loss: 0.22304274141788483, G Loss: 4.028255462646484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9196/100000, D Loss: 0.2335852086544037, G Loss: 4.120826721191406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9197/100000, D Loss: 0.1837044060230255, G Loss: 4.670790672302246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9198/100000, D Loss: 0.18783880397677422, G Loss: 4.604007720947266\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9199/100000, D Loss: 0.2112223356962204, G Loss: 4.098662376403809\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9200/100000, D Loss: 0.22382628917694092, G Loss: 3.9576117992401123\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9201/100000, D Loss: 0.166717991232872, G Loss: 4.3492631912231445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9202/100000, D Loss: 0.16540450602769852, G Loss: 4.7188286781311035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9203/100000, D Loss: 0.19104832410812378, G Loss: 4.419492721557617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9204/100000, D Loss: 0.19657352566719055, G Loss: 3.9281444549560547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9205/100000, D Loss: 0.17348558455705643, G Loss: 4.171760082244873\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9206/100000, D Loss: 0.2041618451476097, G Loss: 4.5390472412109375\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9207/100000, D Loss: 0.1847674325108528, G Loss: 4.804331302642822\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9208/100000, D Loss: 0.22579997777938843, G Loss: 4.311136245727539\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9209/100000, D Loss: 0.20299550145864487, G Loss: 4.112432479858398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9210/100000, D Loss: 0.20361176878213882, G Loss: 4.366395950317383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9211/100000, D Loss: 0.1881302297115326, G Loss: 4.482185363769531\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9212/100000, D Loss: 0.22515758872032166, G Loss: 4.048167705535889\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9213/100000, D Loss: 0.23954558372497559, G Loss: 3.906147003173828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9214/100000, D Loss: 0.2235986590385437, G Loss: 4.434173583984375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9215/100000, D Loss: 0.22896796464920044, G Loss: 4.479184150695801\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9216/100000, D Loss: 0.2765733450651169, G Loss: 3.89905047416687\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9217/100000, D Loss: 0.29146629571914673, G Loss: 3.90718412399292\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9218/100000, D Loss: 0.24274787306785583, G Loss: 4.289977073669434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9219/100000, D Loss: 0.24409273266792297, G Loss: 4.266585826873779\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9220/100000, D Loss: 0.26121091842651367, G Loss: 4.112438201904297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9221/100000, D Loss: 0.23473526537418365, G Loss: 3.9690752029418945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9222/100000, D Loss: 0.27134425938129425, G Loss: 3.909691572189331\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9223/100000, D Loss: 0.24136259406805038, G Loss: 4.190248489379883\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9224/100000, D Loss: 0.22574777156114578, G Loss: 4.316310882568359\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9225/100000, D Loss: 0.259345680475235, G Loss: 3.932067394256592\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9226/100000, D Loss: 0.23067349940538406, G Loss: 3.8687844276428223\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9227/100000, D Loss: 0.22890105098485947, G Loss: 4.270800590515137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9228/100000, D Loss: 0.1999501734972, G Loss: 4.725604057312012\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9229/100000, D Loss: 0.2516713887453079, G Loss: 4.208931922912598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9230/100000, D Loss: 0.22250597178936005, G Loss: 3.9632174968719482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9231/100000, D Loss: 0.23357868194580078, G Loss: 4.271268367767334\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9232/100000, D Loss: 0.21108081191778183, G Loss: 4.579845905303955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9233/100000, D Loss: 0.2502526491880417, G Loss: 4.44460391998291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9234/100000, D Loss: 0.2544515132904053, G Loss: 4.076971054077148\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9235/100000, D Loss: 0.2786885201931, G Loss: 4.051558017730713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9236/100000, D Loss: 0.24992096424102783, G Loss: 4.436614036560059\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9237/100000, D Loss: 0.31889037042856216, G Loss: 4.217660903930664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9238/100000, D Loss: 0.3525545001029968, G Loss: 3.855396032333374\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9239/100000, D Loss: 0.3361458331346512, G Loss: 3.9053092002868652\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9240/100000, D Loss: 0.4365125000476837, G Loss: 3.959045886993408\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9241/100000, D Loss: 0.47572317719459534, G Loss: 3.7422165870666504\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9242/100000, D Loss: 0.5284889191389084, G Loss: 3.738433599472046\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9243/100000, D Loss: 0.48179835081100464, G Loss: 3.8085973262786865\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9244/100000, D Loss: 0.5875226259231567, G Loss: 3.753819465637207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9245/100000, D Loss: 0.46040375530719757, G Loss: 3.9188485145568848\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9246/100000, D Loss: 0.4823871850967407, G Loss: 3.9247283935546875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9247/100000, D Loss: 0.4508862644433975, G Loss: 3.8671319484710693\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9248/100000, D Loss: 0.3913898468017578, G Loss: 4.428089141845703\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9249/100000, D Loss: 0.2846883162856102, G Loss: 4.602687358856201\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9250/100000, D Loss: 0.2655075564980507, G Loss: 4.57884407043457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9251/100000, D Loss: 0.23701253533363342, G Loss: 4.407222270965576\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9252/100000, D Loss: 0.19328536838293076, G Loss: 4.677922248840332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9253/100000, D Loss: 0.2003960907459259, G Loss: 5.074214935302734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9254/100000, D Loss: 0.18247640132904053, G Loss: 5.032070159912109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9255/100000, D Loss: 0.1552996188402176, G Loss: 4.902981281280518\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9256/100000, D Loss: 0.15537630021572113, G Loss: 4.86953592300415\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9257/100000, D Loss: 0.15081331133842468, G Loss: 4.99492073059082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9258/100000, D Loss: 0.1270940750837326, G Loss: 5.065742492675781\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9259/100000, D Loss: 0.1300368458032608, G Loss: 5.032916069030762\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9260/100000, D Loss: 0.1639309674501419, G Loss: 4.731166362762451\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9261/100000, D Loss: 0.16380062699317932, G Loss: 4.836281776428223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9262/100000, D Loss: 0.1864519566297531, G Loss: 4.928521156311035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9263/100000, D Loss: 0.1724831685423851, G Loss: 5.029720306396484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9264/100000, D Loss: 0.17276115715503693, G Loss: 4.849549293518066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9265/100000, D Loss: 0.17978213727474213, G Loss: 5.077190399169922\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9266/100000, D Loss: 0.20007532835006714, G Loss: 4.937163352966309\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9267/100000, D Loss: 0.20431941747665405, G Loss: 4.70414400100708\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9268/100000, D Loss: 0.2188221514225006, G Loss: 4.5089640617370605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9269/100000, D Loss: 0.24287685751914978, G Loss: 4.498038291931152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9270/100000, D Loss: 0.20114178955554962, G Loss: 4.660558223724365\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9271/100000, D Loss: 0.27737511694431305, G Loss: 4.645612716674805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9272/100000, D Loss: 0.22647513449192047, G Loss: 4.354593276977539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9273/100000, D Loss: 0.23002078384160995, G Loss: 4.460010528564453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9274/100000, D Loss: 0.2369702309370041, G Loss: 4.571521282196045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9275/100000, D Loss: 0.2797074690461159, G Loss: 4.215207099914551\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9276/100000, D Loss: 0.2663847804069519, G Loss: 4.0241899490356445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9277/100000, D Loss: 0.2987426221370697, G Loss: 4.255387306213379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9278/100000, D Loss: 0.2643350064754486, G Loss: 4.292219638824463\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9279/100000, D Loss: 0.29063063859939575, G Loss: 3.952699661254883\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9280/100000, D Loss: 0.3246534466743469, G Loss: 4.019351005554199\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9281/100000, D Loss: 0.25650450587272644, G Loss: 4.545976638793945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9282/100000, D Loss: 0.2721613645553589, G Loss: 4.476146697998047\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9283/100000, D Loss: 0.3174327313899994, G Loss: 3.877214193344116\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9284/100000, D Loss: 0.24592411518096924, G Loss: 4.136526584625244\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9285/100000, D Loss: 0.21011503040790558, G Loss: 4.598041534423828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9286/100000, D Loss: 0.2462552711367607, G Loss: 4.639136791229248\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9287/100000, D Loss: 0.23418477177619934, G Loss: 4.3391804695129395\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9288/100000, D Loss: 0.20719577372074127, G Loss: 4.4320783615112305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9289/100000, D Loss: 0.20021969079971313, G Loss: 4.648894786834717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9290/100000, D Loss: 0.18930668383836746, G Loss: 4.865400314331055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9291/100000, D Loss: 0.19898781925439835, G Loss: 4.7152814865112305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9292/100000, D Loss: 0.17275292426347733, G Loss: 4.647198677062988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9293/100000, D Loss: 0.17254797369241714, G Loss: 4.732586860656738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9294/100000, D Loss: 0.18304240703582764, G Loss: 4.598964691162109\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9295/100000, D Loss: 0.17570185661315918, G Loss: 4.576592445373535\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9296/100000, D Loss: 0.18607844412326813, G Loss: 4.37608528137207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9297/100000, D Loss: 0.1929801180958748, G Loss: 4.407042026519775\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9298/100000, D Loss: 0.17731913924217224, G Loss: 4.74049711227417\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9299/100000, D Loss: 0.2172461599111557, G Loss: 4.447779655456543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9300/100000, D Loss: 0.2441275641322136, G Loss: 3.9608163833618164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9301/100000, D Loss: 0.2567211836576462, G Loss: 4.150757789611816\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9302/100000, D Loss: 0.2163614258170128, G Loss: 4.507506370544434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9303/100000, D Loss: 0.25289201736450195, G Loss: 4.4584479331970215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9304/100000, D Loss: 0.25481490790843964, G Loss: 4.062094211578369\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9305/100000, D Loss: 0.2959662824869156, G Loss: 4.007944107055664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9306/100000, D Loss: 0.21199221163988113, G Loss: 4.605435848236084\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9307/100000, D Loss: 0.2553367614746094, G Loss: 4.474905490875244\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9308/100000, D Loss: 0.24605832993984222, G Loss: 4.236900329589844\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9309/100000, D Loss: 0.2368413507938385, G Loss: 4.233427047729492\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9310/100000, D Loss: 0.30671852827072144, G Loss: 4.111602783203125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9311/100000, D Loss: 0.2363533228635788, G Loss: 4.265013694763184\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9312/100000, D Loss: 0.28785833716392517, G Loss: 4.213291168212891\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9313/100000, D Loss: 0.26352642476558685, G Loss: 4.526787281036377\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9314/100000, D Loss: 0.23067950457334518, G Loss: 4.312009811401367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9315/100000, D Loss: 0.2906503677368164, G Loss: 3.891684055328369\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9316/100000, D Loss: 0.21344535052776337, G Loss: 4.22969913482666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9317/100000, D Loss: 0.22629696130752563, G Loss: 4.575251579284668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9318/100000, D Loss: 0.2688310593366623, G Loss: 4.458756446838379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9319/100000, D Loss: 0.23584353923797607, G Loss: 4.275554180145264\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9320/100000, D Loss: 0.19902652502059937, G Loss: 4.208257675170898\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9321/100000, D Loss: 0.20214469730854034, G Loss: 4.605625152587891\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9322/100000, D Loss: 0.19359370321035385, G Loss: 4.766741752624512\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9323/100000, D Loss: 0.1868843361735344, G Loss: 4.501323699951172\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9324/100000, D Loss: 0.17593132704496384, G Loss: 4.321430206298828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9325/100000, D Loss: 0.19401806592941284, G Loss: 4.539902210235596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9326/100000, D Loss: 0.1722991019487381, G Loss: 4.774448871612549\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9327/100000, D Loss: 0.2029137685894966, G Loss: 4.544455528259277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9328/100000, D Loss: 0.18760883063077927, G Loss: 4.291803359985352\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9329/100000, D Loss: 0.1844106689095497, G Loss: 4.3391618728637695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9330/100000, D Loss: 0.18452049046754837, G Loss: 4.609066009521484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9331/100000, D Loss: 0.2188396453857422, G Loss: 4.348265647888184\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9332/100000, D Loss: 0.2005166858434677, G Loss: 4.2979044914245605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9333/100000, D Loss: 0.20598402619361877, G Loss: 4.549738883972168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9334/100000, D Loss: 0.21583081781864166, G Loss: 4.662481307983398\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9335/100000, D Loss: 0.23391036689281464, G Loss: 4.329334259033203\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9336/100000, D Loss: 0.22913708537817, G Loss: 4.059679985046387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9337/100000, D Loss: 0.22617870569229126, G Loss: 4.456331253051758\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9338/100000, D Loss: 0.19243477284908295, G Loss: 4.616869926452637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9339/100000, D Loss: 0.22497817128896713, G Loss: 4.274823188781738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9340/100000, D Loss: 0.2442145049571991, G Loss: 4.070838451385498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9341/100000, D Loss: 0.20487026870250702, G Loss: 4.5008039474487305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9342/100000, D Loss: 0.2068231701850891, G Loss: 4.587741851806641\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9343/100000, D Loss: 0.2279369905591011, G Loss: 4.393094539642334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9344/100000, D Loss: 0.21845820546150208, G Loss: 4.327960968017578\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9345/100000, D Loss: 0.2225622832775116, G Loss: 4.400826454162598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9346/100000, D Loss: 0.2265583798289299, G Loss: 4.394534587860107\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9347/100000, D Loss: 0.21978618204593658, G Loss: 4.323037624359131\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9348/100000, D Loss: 0.21746876090765, G Loss: 4.369792461395264\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9349/100000, D Loss: 0.25478707253932953, G Loss: 4.11762809753418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9350/100000, D Loss: 0.2691591680049896, G Loss: 3.9536852836608887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9351/100000, D Loss: 0.24004336446523666, G Loss: 4.279043197631836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9352/100000, D Loss: 0.2871011793613434, G Loss: 4.277615547180176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9353/100000, D Loss: 0.27624107897281647, G Loss: 4.093461990356445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9354/100000, D Loss: 0.35521456599235535, G Loss: 3.9954333305358887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9355/100000, D Loss: 0.29356127977371216, G Loss: 4.279244899749756\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9356/100000, D Loss: 0.29187195003032684, G Loss: 4.070487022399902\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9357/100000, D Loss: 0.27194611728191376, G Loss: 3.9384899139404297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9358/100000, D Loss: 0.30130505561828613, G Loss: 4.065679550170898\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9359/100000, D Loss: 0.2587096393108368, G Loss: 4.197268486022949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9360/100000, D Loss: 0.2329026460647583, G Loss: 4.3266401290893555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9361/100000, D Loss: 0.24989741295576096, G Loss: 4.038333892822266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9362/100000, D Loss: 0.23212137073278427, G Loss: 4.17808198928833\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9363/100000, D Loss: 0.21012604236602783, G Loss: 4.507828712463379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9364/100000, D Loss: 0.20857741683721542, G Loss: 4.5062255859375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9365/100000, D Loss: 0.1906897947192192, G Loss: 4.459855079650879\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9366/100000, D Loss: 0.21809349954128265, G Loss: 4.191246509552002\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9367/100000, D Loss: 0.21498363465070724, G Loss: 4.352438926696777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9368/100000, D Loss: 0.2187098115682602, G Loss: 4.442809581756592\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9369/100000, D Loss: 0.22777357697486877, G Loss: 4.379847049713135\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9370/100000, D Loss: 0.22082774341106415, G Loss: 4.242809772491455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9371/100000, D Loss: 0.24464992433786392, G Loss: 4.424180507659912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9372/100000, D Loss: 0.23853836953639984, G Loss: 4.187233924865723\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9373/100000, D Loss: 0.24369099736213684, G Loss: 4.368340492248535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9374/100000, D Loss: 0.26255348324775696, G Loss: 4.284533500671387\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9375/100000, D Loss: 0.24829835444688797, G Loss: 4.4803009033203125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9376/100000, D Loss: 0.2539614960551262, G Loss: 4.261875152587891\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9377/100000, D Loss: 0.2943435311317444, G Loss: 3.875657796859741\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9378/100000, D Loss: 0.25874941796064377, G Loss: 4.529551029205322\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9379/100000, D Loss: 0.2776928022503853, G Loss: 4.428210735321045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9380/100000, D Loss: 0.2508574277162552, G Loss: 4.5487380027771\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9381/100000, D Loss: 0.29198718070983887, G Loss: 4.332983016967773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9382/100000, D Loss: 0.3520025610923767, G Loss: 4.329869270324707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9383/100000, D Loss: 0.3368590474128723, G Loss: 4.369327068328857\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9384/100000, D Loss: 0.3476950228214264, G Loss: 4.51708459854126\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9385/100000, D Loss: 0.39145347476005554, G Loss: 4.302962303161621\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9386/100000, D Loss: 0.3707500845193863, G Loss: 4.4419474601745605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9387/100000, D Loss: 0.3880724161863327, G Loss: 4.5281982421875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9388/100000, D Loss: 0.37708839774131775, G Loss: 4.515255451202393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9389/100000, D Loss: 0.3672179877758026, G Loss: 4.481076240539551\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9390/100000, D Loss: 0.28906384110450745, G Loss: 4.8845367431640625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9391/100000, D Loss: 0.3623385727405548, G Loss: 4.469075679779053\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9392/100000, D Loss: 0.2561940997838974, G Loss: 4.584387302398682\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9393/100000, D Loss: 0.22497959434986115, G Loss: 4.5564775466918945\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9394/100000, D Loss: 0.17411401122808456, G Loss: 4.99302864074707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9395/100000, D Loss: 0.16952477395534515, G Loss: 5.312712669372559\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9396/100000, D Loss: 0.14984357357025146, G Loss: 5.135730743408203\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9397/100000, D Loss: 0.1755804419517517, G Loss: 4.812176704406738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9398/100000, D Loss: 0.16749919950962067, G Loss: 4.889777183532715\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9399/100000, D Loss: 0.1417788490653038, G Loss: 5.464637279510498\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9400/100000, D Loss: 0.15631097555160522, G Loss: 5.237557411193848\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9401/100000, D Loss: 0.14622289314866066, G Loss: 4.910497665405273\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9402/100000, D Loss: 0.1794850379228592, G Loss: 4.823451519012451\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9403/100000, D Loss: 0.1566525176167488, G Loss: 5.130068778991699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9404/100000, D Loss: 0.18102480471134186, G Loss: 4.913365364074707\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9405/100000, D Loss: 0.17832884192466736, G Loss: 5.175716876983643\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9406/100000, D Loss: 0.1711786910891533, G Loss: 4.9896745681762695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9407/100000, D Loss: 0.2135167121887207, G Loss: 4.662159442901611\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9408/100000, D Loss: 0.2441944181919098, G Loss: 4.484533309936523\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9409/100000, D Loss: 0.2716035693883896, G Loss: 4.523514747619629\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9410/100000, D Loss: 0.2696208208799362, G Loss: 4.802008152008057\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9411/100000, D Loss: 0.3040100857615471, G Loss: 4.530012130737305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9412/100000, D Loss: 0.3848847597837448, G Loss: 4.103856086730957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9413/100000, D Loss: 0.32810260355472565, G Loss: 4.432520866394043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9414/100000, D Loss: 0.33931712806224823, G Loss: 4.381535530090332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9415/100000, D Loss: 0.358335480093956, G Loss: 4.197853088378906\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9416/100000, D Loss: 0.28932511806488037, G Loss: 4.557548522949219\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9417/100000, D Loss: 0.265465185046196, G Loss: 4.601894855499268\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9418/100000, D Loss: 0.2531110867857933, G Loss: 4.4519782066345215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9419/100000, D Loss: 0.23501548171043396, G Loss: 4.3540568351745605\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9420/100000, D Loss: 0.18288443982601166, G Loss: 4.777554512023926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9421/100000, D Loss: 0.18467017263174057, G Loss: 4.816208362579346\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9422/100000, D Loss: 0.17385367304086685, G Loss: 4.9189252853393555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9423/100000, D Loss: 0.1722562611103058, G Loss: 4.748636245727539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9424/100000, D Loss: 0.18078165501356125, G Loss: 4.542855262756348\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9425/100000, D Loss: 0.1701221987605095, G Loss: 4.773006439208984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9426/100000, D Loss: 0.1393822506070137, G Loss: 5.051956653594971\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9427/100000, D Loss: 0.22010910511016846, G Loss: 4.575168609619141\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9428/100000, D Loss: 0.22663670778274536, G Loss: 4.157064437866211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9429/100000, D Loss: 0.18264029920101166, G Loss: 4.397477149963379\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9430/100000, D Loss: 0.20407376438379288, G Loss: 4.599804878234863\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9431/100000, D Loss: 0.25164493918418884, G Loss: 4.26238489151001\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9432/100000, D Loss: 0.29592664539813995, G Loss: 4.000598430633545\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9433/100000, D Loss: 0.24536361545324326, G Loss: 4.113858222961426\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9434/100000, D Loss: 0.28358040004968643, G Loss: 3.993196487426758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9435/100000, D Loss: 0.27632661163806915, G Loss: 3.9316115379333496\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9436/100000, D Loss: 0.2998933792114258, G Loss: 3.8969597816467285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9437/100000, D Loss: 0.30294281244277954, G Loss: 3.9962527751922607\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9438/100000, D Loss: 0.20796393603086472, G Loss: 4.121607780456543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9439/100000, D Loss: 0.25862447172403336, G Loss: 4.130601406097412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9440/100000, D Loss: 0.26630207896232605, G Loss: 3.900038719177246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9441/100000, D Loss: 0.2522245720028877, G Loss: 4.058384418487549\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9442/100000, D Loss: 0.2400156632065773, G Loss: 4.159113883972168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9443/100000, D Loss: 0.19735756516456604, G Loss: 4.2481279373168945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9444/100000, D Loss: 0.22810359299182892, G Loss: 4.006211757659912\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9445/100000, D Loss: 0.26333215832710266, G Loss: 3.597069501876831\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9446/100000, D Loss: 0.2703232616186142, G Loss: 3.8640809059143066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9447/100000, D Loss: 0.22965940833091736, G Loss: 4.156519889831543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9448/100000, D Loss: 0.29613299667835236, G Loss: 4.104248046875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9449/100000, D Loss: 0.32943058013916016, G Loss: 3.6911697387695312\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9450/100000, D Loss: 0.30696289241313934, G Loss: 3.512403964996338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9451/100000, D Loss: 0.3084470331668854, G Loss: 3.9970180988311768\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9452/100000, D Loss: 0.3040282279253006, G Loss: 4.059342384338379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9453/100000, D Loss: 0.30903808772563934, G Loss: 4.125629425048828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9454/100000, D Loss: 0.29116860777139664, G Loss: 3.7612805366516113\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9455/100000, D Loss: 0.27078647911548615, G Loss: 4.039626121520996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9456/100000, D Loss: 0.1765141487121582, G Loss: 4.620975494384766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9457/100000, D Loss: 0.171993188560009, G Loss: 4.699211120605469\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9458/100000, D Loss: 0.16374069452285767, G Loss: 4.600255489349365\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9459/100000, D Loss: 0.16341694444417953, G Loss: 4.396928787231445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9460/100000, D Loss: 0.15012004971504211, G Loss: 4.615272521972656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9461/100000, D Loss: 0.1406353861093521, G Loss: 4.965888977050781\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9462/100000, D Loss: 0.1040881834924221, G Loss: 5.529837608337402\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 9463/100000, D Loss: 0.11734815686941147, G Loss: 5.528017997741699\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9464/100000, D Loss: 0.10548274964094162, G Loss: 5.167082786560059\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 9465/100000, D Loss: 0.11175967380404472, G Loss: 5.117020130157471\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9466/100000, D Loss: 0.11206139624118805, G Loss: 5.144487380981445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9467/100000, D Loss: 0.09775965288281441, G Loss: 5.291162967681885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9468/100000, D Loss: 0.10356750339269638, G Loss: 5.409424781799316\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9469/100000, D Loss: 0.10428599268198013, G Loss: 5.044408321380615\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9470/100000, D Loss: 0.12952082231640816, G Loss: 4.790966033935547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9471/100000, D Loss: 0.14259659498929977, G Loss: 4.699559211730957\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9472/100000, D Loss: 0.12739144638180733, G Loss: 4.880496025085449\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9473/100000, D Loss: 0.13031302392482758, G Loss: 5.024592399597168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9474/100000, D Loss: 0.16685928404331207, G Loss: 4.715941905975342\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9475/100000, D Loss: 0.16705437004566193, G Loss: 4.273080825805664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9476/100000, D Loss: 0.16552548110485077, G Loss: 4.37108039855957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9477/100000, D Loss: 0.1586908921599388, G Loss: 4.93083381652832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9478/100000, D Loss: 0.21157001703977585, G Loss: 4.521822929382324\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9479/100000, D Loss: 0.18198073655366898, G Loss: 4.119175434112549\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9480/100000, D Loss: 0.20247800648212433, G Loss: 4.116878509521484\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9481/100000, D Loss: 0.2112402394413948, G Loss: 4.46999454498291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9482/100000, D Loss: 0.19929322600364685, G Loss: 4.533088684082031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9483/100000, D Loss: 0.2115015834569931, G Loss: 4.39503288269043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9484/100000, D Loss: 0.24971365928649902, G Loss: 4.110630989074707\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9485/100000, D Loss: 0.24778535962104797, G Loss: 4.127455234527588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9486/100000, D Loss: 0.2256716638803482, G Loss: 4.522574424743652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9487/100000, D Loss: 0.21964145451784134, G Loss: 4.489104270935059\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9488/100000, D Loss: 0.26084718108177185, G Loss: 4.049538612365723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9489/100000, D Loss: 0.2524583786725998, G Loss: 4.012495517730713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9490/100000, D Loss: 0.2195042073726654, G Loss: 4.34959602355957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9491/100000, D Loss: 0.2629973292350769, G Loss: 4.015501976013184\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9492/100000, D Loss: 0.27204209566116333, G Loss: 4.031275749206543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9493/100000, D Loss: 0.28492315113544464, G Loss: 4.038437843322754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9494/100000, D Loss: 0.2708222195506096, G Loss: 4.053007125854492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9495/100000, D Loss: 0.26986709237098694, G Loss: 3.7914516925811768\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9496/100000, D Loss: 0.2937031537294388, G Loss: 3.9198532104492188\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9497/100000, D Loss: 0.29333409667015076, G Loss: 3.7771215438842773\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9498/100000, D Loss: 0.26921239495277405, G Loss: 4.0824384689331055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9499/100000, D Loss: 0.2989053428173065, G Loss: 3.93269419670105\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9500/100000, D Loss: 0.3128054738044739, G Loss: 3.665771245956421\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9501/100000, D Loss: 0.2861882448196411, G Loss: 3.860781192779541\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9502/100000, D Loss: 0.24289080500602722, G Loss: 4.087122440338135\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9503/100000, D Loss: 0.3021012395620346, G Loss: 3.93666934967041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9504/100000, D Loss: 0.2698472887277603, G Loss: 4.050249099731445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9505/100000, D Loss: 0.2337525337934494, G Loss: 4.108068466186523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9506/100000, D Loss: 0.25391779839992523, G Loss: 3.8790090084075928\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9507/100000, D Loss: 0.25467655062675476, G Loss: 3.8277435302734375\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9508/100000, D Loss: 0.23110054433345795, G Loss: 4.111377716064453\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9509/100000, D Loss: 0.2451666221022606, G Loss: 3.943260669708252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9510/100000, D Loss: 0.24316802620887756, G Loss: 4.013031005859375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9511/100000, D Loss: 0.24159570038318634, G Loss: 3.9988255500793457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9512/100000, D Loss: 0.20804846286773682, G Loss: 4.020281791687012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9513/100000, D Loss: 0.22647055238485336, G Loss: 3.982430934906006\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9514/100000, D Loss: 0.20815487205982208, G Loss: 4.302860260009766\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9515/100000, D Loss: 0.22707971185445786, G Loss: 4.209469318389893\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9516/100000, D Loss: 0.23405054211616516, G Loss: 4.2175397872924805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9517/100000, D Loss: 0.20503002405166626, G Loss: 3.986617088317871\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9518/100000, D Loss: 0.24517105519771576, G Loss: 3.9077608585357666\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9519/100000, D Loss: 0.25732141733169556, G Loss: 3.8946990966796875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9520/100000, D Loss: 0.24744783341884613, G Loss: 4.125213146209717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9521/100000, D Loss: 0.24806775897741318, G Loss: 4.0338215827941895\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9522/100000, D Loss: 0.27491970360279083, G Loss: 3.791677474975586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9523/100000, D Loss: 0.28103286027908325, G Loss: 3.7025539875030518\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9524/100000, D Loss: 0.31956855952739716, G Loss: 3.9591736793518066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9525/100000, D Loss: 0.30942845344543457, G Loss: 3.767643451690674\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9526/100000, D Loss: 0.34731192886829376, G Loss: 3.524807929992676\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9527/100000, D Loss: 0.3615668714046478, G Loss: 3.6802306175231934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9528/100000, D Loss: 0.3879416137933731, G Loss: 3.5909810066223145\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9529/100000, D Loss: 0.392400398850441, G Loss: 3.328322410583496\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9530/100000, D Loss: 0.47259628772735596, G Loss: 3.287118911743164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9531/100000, D Loss: 0.4004557877779007, G Loss: 3.5952749252319336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9532/100000, D Loss: 0.4496868848800659, G Loss: 3.60673189163208\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9533/100000, D Loss: 0.4190737158060074, G Loss: 3.322099208831787\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9534/100000, D Loss: 0.4223999083042145, G Loss: 3.265265464782715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9535/100000, D Loss: 0.4144546240568161, G Loss: 3.471503257751465\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9536/100000, D Loss: 0.3382103964686394, G Loss: 3.8297154903411865\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9537/100000, D Loss: 0.3792247027158737, G Loss: 3.399855136871338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9538/100000, D Loss: 0.327201172709465, G Loss: 3.661391019821167\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9539/100000, D Loss: 0.2890445291996002, G Loss: 3.988035202026367\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9540/100000, D Loss: 0.2577463239431381, G Loss: 4.008945465087891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9541/100000, D Loss: 0.2516990303993225, G Loss: 4.175131797790527\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9542/100000, D Loss: 0.2422771081328392, G Loss: 4.028712272644043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9543/100000, D Loss: 0.23429732769727707, G Loss: 3.836993932723999\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9544/100000, D Loss: 0.20780082792043686, G Loss: 4.05479097366333\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9545/100000, D Loss: 0.18791496753692627, G Loss: 4.5931549072265625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9546/100000, D Loss: 0.20594871044158936, G Loss: 4.3465728759765625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9547/100000, D Loss: 0.20917975157499313, G Loss: 4.11895751953125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9548/100000, D Loss: 0.17741093039512634, G Loss: 4.1744704246521\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9549/100000, D Loss: 0.15740743279457092, G Loss: 4.6756510734558105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9550/100000, D Loss: 0.12991247326135635, G Loss: 5.117800235748291\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9551/100000, D Loss: 0.19170258566737175, G Loss: 4.6347150802612305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9552/100000, D Loss: 0.1649099737405777, G Loss: 4.338174819946289\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9553/100000, D Loss: 0.16017050296068192, G Loss: 4.549463272094727\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9554/100000, D Loss: 0.1684708297252655, G Loss: 4.663581848144531\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9555/100000, D Loss: 0.15684831887483597, G Loss: 4.698343276977539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9556/100000, D Loss: 0.15823253989219666, G Loss: 4.838595390319824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9557/100000, D Loss: 0.16934886574745178, G Loss: 4.428050994873047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9558/100000, D Loss: 0.23938745260238647, G Loss: 4.205156326293945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9559/100000, D Loss: 0.1949058473110199, G Loss: 4.531107425689697\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9560/100000, D Loss: 0.16337615251541138, G Loss: 4.958002090454102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9561/100000, D Loss: 0.2241416871547699, G Loss: 4.433957099914551\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9562/100000, D Loss: 0.22600139677524567, G Loss: 4.215424537658691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9563/100000, D Loss: 0.22242320328950882, G Loss: 4.29503870010376\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9564/100000, D Loss: 0.21679368615150452, G Loss: 4.644392490386963\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9565/100000, D Loss: 0.24822204560041428, G Loss: 4.609720230102539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9566/100000, D Loss: 0.2585477903485298, G Loss: 4.164823532104492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9567/100000, D Loss: 0.2799649238586426, G Loss: 3.929165840148926\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9568/100000, D Loss: 0.2674643397331238, G Loss: 3.8406460285186768\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9569/100000, D Loss: 0.26404470205307007, G Loss: 4.2808332443237305\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9570/100000, D Loss: 0.29889173060655594, G Loss: 4.182238578796387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9571/100000, D Loss: 0.3341542035341263, G Loss: 4.039479732513428\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9572/100000, D Loss: 0.3066655993461609, G Loss: 4.081113815307617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9573/100000, D Loss: 0.34514328837394714, G Loss: 3.880131959915161\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9574/100000, D Loss: 0.3430638909339905, G Loss: 3.663111925125122\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9575/100000, D Loss: 0.3597678542137146, G Loss: 3.6533899307250977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9576/100000, D Loss: 0.34941111505031586, G Loss: 4.156974792480469\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9577/100000, D Loss: 0.3303111791610718, G Loss: 4.146418571472168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9578/100000, D Loss: 0.3281106501817703, G Loss: 3.8999123573303223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9579/100000, D Loss: 0.32619553804397583, G Loss: 3.884068250656128\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9580/100000, D Loss: 0.2903919368982315, G Loss: 4.183787822723389\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9581/100000, D Loss: 0.26770057529211044, G Loss: 4.3838958740234375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9582/100000, D Loss: 0.28884467482566833, G Loss: 3.989985704421997\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9583/100000, D Loss: 0.26755155622959137, G Loss: 3.841139554977417\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9584/100000, D Loss: 0.23639246821403503, G Loss: 4.5692877769470215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9585/100000, D Loss: 0.20081447809934616, G Loss: 4.746641635894775\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9586/100000, D Loss: 0.2292756289243698, G Loss: 4.250913143157959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9587/100000, D Loss: 0.21226848661899567, G Loss: 4.473633766174316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9588/100000, D Loss: 0.18149175494909286, G Loss: 4.707818984985352\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9589/100000, D Loss: 0.18015597015619278, G Loss: 4.923935890197754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9590/100000, D Loss: 0.17555604875087738, G Loss: 4.39595890045166\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9591/100000, D Loss: 0.21171019226312637, G Loss: 4.1494574546813965\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9592/100000, D Loss: 0.1768742874264717, G Loss: 4.200201511383057\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9593/100000, D Loss: 0.18964583426713943, G Loss: 4.587919235229492\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9594/100000, D Loss: 0.22286973893642426, G Loss: 4.572117328643799\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9595/100000, D Loss: 0.17423433810472488, G Loss: 4.5294189453125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9596/100000, D Loss: 0.21356230974197388, G Loss: 4.49258279800415\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9597/100000, D Loss: 0.20353062450885773, G Loss: 4.380759239196777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9598/100000, D Loss: 0.2302583083510399, G Loss: 4.3972086906433105\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9599/100000, D Loss: 0.25810737907886505, G Loss: 4.272795677185059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9600/100000, D Loss: 0.2249678149819374, G Loss: 4.370144844055176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9601/100000, D Loss: 0.23108114302158356, G Loss: 4.3882951736450195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9602/100000, D Loss: 0.23510800302028656, G Loss: 4.3197712898254395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9603/100000, D Loss: 0.26943788677453995, G Loss: 4.0634446144104\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9604/100000, D Loss: 0.2866268455982208, G Loss: 3.8992350101470947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9605/100000, D Loss: 0.3570885956287384, G Loss: 3.801572322845459\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9606/100000, D Loss: 0.27067266404628754, G Loss: 3.9484825134277344\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9607/100000, D Loss: 0.3408341705799103, G Loss: 3.7543904781341553\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9608/100000, D Loss: 0.2906677573919296, G Loss: 3.750441312789917\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9609/100000, D Loss: 0.29537129402160645, G Loss: 4.048467636108398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9610/100000, D Loss: 0.2874125838279724, G Loss: 3.9578001499176025\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9611/100000, D Loss: 0.2972417026758194, G Loss: 3.821528434753418\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9612/100000, D Loss: 0.29579633474349976, G Loss: 3.876673698425293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9613/100000, D Loss: 0.24575339257717133, G Loss: 4.166195869445801\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9614/100000, D Loss: 0.2302723526954651, G Loss: 4.28570032119751\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9615/100000, D Loss: 0.20816461741924286, G Loss: 4.173864364624023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9616/100000, D Loss: 0.2521465867757797, G Loss: 4.26708984375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9617/100000, D Loss: 0.18609171360731125, G Loss: 4.497313022613525\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9618/100000, D Loss: 0.24498986452817917, G Loss: 4.478574752807617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9619/100000, D Loss: 0.2129652500152588, G Loss: 4.22518253326416\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9620/100000, D Loss: 0.26266929507255554, G Loss: 4.082332611083984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9621/100000, D Loss: 0.19745034724473953, G Loss: 4.300703048706055\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9622/100000, D Loss: 0.21625344455242157, G Loss: 4.366124153137207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9623/100000, D Loss: 0.23440736532211304, G Loss: 4.2861785888671875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9624/100000, D Loss: 0.21746978163719177, G Loss: 4.109183311462402\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9625/100000, D Loss: 0.21501068770885468, G Loss: 4.118346214294434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9626/100000, D Loss: 0.2264377623796463, G Loss: 4.172387599945068\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9627/100000, D Loss: 0.26805394142866135, G Loss: 3.8793344497680664\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9628/100000, D Loss: 0.24248053133487701, G Loss: 3.9382266998291016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9629/100000, D Loss: 0.24337080121040344, G Loss: 4.164392471313477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9630/100000, D Loss: 0.29523659497499466, G Loss: 3.9372940063476562\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9631/100000, D Loss: 0.29667890071868896, G Loss: 4.081295013427734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9632/100000, D Loss: 0.2408842295408249, G Loss: 4.197124481201172\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9633/100000, D Loss: 0.29296909272670746, G Loss: 4.131837368011475\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9634/100000, D Loss: 0.25768186151981354, G Loss: 4.067990779876709\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9635/100000, D Loss: 0.23204995691776276, G Loss: 4.4600830078125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9636/100000, D Loss: 0.22287143766880035, G Loss: 4.311491012573242\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9637/100000, D Loss: 0.2563125789165497, G Loss: 4.284908294677734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9638/100000, D Loss: 0.2269923910498619, G Loss: 4.2398223876953125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9639/100000, D Loss: 0.23474819958209991, G Loss: 4.185236930847168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9640/100000, D Loss: 0.26307347416877747, G Loss: 4.072795867919922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9641/100000, D Loss: 0.23639145493507385, G Loss: 4.0449419021606445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9642/100000, D Loss: 0.2333342656493187, G Loss: 4.242778778076172\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9643/100000, D Loss: 0.31720636039972305, G Loss: 3.766038417816162\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9644/100000, D Loss: 0.2946154326200485, G Loss: 3.794952869415283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9645/100000, D Loss: 0.2690337598323822, G Loss: 4.0453267097473145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9646/100000, D Loss: 0.3245966285467148, G Loss: 3.9494824409484863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9647/100000, D Loss: 0.3105887919664383, G Loss: 3.7723073959350586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9648/100000, D Loss: 0.30076615512371063, G Loss: 3.791412830352783\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9649/100000, D Loss: 0.30472615361213684, G Loss: 3.744840383529663\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9650/100000, D Loss: 0.24664580821990967, G Loss: 4.041121959686279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9651/100000, D Loss: 0.24100279062986374, G Loss: 4.096375465393066\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9652/100000, D Loss: 0.2851918488740921, G Loss: 4.083057403564453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9653/100000, D Loss: 0.23446211963891983, G Loss: 4.203392028808594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9654/100000, D Loss: 0.2332695797085762, G Loss: 4.276920318603516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9655/100000, D Loss: 0.24320466071367264, G Loss: 4.088259696960449\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9656/100000, D Loss: 0.2287619709968567, G Loss: 4.317624092102051\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9657/100000, D Loss: 0.21248215436935425, G Loss: 4.412801265716553\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9658/100000, D Loss: 0.2140544056892395, G Loss: 4.2881178855896\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9659/100000, D Loss: 0.24113325774669647, G Loss: 4.282107830047607\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9660/100000, D Loss: 0.22754430770874023, G Loss: 4.3646063804626465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9661/100000, D Loss: 0.21298936009407043, G Loss: 4.461297988891602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9662/100000, D Loss: 0.23944737017154694, G Loss: 4.117186546325684\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9663/100000, D Loss: 0.24919257313013077, G Loss: 3.8386123180389404\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9664/100000, D Loss: 0.23325800895690918, G Loss: 4.273322582244873\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9665/100000, D Loss: 0.2089792713522911, G Loss: 4.636609077453613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9666/100000, D Loss: 0.24131275713443756, G Loss: 4.220927715301514\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9667/100000, D Loss: 0.24226348102092743, G Loss: 4.247958183288574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9668/100000, D Loss: 0.21183253079652786, G Loss: 4.275730133056641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9669/100000, D Loss: 0.24162516742944717, G Loss: 4.3945112228393555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9670/100000, D Loss: 0.24839504808187485, G Loss: 4.119808673858643\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9671/100000, D Loss: 0.21609165519475937, G Loss: 4.361523628234863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9672/100000, D Loss: 0.22812920063734055, G Loss: 4.493005752563477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9673/100000, D Loss: 0.2142992466688156, G Loss: 4.548483848571777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9674/100000, D Loss: 0.1928349807858467, G Loss: 4.485360622406006\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9675/100000, D Loss: 0.194161057472229, G Loss: 4.393896102905273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9676/100000, D Loss: 0.1827290803194046, G Loss: 4.370334148406982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9677/100000, D Loss: 0.18031296133995056, G Loss: 4.4946184158325195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9678/100000, D Loss: 0.18199682980775833, G Loss: 4.3902812004089355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9679/100000, D Loss: 0.20138182491064072, G Loss: 3.9625067710876465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9680/100000, D Loss: 0.23084471374750137, G Loss: 3.8861069679260254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9681/100000, D Loss: 0.2099117785692215, G Loss: 4.196773052215576\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9682/100000, D Loss: 0.2256487011909485, G Loss: 4.349857330322266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9683/100000, D Loss: 0.21694442629814148, G Loss: 3.8476345539093018\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9684/100000, D Loss: 0.23085417598485947, G Loss: 3.8643321990966797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9685/100000, D Loss: 0.21504342555999756, G Loss: 4.310233116149902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9686/100000, D Loss: 0.1900252178311348, G Loss: 4.448172569274902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9687/100000, D Loss: 0.18886670470237732, G Loss: 4.317824840545654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9688/100000, D Loss: 0.19618132710456848, G Loss: 3.8814167976379395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9689/100000, D Loss: 0.20501963049173355, G Loss: 3.9839611053466797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9690/100000, D Loss: 0.18812088668346405, G Loss: 4.579409599304199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9691/100000, D Loss: 0.19613206386566162, G Loss: 4.5459160804748535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9692/100000, D Loss: 0.23462051153182983, G Loss: 4.149740219116211\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9693/100000, D Loss: 0.20542876422405243, G Loss: 4.191903114318848\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9694/100000, D Loss: 0.20410537719726562, G Loss: 4.36182165145874\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9695/100000, D Loss: 0.19958387315273285, G Loss: 4.689068794250488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9696/100000, D Loss: 0.2240963578224182, G Loss: 4.281062126159668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9697/100000, D Loss: 0.2244422659277916, G Loss: 3.987741708755493\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9698/100000, D Loss: 0.2182295024394989, G Loss: 4.289494514465332\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9699/100000, D Loss: 0.2115689218044281, G Loss: 4.610487937927246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9700/100000, D Loss: 0.23918943107128143, G Loss: 4.286336898803711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9701/100000, D Loss: 0.3146829456090927, G Loss: 3.755408763885498\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9702/100000, D Loss: 0.2965866029262543, G Loss: 3.8723249435424805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9703/100000, D Loss: 0.2604992985725403, G Loss: 4.0553765296936035\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9704/100000, D Loss: 0.3594541549682617, G Loss: 3.71553897857666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9705/100000, D Loss: 0.38153207302093506, G Loss: 3.6480906009674072\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9706/100000, D Loss: 0.3464251756668091, G Loss: 3.7225682735443115\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9707/100000, D Loss: 0.365988165140152, G Loss: 3.6440768241882324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9708/100000, D Loss: 0.42919157445430756, G Loss: 3.6334924697875977\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9709/100000, D Loss: 0.38928641378879547, G Loss: 3.7166521549224854\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9710/100000, D Loss: 0.41240474581718445, G Loss: 3.6227877140045166\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9711/100000, D Loss: 0.43090707063674927, G Loss: 3.3831887245178223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9712/100000, D Loss: 0.43298493325710297, G Loss: 3.453122854232788\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9713/100000, D Loss: 0.33400991559028625, G Loss: 3.882763385772705\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9714/100000, D Loss: 0.3439386934041977, G Loss: 3.832596778869629\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9715/100000, D Loss: 0.3385140746831894, G Loss: 3.6357619762420654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9716/100000, D Loss: 0.2670968770980835, G Loss: 4.0935564041137695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9717/100000, D Loss: 0.2617999464273453, G Loss: 4.064022064208984\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9718/100000, D Loss: 0.25177402794361115, G Loss: 3.690487861633301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9719/100000, D Loss: 0.24138718843460083, G Loss: 3.7092185020446777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9720/100000, D Loss: 0.21813604980707169, G Loss: 4.138339996337891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9721/100000, D Loss: 0.21367034316062927, G Loss: 4.298381328582764\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9722/100000, D Loss: 0.2085358425974846, G Loss: 4.086813926696777\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9723/100000, D Loss: 0.22620754688978195, G Loss: 3.862553834915161\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9724/100000, D Loss: 0.19345542788505554, G Loss: 4.29752254486084\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9725/100000, D Loss: 0.21129970252513885, G Loss: 4.44970703125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9726/100000, D Loss: 0.20676998794078827, G Loss: 4.222790718078613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9727/100000, D Loss: 0.19481344521045685, G Loss: 3.9972262382507324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9728/100000, D Loss: 0.20590592175722122, G Loss: 4.120110511779785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9729/100000, D Loss: 0.20722489058971405, G Loss: 4.509578704833984\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9730/100000, D Loss: 0.17182041704654694, G Loss: 4.567142486572266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9731/100000, D Loss: 0.19942615181207657, G Loss: 4.431158542633057\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9732/100000, D Loss: 0.16667290031909943, G Loss: 4.361292839050293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9733/100000, D Loss: 0.1767691820859909, G Loss: 4.400779724121094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9734/100000, D Loss: 0.19346332550048828, G Loss: 4.288963794708252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9735/100000, D Loss: 0.19219251722097397, G Loss: 4.249670505523682\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9736/100000, D Loss: 0.19035055488348007, G Loss: 4.367826461791992\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9737/100000, D Loss: 0.21426530182361603, G Loss: 4.193294525146484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9738/100000, D Loss: 0.22293854504823685, G Loss: 4.121088027954102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9739/100000, D Loss: 0.2108282819390297, G Loss: 4.1387176513671875\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9740/100000, D Loss: 0.1928432509303093, G Loss: 4.5783562660217285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9741/100000, D Loss: 0.27367499470710754, G Loss: 4.39163064956665\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9742/100000, D Loss: 0.2686168998479843, G Loss: 3.8923354148864746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9743/100000, D Loss: 0.28751377761363983, G Loss: 3.939192533493042\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9744/100000, D Loss: 0.2752874791622162, G Loss: 4.200069427490234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9745/100000, D Loss: 0.28587816655635834, G Loss: 4.121440410614014\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9746/100000, D Loss: 0.2890968471765518, G Loss: 3.9246654510498047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9747/100000, D Loss: 0.30819645524024963, G Loss: 4.003168106079102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9748/100000, D Loss: 0.2650073245167732, G Loss: 4.197132110595703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9749/100000, D Loss: 0.285211443901062, G Loss: 4.1801581382751465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9750/100000, D Loss: 0.291057750582695, G Loss: 3.7929630279541016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9751/100000, D Loss: 0.2880755215883255, G Loss: 3.8248982429504395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9752/100000, D Loss: 0.27850277721881866, G Loss: 3.9891586303710938\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9753/100000, D Loss: 0.279474213719368, G Loss: 3.9317734241485596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9754/100000, D Loss: 0.28316450119018555, G Loss: 4.044092178344727\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9755/100000, D Loss: 0.28463058173656464, G Loss: 3.7901930809020996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9756/100000, D Loss: 0.29620474576950073, G Loss: 3.7225422859191895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9757/100000, D Loss: 0.2467527985572815, G Loss: 4.1727399826049805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9758/100000, D Loss: 0.25657158344984055, G Loss: 4.214704990386963\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9759/100000, D Loss: 0.23390958458185196, G Loss: 4.234264850616455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9760/100000, D Loss: 0.21755927801132202, G Loss: 4.054940700531006\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9761/100000, D Loss: 0.20643437653779984, G Loss: 4.156635284423828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9762/100000, D Loss: 0.22150234133005142, G Loss: 3.9019904136657715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9763/100000, D Loss: 0.19000647962093353, G Loss: 4.313199996948242\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9764/100000, D Loss: 0.19578110426664352, G Loss: 4.666588306427002\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9765/100000, D Loss: 0.20312482863664627, G Loss: 4.6442084312438965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9766/100000, D Loss: 0.20105022937059402, G Loss: 4.126616477966309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9767/100000, D Loss: 0.18203219771385193, G Loss: 4.168305397033691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9768/100000, D Loss: 0.22316881269216537, G Loss: 3.999171733856201\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9769/100000, D Loss: 0.1981809064745903, G Loss: 4.176353454589844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9770/100000, D Loss: 0.19330096244812012, G Loss: 4.442263603210449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9771/100000, D Loss: 0.2319437861442566, G Loss: 4.279674530029297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9772/100000, D Loss: 0.22445810586214066, G Loss: 4.184213638305664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9773/100000, D Loss: 0.21405141800642014, G Loss: 4.187119483947754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9774/100000, D Loss: 0.23351287841796875, G Loss: 4.492062568664551\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9775/100000, D Loss: 0.22623787820339203, G Loss: 4.338749885559082\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9776/100000, D Loss: 0.2714511752128601, G Loss: 4.16552209854126\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9777/100000, D Loss: 0.22937680035829544, G Loss: 4.432564735412598\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9778/100000, D Loss: 0.22869934141635895, G Loss: 4.344274520874023\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9779/100000, D Loss: 0.24059347808361053, G Loss: 4.268294334411621\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9780/100000, D Loss: 0.2888222560286522, G Loss: 3.846303939819336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9781/100000, D Loss: 0.2881854325532913, G Loss: 3.955174207687378\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9782/100000, D Loss: 0.23959815502166748, G Loss: 4.560519218444824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9783/100000, D Loss: 0.2530973553657532, G Loss: 4.627737998962402\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9784/100000, D Loss: 0.29896683990955353, G Loss: 3.9610204696655273\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9785/100000, D Loss: 0.3414233475923538, G Loss: 3.5829238891601562\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9786/100000, D Loss: 0.25942136347293854, G Loss: 4.181272983551025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9787/100000, D Loss: 0.2600289434194565, G Loss: 4.224132061004639\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9788/100000, D Loss: 0.3042188808321953, G Loss: 3.875737190246582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9789/100000, D Loss: 0.28747543692588806, G Loss: 3.9256720542907715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9790/100000, D Loss: 0.3042771965265274, G Loss: 4.154043197631836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9791/100000, D Loss: 0.28270047903060913, G Loss: 4.313732624053955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9792/100000, D Loss: 0.3325110226869583, G Loss: 3.851973533630371\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9793/100000, D Loss: 0.3255307078361511, G Loss: 3.6837244033813477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9794/100000, D Loss: 0.29029248654842377, G Loss: 4.287103652954102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9795/100000, D Loss: 0.2422875016927719, G Loss: 4.0322489738464355\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9796/100000, D Loss: 0.2896561324596405, G Loss: 3.9648303985595703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9797/100000, D Loss: 0.27205392718315125, G Loss: 4.057225227355957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9798/100000, D Loss: 0.26547153294086456, G Loss: 4.238133430480957\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9799/100000, D Loss: 0.24778076261281967, G Loss: 4.359696388244629\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9800/100000, D Loss: 0.20946113765239716, G Loss: 4.382463455200195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9801/100000, D Loss: 0.2232275754213333, G Loss: 4.288305282592773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9802/100000, D Loss: 0.21705478429794312, G Loss: 4.472951889038086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9803/100000, D Loss: 0.22141913324594498, G Loss: 4.5166015625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9804/100000, D Loss: 0.20802542567253113, G Loss: 4.415943145751953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9805/100000, D Loss: 0.1789378747344017, G Loss: 4.418454170227051\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9806/100000, D Loss: 0.18502338230609894, G Loss: 4.533324241638184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9807/100000, D Loss: 0.19037719815969467, G Loss: 4.435098171234131\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9808/100000, D Loss: 0.18181929737329483, G Loss: 4.33697509765625\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9809/100000, D Loss: 0.19279871881008148, G Loss: 4.335785865783691\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9810/100000, D Loss: 0.1882026195526123, G Loss: 4.236064910888672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9811/100000, D Loss: 0.2008601427078247, G Loss: 4.3208112716674805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9812/100000, D Loss: 0.1885780617594719, G Loss: 4.332545280456543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9813/100000, D Loss: 0.16782881319522858, G Loss: 4.459388732910156\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9814/100000, D Loss: 0.20368212461471558, G Loss: 4.126725673675537\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9815/100000, D Loss: 0.1931915581226349, G Loss: 4.1698174476623535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9816/100000, D Loss: 0.1712971106171608, G Loss: 4.501924514770508\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9817/100000, D Loss: 0.18460780382156372, G Loss: 4.561062812805176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9818/100000, D Loss: 0.145505890250206, G Loss: 4.668971061706543\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9819/100000, D Loss: 0.16842781379818916, G Loss: 4.505107879638672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9820/100000, D Loss: 0.1449410319328308, G Loss: 4.300470352172852\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9821/100000, D Loss: 0.1590491682291031, G Loss: 4.41485595703125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9822/100000, D Loss: 0.1610550656914711, G Loss: 4.55919075012207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9823/100000, D Loss: 0.1793740913271904, G Loss: 4.589760780334473\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9824/100000, D Loss: 0.14915788546204567, G Loss: 4.504632949829102\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9825/100000, D Loss: 0.1672290861606598, G Loss: 4.368149757385254\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9826/100000, D Loss: 0.17595726996660233, G Loss: 4.270125865936279\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9827/100000, D Loss: 0.17852555960416794, G Loss: 4.309635639190674\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9828/100000, D Loss: 0.1980811282992363, G Loss: 4.4925127029418945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9829/100000, D Loss: 0.19235783070325851, G Loss: 4.325544357299805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9830/100000, D Loss: 0.1939854472875595, G Loss: 4.022708892822266\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9831/100000, D Loss: 0.2184755951166153, G Loss: 4.216512680053711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9832/100000, D Loss: 0.17239192873239517, G Loss: 4.492660999298096\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9833/100000, D Loss: 0.20478658378124237, G Loss: 4.352385520935059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9834/100000, D Loss: 0.19708902388811111, G Loss: 4.125726222991943\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9835/100000, D Loss: 0.19321941584348679, G Loss: 4.2764739990234375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9836/100000, D Loss: 0.16209982335567474, G Loss: 4.386331558227539\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9837/100000, D Loss: 0.19989897310733795, G Loss: 4.228750228881836\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9838/100000, D Loss: 0.18711388856172562, G Loss: 4.298822402954102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9839/100000, D Loss: 0.1519007384777069, G Loss: 4.568742752075195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9840/100000, D Loss: 0.15382690727710724, G Loss: 4.486600875854492\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9841/100000, D Loss: 0.1505790650844574, G Loss: 4.556944370269775\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9842/100000, D Loss: 0.16312576830387115, G Loss: 4.482489585876465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9843/100000, D Loss: 0.14211038127541542, G Loss: 4.712334632873535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9844/100000, D Loss: 0.1477888636291027, G Loss: 4.709925651550293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9845/100000, D Loss: 0.16367778927087784, G Loss: 4.592949867248535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9846/100000, D Loss: 0.13887085020542145, G Loss: 4.418485641479492\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9847/100000, D Loss: 0.13481618463993073, G Loss: 4.6509199142456055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9848/100000, D Loss: 0.15705174207687378, G Loss: 4.8067193031311035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9849/100000, D Loss: 0.1521482840180397, G Loss: 4.905848979949951\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9850/100000, D Loss: 0.15420370921492577, G Loss: 4.800675868988037\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9851/100000, D Loss: 0.1477605402469635, G Loss: 4.575238227844238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9852/100000, D Loss: 0.175536148250103, G Loss: 4.569970607757568\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9853/100000, D Loss: 0.14637108147144318, G Loss: 4.722194194793701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9854/100000, D Loss: 0.17359008267521858, G Loss: 4.57901668548584\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9855/100000, D Loss: 0.1899382844567299, G Loss: 4.228240489959717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9856/100000, D Loss: 0.20915458351373672, G Loss: 4.316481590270996\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9857/100000, D Loss: 0.18125896155834198, G Loss: 4.772437572479248\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9858/100000, D Loss: 0.2305365353822708, G Loss: 4.55198860168457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9859/100000, D Loss: 0.27536751329898834, G Loss: 4.047901153564453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9860/100000, D Loss: 0.21841582655906677, G Loss: 4.342402935028076\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9861/100000, D Loss: 0.1717635914683342, G Loss: 4.892319679260254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9862/100000, D Loss: 0.24581697583198547, G Loss: 4.29810905456543\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9863/100000, D Loss: 0.24840456247329712, G Loss: 3.818269968032837\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9864/100000, D Loss: 0.2418581172823906, G Loss: 4.215123176574707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9865/100000, D Loss: 0.20310426503419876, G Loss: 4.7458271980285645\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9866/100000, D Loss: 0.25270976126194, G Loss: 4.24809455871582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9867/100000, D Loss: 0.2825130224227905, G Loss: 3.9345855712890625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9868/100000, D Loss: 0.25513339042663574, G Loss: 4.162077903747559\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9869/100000, D Loss: 0.25839897990226746, G Loss: 4.285577774047852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9870/100000, D Loss: 0.23152713477611542, G Loss: 4.103724479675293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9871/100000, D Loss: 0.2668444737792015, G Loss: 3.890852451324463\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9872/100000, D Loss: 0.22413769364356995, G Loss: 3.9726200103759766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9873/100000, D Loss: 0.2042129561305046, G Loss: 4.302610874176025\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9874/100000, D Loss: 0.2239052578806877, G Loss: 4.323208808898926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9875/100000, D Loss: 0.24494878202676773, G Loss: 4.311272144317627\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9876/100000, D Loss: 0.20505616068840027, G Loss: 4.341728210449219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9877/100000, D Loss: 0.17139145731925964, G Loss: 4.503406047821045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9878/100000, D Loss: 0.14994558691978455, G Loss: 4.615453243255615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9879/100000, D Loss: 0.19558002054691315, G Loss: 4.312558174133301\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9880/100000, D Loss: 0.18170920759439468, G Loss: 4.238502502441406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9881/100000, D Loss: 0.18210045993328094, G Loss: 4.324637413024902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9882/100000, D Loss: 0.17775201052427292, G Loss: 4.357741355895996\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9883/100000, D Loss: 0.17189421504735947, G Loss: 4.4633283615112305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9884/100000, D Loss: 0.18113458901643753, G Loss: 4.35606050491333\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9885/100000, D Loss: 0.19852184504270554, G Loss: 4.330365180969238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9886/100000, D Loss: 0.1765683814883232, G Loss: 4.462939739227295\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9887/100000, D Loss: 0.20658095180988312, G Loss: 4.407934188842773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9888/100000, D Loss: 0.24625945836305618, G Loss: 3.8735790252685547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9889/100000, D Loss: 0.22232161462306976, G Loss: 3.848501682281494\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9890/100000, D Loss: 0.2458135485649109, G Loss: 4.056262969970703\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9891/100000, D Loss: 0.20846756547689438, G Loss: 4.426675319671631\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9892/100000, D Loss: 0.2026834413409233, G Loss: 4.65172004699707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9893/100000, D Loss: 0.2518283426761627, G Loss: 4.016419887542725\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9894/100000, D Loss: 0.2241605743765831, G Loss: 3.853095054626465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9895/100000, D Loss: 0.22057828307151794, G Loss: 4.1716227531433105\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9896/100000, D Loss: 0.2022198736667633, G Loss: 4.499476432800293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9897/100000, D Loss: 0.1704261526465416, G Loss: 4.332000255584717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9898/100000, D Loss: 0.22326504439115524, G Loss: 3.970696449279785\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9899/100000, D Loss: 0.2076929286122322, G Loss: 3.7680869102478027\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9900/100000, D Loss: 0.18989131599664688, G Loss: 4.143124580383301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9901/100000, D Loss: 0.19649386405944824, G Loss: 4.429697036743164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9902/100000, D Loss: 0.21867161989212036, G Loss: 4.158332824707031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9903/100000, D Loss: 0.22226747125387192, G Loss: 3.935662269592285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9904/100000, D Loss: 0.2338816374540329, G Loss: 4.279454231262207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9905/100000, D Loss: 0.23124786466360092, G Loss: 4.167322158813477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9906/100000, D Loss: 0.28636209666728973, G Loss: 3.754880428314209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9907/100000, D Loss: 0.2829480320215225, G Loss: 3.7010581493377686\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9908/100000, D Loss: 0.24364571273326874, G Loss: 3.972486972808838\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9909/100000, D Loss: 0.25346461683511734, G Loss: 4.2112717628479\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9910/100000, D Loss: 0.2776481956243515, G Loss: 3.833543539047241\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9911/100000, D Loss: 0.31322479248046875, G Loss: 3.624518394470215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9912/100000, D Loss: 0.2627282440662384, G Loss: 3.6626880168914795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9913/100000, D Loss: 0.2833501845598221, G Loss: 4.069369792938232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9914/100000, D Loss: 0.2590544670820236, G Loss: 3.977457284927368\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9915/100000, D Loss: 0.3104950040578842, G Loss: 3.700747013092041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9916/100000, D Loss: 0.23800845444202423, G Loss: 3.9761459827423096\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9917/100000, D Loss: 0.2250506952404976, G Loss: 4.457051753997803\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9918/100000, D Loss: 0.20708929747343063, G Loss: 4.456876754760742\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9919/100000, D Loss: 0.2335209995508194, G Loss: 3.968980312347412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9920/100000, D Loss: 0.18719782680273056, G Loss: 3.9926748275756836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9921/100000, D Loss: 0.19300979375839233, G Loss: 4.337067604064941\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9922/100000, D Loss: 0.18013504147529602, G Loss: 4.319785118103027\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9923/100000, D Loss: 0.18727313727140427, G Loss: 4.392462253570557\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9924/100000, D Loss: 0.18174247443675995, G Loss: 4.033904075622559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9925/100000, D Loss: 0.16779118031263351, G Loss: 4.327435493469238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9926/100000, D Loss: 0.16487547755241394, G Loss: 4.428070068359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9927/100000, D Loss: 0.1434013694524765, G Loss: 4.51457405090332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9928/100000, D Loss: 0.16930805891752243, G Loss: 4.32872200012207\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9929/100000, D Loss: 0.17395934462547302, G Loss: 4.147928237915039\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9930/100000, D Loss: 0.1620791032910347, G Loss: 4.3246965408325195\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9931/100000, D Loss: 0.1574321687221527, G Loss: 4.434023857116699\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9932/100000, D Loss: 0.1885627657175064, G Loss: 4.262438774108887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9933/100000, D Loss: 0.20029190927743912, G Loss: 4.1459150314331055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9934/100000, D Loss: 0.14624279737472534, G Loss: 4.255846977233887\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9935/100000, D Loss: 0.17877846211194992, G Loss: 4.596508026123047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9936/100000, D Loss: 0.1717226505279541, G Loss: 4.439892768859863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9937/100000, D Loss: 0.18739701807498932, G Loss: 4.422800064086914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9938/100000, D Loss: 0.17191756516695023, G Loss: 4.393200874328613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9939/100000, D Loss: 0.15893784165382385, G Loss: 4.261478424072266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9940/100000, D Loss: 0.17866620421409607, G Loss: 4.266472816467285\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9941/100000, D Loss: 0.15070752799510956, G Loss: 4.589963912963867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9942/100000, D Loss: 0.1585514321923256, G Loss: 4.779959678649902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9943/100000, D Loss: 0.17217754572629929, G Loss: 4.467887878417969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9944/100000, D Loss: 0.20140495896339417, G Loss: 4.070932865142822\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9945/100000, D Loss: 0.20138169080018997, G Loss: 4.108440399169922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9946/100000, D Loss: 0.19563011825084686, G Loss: 4.491766929626465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9947/100000, D Loss: 0.1627514772117138, G Loss: 4.656073570251465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9948/100000, D Loss: 0.215521939098835, G Loss: 4.033925533294678\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9949/100000, D Loss: 0.21644918620586395, G Loss: 3.8232555389404297\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9950/100000, D Loss: 0.2078782096505165, G Loss: 4.007819175720215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9951/100000, D Loss: 0.1978512480854988, G Loss: 4.452893257141113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9952/100000, D Loss: 0.2202044427394867, G Loss: 4.379298210144043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9953/100000, D Loss: 0.22766664624214172, G Loss: 3.8913402557373047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9954/100000, D Loss: 0.2028757482767105, G Loss: 3.945617198944092\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9955/100000, D Loss: 0.17881984263658524, G Loss: 4.406052112579346\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9956/100000, D Loss: 0.19369100034236908, G Loss: 4.30754280090332\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9957/100000, D Loss: 0.19084663689136505, G Loss: 4.073916435241699\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9958/100000, D Loss: 0.25166114419698715, G Loss: 3.8056650161743164\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9959/100000, D Loss: 0.20903807878494263, G Loss: 3.9382848739624023\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 9960/100000, D Loss: 0.1950223445892334, G Loss: 4.259734153747559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9961/100000, D Loss: 0.23743939399719238, G Loss: 4.255791664123535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9962/100000, D Loss: 0.23964229226112366, G Loss: 3.8208439350128174\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9963/100000, D Loss: 0.2115899994969368, G Loss: 3.8753795623779297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9964/100000, D Loss: 0.1870935633778572, G Loss: 4.147590637207031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9965/100000, D Loss: 0.19701096415519714, G Loss: 4.64034366607666\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9966/100000, D Loss: 0.22154587507247925, G Loss: 4.216380596160889\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9967/100000, D Loss: 0.20748788118362427, G Loss: 3.960885524749756\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9968/100000, D Loss: 0.18766982853412628, G Loss: 4.057354927062988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9969/100000, D Loss: 0.17357975244522095, G Loss: 4.441377639770508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9970/100000, D Loss: 0.16865013539791107, G Loss: 4.529185771942139\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9971/100000, D Loss: 0.20385564863681793, G Loss: 4.2070841789245605\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9972/100000, D Loss: 0.16126904636621475, G Loss: 4.076714515686035\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9973/100000, D Loss: 0.13350475579500198, G Loss: 4.399226665496826\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9974/100000, D Loss: 0.1366066001355648, G Loss: 4.608893871307373\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 9975/100000, D Loss: 0.1607140749692917, G Loss: 4.485272407531738\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9976/100000, D Loss: 0.15343830734491348, G Loss: 4.47312068939209\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9977/100000, D Loss: 0.14423460513353348, G Loss: 4.3785200119018555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 9978/100000, D Loss: 0.18773168325424194, G Loss: 4.160789489746094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9979/100000, D Loss: 0.17904499173164368, G Loss: 4.501032829284668\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9980/100000, D Loss: 0.17922290414571762, G Loss: 4.2794342041015625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9981/100000, D Loss: 0.17695076763629913, G Loss: 4.2220964431762695\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9982/100000, D Loss: 0.23023531585931778, G Loss: 3.9079620838165283\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9983/100000, D Loss: 0.25088391453027725, G Loss: 4.093852996826172\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9984/100000, D Loss: 0.19350385665893555, G Loss: 4.426444053649902\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9985/100000, D Loss: 0.24492450803518295, G Loss: 4.0652055740356445\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 9986/100000, D Loss: 0.2639963626861572, G Loss: 3.924544334411621\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9987/100000, D Loss: 0.23941956460475922, G Loss: 4.307836532592773\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9988/100000, D Loss: 0.2840045988559723, G Loss: 4.06576681137085\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9989/100000, D Loss: 0.3023194372653961, G Loss: 3.732024669647217\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9990/100000, D Loss: 0.26383063197135925, G Loss: 3.8790647983551025\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9991/100000, D Loss: 0.29005247354507446, G Loss: 4.296972274780273\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9992/100000, D Loss: 0.3030666783452034, G Loss: 4.009039878845215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9993/100000, D Loss: 0.36079534888267517, G Loss: 3.940685749053955\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9994/100000, D Loss: 0.369573712348938, G Loss: 3.885007381439209\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9995/100000, D Loss: 0.3454056829214096, G Loss: 3.9099574089050293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9996/100000, D Loss: 0.33897368609905243, G Loss: 3.790755271911621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9997/100000, D Loss: 0.337211012840271, G Loss: 4.066628932952881\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 9998/100000, D Loss: 0.38842688500881195, G Loss: 3.804232597351074\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 9999/100000, D Loss: 0.3534739911556244, G Loss: 3.881838083267212\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10000/100000, D Loss: 0.2768729031085968, G Loss: 4.283188819885254\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10001/100000, D Loss: 0.3116210177540779, G Loss: 3.9471945762634277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10002/100000, D Loss: 0.2840377986431122, G Loss: 3.767725944519043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10003/100000, D Loss: 0.2072136104106903, G Loss: 4.485898017883301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10004/100000, D Loss: 0.23670660704374313, G Loss: 4.555832862854004\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10005/100000, D Loss: 0.21020827442407608, G Loss: 4.431449890136719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10006/100000, D Loss: 0.17229418456554413, G Loss: 4.508632659912109\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10007/100000, D Loss: 0.16014503687620163, G Loss: 4.579080581665039\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10008/100000, D Loss: 0.13469937443733215, G Loss: 4.806527614593506\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10009/100000, D Loss: 0.14675404503941536, G Loss: 4.558534145355225\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10010/100000, D Loss: 0.14373091608285904, G Loss: 4.63610315322876\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10011/100000, D Loss: 0.1376144140958786, G Loss: 5.065507888793945\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10012/100000, D Loss: 0.12090916931629181, G Loss: 4.927685260772705\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10013/100000, D Loss: 0.13011690974235535, G Loss: 4.823564529418945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10014/100000, D Loss: 0.11468604579567909, G Loss: 4.848360061645508\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10015/100000, D Loss: 0.12352371215820312, G Loss: 4.715217590332031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10016/100000, D Loss: 0.1526080220937729, G Loss: 4.633890628814697\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10017/100000, D Loss: 0.13795655965805054, G Loss: 4.9020771980285645\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10018/100000, D Loss: 0.1634965017437935, G Loss: 4.825387001037598\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10019/100000, D Loss: 0.17408450692892075, G Loss: 4.303400039672852\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10020/100000, D Loss: 0.16534411162137985, G Loss: 4.301151752471924\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10021/100000, D Loss: 0.17754647880792618, G Loss: 4.523106575012207\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10022/100000, D Loss: 0.14384260028600693, G Loss: 4.624378204345703\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10023/100000, D Loss: 0.18301521241664886, G Loss: 4.587257385253906\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 10024/100000, D Loss: 0.21919553726911545, G Loss: 4.251165390014648\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10025/100000, D Loss: 0.21611110121011734, G Loss: 4.2755961418151855\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 10026/100000, D Loss: 0.17677761614322662, G Loss: 4.577939987182617\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10027/100000, D Loss: 0.2092379331588745, G Loss: 4.5506792068481445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10028/100000, D Loss: 0.2124474197626114, G Loss: 3.9609603881835938\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10029/100000, D Loss: 0.2306753695011139, G Loss: 3.9388973712921143\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10030/100000, D Loss: 0.23214925825595856, G Loss: 4.40676736831665\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10031/100000, D Loss: 0.21255585551261902, G Loss: 4.356578826904297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10032/100000, D Loss: 0.20251096040010452, G Loss: 4.227056980133057\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10033/100000, D Loss: 0.2417304813861847, G Loss: 4.203672409057617\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10034/100000, D Loss: 0.20593968033790588, G Loss: 4.210820198059082\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10035/100000, D Loss: 0.23241812735795975, G Loss: 4.042549133300781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10036/100000, D Loss: 0.2000834345817566, G Loss: 4.36055326461792\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10037/100000, D Loss: 0.22521433234214783, G Loss: 4.35499382019043\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10038/100000, D Loss: 0.22754370421171188, G Loss: 4.473898887634277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10039/100000, D Loss: 0.22853240370750427, G Loss: 4.223199844360352\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10040/100000, D Loss: 0.22216201573610306, G Loss: 4.222634315490723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10041/100000, D Loss: 0.22196228802204132, G Loss: 4.299684047698975\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10042/100000, D Loss: 0.20421453565359116, G Loss: 4.1886749267578125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10043/100000, D Loss: 0.20129583775997162, G Loss: 4.1645355224609375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10044/100000, D Loss: 0.23511500656604767, G Loss: 4.141233444213867\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10045/100000, D Loss: 0.19897734373807907, G Loss: 4.226690292358398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10046/100000, D Loss: 0.20298732072114944, G Loss: 4.289421558380127\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10047/100000, D Loss: 0.1841205209493637, G Loss: 4.215971946716309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10048/100000, D Loss: 0.19521989673376083, G Loss: 4.270775318145752\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10049/100000, D Loss: 0.14917653799057007, G Loss: 4.497077941894531\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10050/100000, D Loss: 0.15970952808856964, G Loss: 4.719139099121094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10051/100000, D Loss: 0.18266583606600761, G Loss: 4.294126510620117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10052/100000, D Loss: 0.16099371016025543, G Loss: 4.26221227645874\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10053/100000, D Loss: 0.14987026154994965, G Loss: 4.73504114151001\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10054/100000, D Loss: 0.1339433640241623, G Loss: 5.084805011749268\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10055/100000, D Loss: 0.12130501866340637, G Loss: 4.948616027832031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10056/100000, D Loss: 0.1248478889465332, G Loss: 4.593250274658203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10057/100000, D Loss: 0.14058611541986465, G Loss: 4.337918281555176\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10058/100000, D Loss: 0.10441020503640175, G Loss: 4.45944881439209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10059/100000, D Loss: 0.11988203972578049, G Loss: 4.680163383483887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10060/100000, D Loss: 0.12543099001049995, G Loss: 4.763609886169434\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10061/100000, D Loss: 0.12285714223980904, G Loss: 4.7267351150512695\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10062/100000, D Loss: 0.13888871669769287, G Loss: 4.534473896026611\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10063/100000, D Loss: 0.13898218423128128, G Loss: 4.406179428100586\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10064/100000, D Loss: 0.11158189177513123, G Loss: 4.75296688079834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10065/100000, D Loss: 0.12892978638410568, G Loss: 4.92659330368042\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10066/100000, D Loss: 0.13352760300040245, G Loss: 4.50239372253418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10067/100000, D Loss: 0.13741860538721085, G Loss: 4.492359638214111\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10068/100000, D Loss: 0.11363374069333076, G Loss: 4.64210844039917\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10069/100000, D Loss: 0.11876475065946579, G Loss: 4.816752910614014\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10070/100000, D Loss: 0.1320091262459755, G Loss: 4.742044448852539\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 10071/100000, D Loss: 0.14656204730272293, G Loss: 4.579281806945801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10072/100000, D Loss: 0.15282565355300903, G Loss: 4.563608646392822\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10073/100000, D Loss: 0.18221383541822433, G Loss: 4.51417350769043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10074/100000, D Loss: 0.1701277643442154, G Loss: 4.703792572021484\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10075/100000, D Loss: 0.1783713400363922, G Loss: 4.640195846557617\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10076/100000, D Loss: 0.18395398557186127, G Loss: 4.384886264801025\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10077/100000, D Loss: 0.18420390039682388, G Loss: 4.125921249389648\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10078/100000, D Loss: 0.17602208256721497, G Loss: 4.21052360534668\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10079/100000, D Loss: 0.20419324189424515, G Loss: 4.535784721374512\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10080/100000, D Loss: 0.2057698890566826, G Loss: 4.480555534362793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10081/100000, D Loss: 0.19725154340267181, G Loss: 4.214542865753174\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10082/100000, D Loss: 0.2156081646680832, G Loss: 3.9983747005462646\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10083/100000, D Loss: 0.20082684606313705, G Loss: 4.111213207244873\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10084/100000, D Loss: 0.18173469603061676, G Loss: 4.306656360626221\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10085/100000, D Loss: 0.20061644166707993, G Loss: 4.1680908203125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10086/100000, D Loss: 0.18141979724168777, G Loss: 4.211188316345215\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10087/100000, D Loss: 0.18062299489974976, G Loss: 4.292585372924805\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10088/100000, D Loss: 0.18835876137018204, G Loss: 4.455397605895996\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10089/100000, D Loss: 0.19511602818965912, G Loss: 4.537816047668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10090/100000, D Loss: 0.204833984375, G Loss: 4.204214096069336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10091/100000, D Loss: 0.1864498034119606, G Loss: 4.18299674987793\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10092/100000, D Loss: 0.19735221564769745, G Loss: 4.405991077423096\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10093/100000, D Loss: 0.2164265662431717, G Loss: 4.268177509307861\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10094/100000, D Loss: 0.19262254983186722, G Loss: 4.388568878173828\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10095/100000, D Loss: 0.21831366419792175, G Loss: 4.312337875366211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10096/100000, D Loss: 0.20099540054798126, G Loss: 4.206050872802734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10097/100000, D Loss: 0.17617688328027725, G Loss: 4.280669212341309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10098/100000, D Loss: 0.21756482124328613, G Loss: 4.160401344299316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10099/100000, D Loss: 0.18992507457733154, G Loss: 4.6263427734375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10100/100000, D Loss: 0.1880166158080101, G Loss: 4.409358501434326\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10101/100000, D Loss: 0.22541077435016632, G Loss: 4.123064041137695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10102/100000, D Loss: 0.1971278265118599, G Loss: 4.214306831359863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10103/100000, D Loss: 0.19094383716583252, G Loss: 4.444770336151123\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10104/100000, D Loss: 0.18302972614765167, G Loss: 4.6081342697143555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10105/100000, D Loss: 0.20988745242357254, G Loss: 4.17031717300415\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10106/100000, D Loss: 0.21135367453098297, G Loss: 3.964845657348633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10107/100000, D Loss: 0.2132570594549179, G Loss: 4.210428714752197\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10108/100000, D Loss: 0.23624877631664276, G Loss: 4.311802864074707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10109/100000, D Loss: 0.2213670089840889, G Loss: 4.392364978790283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10110/100000, D Loss: 0.232624351978302, G Loss: 4.02545690536499\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10111/100000, D Loss: 0.27394913136959076, G Loss: 4.129660606384277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10112/100000, D Loss: 0.21628528833389282, G Loss: 4.381004333496094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10113/100000, D Loss: 0.24339064210653305, G Loss: 4.668103218078613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10114/100000, D Loss: 0.24440032243728638, G Loss: 4.52708101272583\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10115/100000, D Loss: 0.26122891902923584, G Loss: 3.914696216583252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10116/100000, D Loss: 0.236527219414711, G Loss: 4.066225528717041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10117/100000, D Loss: 0.22774745523929596, G Loss: 4.087127208709717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10118/100000, D Loss: 0.24080902338027954, G Loss: 4.155681610107422\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10119/100000, D Loss: 0.23233181983232498, G Loss: 4.189506530761719\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10120/100000, D Loss: 0.2299502268433571, G Loss: 4.3179216384887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10121/100000, D Loss: 0.2544638067483902, G Loss: 4.40766716003418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10122/100000, D Loss: 0.25678202509880066, G Loss: 4.253350734710693\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10123/100000, D Loss: 0.247170552611351, G Loss: 4.375875473022461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10124/100000, D Loss: 0.23097610473632812, G Loss: 4.71474552154541\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10125/100000, D Loss: 0.27467162162065506, G Loss: 4.721787452697754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10126/100000, D Loss: 0.2317013218998909, G Loss: 4.634613990783691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10127/100000, D Loss: 0.25552158057689667, G Loss: 4.266212463378906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10128/100000, D Loss: 0.23186087608337402, G Loss: 4.5660905838012695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10129/100000, D Loss: 0.2351386696100235, G Loss: 4.784789085388184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10130/100000, D Loss: 0.2109551578760147, G Loss: 4.762164115905762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10131/100000, D Loss: 0.2377457618713379, G Loss: 4.759610652923584\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10132/100000, D Loss: 0.2338135838508606, G Loss: 4.947011947631836\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10133/100000, D Loss: 0.1844843029975891, G Loss: 5.331311225891113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10134/100000, D Loss: 0.20306633412837982, G Loss: 4.987743377685547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10135/100000, D Loss: 0.18741854280233383, G Loss: 4.638454437255859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10136/100000, D Loss: 0.15914618968963623, G Loss: 4.809972763061523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10137/100000, D Loss: 0.1457528993487358, G Loss: 5.1379475593566895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10138/100000, D Loss: 0.12310387939214706, G Loss: 5.60264778137207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10139/100000, D Loss: 0.1458379253745079, G Loss: 5.280734539031982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10140/100000, D Loss: 0.13587693870067596, G Loss: 4.715956687927246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10141/100000, D Loss: 0.1701658070087433, G Loss: 4.484138488769531\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10142/100000, D Loss: 0.16156858205795288, G Loss: 4.96954870223999\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10143/100000, D Loss: 0.11150800436735153, G Loss: 5.385794162750244\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10144/100000, D Loss: 0.15484508126974106, G Loss: 4.920092582702637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10145/100000, D Loss: 0.17140685766935349, G Loss: 4.4662089347839355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10146/100000, D Loss: 0.19984422624111176, G Loss: 4.50437068939209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10147/100000, D Loss: 0.1628922075033188, G Loss: 4.7873945236206055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10148/100000, D Loss: 0.18077589571475983, G Loss: 4.907724857330322\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10149/100000, D Loss: 0.1856226846575737, G Loss: 4.604230880737305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10150/100000, D Loss: 0.1822032853960991, G Loss: 4.309630393981934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10151/100000, D Loss: 0.18706434220075607, G Loss: 4.346523284912109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10152/100000, D Loss: 0.17893514037132263, G Loss: 4.479159355163574\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10153/100000, D Loss: 0.19494902342557907, G Loss: 4.69565486907959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10154/100000, D Loss: 0.21288809180259705, G Loss: 4.232741832733154\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10155/100000, D Loss: 0.21967054158449173, G Loss: 4.206738471984863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10156/100000, D Loss: 0.21984076499938965, G Loss: 4.504415512084961\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10157/100000, D Loss: 0.1903257668018341, G Loss: 4.6917338371276855\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10158/100000, D Loss: 0.2263374924659729, G Loss: 4.400538444519043\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10159/100000, D Loss: 0.27731627225875854, G Loss: 4.110103607177734\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10160/100000, D Loss: 0.26127491146326065, G Loss: 4.219711780548096\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10161/100000, D Loss: 0.24465234577655792, G Loss: 4.572877407073975\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10162/100000, D Loss: 0.2521040365099907, G Loss: 4.21173620223999\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10163/100000, D Loss: 0.25882094353437424, G Loss: 4.020135402679443\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10164/100000, D Loss: 0.25009508430957794, G Loss: 3.9653124809265137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10165/100000, D Loss: 0.2167052924633026, G Loss: 4.299567222595215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10166/100000, D Loss: 0.22957529872655869, G Loss: 4.253373622894287\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10167/100000, D Loss: 0.2681693583726883, G Loss: 3.997896194458008\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10168/100000, D Loss: 0.2258005291223526, G Loss: 3.9819819927215576\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10169/100000, D Loss: 0.20808635652065277, G Loss: 4.225705146789551\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10170/100000, D Loss: 0.20394524931907654, G Loss: 4.2726335525512695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10171/100000, D Loss: 0.18554993718862534, G Loss: 4.286693572998047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10172/100000, D Loss: 0.18615715205669403, G Loss: 4.390499114990234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10173/100000, D Loss: 0.1675569862127304, G Loss: 4.3780388832092285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10174/100000, D Loss: 0.1596376746892929, G Loss: 4.658906936645508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10175/100000, D Loss: 0.15469489246606827, G Loss: 4.636958122253418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10176/100000, D Loss: 0.11581651121377945, G Loss: 4.825632095336914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10177/100000, D Loss: 0.11124330386519432, G Loss: 4.914031028747559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10178/100000, D Loss: 0.13132862001657486, G Loss: 4.609908580780029\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10179/100000, D Loss: 0.12963742017745972, G Loss: 4.422152996063232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10180/100000, D Loss: 0.12250300496816635, G Loss: 4.527275085449219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10181/100000, D Loss: 0.09352317079901695, G Loss: 5.092151641845703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10182/100000, D Loss: 0.11783386394381523, G Loss: 5.057419300079346\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10183/100000, D Loss: 0.139828372746706, G Loss: 4.703008651733398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10184/100000, D Loss: 0.13242565095424652, G Loss: 4.359813690185547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10185/100000, D Loss: 0.14003732055425644, G Loss: 4.434939384460449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10186/100000, D Loss: 0.1526280865073204, G Loss: 4.631376266479492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10187/100000, D Loss: 0.14129723608493805, G Loss: 4.721395492553711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10188/100000, D Loss: 0.15522804856300354, G Loss: 4.436620235443115\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10189/100000, D Loss: 0.16018275916576385, G Loss: 4.312296390533447\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10190/100000, D Loss: 0.14603956043720245, G Loss: 4.605350017547607\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10191/100000, D Loss: 0.16907940804958344, G Loss: 4.606581687927246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10192/100000, D Loss: 0.19197510182857513, G Loss: 4.466028213500977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10193/100000, D Loss: 0.23590455949306488, G Loss: 4.251430988311768\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10194/100000, D Loss: 0.20323532819747925, G Loss: 4.276888847351074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10195/100000, D Loss: 0.20366854965686798, G Loss: 4.370281219482422\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10196/100000, D Loss: 0.2702523544430733, G Loss: 3.7924513816833496\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10197/100000, D Loss: 0.3028402477502823, G Loss: 3.84158992767334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10198/100000, D Loss: 0.30271749198436737, G Loss: 4.426573276519775\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10199/100000, D Loss: 0.2780051529407501, G Loss: 4.685860633850098\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10200/100000, D Loss: 0.28491953015327454, G Loss: 3.7935738563537598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10201/100000, D Loss: 0.30018940567970276, G Loss: 3.5005650520324707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10202/100000, D Loss: 0.2660045400261879, G Loss: 4.098042964935303\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10203/100000, D Loss: 0.2650660127401352, G Loss: 4.3651275634765625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10204/100000, D Loss: 0.30130133032798767, G Loss: 3.739851474761963\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10205/100000, D Loss: 0.25610487908124924, G Loss: 3.7435340881347656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10206/100000, D Loss: 0.2620522379875183, G Loss: 4.2859721183776855\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10207/100000, D Loss: 0.21314206719398499, G Loss: 4.497749328613281\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10208/100000, D Loss: 0.24306661635637283, G Loss: 4.185516834259033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10209/100000, D Loss: 0.2313566356897354, G Loss: 4.090816020965576\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10210/100000, D Loss: 0.21174803376197815, G Loss: 4.340261459350586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10211/100000, D Loss: 0.24380208551883698, G Loss: 4.3524169921875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10212/100000, D Loss: 0.19452764093875885, G Loss: 4.532426834106445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10213/100000, D Loss: 0.1864796280860901, G Loss: 4.4950079917907715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10214/100000, D Loss: 0.1679733544588089, G Loss: 4.447984218597412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10215/100000, D Loss: 0.20066557824611664, G Loss: 4.177109241485596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10216/100000, D Loss: 0.14471754431724548, G Loss: 4.597356796264648\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10217/100000, D Loss: 0.17994087934494019, G Loss: 4.7025861740112305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10218/100000, D Loss: 0.17313841730356216, G Loss: 4.441246509552002\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10219/100000, D Loss: 0.2103898748755455, G Loss: 3.991053342819214\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10220/100000, D Loss: 0.17138339579105377, G Loss: 4.765321254730225\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10221/100000, D Loss: 0.1741887480020523, G Loss: 4.651677131652832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10222/100000, D Loss: 0.23604217916727066, G Loss: 4.267876625061035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10223/100000, D Loss: 0.22919757664203644, G Loss: 3.901196002960205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10224/100000, D Loss: 0.23314761370420456, G Loss: 4.207343101501465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10225/100000, D Loss: 0.1900239661335945, G Loss: 4.5528059005737305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10226/100000, D Loss: 0.20786397904157639, G Loss: 4.6050124168396\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10227/100000, D Loss: 0.2387712374329567, G Loss: 4.101269721984863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10228/100000, D Loss: 0.25555501878261566, G Loss: 4.039649963378906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10229/100000, D Loss: 0.2032044604420662, G Loss: 4.501948833465576\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10230/100000, D Loss: 0.2090435028076172, G Loss: 4.426514625549316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10231/100000, D Loss: 0.21644438803195953, G Loss: 4.121200084686279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10232/100000, D Loss: 0.24241483211517334, G Loss: 4.011612892150879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10233/100000, D Loss: 0.2018643468618393, G Loss: 4.283079624176025\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10234/100000, D Loss: 0.23476627469062805, G Loss: 4.342159271240234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10235/100000, D Loss: 0.2293667271733284, G Loss: 3.9969253540039062\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10236/100000, D Loss: 0.20644177496433258, G Loss: 4.183839797973633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10237/100000, D Loss: 0.20239099115133286, G Loss: 4.689909934997559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10238/100000, D Loss: 0.2148711383342743, G Loss: 4.629087924957275\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10239/100000, D Loss: 0.19126567244529724, G Loss: 4.40894889831543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10240/100000, D Loss: 0.16602102667093277, G Loss: 4.365994453430176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10241/100000, D Loss: 0.1692265346646309, G Loss: 4.675077438354492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10242/100000, D Loss: 0.16401788592338562, G Loss: 5.000925064086914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10243/100000, D Loss: 0.2063116729259491, G Loss: 4.641726493835449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10244/100000, D Loss: 0.1926540657877922, G Loss: 4.352662086486816\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10245/100000, D Loss: 0.1521628424525261, G Loss: 4.627732276916504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10246/100000, D Loss: 0.166936457157135, G Loss: 4.959155559539795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10247/100000, D Loss: 0.1721034049987793, G Loss: 4.747952461242676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10248/100000, D Loss: 0.16774006187915802, G Loss: 4.563855171203613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10249/100000, D Loss: 0.17836944013834, G Loss: 4.370718002319336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10250/100000, D Loss: 0.14661472663283348, G Loss: 4.781798362731934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10251/100000, D Loss: 0.14232635870575905, G Loss: 4.949732780456543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10252/100000, D Loss: 0.16395887359976768, G Loss: 4.631226539611816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10253/100000, D Loss: 0.1686764433979988, G Loss: 4.414181709289551\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10254/100000, D Loss: 0.16209007799625397, G Loss: 4.352752208709717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10255/100000, D Loss: 0.16854456067085266, G Loss: 4.726778984069824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10256/100000, D Loss: 0.16764849424362183, G Loss: 4.782243728637695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10257/100000, D Loss: 0.19572506099939346, G Loss: 4.523880958557129\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10258/100000, D Loss: 0.1977585256099701, G Loss: 4.148553848266602\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10259/100000, D Loss: 0.16042133420705795, G Loss: 4.497311592102051\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10260/100000, D Loss: 0.19425369799137115, G Loss: 4.635193347930908\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10261/100000, D Loss: 0.21965713798999786, G Loss: 3.9913203716278076\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10262/100000, D Loss: 0.23562871664762497, G Loss: 4.090542316436768\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10263/100000, D Loss: 0.22133281826972961, G Loss: 4.588987350463867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10264/100000, D Loss: 0.24598776549100876, G Loss: 4.480637073516846\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10265/100000, D Loss: 0.30913878977298737, G Loss: 3.7763447761535645\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10266/100000, D Loss: 0.32088012993335724, G Loss: 3.7057018280029297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10267/100000, D Loss: 0.23456613719463348, G Loss: 4.38214111328125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10268/100000, D Loss: 0.3121168911457062, G Loss: 4.038283824920654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10269/100000, D Loss: 0.32051020860671997, G Loss: 3.5271785259246826\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10270/100000, D Loss: 0.37864577770233154, G Loss: 3.668386459350586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10271/100000, D Loss: 0.26627402752637863, G Loss: 4.087160110473633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10272/100000, D Loss: 0.3029426634311676, G Loss: 3.763505458831787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10273/100000, D Loss: 0.33877240121364594, G Loss: 3.6874947547912598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10274/100000, D Loss: 0.31982843577861786, G Loss: 3.8863229751586914\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10275/100000, D Loss: 0.30348729342222214, G Loss: 4.051828861236572\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10276/100000, D Loss: 0.32289208471775055, G Loss: 3.7526111602783203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10277/100000, D Loss: 0.3169892430305481, G Loss: 3.5468034744262695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10278/100000, D Loss: 0.2798658311367035, G Loss: 3.9915332794189453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10279/100000, D Loss: 0.24227139353752136, G Loss: 4.3013176918029785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10280/100000, D Loss: 0.2797170728445053, G Loss: 4.230997085571289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10281/100000, D Loss: 0.29145562648773193, G Loss: 3.8578734397888184\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 10282/100000, D Loss: 0.28117311000823975, G Loss: 3.969813585281372\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10283/100000, D Loss: 0.23237957805395126, G Loss: 4.5383477210998535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10284/100000, D Loss: 0.2521386444568634, G Loss: 4.186354160308838\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10285/100000, D Loss: 0.2648286148905754, G Loss: 3.869062900543213\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10286/100000, D Loss: 0.21711447834968567, G Loss: 4.299890041351318\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10287/100000, D Loss: 0.2435585930943489, G Loss: 4.412028789520264\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10288/100000, D Loss: 0.21884094178676605, G Loss: 4.4615631103515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10289/100000, D Loss: 0.2356560081243515, G Loss: 4.2461838722229\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10290/100000, D Loss: 0.20997800678014755, G Loss: 4.109500885009766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10291/100000, D Loss: 0.207786425948143, G Loss: 4.257124900817871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10292/100000, D Loss: 0.18425702303647995, G Loss: 4.588237762451172\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10293/100000, D Loss: 0.20176105201244354, G Loss: 4.331812858581543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10294/100000, D Loss: 0.19433466345071793, G Loss: 3.9972238540649414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10295/100000, D Loss: 0.18629581481218338, G Loss: 4.305678844451904\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10296/100000, D Loss: 0.16467882692813873, G Loss: 4.729475021362305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10297/100000, D Loss: 0.20301121473312378, G Loss: 4.533951759338379\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10298/100000, D Loss: 0.23014214634895325, G Loss: 4.043964385986328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10299/100000, D Loss: 0.20581387728452682, G Loss: 4.059078216552734\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10300/100000, D Loss: 0.17780125886201859, G Loss: 4.679141044616699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10301/100000, D Loss: 0.18214582651853561, G Loss: 4.886778831481934\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10302/100000, D Loss: 0.22972479462623596, G Loss: 4.344849109649658\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10303/100000, D Loss: 0.2298242151737213, G Loss: 3.8509466648101807\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10304/100000, D Loss: 0.21148546040058136, G Loss: 4.358041763305664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10305/100000, D Loss: 0.17766864597797394, G Loss: 4.859932899475098\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10306/100000, D Loss: 0.2243097573518753, G Loss: 4.358924865722656\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10307/100000, D Loss: 0.21641193330287933, G Loss: 4.154659271240234\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10308/100000, D Loss: 0.22357667982578278, G Loss: 4.27974271774292\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10309/100000, D Loss: 0.2091616690158844, G Loss: 4.613682746887207\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10310/100000, D Loss: 0.23429764062166214, G Loss: 4.708263397216797\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10311/100000, D Loss: 0.21897822618484497, G Loss: 4.292775630950928\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10312/100000, D Loss: 0.23797465860843658, G Loss: 4.0292649269104\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10313/100000, D Loss: 0.21936652809381485, G Loss: 4.515576362609863\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10314/100000, D Loss: 0.23544426262378693, G Loss: 4.610429286956787\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10315/100000, D Loss: 0.2316378504037857, G Loss: 4.196749210357666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10316/100000, D Loss: 0.2297399491071701, G Loss: 4.1161603927612305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10317/100000, D Loss: 0.24222909659147263, G Loss: 4.36787748336792\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10318/100000, D Loss: 0.22457588464021683, G Loss: 4.6360039710998535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10319/100000, D Loss: 0.23428602516651154, G Loss: 4.451358795166016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10320/100000, D Loss: 0.258686825633049, G Loss: 4.426042079925537\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10321/100000, D Loss: 0.2644091695547104, G Loss: 4.130586624145508\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10322/100000, D Loss: 0.23804844915866852, G Loss: 4.432981491088867\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10323/100000, D Loss: 0.2662477344274521, G Loss: 4.252248287200928\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10324/100000, D Loss: 0.22638409584760666, G Loss: 4.49091911315918\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10325/100000, D Loss: 0.23560650646686554, G Loss: 4.3064117431640625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10326/100000, D Loss: 0.22338536381721497, G Loss: 4.357038497924805\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10327/100000, D Loss: 0.2633974701166153, G Loss: 4.394413471221924\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10328/100000, D Loss: 0.2647579535841942, G Loss: 4.361970901489258\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10329/100000, D Loss: 0.22445739060640335, G Loss: 4.501631736755371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10330/100000, D Loss: 0.26348940283060074, G Loss: 4.3550848960876465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10331/100000, D Loss: 0.25082041323184967, G Loss: 4.556537628173828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10332/100000, D Loss: 0.21768277138471603, G Loss: 4.375993728637695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10333/100000, D Loss: 0.233854778110981, G Loss: 4.315435409545898\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10334/100000, D Loss: 0.20417524129152298, G Loss: 4.742037773132324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10335/100000, D Loss: 0.19175702333450317, G Loss: 4.6441121101379395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10336/100000, D Loss: 0.20706848800182343, G Loss: 4.603577613830566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10337/100000, D Loss: 0.22034022957086563, G Loss: 4.550944805145264\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10338/100000, D Loss: 0.2075568437576294, G Loss: 4.678913593292236\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10339/100000, D Loss: 0.18751470744609833, G Loss: 5.005888938903809\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10340/100000, D Loss: 0.22263425588607788, G Loss: 4.528059005737305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10341/100000, D Loss: 0.23491916060447693, G Loss: 4.05234432220459\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10342/100000, D Loss: 0.2127911075949669, G Loss: 4.250337600708008\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10343/100000, D Loss: 0.18959515541791916, G Loss: 4.7347917556762695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10344/100000, D Loss: 0.173000767827034, G Loss: 4.645571708679199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10345/100000, D Loss: 0.19995756447315216, G Loss: 4.552649974822998\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10346/100000, D Loss: 0.19384442269802094, G Loss: 4.3738508224487305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10347/100000, D Loss: 0.17585277557373047, G Loss: 4.668632507324219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10348/100000, D Loss: 0.17798539996147156, G Loss: 4.740723609924316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10349/100000, D Loss: 0.16824103891849518, G Loss: 4.824936866760254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10350/100000, D Loss: 0.15425807982683182, G Loss: 4.8848748207092285\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10351/100000, D Loss: 0.14510482549667358, G Loss: 4.813982009887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10352/100000, D Loss: 0.1568245142698288, G Loss: 4.609000205993652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10353/100000, D Loss: 0.1538730189204216, G Loss: 4.67741584777832\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10354/100000, D Loss: 0.18071015924215317, G Loss: 4.525972366333008\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10355/100000, D Loss: 0.14717108756303787, G Loss: 4.48197078704834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10356/100000, D Loss: 0.15690752863883972, G Loss: 4.607358932495117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10357/100000, D Loss: 0.14767205715179443, G Loss: 4.753505229949951\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10358/100000, D Loss: 0.17072857171297073, G Loss: 4.325700759887695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10359/100000, D Loss: 0.1717798188328743, G Loss: 4.388850212097168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10360/100000, D Loss: 0.14958344399929047, G Loss: 4.543476104736328\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10361/100000, D Loss: 0.17822791635990143, G Loss: 4.540999412536621\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10362/100000, D Loss: 0.15629305690526962, G Loss: 4.599431991577148\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10363/100000, D Loss: 0.1720527857542038, G Loss: 4.4029974937438965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10364/100000, D Loss: 0.17347171157598495, G Loss: 4.459866523742676\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10365/100000, D Loss: 0.14970800280570984, G Loss: 4.697949409484863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10366/100000, D Loss: 0.18246503174304962, G Loss: 4.373682975769043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10367/100000, D Loss: 0.16661421954631805, G Loss: 4.022992134094238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10368/100000, D Loss: 0.14948923885822296, G Loss: 4.6155595779418945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10369/100000, D Loss: 0.13408061489462852, G Loss: 5.023732662200928\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10370/100000, D Loss: 0.16184618324041367, G Loss: 4.715601921081543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10371/100000, D Loss: 0.17578520625829697, G Loss: 4.144018650054932\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10372/100000, D Loss: 0.16276514530181885, G Loss: 4.186967372894287\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10373/100000, D Loss: 0.15423811227083206, G Loss: 4.44467306137085\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 10374/100000, D Loss: 0.15811683982610703, G Loss: 4.586639404296875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10375/100000, D Loss: 0.2093568965792656, G Loss: 4.40243673324585\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10376/100000, D Loss: 0.21644530445337296, G Loss: 4.104280471801758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10377/100000, D Loss: 0.19035577028989792, G Loss: 4.372066974639893\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10378/100000, D Loss: 0.22243735194206238, G Loss: 4.592020511627197\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10379/100000, D Loss: 0.2454068437218666, G Loss: 3.968625545501709\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10380/100000, D Loss: 0.20276619493961334, G Loss: 4.116626262664795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10381/100000, D Loss: 0.2038014680147171, G Loss: 4.206809997558594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10382/100000, D Loss: 0.22104179859161377, G Loss: 3.9288058280944824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10383/100000, D Loss: 0.20762667804956436, G Loss: 4.089949607849121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10384/100000, D Loss: 0.233584925532341, G Loss: 4.145815372467041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10385/100000, D Loss: 0.22292281687259674, G Loss: 3.96758770942688\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10386/100000, D Loss: 0.21388772130012512, G Loss: 4.283570289611816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10387/100000, D Loss: 0.20016294717788696, G Loss: 4.526230335235596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10388/100000, D Loss: 0.1960705667734146, G Loss: 4.400232315063477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10389/100000, D Loss: 0.2067987322807312, G Loss: 4.102163314819336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10390/100000, D Loss: 0.20326173305511475, G Loss: 4.2355804443359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10391/100000, D Loss: 0.2100963518023491, G Loss: 4.338616371154785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10392/100000, D Loss: 0.18512559682130814, G Loss: 4.510498523712158\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10393/100000, D Loss: 0.24319174885749817, G Loss: 4.0244035720825195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10394/100000, D Loss: 0.2021179050207138, G Loss: 4.303759574890137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10395/100000, D Loss: 0.1765412911772728, G Loss: 4.548135757446289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10396/100000, D Loss: 0.2395230233669281, G Loss: 4.276785850524902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10397/100000, D Loss: 0.23251397907733917, G Loss: 4.043027400970459\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10398/100000, D Loss: 0.2178616300225258, G Loss: 4.3810858726501465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10399/100000, D Loss: 0.22174054384231567, G Loss: 4.574899673461914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10400/100000, D Loss: 0.2164759635925293, G Loss: 4.533761978149414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10401/100000, D Loss: 0.2477419227361679, G Loss: 3.930190086364746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10402/100000, D Loss: 0.2499612346291542, G Loss: 3.9411463737487793\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10403/100000, D Loss: 0.2384454756975174, G Loss: 4.519163608551025\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10404/100000, D Loss: 0.23177561163902283, G Loss: 4.477975845336914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10405/100000, D Loss: 0.2503882870078087, G Loss: 4.010219573974609\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10406/100000, D Loss: 0.22702378779649734, G Loss: 3.887214183807373\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10407/100000, D Loss: 0.2195829451084137, G Loss: 4.397504806518555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10408/100000, D Loss: 0.19529962539672852, G Loss: 4.585535049438477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10409/100000, D Loss: 0.2558092996478081, G Loss: 4.2512335777282715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10410/100000, D Loss: 0.23392509669065475, G Loss: 4.045304298400879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10411/100000, D Loss: 0.15887542814016342, G Loss: 4.614782333374023\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10412/100000, D Loss: 0.20286856591701508, G Loss: 4.442335605621338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10413/100000, D Loss: 0.19038733839988708, G Loss: 4.316208839416504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10414/100000, D Loss: 0.1928224191069603, G Loss: 4.422547340393066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10415/100000, D Loss: 0.19274257868528366, G Loss: 4.374690055847168\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10416/100000, D Loss: 0.2035534679889679, G Loss: 4.279219150543213\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10417/100000, D Loss: 0.2035445123910904, G Loss: 4.498863220214844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10418/100000, D Loss: 0.1792362928390503, G Loss: 4.685486316680908\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10419/100000, D Loss: 0.16396628320217133, G Loss: 4.810354232788086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10420/100000, D Loss: 0.19364242255687714, G Loss: 4.502725124359131\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10421/100000, D Loss: 0.20569409430027008, G Loss: 4.498355388641357\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10422/100000, D Loss: 0.16307872533798218, G Loss: 4.686676979064941\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10423/100000, D Loss: 0.15950839221477509, G Loss: 4.544025421142578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10424/100000, D Loss: 0.18034957349300385, G Loss: 4.253543853759766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10425/100000, D Loss: 0.1692546084523201, G Loss: 4.315982818603516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10426/100000, D Loss: 0.16886071115732193, G Loss: 4.516061782836914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10427/100000, D Loss: 0.18195029348134995, G Loss: 4.334195137023926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10428/100000, D Loss: 0.21183260530233383, G Loss: 4.131901741027832\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10429/100000, D Loss: 0.20729300379753113, G Loss: 4.369380950927734\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10430/100000, D Loss: 0.2504916489124298, G Loss: 4.193835735321045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10431/100000, D Loss: 0.21155469119548798, G Loss: 4.296169757843018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10432/100000, D Loss: 0.2576785609126091, G Loss: 4.012967109680176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10433/100000, D Loss: 0.22324921190738678, G Loss: 4.178861618041992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10434/100000, D Loss: 0.23402735590934753, G Loss: 4.181553840637207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10435/100000, D Loss: 0.21104265004396439, G Loss: 4.091012954711914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10436/100000, D Loss: 0.2068149894475937, G Loss: 4.122907638549805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10437/100000, D Loss: 0.193650484085083, G Loss: 4.181014537811279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10438/100000, D Loss: 0.21175964176654816, G Loss: 4.226125717163086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10439/100000, D Loss: 0.18807487189769745, G Loss: 4.22659969329834\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10440/100000, D Loss: 0.21658623963594437, G Loss: 4.171555519104004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10441/100000, D Loss: 0.1762077733874321, G Loss: 4.213617324829102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10442/100000, D Loss: 0.17430977523326874, G Loss: 4.261066436767578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10443/100000, D Loss: 0.17357903718948364, G Loss: 4.421241760253906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10444/100000, D Loss: 0.15471435710787773, G Loss: 4.61026668548584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10445/100000, D Loss: 0.2019469290971756, G Loss: 4.461878776550293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10446/100000, D Loss: 0.1765131726861, G Loss: 4.529987335205078\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10447/100000, D Loss: 0.14596977084875107, G Loss: 4.624215126037598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10448/100000, D Loss: 0.1589261144399643, G Loss: 4.70864725112915\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10449/100000, D Loss: 0.1716456189751625, G Loss: 4.424351692199707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10450/100000, D Loss: 0.16375524550676346, G Loss: 4.355607032775879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10451/100000, D Loss: 0.17572757601737976, G Loss: 4.476122856140137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10452/100000, D Loss: 0.18339674174785614, G Loss: 4.474941253662109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10453/100000, D Loss: 0.17495234310626984, G Loss: 4.503337860107422\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10454/100000, D Loss: 0.17924341559410095, G Loss: 4.415335655212402\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10455/100000, D Loss: 0.184834823012352, G Loss: 4.297082901000977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10456/100000, D Loss: 0.18307286500930786, G Loss: 4.224944591522217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10457/100000, D Loss: 0.19616182893514633, G Loss: 4.472848415374756\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10458/100000, D Loss: 0.21416353434324265, G Loss: 4.562155246734619\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10459/100000, D Loss: 0.20975352078676224, G Loss: 4.497890949249268\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10460/100000, D Loss: 0.26010045409202576, G Loss: 4.240448474884033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10461/100000, D Loss: 0.2628813236951828, G Loss: 4.111077308654785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10462/100000, D Loss: 0.24389780312776566, G Loss: 4.543759346008301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10463/100000, D Loss: 0.2733229547739029, G Loss: 4.654269218444824\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10464/100000, D Loss: 0.3016593009233475, G Loss: 4.143250465393066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10465/100000, D Loss: 0.31672514975070953, G Loss: 4.13541841506958\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10466/100000, D Loss: 0.31222666800022125, G Loss: 4.07312536239624\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10467/100000, D Loss: 0.3670753836631775, G Loss: 4.268710136413574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10468/100000, D Loss: 0.3527282625436783, G Loss: 4.218596935272217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10469/100000, D Loss: 0.3722217231988907, G Loss: 3.88197660446167\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10470/100000, D Loss: 0.38965946435928345, G Loss: 3.9189581871032715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10471/100000, D Loss: 0.3208996206521988, G Loss: 4.058162689208984\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10472/100000, D Loss: 0.3485109359025955, G Loss: 4.220651626586914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10473/100000, D Loss: 0.3144628405570984, G Loss: 3.9859135150909424\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10474/100000, D Loss: 0.32593607902526855, G Loss: 3.8257293701171875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10475/100000, D Loss: 0.29029034078121185, G Loss: 4.1695075035095215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10476/100000, D Loss: 0.3310166895389557, G Loss: 4.183204650878906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10477/100000, D Loss: 0.2661391645669937, G Loss: 3.867079019546509\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10478/100000, D Loss: 0.24697045981884003, G Loss: 4.162692070007324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10479/100000, D Loss: 0.25073759257793427, G Loss: 4.376708030700684\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10480/100000, D Loss: 0.2787497192621231, G Loss: 4.749067783355713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10481/100000, D Loss: 0.21485701948404312, G Loss: 4.436959266662598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10482/100000, D Loss: 0.29608774185180664, G Loss: 4.065389633178711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10483/100000, D Loss: 0.2578400447964668, G Loss: 4.2755937576293945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10484/100000, D Loss: 0.21831157803535461, G Loss: 5.018299102783203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10485/100000, D Loss: 0.23493438959121704, G Loss: 5.124188423156738\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10486/100000, D Loss: 0.22602524608373642, G Loss: 4.613222122192383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10487/100000, D Loss: 0.21253319829702377, G Loss: 4.207897186279297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10488/100000, D Loss: 0.1933935582637787, G Loss: 4.575296401977539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10489/100000, D Loss: 0.1668703407049179, G Loss: 5.028472900390625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10490/100000, D Loss: 0.179255411028862, G Loss: 5.177003860473633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10491/100000, D Loss: 0.19034882634878159, G Loss: 4.872871398925781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10492/100000, D Loss: 0.1869518756866455, G Loss: 4.46866512298584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10493/100000, D Loss: 0.1979518160223961, G Loss: 4.673432350158691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10494/100000, D Loss: 0.15535058081150055, G Loss: 4.9147772789001465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10495/100000, D Loss: 0.18230316787958145, G Loss: 4.50581693649292\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10496/100000, D Loss: 0.20648472011089325, G Loss: 4.277499198913574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10497/100000, D Loss: 0.2327229082584381, G Loss: 3.9546051025390625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10498/100000, D Loss: 0.21927978843450546, G Loss: 4.503225326538086\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10499/100000, D Loss: 0.2039129063487053, G Loss: 4.792697429656982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10500/100000, D Loss: 0.2549112066626549, G Loss: 4.346921920776367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10501/100000, D Loss: 0.27497875690460205, G Loss: 3.8461384773254395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10502/100000, D Loss: 0.2663286179304123, G Loss: 4.085318565368652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10503/100000, D Loss: 0.2439030334353447, G Loss: 4.721067428588867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10504/100000, D Loss: 0.23299841582775116, G Loss: 4.352319717407227\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10505/100000, D Loss: 0.2924423813819885, G Loss: 3.8666200637817383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10506/100000, D Loss: 0.2716212645173073, G Loss: 3.8918652534484863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10507/100000, D Loss: 0.249242402613163, G Loss: 4.635284900665283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10508/100000, D Loss: 0.2550104558467865, G Loss: 4.416055679321289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10509/100000, D Loss: 0.24683935940265656, G Loss: 4.013758659362793\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10510/100000, D Loss: 0.23150202631950378, G Loss: 3.8838140964508057\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10511/100000, D Loss: 0.22260423749685287, G Loss: 4.307080268859863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10512/100000, D Loss: 0.19409934431314468, G Loss: 4.490405559539795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10513/100000, D Loss: 0.22086887061595917, G Loss: 4.150947093963623\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10514/100000, D Loss: 0.21138592064380646, G Loss: 4.096744537353516\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10515/100000, D Loss: 0.19656161963939667, G Loss: 4.497223377227783\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10516/100000, D Loss: 0.20684406161308289, G Loss: 4.553348541259766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10517/100000, D Loss: 0.19947565346956253, G Loss: 4.423800468444824\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10518/100000, D Loss: 0.20125730335712433, G Loss: 4.095950126647949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10519/100000, D Loss: 0.19826824963092804, G Loss: 4.272718906402588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10520/100000, D Loss: 0.1795070394873619, G Loss: 4.661587715148926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10521/100000, D Loss: 0.16812244057655334, G Loss: 4.623721599578857\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "Epoch 10522/100000, D Loss: 0.1938687562942505, G Loss: 4.309052467346191\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "Epoch 10523/100000, D Loss: 0.20568515360355377, G Loss: 4.123834133148193\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 10524/100000, D Loss: 0.18706224858760834, G Loss: 4.3829216957092285\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 10525/100000, D Loss: 0.17559881508350372, G Loss: 4.6102294921875\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10526/100000, D Loss: 0.17769478261470795, G Loss: 4.429320335388184\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10527/100000, D Loss: 0.18224402517080307, G Loss: 4.1781816482543945\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 10528/100000, D Loss: 0.20361921936273575, G Loss: 4.272462368011475\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 10529/100000, D Loss: 0.23167784512043, G Loss: 4.386542320251465\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10530/100000, D Loss: 0.26373524963855743, G Loss: 4.219884872436523\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10531/100000, D Loss: 0.25961633026599884, G Loss: 4.143545150756836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10532/100000, D Loss: 0.257252037525177, G Loss: 4.35377311706543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10533/100000, D Loss: 0.26002535223960876, G Loss: 4.2261199951171875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10534/100000, D Loss: 0.28781650960445404, G Loss: 4.022820472717285\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10535/100000, D Loss: 0.26617568731307983, G Loss: 3.9787468910217285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10536/100000, D Loss: 0.24720102548599243, G Loss: 4.356301307678223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10537/100000, D Loss: 0.24669355899095535, G Loss: 4.170380115509033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10538/100000, D Loss: 0.265242800116539, G Loss: 4.093326568603516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10539/100000, D Loss: 0.26008060574531555, G Loss: 4.2258758544921875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10540/100000, D Loss: 0.23134887963533401, G Loss: 4.552634239196777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10541/100000, D Loss: 0.22398918867111206, G Loss: 4.487456798553467\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10542/100000, D Loss: 0.23716623336076736, G Loss: 4.277420997619629\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10543/100000, D Loss: 0.24630433320999146, G Loss: 4.047842025756836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10544/100000, D Loss: 0.23140979558229446, G Loss: 4.49843692779541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10545/100000, D Loss: 0.22207500785589218, G Loss: 4.816261291503906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10546/100000, D Loss: 0.22515279799699783, G Loss: 4.4166460037231445\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10547/100000, D Loss: 0.2615213319659233, G Loss: 4.109157562255859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10548/100000, D Loss: 0.2764076888561249, G Loss: 4.020594596862793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10549/100000, D Loss: 0.24536901712417603, G Loss: 4.60843563079834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10550/100000, D Loss: 0.27142592519521713, G Loss: 4.261613845825195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10551/100000, D Loss: 0.24176447093486786, G Loss: 3.974177598953247\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10552/100000, D Loss: 0.2191060334444046, G Loss: 4.291359901428223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10553/100000, D Loss: 0.24078188836574554, G Loss: 4.503495216369629\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10554/100000, D Loss: 0.2560224086046219, G Loss: 4.437682151794434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10555/100000, D Loss: 0.282639741897583, G Loss: 4.078917980194092\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10556/100000, D Loss: 0.2528151869773865, G Loss: 4.201534748077393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10557/100000, D Loss: 0.2592114359140396, G Loss: 4.17307710647583\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10558/100000, D Loss: 0.2571021690964699, G Loss: 4.221922397613525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10559/100000, D Loss: 0.2746835872530937, G Loss: 3.9912261962890625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10560/100000, D Loss: 0.26068513095378876, G Loss: 3.826728343963623\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10561/100000, D Loss: 0.3024362772703171, G Loss: 4.1054582595825195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10562/100000, D Loss: 0.2584046870470047, G Loss: 4.36135196685791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10563/100000, D Loss: 0.25942056626081467, G Loss: 4.265947341918945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10564/100000, D Loss: 0.26619166135787964, G Loss: 3.9068028926849365\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10565/100000, D Loss: 0.2396404817700386, G Loss: 4.082051753997803\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10566/100000, D Loss: 0.22657158225774765, G Loss: 4.461948394775391\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10567/100000, D Loss: 0.2425682097673416, G Loss: 4.5172505378723145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10568/100000, D Loss: 0.2806997522711754, G Loss: 3.8942105770111084\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10569/100000, D Loss: 0.2602277100086212, G Loss: 4.072248458862305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10570/100000, D Loss: 0.19585561752319336, G Loss: 4.483011245727539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10571/100000, D Loss: 0.212164506316185, G Loss: 4.425707817077637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10572/100000, D Loss: 0.2518215999007225, G Loss: 3.9523820877075195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10573/100000, D Loss: 0.24302681535482407, G Loss: 4.162693977355957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10574/100000, D Loss: 0.2078530713915825, G Loss: 4.303550720214844\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10575/100000, D Loss: 0.2631200700998306, G Loss: 3.9467077255249023\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10576/100000, D Loss: 0.2207348868250847, G Loss: 4.060730934143066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10577/100000, D Loss: 0.21889276802539825, G Loss: 4.40503454208374\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10578/100000, D Loss: 0.2341672033071518, G Loss: 4.174771308898926\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10579/100000, D Loss: 0.251018725335598, G Loss: 4.289786338806152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10580/100000, D Loss: 0.18418291956186295, G Loss: 4.380950450897217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10581/100000, D Loss: 0.20443154871463776, G Loss: 4.448561668395996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10582/100000, D Loss: 0.2578857094049454, G Loss: 4.092567443847656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10583/100000, D Loss: 0.2292991504073143, G Loss: 4.265250205993652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10584/100000, D Loss: 0.2183867245912552, G Loss: 4.5605363845825195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10585/100000, D Loss: 0.2205502688884735, G Loss: 4.41495418548584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10586/100000, D Loss: 0.24642521142959595, G Loss: 4.082832336425781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10587/100000, D Loss: 0.2285410538315773, G Loss: 3.9227333068847656\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10588/100000, D Loss: 0.2806847095489502, G Loss: 3.8293206691741943\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10589/100000, D Loss: 0.2621656507253647, G Loss: 3.9802744388580322\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10590/100000, D Loss: 0.33201439678668976, G Loss: 3.872987985610962\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10591/100000, D Loss: 0.3125731199979782, G Loss: 3.9021432399749756\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10592/100000, D Loss: 0.3368813097476959, G Loss: 4.150977611541748\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10593/100000, D Loss: 0.3221297860145569, G Loss: 3.7833189964294434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10594/100000, D Loss: 0.34657931327819824, G Loss: 3.512791633605957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10595/100000, D Loss: 0.3188868761062622, G Loss: 3.7290008068084717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10596/100000, D Loss: 0.2663922756910324, G Loss: 4.112133502960205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10597/100000, D Loss: 0.25701436400413513, G Loss: 4.218124866485596\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10598/100000, D Loss: 0.2533994987607002, G Loss: 3.8870038986206055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10599/100000, D Loss: 0.25457963347435, G Loss: 3.968776226043701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10600/100000, D Loss: 0.19593646377325058, G Loss: 4.370078086853027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10601/100000, D Loss: 0.19946883618831635, G Loss: 4.567819595336914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10602/100000, D Loss: 0.19139958918094635, G Loss: 4.516283988952637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10603/100000, D Loss: 0.21535414457321167, G Loss: 4.045398235321045\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10604/100000, D Loss: 0.20012514293193817, G Loss: 4.08527946472168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10605/100000, D Loss: 0.1838352233171463, G Loss: 4.283470153808594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10606/100000, D Loss: 0.19885048270225525, G Loss: 4.180112838745117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10607/100000, D Loss: 0.20907419174909592, G Loss: 4.185637474060059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10608/100000, D Loss: 0.2261432558298111, G Loss: 4.234931945800781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10609/100000, D Loss: 0.22060003876686096, G Loss: 4.025154113769531\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10610/100000, D Loss: 0.20607133209705353, G Loss: 4.197179794311523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10611/100000, D Loss: 0.25594305992126465, G Loss: 3.9451804161071777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10612/100000, D Loss: 0.22854846715927124, G Loss: 4.095681667327881\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10613/100000, D Loss: 0.20696818828582764, G Loss: 4.43966007232666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10614/100000, D Loss: 0.20553520321846008, G Loss: 4.476003646850586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10615/100000, D Loss: 0.20511972159147263, G Loss: 4.185600280761719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10616/100000, D Loss: 0.2488659769296646, G Loss: 4.055947303771973\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10617/100000, D Loss: 0.2501637190580368, G Loss: 4.285186767578125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10618/100000, D Loss: 0.20121783018112183, G Loss: 4.374110221862793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10619/100000, D Loss: 0.23029224574565887, G Loss: 4.047468185424805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10620/100000, D Loss: 0.23839212954044342, G Loss: 3.96518611907959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10621/100000, D Loss: 0.24311710894107819, G Loss: 4.272035598754883\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10622/100000, D Loss: 0.2254137471318245, G Loss: 4.036920547485352\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10623/100000, D Loss: 0.2944670021533966, G Loss: 4.054123878479004\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10624/100000, D Loss: 0.2689511179924011, G Loss: 4.229152679443359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10625/100000, D Loss: 0.29863159358501434, G Loss: 4.017017364501953\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10626/100000, D Loss: 0.33478187024593353, G Loss: 3.509984016418457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10627/100000, D Loss: 0.2798979729413986, G Loss: 3.925156831741333\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10628/100000, D Loss: 0.3452308773994446, G Loss: 4.109834671020508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10629/100000, D Loss: 0.32917770743370056, G Loss: 3.8216962814331055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10630/100000, D Loss: 0.4110642671585083, G Loss: 3.632972002029419\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10631/100000, D Loss: 0.3522365987300873, G Loss: 3.9927501678466797\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10632/100000, D Loss: 0.3691776245832443, G Loss: 3.847397804260254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10633/100000, D Loss: 0.4013383239507675, G Loss: 3.616170644760132\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10634/100000, D Loss: 0.40020686388015747, G Loss: 3.497340679168701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10635/100000, D Loss: 0.414936825633049, G Loss: 3.494320869445801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10636/100000, D Loss: 0.3787747919559479, G Loss: 3.8608131408691406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10637/100000, D Loss: 0.4165291488170624, G Loss: 3.565005302429199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10638/100000, D Loss: 0.41670891642570496, G Loss: 3.6064000129699707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10639/100000, D Loss: 0.30501486361026764, G Loss: 4.209864616394043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10640/100000, D Loss: 0.2864615470170975, G Loss: 4.269172668457031\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10641/100000, D Loss: 0.28725193440914154, G Loss: 3.8407516479492188\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10642/100000, D Loss: 0.2616439312696457, G Loss: 4.085766315460205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10643/100000, D Loss: 0.194016695022583, G Loss: 4.6020097732543945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10644/100000, D Loss: 0.2477644979953766, G Loss: 4.505827903747559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10645/100000, D Loss: 0.18800388276576996, G Loss: 4.458547115325928\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10646/100000, D Loss: 0.17411547899246216, G Loss: 4.1330437660217285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10647/100000, D Loss: 0.19520626962184906, G Loss: 4.15886116027832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10648/100000, D Loss: 0.1651712730526924, G Loss: 4.724212646484375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10649/100000, D Loss: 0.17646196484565735, G Loss: 4.617033958435059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10650/100000, D Loss: 0.195301353931427, G Loss: 4.351055145263672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10651/100000, D Loss: 0.189351424574852, G Loss: 4.262002944946289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10652/100000, D Loss: 0.15229444950819016, G Loss: 4.6122846603393555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10653/100000, D Loss: 0.16701795905828476, G Loss: 5.0123395919799805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10654/100000, D Loss: 0.20091962814331055, G Loss: 4.472784996032715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10655/100000, D Loss: 0.21859654784202576, G Loss: 4.1142988204956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10656/100000, D Loss: 0.18531127274036407, G Loss: 4.640469551086426\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10657/100000, D Loss: 0.17275503277778625, G Loss: 4.985595703125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10658/100000, D Loss: 0.22204293310642242, G Loss: 4.4383087158203125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10659/100000, D Loss: 0.2515821009874344, G Loss: 4.063950538635254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10660/100000, D Loss: 0.24757923930883408, G Loss: 4.054485321044922\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10661/100000, D Loss: 0.23953799158334732, G Loss: 4.541472434997559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10662/100000, D Loss: 0.2817855626344681, G Loss: 4.3614044189453125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10663/100000, D Loss: 0.29074928164482117, G Loss: 4.011176109313965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10664/100000, D Loss: 0.2840130403637886, G Loss: 4.171203136444092\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10665/100000, D Loss: 0.28964222967624664, G Loss: 4.555168628692627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10666/100000, D Loss: 0.3356744349002838, G Loss: 4.282720565795898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10667/100000, D Loss: 0.2929246574640274, G Loss: 4.208780288696289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10668/100000, D Loss: 0.2828958183526993, G Loss: 4.30217170715332\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10669/100000, D Loss: 0.2778837978839874, G Loss: 4.228517532348633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10670/100000, D Loss: 0.2711632251739502, G Loss: 4.000480651855469\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10671/100000, D Loss: 0.2679377943277359, G Loss: 4.229759216308594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10672/100000, D Loss: 0.2420862466096878, G Loss: 4.533315181732178\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10673/100000, D Loss: 0.21919358521699905, G Loss: 4.814469337463379\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10674/100000, D Loss: 0.2157016396522522, G Loss: 4.590514183044434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10675/100000, D Loss: 0.1956399604678154, G Loss: 4.630985260009766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10676/100000, D Loss: 0.18339336663484573, G Loss: 4.684070587158203\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10677/100000, D Loss: 0.15188400447368622, G Loss: 4.83866548538208\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10678/100000, D Loss: 0.15032600611448288, G Loss: 5.111789703369141\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10679/100000, D Loss: 0.1624266654253006, G Loss: 4.953563690185547\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10680/100000, D Loss: 0.17780418694019318, G Loss: 4.79438591003418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10681/100000, D Loss: 0.14791611582040787, G Loss: 4.870029449462891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10682/100000, D Loss: 0.1649044156074524, G Loss: 4.939172267913818\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10683/100000, D Loss: 0.15858115255832672, G Loss: 4.751609802246094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10684/100000, D Loss: 0.1640949323773384, G Loss: 4.892551422119141\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10685/100000, D Loss: 0.18124283105134964, G Loss: 4.518763065338135\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10686/100000, D Loss: 0.1776077002286911, G Loss: 4.673201084136963\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10687/100000, D Loss: 0.15966583788394928, G Loss: 5.036581516265869\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10688/100000, D Loss: 0.18894729018211365, G Loss: 4.630829334259033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10689/100000, D Loss: 0.22223346680402756, G Loss: 4.0706939697265625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10690/100000, D Loss: 0.22011210024356842, G Loss: 4.353411674499512\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10691/100000, D Loss: 0.20791970193386078, G Loss: 4.651849746704102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10692/100000, D Loss: 0.1987137496471405, G Loss: 4.655965328216553\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10693/100000, D Loss: 0.2492935210466385, G Loss: 4.273543357849121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10694/100000, D Loss: 0.25905841588974, G Loss: 3.961953639984131\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10695/100000, D Loss: 0.24231436848640442, G Loss: 4.5496344566345215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10696/100000, D Loss: 0.23883350938558578, G Loss: 4.27221155166626\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10697/100000, D Loss: 0.2648668438196182, G Loss: 3.8971099853515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10698/100000, D Loss: 0.23975612223148346, G Loss: 4.059351921081543\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10699/100000, D Loss: 0.22902712225914001, G Loss: 4.268487453460693\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10700/100000, D Loss: 0.23605984449386597, G Loss: 4.235965728759766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10701/100000, D Loss: 0.2148609459400177, G Loss: 4.259095191955566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10702/100000, D Loss: 0.1962805539369583, G Loss: 4.453015327453613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10703/100000, D Loss: 0.19808989763259888, G Loss: 4.364319801330566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10704/100000, D Loss: 0.2264973148703575, G Loss: 4.112784385681152\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10705/100000, D Loss: 0.22423513233661652, G Loss: 4.121294975280762\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10706/100000, D Loss: 0.20343469828367233, G Loss: 4.5152788162231445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10707/100000, D Loss: 0.2439800128340721, G Loss: 4.265307426452637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10708/100000, D Loss: 0.2332170009613037, G Loss: 4.074317932128906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10709/100000, D Loss: 0.21482939273118973, G Loss: 4.092385292053223\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10710/100000, D Loss: 0.24304243922233582, G Loss: 3.9991908073425293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10711/100000, D Loss: 0.24532057344913483, G Loss: 4.227842330932617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10712/100000, D Loss: 0.28808867931365967, G Loss: 4.164772033691406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10713/100000, D Loss: 0.2418217882514, G Loss: 3.93627667427063\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10714/100000, D Loss: 0.28263480961322784, G Loss: 4.007158279418945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10715/100000, D Loss: 0.2824447602033615, G Loss: 4.052170753479004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10716/100000, D Loss: 0.25952477753162384, G Loss: 4.138849258422852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10717/100000, D Loss: 0.27732372283935547, G Loss: 3.987260341644287\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10718/100000, D Loss: 0.2455669641494751, G Loss: 3.946796417236328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10719/100000, D Loss: 0.20609666407108307, G Loss: 4.409823417663574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10720/100000, D Loss: 0.23791451752185822, G Loss: 4.170003890991211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10721/100000, D Loss: 0.19727613031864166, G Loss: 3.8569374084472656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10722/100000, D Loss: 0.20030487328767776, G Loss: 4.014455795288086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10723/100000, D Loss: 0.16984381526708603, G Loss: 4.532440662384033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10724/100000, D Loss: 0.17379629239439964, G Loss: 4.507102966308594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10725/100000, D Loss: 0.16190554201602936, G Loss: 4.254426002502441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10726/100000, D Loss: 0.19673947989940643, G Loss: 3.8367342948913574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10727/100000, D Loss: 0.19816261529922485, G Loss: 4.065476417541504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10728/100000, D Loss: 0.18723945319652557, G Loss: 4.342543601989746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10729/100000, D Loss: 0.18100996315479279, G Loss: 4.434950351715088\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10730/100000, D Loss: 0.2510070353746414, G Loss: 3.850722551345825\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10731/100000, D Loss: 0.22773484140634537, G Loss: 3.647634983062744\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10732/100000, D Loss: 0.25923778116703033, G Loss: 3.959763526916504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10733/100000, D Loss: 0.23735424876213074, G Loss: 4.359560966491699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10734/100000, D Loss: 0.26084673404693604, G Loss: 4.075857639312744\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10735/100000, D Loss: 0.26551003009080887, G Loss: 3.745602607727051\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10736/100000, D Loss: 0.2825082093477249, G Loss: 4.113290786743164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10737/100000, D Loss: 0.27663710713386536, G Loss: 3.769965648651123\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10738/100000, D Loss: 0.2855895906686783, G Loss: 3.8708109855651855\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10739/100000, D Loss: 0.27014752477407455, G Loss: 3.9741837978363037\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10740/100000, D Loss: 0.2781008183956146, G Loss: 3.99560809135437\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10741/100000, D Loss: 0.3142538368701935, G Loss: 3.99006724357605\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10742/100000, D Loss: 0.38108786940574646, G Loss: 3.7212719917297363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10743/100000, D Loss: 0.2685893028974533, G Loss: 4.261399269104004\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10744/100000, D Loss: 0.3289499208331108, G Loss: 3.7026522159576416\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10745/100000, D Loss: 0.31295667588710785, G Loss: 3.804760456085205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10746/100000, D Loss: 0.22799086570739746, G Loss: 4.4374823570251465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10747/100000, D Loss: 0.23689139634370804, G Loss: 4.417920112609863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10748/100000, D Loss: 0.2284994274377823, G Loss: 4.0141921043396\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10749/100000, D Loss: 0.23308388888835907, G Loss: 4.1569132804870605\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10750/100000, D Loss: 0.18352241069078445, G Loss: 4.588898181915283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10751/100000, D Loss: 0.18764156103134155, G Loss: 4.44887638092041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10752/100000, D Loss: 0.1938267946243286, G Loss: 4.295276641845703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10753/100000, D Loss: 0.21363798528909683, G Loss: 4.072897911071777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10754/100000, D Loss: 0.18320877104997635, G Loss: 4.403882026672363\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10755/100000, D Loss: 0.19963627308607101, G Loss: 4.383558750152588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10756/100000, D Loss: 0.1940733715891838, G Loss: 4.427619934082031\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10757/100000, D Loss: 0.19356685876846313, G Loss: 4.423581123352051\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10758/100000, D Loss: 0.21896236389875412, G Loss: 4.362985134124756\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10759/100000, D Loss: 0.2509729787707329, G Loss: 4.320374011993408\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10760/100000, D Loss: 0.26844608783721924, G Loss: 4.792781352996826\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10761/100000, D Loss: 0.26930709928274155, G Loss: 4.8965349197387695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10762/100000, D Loss: 0.26844073832035065, G Loss: 4.438450336456299\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10763/100000, D Loss: 0.30352504551410675, G Loss: 4.306980133056641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10764/100000, D Loss: 0.2855810821056366, G Loss: 4.901012897491455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10765/100000, D Loss: 0.24759607017040253, G Loss: 4.963498592376709\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10766/100000, D Loss: 0.3351924270391464, G Loss: 4.405297756195068\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10767/100000, D Loss: 0.2974063903093338, G Loss: 4.356939315795898\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10768/100000, D Loss: 0.23235217481851578, G Loss: 5.045080184936523\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10769/100000, D Loss: 0.22807560861110687, G Loss: 5.187697410583496\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10770/100000, D Loss: 0.2887653708457947, G Loss: 4.5974907875061035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10771/100000, D Loss: 0.26547814905643463, G Loss: 4.410215854644775\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10772/100000, D Loss: 0.20847030729055405, G Loss: 4.823332786560059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10773/100000, D Loss: 0.19074185192584991, G Loss: 5.20880651473999\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10774/100000, D Loss: 0.21239985525608063, G Loss: 4.805253028869629\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10775/100000, D Loss: 0.19880346208810806, G Loss: 4.418021202087402\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10776/100000, D Loss: 0.19586366415023804, G Loss: 4.466087341308594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10777/100000, D Loss: 0.21505369246006012, G Loss: 4.701341152191162\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10778/100000, D Loss: 0.18649619072675705, G Loss: 5.053441047668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10779/100000, D Loss: 0.1805669404566288, G Loss: 4.871847629547119\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10780/100000, D Loss: 0.1751282811164856, G Loss: 4.458227634429932\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10781/100000, D Loss: 0.1988515853881836, G Loss: 4.265310287475586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10782/100000, D Loss: 0.17117539048194885, G Loss: 4.508182525634766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10783/100000, D Loss: 0.18620213121175766, G Loss: 4.7081193923950195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10784/100000, D Loss: 0.2393546923995018, G Loss: 4.267868995666504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10785/100000, D Loss: 0.2191854566335678, G Loss: 4.073883056640625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10786/100000, D Loss: 0.20733492821455002, G Loss: 4.529240608215332\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10787/100000, D Loss: 0.2354600504040718, G Loss: 4.804538249969482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10788/100000, D Loss: 0.2689164727926254, G Loss: 4.363724708557129\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10789/100000, D Loss: 0.2855289876461029, G Loss: 4.13260555267334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10790/100000, D Loss: 0.27824927866458893, G Loss: 4.393684387207031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10791/100000, D Loss: 0.29935331642627716, G Loss: 4.224268436431885\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10792/100000, D Loss: 0.2766362130641937, G Loss: 4.174150466918945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10793/100000, D Loss: 0.32622167468070984, G Loss: 4.078304767608643\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10794/100000, D Loss: 0.2931363433599472, G Loss: 3.99562406539917\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10795/100000, D Loss: 0.2679487466812134, G Loss: 4.218849182128906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10796/100000, D Loss: 0.2711760923266411, G Loss: 4.5784406661987305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10797/100000, D Loss: 0.3231976330280304, G Loss: 4.253135681152344\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10798/100000, D Loss: 0.2978113740682602, G Loss: 4.3077778816223145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10799/100000, D Loss: 0.29301270842552185, G Loss: 4.3078932762146\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10800/100000, D Loss: 0.2901255041360855, G Loss: 4.4180145263671875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10801/100000, D Loss: 0.25577062368392944, G Loss: 4.251392364501953\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10802/100000, D Loss: 0.23645395040512085, G Loss: 4.147030830383301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10803/100000, D Loss: 0.25208809971809387, G Loss: 4.415493011474609\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10804/100000, D Loss: 0.28003183007240295, G Loss: 4.280405044555664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10805/100000, D Loss: 0.27655650675296783, G Loss: 4.006289482116699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10806/100000, D Loss: 0.2706613391637802, G Loss: 4.314639091491699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10807/100000, D Loss: 0.25784845650196075, G Loss: 4.198425769805908\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10808/100000, D Loss: 0.3037208318710327, G Loss: 3.866490125656128\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10809/100000, D Loss: 0.3198911249637604, G Loss: 3.7245845794677734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10810/100000, D Loss: 0.29842759668827057, G Loss: 4.103700637817383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10811/100000, D Loss: 0.2636883035302162, G Loss: 4.173382759094238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10812/100000, D Loss: 0.2967441529035568, G Loss: 3.8274147510528564\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10813/100000, D Loss: 0.28442421555519104, G Loss: 3.9227328300476074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10814/100000, D Loss: 0.22280770540237427, G Loss: 4.202239036560059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10815/100000, D Loss: 0.2647152990102768, G Loss: 4.216554641723633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10816/100000, D Loss: 0.2429652363061905, G Loss: 3.911686897277832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10817/100000, D Loss: 0.223246768116951, G Loss: 4.131753921508789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10818/100000, D Loss: 0.20092982053756714, G Loss: 4.658847332000732\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10819/100000, D Loss: 0.21663452684879303, G Loss: 4.333799362182617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10820/100000, D Loss: 0.19755545258522034, G Loss: 4.265918254852295\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10821/100000, D Loss: 0.20993492007255554, G Loss: 4.393070697784424\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10822/100000, D Loss: 0.16820112615823746, G Loss: 4.807281970977783\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10823/100000, D Loss: 0.17575395107269287, G Loss: 4.810244560241699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10824/100000, D Loss: 0.17035266011953354, G Loss: 4.451337814331055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10825/100000, D Loss: 0.1844833493232727, G Loss: 4.328118324279785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10826/100000, D Loss: 0.12497466802597046, G Loss: 4.7066497802734375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10827/100000, D Loss: 0.13617641478776932, G Loss: 4.923842906951904\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10828/100000, D Loss: 0.14891809970140457, G Loss: 4.719005107879639\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10829/100000, D Loss: 0.14233219623565674, G Loss: 4.302659034729004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10830/100000, D Loss: 0.19117378443479538, G Loss: 4.278722286224365\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10831/100000, D Loss: 0.1626923307776451, G Loss: 4.466836929321289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10832/100000, D Loss: 0.1488840952515602, G Loss: 4.52607536315918\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10833/100000, D Loss: 0.17649175971746445, G Loss: 4.4513092041015625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10834/100000, D Loss: 0.21609650552272797, G Loss: 4.086854457855225\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10835/100000, D Loss: 0.21871890872716904, G Loss: 4.0889153480529785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10836/100000, D Loss: 0.21722251921892166, G Loss: 4.216419696807861\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10837/100000, D Loss: 0.20190004259347916, G Loss: 4.163390159606934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10838/100000, D Loss: 0.22369373589754105, G Loss: 4.095051288604736\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10839/100000, D Loss: 0.2513934075832367, G Loss: 3.866485357284546\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10840/100000, D Loss: 0.2725065350532532, G Loss: 3.9863767623901367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10841/100000, D Loss: 0.23760798573493958, G Loss: 4.092657089233398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10842/100000, D Loss: 0.32470613718032837, G Loss: 3.9107422828674316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10843/100000, D Loss: 0.29690854251384735, G Loss: 3.964777946472168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10844/100000, D Loss: 0.30423134565353394, G Loss: 3.9403271675109863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10845/100000, D Loss: 0.33635348081588745, G Loss: 3.6742336750030518\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10846/100000, D Loss: 0.2885843962430954, G Loss: 3.9315807819366455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10847/100000, D Loss: 0.2914624512195587, G Loss: 4.159372806549072\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10848/100000, D Loss: 0.2991485148668289, G Loss: 3.9834349155426025\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10849/100000, D Loss: 0.35052989423274994, G Loss: 3.682893753051758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10850/100000, D Loss: 0.3521842360496521, G Loss: 3.8846611976623535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10851/100000, D Loss: 0.2785436660051346, G Loss: 4.1095685958862305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10852/100000, D Loss: 0.2829223871231079, G Loss: 4.14132022857666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10853/100000, D Loss: 0.2747344672679901, G Loss: 3.868067741394043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10854/100000, D Loss: 0.26157888770103455, G Loss: 4.1475677490234375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10855/100000, D Loss: 0.22961606085300446, G Loss: 4.48095703125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10856/100000, D Loss: 0.21230679750442505, G Loss: 4.510605812072754\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 10857/100000, D Loss: 0.2623477876186371, G Loss: 4.1645965576171875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10858/100000, D Loss: 0.20094870030879974, G Loss: 4.231705665588379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10859/100000, D Loss: 0.1808549165725708, G Loss: 4.615324974060059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10860/100000, D Loss: 0.1871999353170395, G Loss: 4.591951370239258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10861/100000, D Loss: 0.16883239895105362, G Loss: 4.635258674621582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10862/100000, D Loss: 0.17559218406677246, G Loss: 4.5615644454956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10863/100000, D Loss: 0.1601036787033081, G Loss: 4.807607173919678\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10864/100000, D Loss: 0.17332275956869125, G Loss: 4.744138240814209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10865/100000, D Loss: 0.1408272385597229, G Loss: 4.812623023986816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10866/100000, D Loss: 0.17206549644470215, G Loss: 4.707298278808594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10867/100000, D Loss: 0.18183988332748413, G Loss: 4.670223712921143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10868/100000, D Loss: 0.2038685828447342, G Loss: 4.937250137329102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10869/100000, D Loss: 0.20742320269346237, G Loss: 4.991756439208984\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10870/100000, D Loss: 0.2059159278869629, G Loss: 4.618249893188477\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10871/100000, D Loss: 0.24512162804603577, G Loss: 4.441161632537842\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10872/100000, D Loss: 0.21005269140005112, G Loss: 4.547762393951416\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10873/100000, D Loss: 0.2256191372871399, G Loss: 4.366641044616699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10874/100000, D Loss: 0.23805329203605652, G Loss: 4.532951354980469\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10875/100000, D Loss: 0.284064844250679, G Loss: 4.189065456390381\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10876/100000, D Loss: 0.28005269169807434, G Loss: 3.9094839096069336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10877/100000, D Loss: 0.2500215023756027, G Loss: 4.41081428527832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10878/100000, D Loss: 0.25963006913661957, G Loss: 4.244317531585693\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10879/100000, D Loss: 0.2820845991373062, G Loss: 4.180305480957031\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10880/100000, D Loss: 0.2171391397714615, G Loss: 4.484458923339844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10881/100000, D Loss: 0.21901589632034302, G Loss: 4.244494438171387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10882/100000, D Loss: 0.2621229887008667, G Loss: 3.861144542694092\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10883/100000, D Loss: 0.2556147426366806, G Loss: 4.079999923706055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10884/100000, D Loss: 0.2315233200788498, G Loss: 4.272229194641113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10885/100000, D Loss: 0.23700866103172302, G Loss: 4.093527793884277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10886/100000, D Loss: 0.26810045540332794, G Loss: 3.9267690181732178\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10887/100000, D Loss: 0.24066497385501862, G Loss: 4.091569423675537\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10888/100000, D Loss: 0.2567771077156067, G Loss: 3.938497543334961\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10889/100000, D Loss: 0.2919714003801346, G Loss: 3.9331037998199463\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10890/100000, D Loss: 0.2660173624753952, G Loss: 4.211939811706543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10891/100000, D Loss: 0.22353307902812958, G Loss: 4.17852783203125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10892/100000, D Loss: 0.32503335177898407, G Loss: 3.8173561096191406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10893/100000, D Loss: 0.29660268127918243, G Loss: 3.707881450653076\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10894/100000, D Loss: 0.2661232501268387, G Loss: 4.190778732299805\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10895/100000, D Loss: 0.285179078578949, G Loss: 4.199381351470947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10896/100000, D Loss: 0.2770204097032547, G Loss: 4.085262775421143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10897/100000, D Loss: 0.3176393508911133, G Loss: 3.499870538711548\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10898/100000, D Loss: 0.32186803221702576, G Loss: 3.854419231414795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10899/100000, D Loss: 0.24409423768520355, G Loss: 4.409582138061523\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10900/100000, D Loss: 0.3595418483018875, G Loss: 4.015737533569336\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10901/100000, D Loss: 0.32265377044677734, G Loss: 3.7325048446655273\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10902/100000, D Loss: 0.31231772899627686, G Loss: 3.9122986793518066\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10903/100000, D Loss: 0.3142766058444977, G Loss: 4.15779972076416\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10904/100000, D Loss: 0.32981202751398087, G Loss: 3.6983723640441895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10905/100000, D Loss: 0.30648860335350037, G Loss: 4.042913436889648\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10906/100000, D Loss: 0.2850879281759262, G Loss: 4.0823750495910645\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10907/100000, D Loss: 0.29978521168231964, G Loss: 3.9882419109344482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10908/100000, D Loss: 0.33832138776779175, G Loss: 3.6576199531555176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10909/100000, D Loss: 0.3228164464235306, G Loss: 3.728163242340088\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10910/100000, D Loss: 0.3139636665582657, G Loss: 4.016639709472656\n",
      "32/32 [==============================] - 0s 11ms/step\n",
      "Epoch 10911/100000, D Loss: 0.33188024163246155, G Loss: 3.9976799488067627\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "Epoch 10912/100000, D Loss: 0.36286938190460205, G Loss: 3.5110881328582764\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10913/100000, D Loss: 0.32937493920326233, G Loss: 3.7416200637817383\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10914/100000, D Loss: 0.3366505652666092, G Loss: 3.905818462371826\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10915/100000, D Loss: 0.31494858860969543, G Loss: 4.154199123382568\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 10916/100000, D Loss: 0.33034057915210724, G Loss: 3.9635353088378906\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10917/100000, D Loss: 0.2689255625009537, G Loss: 3.8202896118164062\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 10918/100000, D Loss: 0.31128519773483276, G Loss: 4.009462356567383\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10919/100000, D Loss: 0.26636119186878204, G Loss: 4.190161228179932\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10920/100000, D Loss: 0.27798624336719513, G Loss: 3.8688573837280273\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10921/100000, D Loss: 0.2859780788421631, G Loss: 4.000563621520996\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10922/100000, D Loss: 0.2549799084663391, G Loss: 4.053260803222656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10923/100000, D Loss: 0.26292407512664795, G Loss: 4.070786476135254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10924/100000, D Loss: 0.29353080689907074, G Loss: 4.081081390380859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10925/100000, D Loss: 0.27168507874011993, G Loss: 4.004646301269531\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10926/100000, D Loss: 0.25039055943489075, G Loss: 3.905799627304077\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10927/100000, D Loss: 0.2766183316707611, G Loss: 3.959840774536133\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10928/100000, D Loss: 0.3373278081417084, G Loss: 4.066615104675293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10929/100000, D Loss: 0.2851322963833809, G Loss: 4.103918075561523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10930/100000, D Loss: 0.29676225781440735, G Loss: 3.800865650177002\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10931/100000, D Loss: 0.2937827706336975, G Loss: 3.903437852859497\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10932/100000, D Loss: 0.26121266186237335, G Loss: 4.177563667297363\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10933/100000, D Loss: 0.2786879688501358, G Loss: 3.9612677097320557\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10934/100000, D Loss: 0.2833855301141739, G Loss: 3.8438737392425537\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10935/100000, D Loss: 0.25579793751239777, G Loss: 4.155055046081543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10936/100000, D Loss: 0.22109070420265198, G Loss: 4.246562957763672\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 10937/100000, D Loss: 0.2614961639046669, G Loss: 4.058282852172852\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 10938/100000, D Loss: 0.28725332021713257, G Loss: 3.7428126335144043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10939/100000, D Loss: 0.2241256758570671, G Loss: 3.879582405090332\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10940/100000, D Loss: 0.24457819014787674, G Loss: 4.3455915451049805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10941/100000, D Loss: 0.26156575977802277, G Loss: 4.182969093322754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10942/100000, D Loss: 0.2654047757387161, G Loss: 3.724813938140869\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10943/100000, D Loss: 0.274580642580986, G Loss: 3.8336331844329834\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 10944/100000, D Loss: 0.2425476610660553, G Loss: 4.195943832397461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10945/100000, D Loss: 0.24498751014471054, G Loss: 4.417817115783691\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10946/100000, D Loss: 0.27853624522686005, G Loss: 3.9171717166900635\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10947/100000, D Loss: 0.2929393798112869, G Loss: 3.625669479370117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10948/100000, D Loss: 0.2971849739551544, G Loss: 3.7595391273498535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10949/100000, D Loss: 0.21300935745239258, G Loss: 4.262551307678223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10950/100000, D Loss: 0.2795327827334404, G Loss: 4.1498589515686035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10951/100000, D Loss: 0.278635174036026, G Loss: 3.6800076961517334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10952/100000, D Loss: 0.2862134724855423, G Loss: 3.6097044944763184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10953/100000, D Loss: 0.23627058416604996, G Loss: 4.156255722045898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10954/100000, D Loss: 0.310682475566864, G Loss: 4.080386161804199\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10955/100000, D Loss: 0.25492846220731735, G Loss: 3.7574615478515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10956/100000, D Loss: 0.29605361819267273, G Loss: 3.6617794036865234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10957/100000, D Loss: 0.23668430000543594, G Loss: 4.030838489532471\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10958/100000, D Loss: 0.23902322351932526, G Loss: 4.241128444671631\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10959/100000, D Loss: 0.27667436003685, G Loss: 3.945498466491699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10960/100000, D Loss: 0.23712900280952454, G Loss: 3.829066276550293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10961/100000, D Loss: 0.2141548916697502, G Loss: 3.9831531047821045\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10962/100000, D Loss: 0.16809868067502975, G Loss: 4.288722991943359\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10963/100000, D Loss: 0.204514741897583, G Loss: 4.467109680175781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10964/100000, D Loss: 0.21111160516738892, G Loss: 4.118844032287598\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10965/100000, D Loss: 0.18919353187084198, G Loss: 3.903148651123047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10966/100000, D Loss: 0.19203267991542816, G Loss: 3.9198501110076904\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10967/100000, D Loss: 0.19992326945066452, G Loss: 4.516712188720703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10968/100000, D Loss: 0.18589230626821518, G Loss: 4.727771282196045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10969/100000, D Loss: 0.22740557044744492, G Loss: 4.367257118225098\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10970/100000, D Loss: 0.17650047689676285, G Loss: 4.172918319702148\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10971/100000, D Loss: 0.18981874734163284, G Loss: 4.153122425079346\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10972/100000, D Loss: 0.1893063262104988, G Loss: 4.189690113067627\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10973/100000, D Loss: 0.16999917477369308, G Loss: 4.189898490905762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10974/100000, D Loss: 0.19690585136413574, G Loss: 4.12296724319458\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10975/100000, D Loss: 0.19559531658887863, G Loss: 3.93182373046875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10976/100000, D Loss: 0.21769225597381592, G Loss: 4.01892614364624\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10977/100000, D Loss: 0.1749943271279335, G Loss: 4.270926475524902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10978/100000, D Loss: 0.21695304661989212, G Loss: 4.322665691375732\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10979/100000, D Loss: 0.23481540381908417, G Loss: 4.053150653839111\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10980/100000, D Loss: 0.24098889529705048, G Loss: 3.91856050491333\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10981/100000, D Loss: 0.20662029832601547, G Loss: 4.174393653869629\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10982/100000, D Loss: 0.2203977406024933, G Loss: 4.465683937072754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10983/100000, D Loss: 0.22327826172113419, G Loss: 4.31770133972168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10984/100000, D Loss: 0.24046558141708374, G Loss: 3.945284843444824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10985/100000, D Loss: 0.245622456073761, G Loss: 3.999053955078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10986/100000, D Loss: 0.24729935824871063, G Loss: 4.397662162780762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10987/100000, D Loss: 0.27671390771865845, G Loss: 4.234799861907959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10988/100000, D Loss: 0.2803235799074173, G Loss: 4.007238864898682\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10989/100000, D Loss: 0.3020467013120651, G Loss: 3.903778553009033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10990/100000, D Loss: 0.27913370728492737, G Loss: 4.161349296569824\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10991/100000, D Loss: 0.2584150955080986, G Loss: 4.234435081481934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10992/100000, D Loss: 0.2845495939254761, G Loss: 3.989173650741577\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10993/100000, D Loss: 0.3322116285562515, G Loss: 3.737656593322754\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 10994/100000, D Loss: 0.2656680792570114, G Loss: 4.212391376495361\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10995/100000, D Loss: 0.2982789948582649, G Loss: 4.307650566101074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10996/100000, D Loss: 0.32765525579452515, G Loss: 4.030394554138184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10997/100000, D Loss: 0.28593848645687103, G Loss: 4.051817893981934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10998/100000, D Loss: 0.2982401102781296, G Loss: 4.099283218383789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 10999/100000, D Loss: 0.24223355948925018, G Loss: 4.521543979644775\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11000/100000, D Loss: 0.2537818178534508, G Loss: 4.299167156219482\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11001/100000, D Loss: 0.2585950344800949, G Loss: 3.9626965522766113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11002/100000, D Loss: 0.28946246206760406, G Loss: 3.902616024017334\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11003/100000, D Loss: 0.22809714078903198, G Loss: 4.414121150970459\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11004/100000, D Loss: 0.24096641689538956, G Loss: 4.479020118713379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11005/100000, D Loss: 0.2983785718679428, G Loss: 4.082126140594482\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11006/100000, D Loss: 0.23439469188451767, G Loss: 4.10858154296875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11007/100000, D Loss: 0.2255941778421402, G Loss: 4.449586391448975\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11008/100000, D Loss: 0.22847379744052887, G Loss: 4.426680564880371\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11009/100000, D Loss: 0.24750760197639465, G Loss: 4.04730224609375\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11010/100000, D Loss: 0.22636190056800842, G Loss: 4.517967224121094\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11011/100000, D Loss: 0.219606913626194, G Loss: 4.57211971282959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11012/100000, D Loss: 0.21163376420736313, G Loss: 4.372637748718262\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11013/100000, D Loss: 0.23330682516098022, G Loss: 3.8537352085113525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11014/100000, D Loss: 0.245439350605011, G Loss: 4.178095817565918\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11015/100000, D Loss: 0.22666901350021362, G Loss: 4.6581339836120605\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11016/100000, D Loss: 0.22864875197410583, G Loss: 4.314654350280762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11017/100000, D Loss: 0.22786419838666916, G Loss: 4.007455825805664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11018/100000, D Loss: 0.22165527939796448, G Loss: 4.05177116394043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11019/100000, D Loss: 0.1771847978234291, G Loss: 4.587127208709717\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11020/100000, D Loss: 0.19136381149291992, G Loss: 4.559754371643066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11021/100000, D Loss: 0.21592848002910614, G Loss: 4.374379634857178\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11022/100000, D Loss: 0.22140220552682877, G Loss: 4.467894554138184\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11023/100000, D Loss: 0.1802428588271141, G Loss: 4.4490251541137695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11024/100000, D Loss: 0.2000369355082512, G Loss: 4.505673408508301\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11025/100000, D Loss: 0.20006932318210602, G Loss: 4.540607929229736\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11026/100000, D Loss: 0.201139897108078, G Loss: 4.5259294509887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11027/100000, D Loss: 0.1879771500825882, G Loss: 4.453813552856445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11028/100000, D Loss: 0.1918521672487259, G Loss: 4.368363380432129\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11029/100000, D Loss: 0.23059991002082825, G Loss: 4.3618669509887695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11030/100000, D Loss: 0.17311721295118332, G Loss: 4.682267189025879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11031/100000, D Loss: 0.18432606756687164, G Loss: 4.799694538116455\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11032/100000, D Loss: 0.21832238137722015, G Loss: 4.16151762008667\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11033/100000, D Loss: 0.21326475590467453, G Loss: 4.29396915435791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11034/100000, D Loss: 0.1711304932832718, G Loss: 4.636224746704102\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11035/100000, D Loss: 0.19544366747140884, G Loss: 4.715149879455566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11036/100000, D Loss: 0.2141852155327797, G Loss: 4.354022026062012\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11037/100000, D Loss: 0.2234300896525383, G Loss: 4.3603620529174805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11038/100000, D Loss: 0.21665261685848236, G Loss: 4.249026775360107\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11039/100000, D Loss: 0.2455621361732483, G Loss: 4.385955333709717\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11040/100000, D Loss: 0.288762204349041, G Loss: 4.053908348083496\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11041/100000, D Loss: 0.2856087237596512, G Loss: 3.8331310749053955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11042/100000, D Loss: 0.2284628078341484, G Loss: 4.223248481750488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11043/100000, D Loss: 0.2755272313952446, G Loss: 4.419731140136719\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11044/100000, D Loss: 0.26622021943330765, G Loss: 4.030154228210449\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11045/100000, D Loss: 0.279344767332077, G Loss: 3.842707633972168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11046/100000, D Loss: 0.24078677594661713, G Loss: 4.28605318069458\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11047/100000, D Loss: 0.26758352667093277, G Loss: 4.291109085083008\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11048/100000, D Loss: 0.24336257576942444, G Loss: 3.92122220993042\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11049/100000, D Loss: 0.208995021879673, G Loss: 4.113652229309082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11050/100000, D Loss: 0.18730724602937698, G Loss: 4.586484909057617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11051/100000, D Loss: 0.17559777200222015, G Loss: 4.7791032791137695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11052/100000, D Loss: 0.19737665355205536, G Loss: 4.3701324462890625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11053/100000, D Loss: 0.19057618081569672, G Loss: 4.338230133056641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11054/100000, D Loss: 0.12273098528385162, G Loss: 5.04543399810791\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11055/100000, D Loss: 0.13442179560661316, G Loss: 5.222302436828613\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11056/100000, D Loss: 0.14267517626285553, G Loss: 4.6864728927612305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11057/100000, D Loss: 0.14724668115377426, G Loss: 4.350493907928467\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11058/100000, D Loss: 0.13814690336585045, G Loss: 4.603896141052246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11059/100000, D Loss: 0.13238732516765594, G Loss: 4.934171676635742\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11060/100000, D Loss: 0.1405356265604496, G Loss: 4.937213897705078\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11061/100000, D Loss: 0.15932060778141022, G Loss: 4.470242977142334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11062/100000, D Loss: 0.1453821212053299, G Loss: 4.387877464294434\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11063/100000, D Loss: 0.13892167806625366, G Loss: 4.773216247558594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11064/100000, D Loss: 0.1575736701488495, G Loss: 4.75123405456543\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11065/100000, D Loss: 0.18514136224985123, G Loss: 4.426675796508789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11066/100000, D Loss: 0.20403467118740082, G Loss: 4.242034435272217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11067/100000, D Loss: 0.18342096358537674, G Loss: 4.488400459289551\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11068/100000, D Loss: 0.15973982959985733, G Loss: 4.783917427062988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11069/100000, D Loss: 0.2009015753865242, G Loss: 4.26114559173584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11070/100000, D Loss: 0.17623458802700043, G Loss: 4.362694263458252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11071/100000, D Loss: 0.18371839076280594, G Loss: 4.463357448577881\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11072/100000, D Loss: 0.24090611934661865, G Loss: 4.235113143920898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11073/100000, D Loss: 0.258589431643486, G Loss: 4.152644157409668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11074/100000, D Loss: 0.2960425317287445, G Loss: 4.054521083831787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11075/100000, D Loss: 0.25660406053066254, G Loss: 4.258589744567871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11076/100000, D Loss: 0.3427022397518158, G Loss: 3.954868793487549\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11077/100000, D Loss: 0.32286176085472107, G Loss: 3.695331335067749\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11078/100000, D Loss: 0.3445793390274048, G Loss: 3.6521239280700684\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11079/100000, D Loss: 0.47364288568496704, G Loss: 3.667184829711914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11080/100000, D Loss: 0.413506343960762, G Loss: 3.8803505897521973\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11081/100000, D Loss: 0.47330883145332336, G Loss: 3.666731357574463\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11082/100000, D Loss: 0.5173865407705307, G Loss: 3.542813777923584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11083/100000, D Loss: 0.597826361656189, G Loss: 3.498655319213867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11084/100000, D Loss: 0.5568222403526306, G Loss: 3.739051103591919\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11085/100000, D Loss: 0.5037853717803955, G Loss: 3.699942111968994\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11086/100000, D Loss: 0.5942486226558685, G Loss: 3.4606785774230957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11087/100000, D Loss: 0.489959716796875, G Loss: 3.6392481327056885\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 11088/100000, D Loss: 0.5299126207828522, G Loss: 3.654252052307129\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11089/100000, D Loss: 0.3974253684282303, G Loss: 3.8500759601593018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11090/100000, D Loss: 0.35496310889720917, G Loss: 3.9921278953552246\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11091/100000, D Loss: 0.408864825963974, G Loss: 3.861934185028076\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11092/100000, D Loss: 0.26260874420404434, G Loss: 4.398179531097412\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11093/100000, D Loss: 0.23705586045980453, G Loss: 4.714050769805908\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11094/100000, D Loss: 0.22480615973472595, G Loss: 4.432498931884766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11095/100000, D Loss: 0.17719298601150513, G Loss: 4.613490104675293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11096/100000, D Loss: 0.15352360904216766, G Loss: 4.8686203956604\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11097/100000, D Loss: 0.13620128482580185, G Loss: 5.216096878051758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11098/100000, D Loss: 0.13410025089979172, G Loss: 5.165701866149902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11099/100000, D Loss: 0.12747365981340408, G Loss: 4.857553958892822\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11100/100000, D Loss: 0.11648810654878616, G Loss: 4.884176731109619\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11101/100000, D Loss: 0.13981330394744873, G Loss: 5.064377307891846\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11102/100000, D Loss: 0.11039658263325691, G Loss: 5.248759746551514\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11103/100000, D Loss: 0.13602030277252197, G Loss: 5.235875606536865\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11104/100000, D Loss: 0.13557011634111404, G Loss: 4.838261127471924\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11105/100000, D Loss: 0.12975266575813293, G Loss: 4.598469257354736\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11106/100000, D Loss: 0.13196684420108795, G Loss: 4.75897216796875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11107/100000, D Loss: 0.11967362090945244, G Loss: 4.921753883361816\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11108/100000, D Loss: 0.16717103868722916, G Loss: 4.733994483947754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11109/100000, D Loss: 0.15248584002256393, G Loss: 4.45249080657959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11110/100000, D Loss: 0.19641059637069702, G Loss: 4.40009880065918\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11111/100000, D Loss: 0.1759035959839821, G Loss: 4.635058403015137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11112/100000, D Loss: 0.15239044278860092, G Loss: 4.804041862487793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11113/100000, D Loss: 0.15634499117732048, G Loss: 4.869829177856445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11114/100000, D Loss: 0.173707515001297, G Loss: 4.174604415893555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11115/100000, D Loss: 0.1878890097141266, G Loss: 4.131767272949219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11116/100000, D Loss: 0.14681615680456161, G Loss: 4.477002143859863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11117/100000, D Loss: 0.1950230747461319, G Loss: 4.302556037902832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11118/100000, D Loss: 0.2270907759666443, G Loss: 4.028264999389648\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11119/100000, D Loss: 0.191839300096035, G Loss: 4.348968029022217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11120/100000, D Loss: 0.18401620537042618, G Loss: 4.6025848388671875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11121/100000, D Loss: 0.22781910747289658, G Loss: 4.313786506652832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11122/100000, D Loss: 0.2368934154510498, G Loss: 4.0758137702941895\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11123/100000, D Loss: 0.21922148764133453, G Loss: 4.200250625610352\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11124/100000, D Loss: 0.23938315361738205, G Loss: 4.260966777801514\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11125/100000, D Loss: 0.2259962037205696, G Loss: 4.0372209548950195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11126/100000, D Loss: 0.22483301162719727, G Loss: 4.165406227111816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11127/100000, D Loss: 0.213173508644104, G Loss: 4.093264579772949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11128/100000, D Loss: 0.23458293080329895, G Loss: 4.324140548706055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11129/100000, D Loss: 0.23118095844984055, G Loss: 4.0882673263549805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11130/100000, D Loss: 0.23799607157707214, G Loss: 4.077087879180908\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11131/100000, D Loss: 0.25299981236457825, G Loss: 4.099222183227539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11132/100000, D Loss: 0.27101723849773407, G Loss: 4.079302787780762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11133/100000, D Loss: 0.2218884825706482, G Loss: 4.20391845703125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11134/100000, D Loss: 0.24882259219884872, G Loss: 4.083617210388184\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11135/100000, D Loss: 0.24033313244581223, G Loss: 3.8774895668029785\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11136/100000, D Loss: 0.23107516765594482, G Loss: 4.10580587387085\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11137/100000, D Loss: 0.21863434463739395, G Loss: 4.276035308837891\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11138/100000, D Loss: 0.23505515605211258, G Loss: 4.136419296264648\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11139/100000, D Loss: 0.27735769748687744, G Loss: 3.9698402881622314\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11140/100000, D Loss: 0.22638249397277832, G Loss: 4.202171325683594\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11141/100000, D Loss: 0.21177736669778824, G Loss: 4.4922943115234375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11142/100000, D Loss: 0.24531211704015732, G Loss: 4.41218376159668\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11143/100000, D Loss: 0.24168291687965393, G Loss: 3.9538211822509766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11144/100000, D Loss: 0.23660089075565338, G Loss: 4.079230308532715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11145/100000, D Loss: 0.2617246061563492, G Loss: 4.274852275848389\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11146/100000, D Loss: 0.2350001186132431, G Loss: 4.362771034240723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11147/100000, D Loss: 0.24991171807050705, G Loss: 4.163432598114014\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11148/100000, D Loss: 0.3124030530452728, G Loss: 3.895310878753662\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11149/100000, D Loss: 0.2506102919578552, G Loss: 4.1924967765808105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11150/100000, D Loss: 0.2615658715367317, G Loss: 4.400869369506836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11151/100000, D Loss: 0.25708965957164764, G Loss: 4.277194976806641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11152/100000, D Loss: 0.33052854239940643, G Loss: 3.812225341796875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11153/100000, D Loss: 0.31929540634155273, G Loss: 4.114773750305176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11154/100000, D Loss: 0.3785138428211212, G Loss: 4.137337684631348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11155/100000, D Loss: 0.3482033759355545, G Loss: 4.0572967529296875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11156/100000, D Loss: 0.3993230164051056, G Loss: 4.0026092529296875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11157/100000, D Loss: 0.3693978786468506, G Loss: 3.939530849456787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11158/100000, D Loss: 0.37203407287597656, G Loss: 4.007486343383789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11159/100000, D Loss: 0.3949819952249527, G Loss: 3.994187355041504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11160/100000, D Loss: 0.3881978988647461, G Loss: 4.0478925704956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11161/100000, D Loss: 0.33316275477409363, G Loss: 4.304713726043701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11162/100000, D Loss: 0.33371490240097046, G Loss: 4.27377986907959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11163/100000, D Loss: 0.3038237392902374, G Loss: 4.154565811157227\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11164/100000, D Loss: 0.3030628561973572, G Loss: 4.060985088348389\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11165/100000, D Loss: 0.26085981726646423, G Loss: 4.3986430168151855\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11166/100000, D Loss: 0.26645922660827637, G Loss: 4.70670223236084\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11167/100000, D Loss: 0.23369904607534409, G Loss: 4.426634311676025\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11168/100000, D Loss: 0.22802215069532394, G Loss: 4.554000377655029\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11169/100000, D Loss: 0.20798954367637634, G Loss: 4.685214996337891\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11170/100000, D Loss: 0.18939919769763947, G Loss: 4.706834316253662\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11171/100000, D Loss: 0.1789669468998909, G Loss: 4.580950736999512\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11172/100000, D Loss: 0.18809281289577484, G Loss: 4.152034759521484\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11173/100000, D Loss: 0.1841873973608017, G Loss: 4.466396331787109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11174/100000, D Loss: 0.19106726348400116, G Loss: 4.474255561828613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11175/100000, D Loss: 0.19628846645355225, G Loss: 4.6198015213012695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11176/100000, D Loss: 0.20978867262601852, G Loss: 4.430668354034424\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11177/100000, D Loss: 0.2294422686100006, G Loss: 4.40953254699707\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11178/100000, D Loss: 0.20241958647966385, G Loss: 4.4511895179748535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11179/100000, D Loss: 0.25117672979831696, G Loss: 4.156968593597412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11180/100000, D Loss: 0.25279802083969116, G Loss: 4.005485534667969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11181/100000, D Loss: 0.2494601160287857, G Loss: 4.207210540771484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11182/100000, D Loss: 0.2616719976067543, G Loss: 4.411749839782715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11183/100000, D Loss: 0.24608705937862396, G Loss: 3.990237236022949\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11184/100000, D Loss: 0.23973442614078522, G Loss: 4.04057502746582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11185/100000, D Loss: 0.21465537697076797, G Loss: 4.223882675170898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11186/100000, D Loss: 0.21729019284248352, G Loss: 4.2244672775268555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11187/100000, D Loss: 0.24183230847120285, G Loss: 4.066527366638184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11188/100000, D Loss: 0.2617730498313904, G Loss: 4.039050102233887\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11189/100000, D Loss: 0.24124328792095184, G Loss: 3.920584201812744\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11190/100000, D Loss: 0.2454337701201439, G Loss: 4.208325386047363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11191/100000, D Loss: 0.253547802567482, G Loss: 4.162943363189697\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11192/100000, D Loss: 0.24304845929145813, G Loss: 3.9709272384643555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11193/100000, D Loss: 0.29719074070453644, G Loss: 3.962623119354248\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11194/100000, D Loss: 0.3150932937860489, G Loss: 3.9289937019348145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11195/100000, D Loss: 0.26637880504131317, G Loss: 4.031573295593262\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11196/100000, D Loss: 0.27876274287700653, G Loss: 4.050753593444824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11197/100000, D Loss: 0.2737152874469757, G Loss: 3.7887203693389893\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11198/100000, D Loss: 0.25776506960392, G Loss: 3.915544033050537\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11199/100000, D Loss: 0.2453080490231514, G Loss: 4.007226943969727\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11200/100000, D Loss: 0.2773791402578354, G Loss: 3.8303580284118652\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11201/100000, D Loss: 0.24208610504865646, G Loss: 4.102365493774414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11202/100000, D Loss: 0.2466953843832016, G Loss: 3.854893207550049\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11203/100000, D Loss: 0.20432385802268982, G Loss: 4.098377227783203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11204/100000, D Loss: 0.2278253734111786, G Loss: 4.165541172027588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11205/100000, D Loss: 0.2502492070198059, G Loss: 4.043984889984131\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11206/100000, D Loss: 0.22595509141683578, G Loss: 4.023512840270996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11207/100000, D Loss: 0.21064803004264832, G Loss: 4.433544158935547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11208/100000, D Loss: 0.212711401283741, G Loss: 4.52432107925415\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11209/100000, D Loss: 0.20179468393325806, G Loss: 4.294502258300781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11210/100000, D Loss: 0.1953769028186798, G Loss: 4.198439598083496\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11211/100000, D Loss: 0.19576994329690933, G Loss: 4.242748260498047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11212/100000, D Loss: 0.164964959025383, G Loss: 4.499903678894043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11213/100000, D Loss: 0.1648244559764862, G Loss: 4.834026336669922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11214/100000, D Loss: 0.1505567952990532, G Loss: 4.548636436462402\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11215/100000, D Loss: 0.18911202251911163, G Loss: 4.405821800231934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11216/100000, D Loss: 0.1608624905347824, G Loss: 4.349217414855957\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11217/100000, D Loss: 0.1718631461262703, G Loss: 4.560638904571533\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11218/100000, D Loss: 0.17640843242406845, G Loss: 4.532768249511719\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11219/100000, D Loss: 0.16391167044639587, G Loss: 4.476507663726807\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11220/100000, D Loss: 0.16758055984973907, G Loss: 4.343111991882324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11221/100000, D Loss: 0.20373348891735077, G Loss: 4.070197582244873\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11222/100000, D Loss: 0.21906985342502594, G Loss: 4.062748908996582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11223/100000, D Loss: 0.21961191296577454, G Loss: 4.332053184509277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11224/100000, D Loss: 0.22710194438695908, G Loss: 4.365983963012695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11225/100000, D Loss: 0.260949470102787, G Loss: 4.094193935394287\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11226/100000, D Loss: 0.3013663589954376, G Loss: 3.881765842437744\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11227/100000, D Loss: 0.2925785779953003, G Loss: 3.839262008666992\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11228/100000, D Loss: 0.2824576422572136, G Loss: 3.9259591102600098\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11229/100000, D Loss: 0.39896753430366516, G Loss: 3.691934585571289\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11230/100000, D Loss: 0.3598466068506241, G Loss: 3.7063283920288086\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11231/100000, D Loss: 0.3589458018541336, G Loss: 4.0150146484375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11232/100000, D Loss: 0.3633672446012497, G Loss: 3.9087111949920654\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11233/100000, D Loss: 0.3852514773607254, G Loss: 3.664801597595215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11234/100000, D Loss: 0.3689567446708679, G Loss: 3.854541301727295\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11235/100000, D Loss: 0.339699387550354, G Loss: 3.9113211631774902\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11236/100000, D Loss: 0.3711582124233246, G Loss: 3.6189467906951904\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11237/100000, D Loss: 0.33098335564136505, G Loss: 3.7038557529449463\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11238/100000, D Loss: 0.29182465374469757, G Loss: 3.8018791675567627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11239/100000, D Loss: 0.3258860856294632, G Loss: 4.103050708770752\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11240/100000, D Loss: 0.3695889413356781, G Loss: 3.594691753387451\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11241/100000, D Loss: 0.28617869317531586, G Loss: 3.876032829284668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11242/100000, D Loss: 0.29057633876800537, G Loss: 3.949888229370117\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11243/100000, D Loss: 0.2766845375299454, G Loss: 3.7932581901550293\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11244/100000, D Loss: 0.2436377927660942, G Loss: 3.980290174484253\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11245/100000, D Loss: 0.24398818612098694, G Loss: 3.8781967163085938\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11246/100000, D Loss: 0.22914601862430573, G Loss: 3.9442315101623535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11247/100000, D Loss: 0.19470059871673584, G Loss: 4.253055572509766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11248/100000, D Loss: 0.19732870161533356, G Loss: 4.29625129699707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11249/100000, D Loss: 0.1982632577419281, G Loss: 4.25753116607666\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11250/100000, D Loss: 0.16039078682661057, G Loss: 4.310493469238281\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11251/100000, D Loss: 0.16384129226207733, G Loss: 4.445107460021973\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11252/100000, D Loss: 0.1634957417845726, G Loss: 4.6379828453063965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11253/100000, D Loss: 0.1389838233590126, G Loss: 4.662604331970215\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11254/100000, D Loss: 0.15127231180667877, G Loss: 4.593789577484131\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11255/100000, D Loss: 0.1550867110490799, G Loss: 4.316330909729004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11256/100000, D Loss: 0.165789395570755, G Loss: 4.326216697692871\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11257/100000, D Loss: 0.1518181636929512, G Loss: 4.4956865310668945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11258/100000, D Loss: 0.16351980715990067, G Loss: 4.580071926116943\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11259/100000, D Loss: 0.20627832412719727, G Loss: 4.284408092498779\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11260/100000, D Loss: 0.18338343501091003, G Loss: 4.219283103942871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11261/100000, D Loss: 0.18337497115135193, G Loss: 4.157077312469482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11262/100000, D Loss: 0.2042444571852684, G Loss: 4.064171314239502\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11263/100000, D Loss: 0.2139192521572113, G Loss: 4.152841567993164\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11264/100000, D Loss: 0.21015242487192154, G Loss: 4.01597785949707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11265/100000, D Loss: 0.21022659540176392, G Loss: 4.088676929473877\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11266/100000, D Loss: 0.2545251250267029, G Loss: 3.829578161239624\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11267/100000, D Loss: 0.24197061359882355, G Loss: 3.9196460247039795\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11268/100000, D Loss: 0.24562858790159225, G Loss: 4.080238342285156\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11269/100000, D Loss: 0.2740286886692047, G Loss: 3.902132034301758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11270/100000, D Loss: 0.24430940300226212, G Loss: 3.933931350708008\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11271/100000, D Loss: 0.21896369755268097, G Loss: 4.232786178588867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11272/100000, D Loss: 0.2703525796532631, G Loss: 3.9735474586486816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11273/100000, D Loss: 0.23211079090833664, G Loss: 3.7742867469787598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11274/100000, D Loss: 0.22656580805778503, G Loss: 3.739412546157837\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11275/100000, D Loss: 0.2087402492761612, G Loss: 4.292693138122559\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11276/100000, D Loss: 0.2026202455163002, G Loss: 4.334752082824707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11277/100000, D Loss: 0.19893084466457367, G Loss: 4.255465507507324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11278/100000, D Loss: 0.21981816738843918, G Loss: 4.010244369506836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11279/100000, D Loss: 0.23940235376358032, G Loss: 3.8047454357147217\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11280/100000, D Loss: 0.2199568748474121, G Loss: 4.0578718185424805\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11281/100000, D Loss: 0.1878487765789032, G Loss: 4.509202480316162\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11282/100000, D Loss: 0.23918652534484863, G Loss: 4.211548805236816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11283/100000, D Loss: 0.2217385694384575, G Loss: 3.9592251777648926\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11284/100000, D Loss: 0.19572479277849197, G Loss: 3.916919708251953\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11285/100000, D Loss: 0.21624770015478134, G Loss: 4.192806720733643\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11286/100000, D Loss: 0.23125629127025604, G Loss: 3.9735593795776367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11287/100000, D Loss: 0.22018887102603912, G Loss: 4.038005828857422\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11288/100000, D Loss: 0.2354724407196045, G Loss: 4.093914985656738\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11289/100000, D Loss: 0.27528804540634155, G Loss: 3.9355406761169434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11290/100000, D Loss: 0.24031981825828552, G Loss: 4.161200046539307\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11291/100000, D Loss: 0.19470873475074768, G Loss: 4.219400882720947\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 11292/100000, D Loss: 0.23487605154514313, G Loss: 4.091136932373047\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11293/100000, D Loss: 0.21093330532312393, G Loss: 4.057797431945801\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11294/100000, D Loss: 0.21581660211086273, G Loss: 4.2501325607299805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11295/100000, D Loss: 0.2122674137353897, G Loss: 4.201654434204102\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11296/100000, D Loss: 0.2559645175933838, G Loss: 3.991730213165283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11297/100000, D Loss: 0.2590338811278343, G Loss: 3.8606314659118652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11298/100000, D Loss: 0.2705722600221634, G Loss: 3.914572238922119\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11299/100000, D Loss: 0.2971794158220291, G Loss: 4.028801441192627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11300/100000, D Loss: 0.32376137375831604, G Loss: 3.8946828842163086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11301/100000, D Loss: 0.35536807775497437, G Loss: 3.5536694526672363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11302/100000, D Loss: 0.3200134187936783, G Loss: 4.219388961791992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11303/100000, D Loss: 0.2943875938653946, G Loss: 4.030316352844238\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11304/100000, D Loss: 0.4269945025444031, G Loss: 3.2560760974884033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11305/100000, D Loss: 0.39728811383247375, G Loss: 3.391976833343506\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11306/100000, D Loss: 0.26779206097126007, G Loss: 4.040670871734619\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11307/100000, D Loss: 0.32935160398483276, G Loss: 3.958897590637207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11308/100000, D Loss: 0.31749971956014633, G Loss: 3.6642677783966064\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11309/100000, D Loss: 0.33567892014980316, G Loss: 3.3992364406585693\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11310/100000, D Loss: 0.3026625066995621, G Loss: 3.7261080741882324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11311/100000, D Loss: 0.29381608217954636, G Loss: 4.201117515563965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11312/100000, D Loss: 0.2986292466521263, G Loss: 3.947244167327881\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11313/100000, D Loss: 0.3206457793712616, G Loss: 3.5972282886505127\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11314/100000, D Loss: 0.2431865781545639, G Loss: 3.9077837467193604\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11315/100000, D Loss: 0.23343372344970703, G Loss: 4.3322601318359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11316/100000, D Loss: 0.253280833363533, G Loss: 4.225193977355957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11317/100000, D Loss: 0.2545333802700043, G Loss: 3.941202402114868\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11318/100000, D Loss: 0.23058920353651047, G Loss: 3.9925966262817383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11319/100000, D Loss: 0.17748518288135529, G Loss: 4.309243679046631\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11320/100000, D Loss: 0.22199836373329163, G Loss: 4.255825042724609\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11321/100000, D Loss: 0.20311596244573593, G Loss: 4.092653751373291\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 11322/100000, D Loss: 0.21597091853618622, G Loss: 4.0403571128845215\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11323/100000, D Loss: 0.21205739676952362, G Loss: 4.193126678466797\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11324/100000, D Loss: 0.19874616712331772, G Loss: 4.279909133911133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11325/100000, D Loss: 0.1811034232378006, G Loss: 4.193093299865723\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11326/100000, D Loss: 0.21342530846595764, G Loss: 3.933980941772461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11327/100000, D Loss: 0.17955829203128815, G Loss: 4.151464939117432\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11328/100000, D Loss: 0.17656215280294418, G Loss: 4.381490707397461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11329/100000, D Loss: 0.17119138687849045, G Loss: 4.511321067810059\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11330/100000, D Loss: 0.16236798465251923, G Loss: 4.385802268981934\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11331/100000, D Loss: 0.17616792023181915, G Loss: 3.8794379234313965\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11332/100000, D Loss: 0.2093374878168106, G Loss: 4.1982221603393555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11333/100000, D Loss: 0.16628038883209229, G Loss: 4.344335079193115\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11334/100000, D Loss: 0.18068090081214905, G Loss: 4.401456832885742\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11335/100000, D Loss: 0.18653202056884766, G Loss: 4.339513301849365\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11336/100000, D Loss: 0.2093299701809883, G Loss: 4.213743209838867\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11337/100000, D Loss: 0.2319508120417595, G Loss: 3.9916067123413086\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11338/100000, D Loss: 0.2192249447107315, G Loss: 4.134451866149902\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11339/100000, D Loss: 0.2463822364807129, G Loss: 4.1344709396362305\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11340/100000, D Loss: 0.25143013894557953, G Loss: 4.151917457580566\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11341/100000, D Loss: 0.2802686244249344, G Loss: 4.051117420196533\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11342/100000, D Loss: 0.22777871042490005, G Loss: 4.2179975509643555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11343/100000, D Loss: 0.27584485709667206, G Loss: 3.85300612449646\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11344/100000, D Loss: 0.2716355472803116, G Loss: 3.683192491531372\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11345/100000, D Loss: 0.27764272689819336, G Loss: 3.9842920303344727\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11346/100000, D Loss: 0.26340729743242264, G Loss: 4.205007076263428\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11347/100000, D Loss: 0.27568434923887253, G Loss: 3.8394486904144287\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11348/100000, D Loss: 0.3223324716091156, G Loss: 3.6594529151916504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11349/100000, D Loss: 0.30253472924232483, G Loss: 4.017794609069824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11350/100000, D Loss: 0.34271226823329926, G Loss: 3.8611788749694824\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11351/100000, D Loss: 0.3131672292947769, G Loss: 4.0002241134643555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11352/100000, D Loss: 0.2848343476653099, G Loss: 4.087436676025391\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11353/100000, D Loss: 0.26792867481708527, G Loss: 4.009739875793457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11354/100000, D Loss: 0.28191255778074265, G Loss: 3.7954888343811035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11355/100000, D Loss: 0.28044943511486053, G Loss: 3.942850112915039\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11356/100000, D Loss: 0.23398126661777496, G Loss: 4.34622859954834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11357/100000, D Loss: 0.28442220389842987, G Loss: 4.224424839019775\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11358/100000, D Loss: 0.2410999983549118, G Loss: 4.194684982299805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11359/100000, D Loss: 0.21012794226408005, G Loss: 4.472762584686279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11360/100000, D Loss: 0.22314968705177307, G Loss: 4.419620513916016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11361/100000, D Loss: 0.23575499653816223, G Loss: 4.124814987182617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11362/100000, D Loss: 0.24810262024402618, G Loss: 4.346024990081787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11363/100000, D Loss: 0.24819709360599518, G Loss: 4.535325527191162\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11364/100000, D Loss: 0.2465835064649582, G Loss: 4.524752616882324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11365/100000, D Loss: 0.2518157437443733, G Loss: 4.130943775177002\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11366/100000, D Loss: 0.2708227410912514, G Loss: 4.190490245819092\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11367/100000, D Loss: 0.22559310495853424, G Loss: 4.665113925933838\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11368/100000, D Loss: 0.2564683184027672, G Loss: 4.7852463722229\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11369/100000, D Loss: 0.2798733413219452, G Loss: 4.488922119140625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11370/100000, D Loss: 0.23482301831245422, G Loss: 4.505605697631836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11371/100000, D Loss: 0.25794629007577896, G Loss: 4.37166690826416\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11372/100000, D Loss: 0.25644198805093765, G Loss: 4.240146636962891\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11373/100000, D Loss: 0.25260061025619507, G Loss: 4.753323554992676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11374/100000, D Loss: 0.24246563017368317, G Loss: 4.930253505706787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11375/100000, D Loss: 0.2785721570253372, G Loss: 4.333474159240723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11376/100000, D Loss: 0.27202108502388, G Loss: 4.119028091430664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11377/100000, D Loss: 0.2866603881120682, G Loss: 4.447690963745117\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11378/100000, D Loss: 0.2852133512496948, G Loss: 4.437085151672363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11379/100000, D Loss: 0.28217655420303345, G Loss: 4.303193092346191\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11380/100000, D Loss: 0.28051261603832245, G Loss: 4.650415897369385\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11381/100000, D Loss: 0.28762736916542053, G Loss: 4.515524387359619\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11382/100000, D Loss: 0.27804340422153473, G Loss: 4.214193344116211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11383/100000, D Loss: 0.2658299654722214, G Loss: 4.455327987670898\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11384/100000, D Loss: 0.22679227590560913, G Loss: 4.725090980529785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11385/100000, D Loss: 0.22037526965141296, G Loss: 4.7766432762146\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11386/100000, D Loss: 0.20184297114610672, G Loss: 4.435208797454834\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11387/100000, D Loss: 0.19302596151828766, G Loss: 4.453758716583252\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11388/100000, D Loss: 0.20479774475097656, G Loss: 4.804831504821777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11389/100000, D Loss: 0.21485170722007751, G Loss: 4.885837078094482\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11390/100000, D Loss: 0.18207243829965591, G Loss: 5.032438278198242\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11391/100000, D Loss: 0.20003260672092438, G Loss: 4.328276634216309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11392/100000, D Loss: 0.18579696863889694, G Loss: 4.435561180114746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11393/100000, D Loss: 0.17432834208011627, G Loss: 4.820908546447754\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11394/100000, D Loss: 0.19106793403625488, G Loss: 4.973019123077393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11395/100000, D Loss: 0.20445311069488525, G Loss: 4.738951206207275\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11396/100000, D Loss: 0.22921819984912872, G Loss: 4.440329551696777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11397/100000, D Loss: 0.1847982183098793, G Loss: 4.411882400512695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11398/100000, D Loss: 0.2001553699374199, G Loss: 4.884507656097412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11399/100000, D Loss: 0.19701971113681793, G Loss: 4.566107749938965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11400/100000, D Loss: 0.25141800940036774, G Loss: 4.14304256439209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11401/100000, D Loss: 0.2592007517814636, G Loss: 4.065691947937012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11402/100000, D Loss: 0.23065226525068283, G Loss: 4.14335823059082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11403/100000, D Loss: 0.21897650510072708, G Loss: 4.464667320251465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11404/100000, D Loss: 0.25258348882198334, G Loss: 4.157187461853027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11405/100000, D Loss: 0.29944629967212677, G Loss: 3.95875883102417\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11406/100000, D Loss: 0.2674062252044678, G Loss: 3.92803955078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11407/100000, D Loss: 0.30830469727516174, G Loss: 4.059915065765381\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11408/100000, D Loss: 0.2501147836446762, G Loss: 3.957469940185547\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11409/100000, D Loss: 0.2769410014152527, G Loss: 3.719834327697754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11410/100000, D Loss: 0.26841580867767334, G Loss: 3.898484706878662\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11411/100000, D Loss: 0.2650100737810135, G Loss: 3.964859962463379\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11412/100000, D Loss: 0.3247612416744232, G Loss: 3.6725316047668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11413/100000, D Loss: 0.2790081948041916, G Loss: 3.653855085372925\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11414/100000, D Loss: 0.31448638439178467, G Loss: 3.687304735183716\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11415/100000, D Loss: 0.31061267852783203, G Loss: 3.8167624473571777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11416/100000, D Loss: 0.2936824783682823, G Loss: 3.788355827331543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11417/100000, D Loss: 0.2973783165216446, G Loss: 3.686086893081665\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11418/100000, D Loss: 0.2916509360074997, G Loss: 3.5448341369628906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11419/100000, D Loss: 0.3052447438240051, G Loss: 3.6094846725463867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11420/100000, D Loss: 0.3054836243391037, G Loss: 3.930683135986328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11421/100000, D Loss: 0.26284489035606384, G Loss: 4.162545680999756\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11422/100000, D Loss: 0.2301504760980606, G Loss: 4.011164665222168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11423/100000, D Loss: 0.2620462477207184, G Loss: 3.774040937423706\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11424/100000, D Loss: 0.21228373050689697, G Loss: 4.171577453613281\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11425/100000, D Loss: 0.1721518561244011, G Loss: 4.71485710144043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11426/100000, D Loss: 0.21985220909118652, G Loss: 4.333296298980713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11427/100000, D Loss: 0.23006902635097504, G Loss: 3.828507423400879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11428/100000, D Loss: 0.20886851847171783, G Loss: 4.201613903045654\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11429/100000, D Loss: 0.16222529113292694, G Loss: 4.788398742675781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11430/100000, D Loss: 0.1553328074514866, G Loss: 5.034196376800537\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11431/100000, D Loss: 0.1818634644150734, G Loss: 4.443330764770508\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11432/100000, D Loss: 0.19263260066509247, G Loss: 4.084935665130615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11433/100000, D Loss: 0.17115601897239685, G Loss: 4.491951942443848\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11434/100000, D Loss: 0.15829858928918839, G Loss: 5.016791343688965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11435/100000, D Loss: 0.1995369717478752, G Loss: 4.556951522827148\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11436/100000, D Loss: 0.21947955340147018, G Loss: 4.149868965148926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11437/100000, D Loss: 0.21480496227741241, G Loss: 4.015814781188965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11438/100000, D Loss: 0.22230328619480133, G Loss: 4.144937515258789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11439/100000, D Loss: 0.2190040573477745, G Loss: 4.000494003295898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11440/100000, D Loss: 0.24491196870803833, G Loss: 4.275555610656738\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11441/100000, D Loss: 0.24396499246358871, G Loss: 4.176663398742676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11442/100000, D Loss: 0.3091312646865845, G Loss: 3.80668568611145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11443/100000, D Loss: 0.28718146681785583, G Loss: 3.6763925552368164\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11444/100000, D Loss: 0.27613914012908936, G Loss: 3.888978958129883\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11445/100000, D Loss: 0.25467053055763245, G Loss: 4.120101451873779\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11446/100000, D Loss: 0.2886626869440079, G Loss: 3.8841733932495117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11447/100000, D Loss: 0.32119953632354736, G Loss: 3.7419795989990234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11448/100000, D Loss: 0.31056830286979675, G Loss: 3.976097583770752\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11449/100000, D Loss: 0.270966112613678, G Loss: 4.000929355621338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11450/100000, D Loss: 0.30154576152563095, G Loss: 4.2098212242126465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11451/100000, D Loss: 0.3172874301671982, G Loss: 3.8187196254730225\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11452/100000, D Loss: 0.28364381194114685, G Loss: 3.7389750480651855\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11453/100000, D Loss: 0.24554834514856339, G Loss: 4.130415916442871\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11454/100000, D Loss: 0.2663923650979996, G Loss: 4.302192687988281\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11455/100000, D Loss: 0.2043314203619957, G Loss: 4.521881103515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11456/100000, D Loss: 0.22136500477790833, G Loss: 4.29989767074585\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11457/100000, D Loss: 0.20819048583507538, G Loss: 4.002155303955078\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11458/100000, D Loss: 0.1859990879893303, G Loss: 4.3773698806762695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11459/100000, D Loss: 0.15999241173267365, G Loss: 4.846430778503418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11460/100000, D Loss: 0.16814249008893967, G Loss: 5.114800930023193\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11461/100000, D Loss: 0.1555609218776226, G Loss: 4.793727874755859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11462/100000, D Loss: 0.15224207192659378, G Loss: 4.459447860717773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11463/100000, D Loss: 0.14196200296282768, G Loss: 4.360657691955566\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11464/100000, D Loss: 0.13903351873159409, G Loss: 4.636676788330078\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11465/100000, D Loss: 0.12672973796725273, G Loss: 4.854800224304199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11466/100000, D Loss: 0.13775267079472542, G Loss: 4.880429267883301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11467/100000, D Loss: 0.16536405682563782, G Loss: 4.457489013671875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11468/100000, D Loss: 0.14762450009584427, G Loss: 4.394244194030762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11469/100000, D Loss: 0.16794541478157043, G Loss: 4.483436584472656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11470/100000, D Loss: 0.1704639121890068, G Loss: 4.422407150268555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11471/100000, D Loss: 0.1834070160984993, G Loss: 4.220073699951172\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11472/100000, D Loss: 0.19118338078260422, G Loss: 4.199886322021484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11473/100000, D Loss: 0.1726027876138687, G Loss: 4.369052886962891\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11474/100000, D Loss: 0.17658069729804993, G Loss: 4.291172981262207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11475/100000, D Loss: 0.2118036448955536, G Loss: 4.29595947265625\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11476/100000, D Loss: 0.2377169281244278, G Loss: 4.090068340301514\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11477/100000, D Loss: 0.20591311156749725, G Loss: 4.107666015625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11478/100000, D Loss: 0.2290627583861351, G Loss: 4.106895446777344\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11479/100000, D Loss: 0.23644796013832092, G Loss: 4.089443206787109\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11480/100000, D Loss: 0.24649877846240997, G Loss: 3.8321709632873535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11481/100000, D Loss: 0.2678714692592621, G Loss: 3.7898240089416504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11482/100000, D Loss: 0.2791997641324997, G Loss: 3.8976950645446777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11483/100000, D Loss: 0.29717162251472473, G Loss: 3.6292829513549805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11484/100000, D Loss: 0.296109139919281, G Loss: 3.6388907432556152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11485/100000, D Loss: 0.2995200455188751, G Loss: 3.893618106842041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11486/100000, D Loss: 0.3168276846408844, G Loss: 3.880286931991577\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11487/100000, D Loss: 0.30795425176620483, G Loss: 3.509423017501831\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11488/100000, D Loss: 0.32616862654685974, G Loss: 3.314195156097412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11489/100000, D Loss: 0.33315980434417725, G Loss: 3.7263214588165283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11490/100000, D Loss: 0.35146503150463104, G Loss: 3.886547565460205\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11491/100000, D Loss: 0.3967931568622589, G Loss: 3.4755380153656006\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11492/100000, D Loss: 0.3848785310983658, G Loss: 3.2220664024353027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11493/100000, D Loss: 0.343548521399498, G Loss: 3.7691688537597656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11494/100000, D Loss: 0.3632836192846298, G Loss: 3.8054518699645996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11495/100000, D Loss: 0.3704942315816879, G Loss: 3.6951870918273926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11496/100000, D Loss: 0.39009250700473785, G Loss: 3.3487820625305176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11497/100000, D Loss: 0.38777241110801697, G Loss: 3.605391025543213\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11498/100000, D Loss: 0.3213263005018234, G Loss: 4.061806678771973\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11499/100000, D Loss: 0.33243047446012497, G Loss: 4.046935081481934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11500/100000, D Loss: 0.3315090537071228, G Loss: 3.637810707092285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11501/100000, D Loss: 0.2911466509103775, G Loss: 3.6368765830993652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11502/100000, D Loss: 0.2111520618200302, G Loss: 4.199676513671875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11503/100000, D Loss: 0.20293359458446503, G Loss: 4.716617107391357\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11504/100000, D Loss: 0.20762884616851807, G Loss: 4.480583190917969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11505/100000, D Loss: 0.1993085816502571, G Loss: 4.246115684509277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11506/100000, D Loss: 0.18282273411750793, G Loss: 4.449130058288574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11507/100000, D Loss: 0.12379605323076248, G Loss: 4.991827964782715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11508/100000, D Loss: 0.1739022582769394, G Loss: 4.852165222167969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11509/100000, D Loss: 0.14091669768095016, G Loss: 4.702104568481445\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11510/100000, D Loss: 0.1443067491054535, G Loss: 4.572249412536621\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11511/100000, D Loss: 0.15560682117938995, G Loss: 4.549020290374756\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11512/100000, D Loss: 0.15286165475845337, G Loss: 4.473439693450928\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11513/100000, D Loss: 0.1584564372897148, G Loss: 4.422659397125244\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11514/100000, D Loss: 0.17414596676826477, G Loss: 4.410005569458008\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11515/100000, D Loss: 0.1883886680006981, G Loss: 4.1517839431762695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11516/100000, D Loss: 0.17536219209432602, G Loss: 4.318206787109375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11517/100000, D Loss: 0.22785405814647675, G Loss: 4.0935492515563965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11518/100000, D Loss: 0.23306617885828018, G Loss: 3.95540452003479\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11519/100000, D Loss: 0.22911763936281204, G Loss: 3.8208322525024414\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11520/100000, D Loss: 0.27632902562618256, G Loss: 3.899904251098633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11521/100000, D Loss: 0.24891041964292526, G Loss: 4.036245346069336\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11522/100000, D Loss: 0.32457107305526733, G Loss: 3.703805446624756\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11523/100000, D Loss: 0.3419388234615326, G Loss: 3.3487191200256348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11524/100000, D Loss: 0.2796509861946106, G Loss: 3.9038074016571045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11525/100000, D Loss: 0.2986331582069397, G Loss: 3.935338020324707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11526/100000, D Loss: 0.3300462067127228, G Loss: 3.597496271133423\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11527/100000, D Loss: 0.3162517696619034, G Loss: 3.641897201538086\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11528/100000, D Loss: 0.3355054557323456, G Loss: 3.7002792358398438\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11529/100000, D Loss: 0.32642804086208344, G Loss: 3.718571186065674\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11530/100000, D Loss: 0.34157364070415497, G Loss: 3.598822593688965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11531/100000, D Loss: 0.3295144587755203, G Loss: 3.5420706272125244\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11532/100000, D Loss: 0.31849047541618347, G Loss: 3.598536968231201\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11533/100000, D Loss: 0.3558379113674164, G Loss: 3.641772747039795\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11534/100000, D Loss: 0.33810798823833466, G Loss: 3.824678421020508\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11535/100000, D Loss: 0.32222679257392883, G Loss: 4.015044212341309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11536/100000, D Loss: 0.30895930528640747, G Loss: 3.8864123821258545\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11537/100000, D Loss: 0.34023794531822205, G Loss: 3.6955442428588867\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11538/100000, D Loss: 0.2745352014899254, G Loss: 3.8525032997131348\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11539/100000, D Loss: 0.2696050554513931, G Loss: 3.9308393001556396\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11540/100000, D Loss: 0.2343590036034584, G Loss: 4.0225830078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11541/100000, D Loss: 0.22751712799072266, G Loss: 4.203869819641113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11542/100000, D Loss: 0.19214921444654465, G Loss: 4.477362632751465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11543/100000, D Loss: 0.2046176791191101, G Loss: 4.079090595245361\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11544/100000, D Loss: 0.2124270275235176, G Loss: 3.956875801086426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11545/100000, D Loss: 0.17728066444396973, G Loss: 4.203620910644531\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11546/100000, D Loss: 0.16665734350681305, G Loss: 4.273324489593506\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11547/100000, D Loss: 0.1588570550084114, G Loss: 4.316742897033691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11548/100000, D Loss: 0.17587153613567352, G Loss: 4.153620719909668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11549/100000, D Loss: 0.16918987035751343, G Loss: 4.330540657043457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11550/100000, D Loss: 0.18858175724744797, G Loss: 4.478076934814453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11551/100000, D Loss: 0.16783925145864487, G Loss: 4.539913177490234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11552/100000, D Loss: 0.16870318353176117, G Loss: 4.550392150878906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11553/100000, D Loss: 0.16437889635562897, G Loss: 4.416623115539551\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11554/100000, D Loss: 0.1592230722308159, G Loss: 4.349339485168457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11555/100000, D Loss: 0.15607519447803497, G Loss: 4.260043621063232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11556/100000, D Loss: 0.1681491807103157, G Loss: 4.306563854217529\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11557/100000, D Loss: 0.17881552129983902, G Loss: 4.459707260131836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11558/100000, D Loss: 0.17918135225772858, G Loss: 4.268998622894287\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11559/100000, D Loss: 0.19087734818458557, G Loss: 4.106098651885986\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11560/100000, D Loss: 0.1875515952706337, G Loss: 4.204220294952393\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11561/100000, D Loss: 0.219917893409729, G Loss: 4.108784198760986\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11562/100000, D Loss: 0.25353510677814484, G Loss: 3.796969175338745\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11563/100000, D Loss: 0.2719157785177231, G Loss: 4.007984161376953\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11564/100000, D Loss: 0.23736058175563812, G Loss: 4.232905387878418\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11565/100000, D Loss: 0.27589843422174454, G Loss: 4.190212726593018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11566/100000, D Loss: 0.31373484432697296, G Loss: 3.8237552642822266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11567/100000, D Loss: 0.30121563374996185, G Loss: 3.8952906131744385\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11568/100000, D Loss: 0.27448494732379913, G Loss: 4.018185138702393\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11569/100000, D Loss: 0.29596225172281265, G Loss: 3.890021562576294\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11570/100000, D Loss: 0.32066020369529724, G Loss: 3.867339611053467\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11571/100000, D Loss: 0.3200279325246811, G Loss: 3.9699597358703613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11572/100000, D Loss: 0.294798381626606, G Loss: 3.853943347930908\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11573/100000, D Loss: 0.37908537685871124, G Loss: 3.6212615966796875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11574/100000, D Loss: 0.32663479447364807, G Loss: 3.8359241485595703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11575/100000, D Loss: 0.30228204280138016, G Loss: 3.887056350708008\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11576/100000, D Loss: 0.3848334848880768, G Loss: 3.4540839195251465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11577/100000, D Loss: 0.3180568814277649, G Loss: 3.465878963470459\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11578/100000, D Loss: 0.2815905511379242, G Loss: 4.17640495300293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11579/100000, D Loss: 0.2389030158519745, G Loss: 4.375277042388916\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11580/100000, D Loss: 0.27028726786375046, G Loss: 3.9159369468688965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11581/100000, D Loss: 0.24711501598358154, G Loss: 3.7405142784118652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11582/100000, D Loss: 0.20450516045093536, G Loss: 4.115543842315674\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11583/100000, D Loss: 0.1967869997024536, G Loss: 4.495855331420898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11584/100000, D Loss: 0.20908166468143463, G Loss: 4.181147575378418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11585/100000, D Loss: 0.1884445771574974, G Loss: 4.1870222091674805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11586/100000, D Loss: 0.15892373770475388, G Loss: 4.4675421714782715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11587/100000, D Loss: 0.15798797458410263, G Loss: 4.543976783752441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11588/100000, D Loss: 0.16545704752206802, G Loss: 4.293961524963379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11589/100000, D Loss: 0.16454841941595078, G Loss: 4.521073341369629\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11590/100000, D Loss: 0.1375444084405899, G Loss: 4.8216753005981445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11591/100000, D Loss: 0.14653269201517105, G Loss: 5.055346488952637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11592/100000, D Loss: 0.14148783311247826, G Loss: 5.06095027923584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11593/100000, D Loss: 0.15965553000569344, G Loss: 4.485645294189453\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11594/100000, D Loss: 0.12938176095485687, G Loss: 4.568560600280762\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11595/100000, D Loss: 0.11487319320440292, G Loss: 4.922170639038086\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11596/100000, D Loss: 0.1212245412170887, G Loss: 5.073829650878906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11597/100000, D Loss: 0.14792312309145927, G Loss: 4.71001672744751\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11598/100000, D Loss: 0.1481693983078003, G Loss: 4.290410041809082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11599/100000, D Loss: 0.13064398989081383, G Loss: 4.846469402313232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11600/100000, D Loss: 0.15544050186872482, G Loss: 4.712279319763184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11601/100000, D Loss: 0.19421450793743134, G Loss: 4.55277156829834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11602/100000, D Loss: 0.19245314598083496, G Loss: 4.230564117431641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11603/100000, D Loss: 0.16259440779685974, G Loss: 4.635786056518555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11604/100000, D Loss: 0.18997813761234283, G Loss: 4.662081241607666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11605/100000, D Loss: 0.22026967257261276, G Loss: 4.379508972167969\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11606/100000, D Loss: 0.2620761841535568, G Loss: 4.031679630279541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11607/100000, D Loss: 0.21416613459587097, G Loss: 4.269881248474121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11608/100000, D Loss: 0.23122763633728027, G Loss: 4.39000940322876\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11609/100000, D Loss: 0.28122057020664215, G Loss: 4.087954521179199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11610/100000, D Loss: 0.27493010461330414, G Loss: 3.974358081817627\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11611/100000, D Loss: 0.2896992266178131, G Loss: 4.090350151062012\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11612/100000, D Loss: 0.2732357531785965, G Loss: 4.442303657531738\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11613/100000, D Loss: 0.34614433348178864, G Loss: 3.6192522048950195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11614/100000, D Loss: 0.35297586023807526, G Loss: 3.7790122032165527\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11615/100000, D Loss: 0.3018312454223633, G Loss: 4.1883721351623535\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11616/100000, D Loss: 0.27592749893665314, G Loss: 4.114874839782715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11617/100000, D Loss: 0.40472397208213806, G Loss: 3.3137497901916504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11618/100000, D Loss: 0.3211151659488678, G Loss: 3.8475327491760254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11619/100000, D Loss: 0.2853616327047348, G Loss: 4.196681022644043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11620/100000, D Loss: 0.38414305448532104, G Loss: 3.843353748321533\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11621/100000, D Loss: 0.3507095277309418, G Loss: 3.562992572784424\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11622/100000, D Loss: 0.2877485603094101, G Loss: 3.938392162322998\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11623/100000, D Loss: 0.2589494585990906, G Loss: 4.349924087524414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11624/100000, D Loss: 0.28271937370300293, G Loss: 3.8652122020721436\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11625/100000, D Loss: 0.28473514318466187, G Loss: 3.7667226791381836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11626/100000, D Loss: 0.20529338717460632, G Loss: 4.320497989654541\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11627/100000, D Loss: 0.2306295931339264, G Loss: 4.279107093811035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11628/100000, D Loss: 0.2206379920244217, G Loss: 4.097708702087402\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11629/100000, D Loss: 0.2532932907342911, G Loss: 4.05910587310791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11630/100000, D Loss: 0.1791347712278366, G Loss: 4.420225143432617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11631/100000, D Loss: 0.1631307676434517, G Loss: 4.546792030334473\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11632/100000, D Loss: 0.1879873126745224, G Loss: 4.5218305587768555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11633/100000, D Loss: 0.1837426871061325, G Loss: 4.323247909545898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11634/100000, D Loss: 0.15939701348543167, G Loss: 4.532495975494385\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11635/100000, D Loss: 0.16026968508958817, G Loss: 4.393869876861572\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11636/100000, D Loss: 0.18769916892051697, G Loss: 4.49558162689209\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11637/100000, D Loss: 0.14353487640619278, G Loss: 4.551220417022705\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11638/100000, D Loss: 0.1851150542497635, G Loss: 4.549307346343994\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11639/100000, D Loss: 0.1670403927564621, G Loss: 4.396531105041504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11640/100000, D Loss: 0.20467519760131836, G Loss: 4.298718452453613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11641/100000, D Loss: 0.17507488280534744, G Loss: 4.356647968292236\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11642/100000, D Loss: 0.19625528901815414, G Loss: 4.359443664550781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11643/100000, D Loss: 0.1725904494524002, G Loss: 4.270205974578857\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11644/100000, D Loss: 0.1928621232509613, G Loss: 3.969663143157959\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11645/100000, D Loss: 0.21619348227977753, G Loss: 3.978851318359375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11646/100000, D Loss: 0.19336891919374466, G Loss: 4.161258697509766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11647/100000, D Loss: 0.20191297680139542, G Loss: 4.117823123931885\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11648/100000, D Loss: 0.254154808819294, G Loss: 3.680582284927368\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11649/100000, D Loss: 0.2425936460494995, G Loss: 3.9495553970336914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11650/100000, D Loss: 0.22701632976531982, G Loss: 4.289913177490234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11651/100000, D Loss: 0.20844247937202454, G Loss: 4.509142875671387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11652/100000, D Loss: 0.22273454070091248, G Loss: 4.0426435470581055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11653/100000, D Loss: 0.2547229677438736, G Loss: 3.982145309448242\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11654/100000, D Loss: 0.21919089555740356, G Loss: 4.319948196411133\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11655/100000, D Loss: 0.16323301196098328, G Loss: 4.483672142028809\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11656/100000, D Loss: 0.1955825835466385, G Loss: 4.26414155960083\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11657/100000, D Loss: 0.20685255527496338, G Loss: 3.968492031097412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11658/100000, D Loss: 0.16853778064250946, G Loss: 4.208884239196777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11659/100000, D Loss: 0.2079179584980011, G Loss: 4.251635551452637\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11660/100000, D Loss: 0.16736456006765366, G Loss: 4.457282066345215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11661/100000, D Loss: 0.18628622591495514, G Loss: 4.432011604309082\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11662/100000, D Loss: 0.18487746268510818, G Loss: 4.310337066650391\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11663/100000, D Loss: 0.2048710733652115, G Loss: 4.497220039367676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11664/100000, D Loss: 0.2080172374844551, G Loss: 4.563088417053223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11665/100000, D Loss: 0.2072015404701233, G Loss: 4.231435775756836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11666/100000, D Loss: 0.21960819512605667, G Loss: 4.062437534332275\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11667/100000, D Loss: 0.1853596568107605, G Loss: 4.219245910644531\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11668/100000, D Loss: 0.20270220935344696, G Loss: 4.3247175216674805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11669/100000, D Loss: 0.23578239232301712, G Loss: 3.9385335445404053\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11670/100000, D Loss: 0.22453834116458893, G Loss: 4.255239009857178\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11671/100000, D Loss: 0.21742191910743713, G Loss: 4.456759929656982\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11672/100000, D Loss: 0.2003387287259102, G Loss: 4.049197673797607\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11673/100000, D Loss: 0.30096757411956787, G Loss: 3.602419137954712\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11674/100000, D Loss: 0.24873805046081543, G Loss: 3.938687324523926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11675/100000, D Loss: 0.24789200723171234, G Loss: 4.2711615562438965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11676/100000, D Loss: 0.27236708998680115, G Loss: 4.106112480163574\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11677/100000, D Loss: 0.3108530193567276, G Loss: 3.740657329559326\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11678/100000, D Loss: 0.2586427628993988, G Loss: 3.7652313709259033\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11679/100000, D Loss: 0.252682164311409, G Loss: 4.034637451171875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11680/100000, D Loss: 0.26355601102113724, G Loss: 4.088343143463135\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11681/100000, D Loss: 0.2527741938829422, G Loss: 4.173784255981445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11682/100000, D Loss: 0.24347414076328278, G Loss: 4.099462985992432\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11683/100000, D Loss: 0.24919915944337845, G Loss: 4.185512542724609\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11684/100000, D Loss: 0.21210184693336487, G Loss: 4.150030612945557\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11685/100000, D Loss: 0.23181933164596558, G Loss: 4.0838623046875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11686/100000, D Loss: 0.2198743149638176, G Loss: 4.032051086425781\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11687/100000, D Loss: 0.21123259514570236, G Loss: 3.9834938049316406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11688/100000, D Loss: 0.2029261216521263, G Loss: 4.303862571716309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11689/100000, D Loss: 0.21885351836681366, G Loss: 4.35565185546875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11690/100000, D Loss: 0.22112446278333664, G Loss: 4.218503952026367\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11691/100000, D Loss: 0.2334938794374466, G Loss: 4.290867328643799\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11692/100000, D Loss: 0.22387447953224182, G Loss: 4.3853864669799805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11693/100000, D Loss: 0.26224958896636963, G Loss: 4.121805667877197\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11694/100000, D Loss: 0.2803928554058075, G Loss: 3.887826919555664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11695/100000, D Loss: 0.2707495540380478, G Loss: 4.092592239379883\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11696/100000, D Loss: 0.2225150614976883, G Loss: 4.503767967224121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11697/100000, D Loss: 0.26560942083597183, G Loss: 4.127044677734375\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11698/100000, D Loss: 0.24263841658830643, G Loss: 4.183325290679932\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11699/100000, D Loss: 0.20518344640731812, G Loss: 4.344333648681641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11700/100000, D Loss: 0.2739001512527466, G Loss: 4.506246089935303\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11701/100000, D Loss: 0.253224216401577, G Loss: 4.193831443786621\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11702/100000, D Loss: 0.2239982932806015, G Loss: 4.194645881652832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11703/100000, D Loss: 0.23017580807209015, G Loss: 4.320420742034912\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11704/100000, D Loss: 0.20748472958803177, G Loss: 4.751316070556641\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11705/100000, D Loss: 0.203145369887352, G Loss: 4.6165313720703125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11706/100000, D Loss: 0.22915621101856232, G Loss: 4.07670783996582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11707/100000, D Loss: 0.23283495008945465, G Loss: 3.8547306060791016\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11708/100000, D Loss: 0.20082077383995056, G Loss: 4.419907569885254\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11709/100000, D Loss: 0.1984252631664276, G Loss: 4.76857328414917\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11710/100000, D Loss: 0.23609467595815659, G Loss: 4.371730804443359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11711/100000, D Loss: 0.264547660946846, G Loss: 3.822143793106079\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11712/100000, D Loss: 0.27398066222667694, G Loss: 4.119272232055664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11713/100000, D Loss: 0.24809540063142776, G Loss: 4.351850509643555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11714/100000, D Loss: 0.2771386578679085, G Loss: 4.521692276000977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11715/100000, D Loss: 0.2693088501691818, G Loss: 3.992276906967163\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11716/100000, D Loss: 0.319790855050087, G Loss: 3.791849136352539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11717/100000, D Loss: 0.2723795250058174, G Loss: 4.0998992919921875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11718/100000, D Loss: 0.28481346368789673, G Loss: 4.256790637969971\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11719/100000, D Loss: 0.29071400314569473, G Loss: 4.005722999572754\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11720/100000, D Loss: 0.32395608723163605, G Loss: 3.8205406665802\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11721/100000, D Loss: 0.2940969914197922, G Loss: 3.8235836029052734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11722/100000, D Loss: 0.3372746706008911, G Loss: 3.9922776222229004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11723/100000, D Loss: 0.2659952715039253, G Loss: 4.334217071533203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11724/100000, D Loss: 0.34398767352104187, G Loss: 3.8221235275268555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11725/100000, D Loss: 0.2994803488254547, G Loss: 3.7608683109283447\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11726/100000, D Loss: 0.26265713572502136, G Loss: 4.1939849853515625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11727/100000, D Loss: 0.2679676488041878, G Loss: 4.111668586730957\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11728/100000, D Loss: 0.26848817616701126, G Loss: 3.945390224456787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11729/100000, D Loss: 0.2601233720779419, G Loss: 3.749101161956787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11730/100000, D Loss: 0.21339291334152222, G Loss: 4.224735260009766\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11731/100000, D Loss: 0.21596360206604004, G Loss: 4.324193477630615\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11732/100000, D Loss: 0.20637862384319305, G Loss: 4.129265308380127\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11733/100000, D Loss: 0.18963005393743515, G Loss: 4.1323466300964355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11734/100000, D Loss: 0.16932644695043564, G Loss: 4.373142242431641\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11735/100000, D Loss: 0.18694685399532318, G Loss: 4.406983375549316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11736/100000, D Loss: 0.15416640788316727, G Loss: 4.517966270446777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11737/100000, D Loss: 0.15966825187206268, G Loss: 4.448851585388184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11738/100000, D Loss: 0.13780145347118378, G Loss: 4.702709674835205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11739/100000, D Loss: 0.141923476010561, G Loss: 4.7925920486450195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11740/100000, D Loss: 0.16798090189695358, G Loss: 4.5542192459106445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11741/100000, D Loss: 0.14857874810695648, G Loss: 4.2977294921875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11742/100000, D Loss: 0.13193753361701965, G Loss: 4.226413726806641\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11743/100000, D Loss: 0.14329294860363007, G Loss: 4.4105119705200195\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11744/100000, D Loss: 0.13774436712265015, G Loss: 4.742987155914307\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11745/100000, D Loss: 0.14845917373895645, G Loss: 4.519711494445801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11746/100000, D Loss: 0.15278975665569305, G Loss: 4.046294212341309\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11747/100000, D Loss: 0.16665328294038773, G Loss: 3.982191562652588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11748/100000, D Loss: 0.15542974323034286, G Loss: 4.24430513381958\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11749/100000, D Loss: 0.15387535840272903, G Loss: 4.574193000793457\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11750/100000, D Loss: 0.19342492520809174, G Loss: 4.241505146026611\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11751/100000, D Loss: 0.22084469348192215, G Loss: 3.714609146118164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11752/100000, D Loss: 0.21263115108013153, G Loss: 3.530606746673584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11753/100000, D Loss: 0.18688203394412994, G Loss: 4.130499839782715\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11754/100000, D Loss: 0.24260297417640686, G Loss: 4.1838860511779785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11755/100000, D Loss: 0.2667044699192047, G Loss: 3.8583309650421143\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11756/100000, D Loss: 0.28924690186977386, G Loss: 3.56252384185791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11757/100000, D Loss: 0.31193000078201294, G Loss: 3.794520854949951\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11758/100000, D Loss: 0.27109695971012115, G Loss: 3.944485664367676\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11759/100000, D Loss: 0.3310554027557373, G Loss: 3.6096057891845703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11760/100000, D Loss: 0.32287730276584625, G Loss: 3.402362585067749\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11761/100000, D Loss: 0.3660324066877365, G Loss: 3.458606481552124\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11762/100000, D Loss: 0.3467777222394943, G Loss: 3.6860263347625732\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11763/100000, D Loss: 0.4070819020271301, G Loss: 3.4818336963653564\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11764/100000, D Loss: 0.3354974091053009, G Loss: 3.3856406211853027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11765/100000, D Loss: 0.3868319094181061, G Loss: 3.2807517051696777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11766/100000, D Loss: 0.34856976568698883, G Loss: 3.5308845043182373\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11767/100000, D Loss: 0.38452599942684174, G Loss: 3.5490965843200684\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11768/100000, D Loss: 0.38453756272792816, G Loss: 3.5811078548431396\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11769/100000, D Loss: 0.37510769069194794, G Loss: 3.6219422817230225\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11770/100000, D Loss: 0.32891666889190674, G Loss: 3.751789093017578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11771/100000, D Loss: 0.314255028963089, G Loss: 3.7781078815460205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11772/100000, D Loss: 0.30006279051303864, G Loss: 3.6079306602478027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11773/100000, D Loss: 0.31091922521591187, G Loss: 3.7739057540893555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11774/100000, D Loss: 0.23440831154584885, G Loss: 4.308773994445801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11775/100000, D Loss: 0.23337339609861374, G Loss: 4.459043025970459\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11776/100000, D Loss: 0.1962178498506546, G Loss: 4.5607404708862305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11777/100000, D Loss: 0.21855774521827698, G Loss: 4.332333564758301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11778/100000, D Loss: 0.1454370766878128, G Loss: 4.616192817687988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11779/100000, D Loss: 0.14448846131563187, G Loss: 4.913056373596191\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11780/100000, D Loss: 0.1346266157925129, G Loss: 4.974285125732422\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11781/100000, D Loss: 0.1472373679280281, G Loss: 4.609697341918945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11782/100000, D Loss: 0.15019185841083527, G Loss: 4.431516647338867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11783/100000, D Loss: 0.144510917365551, G Loss: 4.5702009201049805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11784/100000, D Loss: 0.14349980652332306, G Loss: 5.024508476257324\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11785/100000, D Loss: 0.1276252269744873, G Loss: 5.199781894683838\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11786/100000, D Loss: 0.15065345168113708, G Loss: 4.707752227783203\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11787/100000, D Loss: 0.18639715015888214, G Loss: 4.357096195220947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11788/100000, D Loss: 0.1424388289451599, G Loss: 4.585172653198242\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11789/100000, D Loss: 0.17745574563741684, G Loss: 4.90858268737793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11790/100000, D Loss: 0.1900065317749977, G Loss: 5.00753116607666\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11791/100000, D Loss: 0.2474474385380745, G Loss: 4.5983991622924805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11792/100000, D Loss: 0.25980018079280853, G Loss: 4.6169610023498535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11793/100000, D Loss: 0.23482142388820648, G Loss: 4.757494926452637\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11794/100000, D Loss: 0.23699522018432617, G Loss: 4.683826923370361\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11795/100000, D Loss: 0.3049027919769287, G Loss: 4.313368320465088\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11796/100000, D Loss: 0.27398061752319336, G Loss: 4.220715045928955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11797/100000, D Loss: 0.2536321431398392, G Loss: 4.334878444671631\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11798/100000, D Loss: 0.2574310451745987, G Loss: 4.5518903732299805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11799/100000, D Loss: 0.3106260970234871, G Loss: 4.213882923126221\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11800/100000, D Loss: 0.27072151005268097, G Loss: 3.9987540245056152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11801/100000, D Loss: 0.27135270833969116, G Loss: 4.049942970275879\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11802/100000, D Loss: 0.24107295274734497, G Loss: 4.052000522613525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11803/100000, D Loss: 0.2357158064842224, G Loss: 4.49308967590332\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11804/100000, D Loss: 0.26954038441181183, G Loss: 4.091941833496094\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11805/100000, D Loss: 0.22892922163009644, G Loss: 4.062817573547363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11806/100000, D Loss: 0.2131628692150116, G Loss: 4.419764995574951\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11807/100000, D Loss: 0.22661790996789932, G Loss: 4.552138328552246\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11808/100000, D Loss: 0.23433344066143036, G Loss: 4.368574142456055\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11809/100000, D Loss: 0.1695598140358925, G Loss: 4.722711563110352\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11810/100000, D Loss: 0.19161628186702728, G Loss: 4.657797336578369\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11811/100000, D Loss: 0.19128379970788956, G Loss: 4.310847759246826\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11812/100000, D Loss: 0.1953701376914978, G Loss: 4.328287124633789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11813/100000, D Loss: 0.20794503390789032, G Loss: 4.381739616394043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11814/100000, D Loss: 0.20472580939531326, G Loss: 4.426718711853027\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11815/100000, D Loss: 0.20288660377264023, G Loss: 4.5811991691589355\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 11816/100000, D Loss: 0.1843818873167038, G Loss: 4.70875883102417\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11817/100000, D Loss: 0.2237882986664772, G Loss: 4.179910659790039\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11818/100000, D Loss: 0.25815194845199585, G Loss: 3.972785472869873\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11819/100000, D Loss: 0.21666962653398514, G Loss: 4.4283013343811035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11820/100000, D Loss: 0.2287071794271469, G Loss: 4.436001777648926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11821/100000, D Loss: 0.2551303431391716, G Loss: 4.212740898132324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11822/100000, D Loss: 0.2621612995862961, G Loss: 3.928280830383301\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11823/100000, D Loss: 0.2594246417284012, G Loss: 4.090367794036865\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11824/100000, D Loss: 0.26507385075092316, G Loss: 4.250730991363525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11825/100000, D Loss: 0.2767300605773926, G Loss: 4.264340400695801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11826/100000, D Loss: 0.23332811146974564, G Loss: 4.331280708312988\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11827/100000, D Loss: 0.2591639310121536, G Loss: 4.000637054443359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11828/100000, D Loss: 0.2261977195739746, G Loss: 4.4831671714782715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11829/100000, D Loss: 0.220863476395607, G Loss: 4.534425735473633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11830/100000, D Loss: 0.23689275979995728, G Loss: 4.401168346405029\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11831/100000, D Loss: 0.24313801527023315, G Loss: 4.187557220458984\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11832/100000, D Loss: 0.23649899661540985, G Loss: 4.350174903869629\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11833/100000, D Loss: 0.23424464464187622, G Loss: 4.162580966949463\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11834/100000, D Loss: 0.2415008693933487, G Loss: 4.412775993347168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11835/100000, D Loss: 0.28141946345567703, G Loss: 4.323194980621338\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11836/100000, D Loss: 0.2527838945388794, G Loss: 4.005237579345703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11837/100000, D Loss: 0.245652973651886, G Loss: 4.134639739990234\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11838/100000, D Loss: 0.23884408921003342, G Loss: 4.260280609130859\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11839/100000, D Loss: 0.26099447906017303, G Loss: 4.109302520751953\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11840/100000, D Loss: 0.24107500910758972, G Loss: 4.24513053894043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11841/100000, D Loss: 0.2897792011499405, G Loss: 4.0816874504089355\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11842/100000, D Loss: 0.25547948479652405, G Loss: 4.055353164672852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11843/100000, D Loss: 0.2769702672958374, G Loss: 4.005117416381836\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11844/100000, D Loss: 0.24480293691158295, G Loss: 4.028741836547852\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11845/100000, D Loss: 0.26962941139936447, G Loss: 4.137476444244385\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11846/100000, D Loss: 0.28502967208623886, G Loss: 4.148508548736572\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11847/100000, D Loss: 0.3084723800420761, G Loss: 3.8500490188598633\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11848/100000, D Loss: 0.2791869342327118, G Loss: 4.170903205871582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11849/100000, D Loss: 0.2214614450931549, G Loss: 4.453679084777832\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11850/100000, D Loss: 0.21667982637882233, G Loss: 4.213206768035889\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11851/100000, D Loss: 0.28051339089870453, G Loss: 3.826833724975586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11852/100000, D Loss: 0.2672383114695549, G Loss: 3.936063766479492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11853/100000, D Loss: 0.2081872522830963, G Loss: 4.466000556945801\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11854/100000, D Loss: 0.2384338453412056, G Loss: 4.325972080230713\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11855/100000, D Loss: 0.2573521137237549, G Loss: 3.7790112495422363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11856/100000, D Loss: 0.25767505168914795, G Loss: 3.985360860824585\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11857/100000, D Loss: 0.2437552884221077, G Loss: 4.1095991134643555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11858/100000, D Loss: 0.275569424033165, G Loss: 4.139785289764404\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11859/100000, D Loss: 0.25189755856990814, G Loss: 4.049107551574707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11860/100000, D Loss: 0.24527215212583542, G Loss: 4.074416160583496\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11861/100000, D Loss: 0.23751140385866165, G Loss: 4.238712310791016\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11862/100000, D Loss: 0.21173177659511566, G Loss: 4.231054306030273\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11863/100000, D Loss: 0.22419428825378418, G Loss: 4.384286880493164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11864/100000, D Loss: 0.2389611154794693, G Loss: 4.3033905029296875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11865/100000, D Loss: 0.21464787423610687, G Loss: 4.216759204864502\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11866/100000, D Loss: 0.21666225790977478, G Loss: 4.415475845336914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11867/100000, D Loss: 0.21741119772195816, G Loss: 4.584159851074219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11868/100000, D Loss: 0.18233437091112137, G Loss: 4.657435417175293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11869/100000, D Loss: 0.20679953694343567, G Loss: 4.4183807373046875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11870/100000, D Loss: 0.2040206789970398, G Loss: 4.246612071990967\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11871/100000, D Loss: 0.2069249451160431, G Loss: 4.460579872131348\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11872/100000, D Loss: 0.2077859789133072, G Loss: 4.507284164428711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11873/100000, D Loss: 0.19800446182489395, G Loss: 4.429652214050293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11874/100000, D Loss: 0.21485640108585358, G Loss: 4.4203667640686035\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11875/100000, D Loss: 0.22526749968528748, G Loss: 4.329444885253906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11876/100000, D Loss: 0.20577386021614075, G Loss: 4.416266441345215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11877/100000, D Loss: 0.22874964773654938, G Loss: 4.627128601074219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11878/100000, D Loss: 0.2258492410182953, G Loss: 4.3849196434021\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11879/100000, D Loss: 0.22482094168663025, G Loss: 4.413874626159668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11880/100000, D Loss: 0.22670193016529083, G Loss: 4.391338348388672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11881/100000, D Loss: 0.23637571930885315, G Loss: 4.459203720092773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11882/100000, D Loss: 0.2406436651945114, G Loss: 4.4943671226501465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11883/100000, D Loss: 0.3085743933916092, G Loss: 4.073760509490967\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11884/100000, D Loss: 0.2752481549978256, G Loss: 3.9776806831359863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11885/100000, D Loss: 0.3415823131799698, G Loss: 4.006505012512207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11886/100000, D Loss: 0.3573810011148453, G Loss: 4.075018882751465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11887/100000, D Loss: 0.33008959889411926, G Loss: 4.166786193847656\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11888/100000, D Loss: 0.38748799264431, G Loss: 3.8752121925354004\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11889/100000, D Loss: 0.43436169624328613, G Loss: 3.7348780632019043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11890/100000, D Loss: 0.4192609190940857, G Loss: 3.776582956314087\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11891/100000, D Loss: 0.39411452412605286, G Loss: 3.977778434753418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11892/100000, D Loss: 0.39692260324954987, G Loss: 3.6348562240600586\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11893/100000, D Loss: 0.4061571955680847, G Loss: 3.5089173316955566\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11894/100000, D Loss: 0.3213731050491333, G Loss: 3.6632795333862305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11895/100000, D Loss: 0.34972696006298065, G Loss: 3.7181344032287598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11896/100000, D Loss: 0.31310103833675385, G Loss: 3.778970718383789\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11897/100000, D Loss: 0.28134238719940186, G Loss: 4.096831798553467\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11898/100000, D Loss: 0.28189558535814285, G Loss: 4.015169143676758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11899/100000, D Loss: 0.24610653519630432, G Loss: 4.134709358215332\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11900/100000, D Loss: 0.2301691770553589, G Loss: 4.241172790527344\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11901/100000, D Loss: 0.21037019789218903, G Loss: 4.497627258300781\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11902/100000, D Loss: 0.2069527581334114, G Loss: 4.501308441162109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11903/100000, D Loss: 0.21408607065677643, G Loss: 4.370388507843018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11904/100000, D Loss: 0.22065634280443192, G Loss: 4.618459701538086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11905/100000, D Loss: 0.15436778962612152, G Loss: 4.72798490524292\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11906/100000, D Loss: 0.18570777773857117, G Loss: 4.7674455642700195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11907/100000, D Loss: 0.19409750401973724, G Loss: 4.631257057189941\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11908/100000, D Loss: 0.17498819530010223, G Loss: 4.518420219421387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11909/100000, D Loss: 0.16694440692663193, G Loss: 4.815073013305664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11910/100000, D Loss: 0.14464278519153595, G Loss: 4.89496374130249\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11911/100000, D Loss: 0.1735791265964508, G Loss: 4.613510608673096\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11912/100000, D Loss: 0.14603012800216675, G Loss: 4.570041656494141\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11913/100000, D Loss: 0.14955545961856842, G Loss: 4.735367774963379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11914/100000, D Loss: 0.18703672289848328, G Loss: 4.720122814178467\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11915/100000, D Loss: 0.1589951515197754, G Loss: 4.722967147827148\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11916/100000, D Loss: 0.18751026690006256, G Loss: 4.3457722663879395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11917/100000, D Loss: 0.20016898214817047, G Loss: 4.366446495056152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11918/100000, D Loss: 0.22464805096387863, G Loss: 4.5929718017578125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11919/100000, D Loss: 0.1958550214767456, G Loss: 4.564836502075195\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11920/100000, D Loss: 0.22254450619220734, G Loss: 4.337312698364258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11921/100000, D Loss: 0.26815134286880493, G Loss: 3.9909958839416504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11922/100000, D Loss: 0.2683439254760742, G Loss: 3.894639492034912\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11923/100000, D Loss: 0.26056425273418427, G Loss: 4.25773286819458\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11924/100000, D Loss: 0.2378915399312973, G Loss: 4.149936676025391\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11925/100000, D Loss: 0.26204876601696014, G Loss: 3.9680774211883545\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11926/100000, D Loss: 0.31126901507377625, G Loss: 3.8746142387390137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11927/100000, D Loss: 0.27508413791656494, G Loss: 4.0943074226379395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11928/100000, D Loss: 0.29575247317552567, G Loss: 4.078474521636963\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11929/100000, D Loss: 0.3178535997867584, G Loss: 3.9688830375671387\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11930/100000, D Loss: 0.29404039680957794, G Loss: 3.891700267791748\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11931/100000, D Loss: 0.2923738807439804, G Loss: 4.149161338806152\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11932/100000, D Loss: 0.2621162682771683, G Loss: 4.256964683532715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11933/100000, D Loss: 0.2816392183303833, G Loss: 4.005521774291992\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11934/100000, D Loss: 0.29682256281375885, G Loss: 3.824138641357422\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11935/100000, D Loss: 0.24943336844444275, G Loss: 4.147922992706299\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11936/100000, D Loss: 0.24102552235126495, G Loss: 4.372824668884277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11937/100000, D Loss: 0.28002261370420456, G Loss: 3.822538375854492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11938/100000, D Loss: 0.27066517621278763, G Loss: 3.9778051376342773\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11939/100000, D Loss: 0.19504748284816742, G Loss: 4.4271039962768555\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11940/100000, D Loss: 0.24744971096515656, G Loss: 4.117193222045898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11941/100000, D Loss: 0.22844666987657547, G Loss: 4.059181213378906\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11942/100000, D Loss: 0.207813560962677, G Loss: 4.290484428405762\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11943/100000, D Loss: 0.21509161591529846, G Loss: 4.318979263305664\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11944/100000, D Loss: 0.24258433282375336, G Loss: 4.107729911804199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11945/100000, D Loss: 0.19818024337291718, G Loss: 4.161637783050537\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11946/100000, D Loss: 0.22788991779088974, G Loss: 4.502772331237793\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11947/100000, D Loss: 0.23331598937511444, G Loss: 4.39288330078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11948/100000, D Loss: 0.23329172283411026, G Loss: 4.179622650146484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11949/100000, D Loss: 0.19823008030653, G Loss: 4.192360877990723\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11950/100000, D Loss: 0.19385996460914612, G Loss: 4.267327308654785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11951/100000, D Loss: 0.20810900628566742, G Loss: 4.656722068786621\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11952/100000, D Loss: 0.22894805669784546, G Loss: 4.2978010177612305\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11953/100000, D Loss: 0.2030123844742775, G Loss: 4.2562575340271\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11954/100000, D Loss: 0.21709109097719193, G Loss: 4.221508502960205\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11955/100000, D Loss: 0.19014911353588104, G Loss: 4.166656494140625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11956/100000, D Loss: 0.21727024763822556, G Loss: 4.439504623413086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11957/100000, D Loss: 0.23677746951580048, G Loss: 4.169719696044922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11958/100000, D Loss: 0.2626795470714569, G Loss: 3.789076566696167\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11959/100000, D Loss: 0.2602458596229553, G Loss: 3.859248638153076\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 11960/100000, D Loss: 0.25373320281505585, G Loss: 4.103492736816406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11961/100000, D Loss: 0.262121818959713, G Loss: 4.101279258728027\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11962/100000, D Loss: 0.3189038634300232, G Loss: 3.77188777923584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11963/100000, D Loss: 0.3118079751729965, G Loss: 3.787041664123535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11964/100000, D Loss: 0.31183797121047974, G Loss: 4.208219528198242\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11965/100000, D Loss: 0.2868412137031555, G Loss: 3.9473063945770264\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11966/100000, D Loss: 0.3486595004796982, G Loss: 3.670546770095825\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11967/100000, D Loss: 0.3023518770933151, G Loss: 3.8262524604797363\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11968/100000, D Loss: 0.3163214921951294, G Loss: 4.044926643371582\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11969/100000, D Loss: 0.29429657757282257, G Loss: 3.8414769172668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11970/100000, D Loss: 0.3048402816057205, G Loss: 3.781320095062256\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11971/100000, D Loss: 0.3108173906803131, G Loss: 3.9761388301849365\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11972/100000, D Loss: 0.28703004121780396, G Loss: 4.14292049407959\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11973/100000, D Loss: 0.28972360491752625, G Loss: 4.070535659790039\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11974/100000, D Loss: 0.2918028235435486, G Loss: 4.107843399047852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11975/100000, D Loss: 0.2541186213493347, G Loss: 4.068910121917725\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11976/100000, D Loss: 0.23235642910003662, G Loss: 4.350944995880127\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11977/100000, D Loss: 0.19626618176698685, G Loss: 4.808485507965088\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11978/100000, D Loss: 0.20375315845012665, G Loss: 4.323755264282227\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11979/100000, D Loss: 0.22586777061223984, G Loss: 4.0177435874938965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11980/100000, D Loss: 0.18995842337608337, G Loss: 4.733433723449707\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11981/100000, D Loss: 0.18664735555648804, G Loss: 5.054462432861328\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11982/100000, D Loss: 0.1902223415672779, G Loss: 4.564739227294922\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11983/100000, D Loss: 0.18814250081777573, G Loss: 4.094240665435791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11984/100000, D Loss: 0.18718871474266052, G Loss: 4.307366847991943\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11985/100000, D Loss: 0.16399847716093063, G Loss: 4.897153854370117\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11986/100000, D Loss: 0.194264255464077, G Loss: 4.682234764099121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11987/100000, D Loss: 0.20698828250169754, G Loss: 4.228764533996582\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11988/100000, D Loss: 0.23983965814113617, G Loss: 4.063952922821045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11989/100000, D Loss: 0.18840580433607101, G Loss: 4.320496559143066\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11990/100000, D Loss: 0.20796813070774078, G Loss: 4.314408779144287\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11991/100000, D Loss: 0.25219058245420456, G Loss: 4.164133548736572\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 11992/100000, D Loss: 0.24225759506225586, G Loss: 3.9693961143493652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11993/100000, D Loss: 0.2342294082045555, G Loss: 3.9351274967193604\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11994/100000, D Loss: 0.25472890585660934, G Loss: 4.060812950134277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11995/100000, D Loss: 0.3008561283349991, G Loss: 3.8497862815856934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11996/100000, D Loss: 0.3424314111471176, G Loss: 3.578683853149414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11997/100000, D Loss: 0.3408443033695221, G Loss: 3.6640055179595947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11998/100000, D Loss: 0.33954934775829315, G Loss: 3.8551228046417236\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 11999/100000, D Loss: 0.38321250677108765, G Loss: 3.752269744873047\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12000/100000, D Loss: 0.4159775376319885, G Loss: 3.538051128387451\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12001/100000, D Loss: 0.39995963871479034, G Loss: 3.4625353813171387\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12002/100000, D Loss: 0.3917500525712967, G Loss: 3.5952072143554688\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12003/100000, D Loss: 0.41377465426921844, G Loss: 3.729363441467285\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12004/100000, D Loss: 0.3945600986480713, G Loss: 3.618389129638672\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12005/100000, D Loss: 0.3694285750389099, G Loss: 3.8285398483276367\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12006/100000, D Loss: 0.3029935508966446, G Loss: 3.9834835529327393\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12007/100000, D Loss: 0.28621890395879745, G Loss: 4.387855052947998\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12008/100000, D Loss: 0.24490977823734283, G Loss: 4.118814945220947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12009/100000, D Loss: 0.23800373077392578, G Loss: 4.205524444580078\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12010/100000, D Loss: 0.207871213555336, G Loss: 4.6331892013549805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12011/100000, D Loss: 0.1778629645705223, G Loss: 4.678630828857422\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12012/100000, D Loss: 0.16183805465698242, G Loss: 4.649501800537109\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12013/100000, D Loss: 0.17162268608808517, G Loss: 4.675152778625488\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12014/100000, D Loss: 0.19323238730430603, G Loss: 4.652766704559326\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12015/100000, D Loss: 0.15867406874895096, G Loss: 4.852797031402588\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12016/100000, D Loss: 0.1834906041622162, G Loss: 4.592288970947266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12017/100000, D Loss: 0.21748103946447372, G Loss: 4.332608699798584\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12018/100000, D Loss: 0.183077372610569, G Loss: 4.487112998962402\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12019/100000, D Loss: 0.20547619462013245, G Loss: 4.578338623046875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12020/100000, D Loss: 0.19623538106679916, G Loss: 4.75714111328125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12021/100000, D Loss: 0.24120286852121353, G Loss: 4.4084014892578125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12022/100000, D Loss: 0.26549261808395386, G Loss: 4.089949607849121\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12023/100000, D Loss: 0.25986581295728683, G Loss: 4.128274917602539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12024/100000, D Loss: 0.2472531870007515, G Loss: 4.571926116943359\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12025/100000, D Loss: 0.3432249426841736, G Loss: 4.2714152336120605\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12026/100000, D Loss: 0.3576665371656418, G Loss: 3.742185115814209\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12027/100000, D Loss: 0.32151150703430176, G Loss: 3.9764552116394043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12028/100000, D Loss: 0.332601934671402, G Loss: 4.255871295928955\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12029/100000, D Loss: 0.2950192987918854, G Loss: 4.019157409667969\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12030/100000, D Loss: 0.338643342256546, G Loss: 3.9380576610565186\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12031/100000, D Loss: 0.3207474797964096, G Loss: 4.013214588165283\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12032/100000, D Loss: 0.23433682322502136, G Loss: 4.232705593109131\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12033/100000, D Loss: 0.23769530653953552, G Loss: 4.414340972900391\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12034/100000, D Loss: 0.24046891182661057, G Loss: 4.269487380981445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12035/100000, D Loss: 0.21508462727069855, G Loss: 4.345654487609863\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12036/100000, D Loss: 0.2088090032339096, G Loss: 4.325861930847168\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12037/100000, D Loss: 0.206510990858078, G Loss: 4.220492839813232\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12038/100000, D Loss: 0.1983407437801361, G Loss: 4.404762268066406\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12039/100000, D Loss: 0.19618675857782364, G Loss: 4.378107070922852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12040/100000, D Loss: 0.20754063874483109, G Loss: 4.289527893066406\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12041/100000, D Loss: 0.20906365662813187, G Loss: 4.167616844177246\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12042/100000, D Loss: 0.1959524154663086, G Loss: 4.264468193054199\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12043/100000, D Loss: 0.21212411671876907, G Loss: 4.338779449462891\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12044/100000, D Loss: 0.21801212430000305, G Loss: 4.3983073234558105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12045/100000, D Loss: 0.23223428428173065, G Loss: 4.1702094078063965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12046/100000, D Loss: 0.22098568081855774, G Loss: 4.126044273376465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12047/100000, D Loss: 0.1870158389210701, G Loss: 4.312841415405273\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12048/100000, D Loss: 0.21834252774715424, G Loss: 4.3094987869262695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12049/100000, D Loss: 0.2434384524822235, G Loss: 4.086360931396484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12050/100000, D Loss: 0.21536695957183838, G Loss: 4.208796501159668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12051/100000, D Loss: 0.22475051879882812, G Loss: 4.122767448425293\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12052/100000, D Loss: 0.2087487205862999, G Loss: 4.3671040534973145\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12053/100000, D Loss: 0.18950603902339935, G Loss: 4.275333881378174\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12054/100000, D Loss: 0.20443317294120789, G Loss: 4.211026191711426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12055/100000, D Loss: 0.21541261672973633, G Loss: 4.185503959655762\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12056/100000, D Loss: 0.20154906064271927, G Loss: 4.167721271514893\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12057/100000, D Loss: 0.21845842897891998, G Loss: 4.117487907409668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12058/100000, D Loss: 0.19019608944654465, G Loss: 4.287209987640381\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12059/100000, D Loss: 0.1779639944434166, G Loss: 4.481525421142578\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12060/100000, D Loss: 0.20125730335712433, G Loss: 4.148222923278809\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12061/100000, D Loss: 0.2051713541150093, G Loss: 4.014060020446777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12062/100000, D Loss: 0.19292503595352173, G Loss: 4.28981876373291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12063/100000, D Loss: 0.17062076926231384, G Loss: 4.479388236999512\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12064/100000, D Loss: 0.21066878736019135, G Loss: 4.193795204162598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12065/100000, D Loss: 0.1816626936197281, G Loss: 4.071656703948975\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12066/100000, D Loss: 0.15917756408452988, G Loss: 4.360812187194824\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12067/100000, D Loss: 0.1661103069782257, G Loss: 4.593766212463379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12068/100000, D Loss: 0.18590440601110458, G Loss: 4.49609899520874\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12069/100000, D Loss: 0.19218454509973526, G Loss: 4.352821350097656\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12070/100000, D Loss: 0.206584632396698, G Loss: 4.1450629234313965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12071/100000, D Loss: 0.20614536106586456, G Loss: 4.2793378829956055\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12072/100000, D Loss: 0.17011259496212006, G Loss: 4.591036796569824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12073/100000, D Loss: 0.19012366235256195, G Loss: 4.435266971588135\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12074/100000, D Loss: 0.24176272749900818, G Loss: 3.8950014114379883\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12075/100000, D Loss: 0.23273440450429916, G Loss: 4.027655601501465\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12076/100000, D Loss: 0.2025156021118164, G Loss: 4.536617755889893\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12077/100000, D Loss: 0.20939312130212784, G Loss: 4.48213529586792\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12078/100000, D Loss: 0.20951616019010544, G Loss: 4.30394172668457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12079/100000, D Loss: 0.21418863534927368, G Loss: 3.840846300125122\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12080/100000, D Loss: 0.18698281794786453, G Loss: 3.8943166732788086\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12081/100000, D Loss: 0.15785488486289978, G Loss: 4.595779895782471\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12082/100000, D Loss: 0.21035590022802353, G Loss: 4.362337112426758\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12083/100000, D Loss: 0.19903626292943954, G Loss: 4.121455669403076\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12084/100000, D Loss: 0.21855494379997253, G Loss: 4.081862449645996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12085/100000, D Loss: 0.2000095248222351, G Loss: 4.294353485107422\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12086/100000, D Loss: 0.2076224759221077, G Loss: 4.249666213989258\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12087/100000, D Loss: 0.21767622977495193, G Loss: 4.049997329711914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12088/100000, D Loss: 0.24101470410823822, G Loss: 4.077177047729492\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12089/100000, D Loss: 0.2658348008990288, G Loss: 4.036763668060303\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12090/100000, D Loss: 0.21085577458143234, G Loss: 4.109936714172363\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12091/100000, D Loss: 0.2691998705267906, G Loss: 3.8871960639953613\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 12092/100000, D Loss: 0.26095837354660034, G Loss: 3.792675256729126\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12093/100000, D Loss: 0.2724711298942566, G Loss: 3.822477340698242\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12094/100000, D Loss: 0.30201898515224457, G Loss: 3.929731845855713\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12095/100000, D Loss: 0.33178412914276123, G Loss: 3.9052648544311523\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12096/100000, D Loss: 0.34770576655864716, G Loss: 3.4929752349853516\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12097/100000, D Loss: 0.37629184126853943, G Loss: 3.4723877906799316\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12098/100000, D Loss: 0.35647958517074585, G Loss: 3.666592597961426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12099/100000, D Loss: 0.42148353159427643, G Loss: 3.2815041542053223\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12100/100000, D Loss: 0.41049806773662567, G Loss: 3.484938144683838\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12101/100000, D Loss: 0.42557334899902344, G Loss: 3.6693954467773438\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12102/100000, D Loss: 0.39574919641017914, G Loss: 3.6525168418884277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12103/100000, D Loss: 0.47348229587078094, G Loss: 3.36236310005188\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12104/100000, D Loss: 0.4124685525894165, G Loss: 3.55391788482666\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12105/100000, D Loss: 0.35067084431648254, G Loss: 4.052112579345703\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12106/100000, D Loss: 0.3198324292898178, G Loss: 4.102032661437988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12107/100000, D Loss: 0.26662417501211166, G Loss: 3.9035868644714355\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12108/100000, D Loss: 0.28679537773132324, G Loss: 3.7640814781188965\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 12109/100000, D Loss: 0.24964527785778046, G Loss: 4.140460968017578\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12110/100000, D Loss: 0.23702694475650787, G Loss: 4.446959495544434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12111/100000, D Loss: 0.21412935853004456, G Loss: 4.474416732788086\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12112/100000, D Loss: 0.24322299659252167, G Loss: 4.108244895935059\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12113/100000, D Loss: 0.2424813210964203, G Loss: 4.120323657989502\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12114/100000, D Loss: 0.2023431807756424, G Loss: 4.068151473999023\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12115/100000, D Loss: 0.24040363729000092, G Loss: 4.080209732055664\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12116/100000, D Loss: 0.27451109886169434, G Loss: 3.9622292518615723\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 12117/100000, D Loss: 0.27656978368759155, G Loss: 3.9033918380737305\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12118/100000, D Loss: 0.24524425715208054, G Loss: 4.308279037475586\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12119/100000, D Loss: 0.2796390950679779, G Loss: 4.067320823669434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12120/100000, D Loss: 0.2557203844189644, G Loss: 4.222628116607666\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12121/100000, D Loss: 0.2847209572792053, G Loss: 3.9840281009674072\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12122/100000, D Loss: 0.2714405059814453, G Loss: 3.9724414348602295\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12123/100000, D Loss: 0.25188343971967697, G Loss: 4.136526107788086\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12124/100000, D Loss: 0.2545931860804558, G Loss: 4.4446330070495605\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12125/100000, D Loss: 0.2725522965192795, G Loss: 3.992358922958374\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12126/100000, D Loss: 0.3029205799102783, G Loss: 3.596823215484619\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12127/100000, D Loss: 0.24223120510578156, G Loss: 3.92110013961792\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12128/100000, D Loss: 0.25126221030950546, G Loss: 4.24580717086792\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12129/100000, D Loss: 0.2528657987713814, G Loss: 4.154783248901367\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12130/100000, D Loss: 0.28918537497520447, G Loss: 4.034704685211182\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 12131/100000, D Loss: 0.3064485341310501, G Loss: 3.745199203491211\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12132/100000, D Loss: 0.26555292308330536, G Loss: 4.075364589691162\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12133/100000, D Loss: 0.2780020609498024, G Loss: 4.083749771118164\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12134/100000, D Loss: 0.26444993913173676, G Loss: 4.062047004699707\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12135/100000, D Loss: 0.2595217078924179, G Loss: 4.305436134338379\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Epoch 12136/100000, D Loss: 0.27599602937698364, G Loss: 4.084127426147461\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12137/100000, D Loss: 0.2967154085636139, G Loss: 4.073023796081543\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12138/100000, D Loss: 0.26366014778614044, G Loss: 4.092103004455566\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12139/100000, D Loss: 0.2744201421737671, G Loss: 3.9882969856262207\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12140/100000, D Loss: 0.294720783829689, G Loss: 3.7323386669158936\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12141/100000, D Loss: 0.3255770802497864, G Loss: 3.8556344509124756\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12142/100000, D Loss: 0.28232938796281815, G Loss: 4.100747108459473\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 12143/100000, D Loss: 0.3555166870355606, G Loss: 4.000921249389648\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12144/100000, D Loss: 0.34036536514759064, G Loss: 4.032955169677734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12145/100000, D Loss: 0.29441823065280914, G Loss: 4.317608833312988\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12146/100000, D Loss: 0.34705960750579834, G Loss: 4.009814262390137\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12147/100000, D Loss: 0.3322252035140991, G Loss: 3.8992977142333984\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12148/100000, D Loss: 0.30721569061279297, G Loss: 4.105813980102539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12149/100000, D Loss: 0.2510428875684738, G Loss: 4.371735572814941\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12150/100000, D Loss: 0.24629312008619308, G Loss: 4.343555450439453\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12151/100000, D Loss: 0.203880175948143, G Loss: 4.26578426361084\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12152/100000, D Loss: 0.18031825870275497, G Loss: 4.559008598327637\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12153/100000, D Loss: 0.1990579143166542, G Loss: 4.740899562835693\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12154/100000, D Loss: 0.18210892379283905, G Loss: 4.684516429901123\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12155/100000, D Loss: 0.17891984432935715, G Loss: 4.400705337524414\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12156/100000, D Loss: 0.14492301642894745, G Loss: 4.861780166625977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12157/100000, D Loss: 0.17878106981515884, G Loss: 4.621530532836914\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12158/100000, D Loss: 0.19173067808151245, G Loss: 4.659365653991699\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12159/100000, D Loss: 0.17207250744104385, G Loss: 4.806310176849365\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12160/100000, D Loss: 0.20176349580287933, G Loss: 4.590717315673828\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12161/100000, D Loss: 0.22407617419958115, G Loss: 4.200216293334961\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12162/100000, D Loss: 0.22581057250499725, G Loss: 4.030776023864746\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12163/100000, D Loss: 0.2365504652261734, G Loss: 4.264634609222412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12164/100000, D Loss: 0.21497999876737595, G Loss: 4.340228080749512\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12165/100000, D Loss: 0.2582983672618866, G Loss: 4.0684003829956055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12166/100000, D Loss: 0.2917077839374542, G Loss: 4.029747009277344\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12167/100000, D Loss: 0.2655160427093506, G Loss: 4.07166862487793\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12168/100000, D Loss: 0.2710815966129303, G Loss: 4.167569637298584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12169/100000, D Loss: 0.29947274923324585, G Loss: 4.112340927124023\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12170/100000, D Loss: 0.3064759373664856, G Loss: 3.9257779121398926\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12171/100000, D Loss: 0.32105594873428345, G Loss: 4.192861557006836\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12172/100000, D Loss: 0.30764198303222656, G Loss: 4.25985050201416\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12173/100000, D Loss: 0.2859063148498535, G Loss: 4.008200645446777\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12174/100000, D Loss: 0.29458801448345184, G Loss: 3.9309771060943604\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12175/100000, D Loss: 0.3016522526741028, G Loss: 4.031554222106934\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12176/100000, D Loss: 0.2827509641647339, G Loss: 4.255987167358398\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12177/100000, D Loss: 0.27432529628276825, G Loss: 4.253765106201172\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12178/100000, D Loss: 0.2211119756102562, G Loss: 4.038749694824219\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12179/100000, D Loss: 0.23105789721012115, G Loss: 4.154544830322266\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12180/100000, D Loss: 0.20948576927185059, G Loss: 4.372564315795898\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12181/100000, D Loss: 0.2176642045378685, G Loss: 4.5930352210998535\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12182/100000, D Loss: 0.1754000037908554, G Loss: 4.557446002960205\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12183/100000, D Loss: 0.2284538596868515, G Loss: 4.326504707336426\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12184/100000, D Loss: 0.19320081919431686, G Loss: 4.16507625579834\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12185/100000, D Loss: 0.1598617136478424, G Loss: 4.675068378448486\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12186/100000, D Loss: 0.18896230310201645, G Loss: 4.734658718109131\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12187/100000, D Loss: 0.17615672200918198, G Loss: 4.453521251678467\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12188/100000, D Loss: 0.22390970587730408, G Loss: 4.162911415100098\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12189/100000, D Loss: 0.18457257747650146, G Loss: 4.064196586608887\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12190/100000, D Loss: 0.1707998290657997, G Loss: 4.552947998046875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12191/100000, D Loss: 0.21635837852954865, G Loss: 4.487056732177734\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12192/100000, D Loss: 0.24324215948581696, G Loss: 3.926693916320801\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12193/100000, D Loss: 0.26960398256778717, G Loss: 3.8969032764434814\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12194/100000, D Loss: 0.27078284323215485, G Loss: 3.8565847873687744\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12195/100000, D Loss: 0.27908268570899963, G Loss: 4.125479698181152\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12196/100000, D Loss: 0.3208053261041641, G Loss: 3.9745306968688965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12197/100000, D Loss: 0.3042893409729004, G Loss: 3.780139923095703\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12198/100000, D Loss: 0.32333147525787354, G Loss: 3.8579373359680176\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12199/100000, D Loss: 0.31815746426582336, G Loss: 3.67478084564209\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12200/100000, D Loss: 0.3983664959669113, G Loss: 3.5316569805145264\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12201/100000, D Loss: 0.3019597828388214, G Loss: 3.8143064975738525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12202/100000, D Loss: 0.34392134845256805, G Loss: 3.9288980960845947\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12203/100000, D Loss: 0.2931927740573883, G Loss: 3.6851468086242676\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12204/100000, D Loss: 0.2598930150270462, G Loss: 3.9033069610595703\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12205/100000, D Loss: 0.24786075204610825, G Loss: 4.037950038909912\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12206/100000, D Loss: 0.265883132815361, G Loss: 3.8102927207946777\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12207/100000, D Loss: 0.3047676235437393, G Loss: 3.7146081924438477\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12208/100000, D Loss: 0.24626339972019196, G Loss: 4.085138320922852\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12209/100000, D Loss: 0.2526090741157532, G Loss: 4.12006950378418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12210/100000, D Loss: 0.24818626046180725, G Loss: 3.8086774349212646\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12211/100000, D Loss: 0.2834477424621582, G Loss: 3.5647897720336914\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12212/100000, D Loss: 0.24424640834331512, G Loss: 3.9778716564178467\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12213/100000, D Loss: 0.1981923133134842, G Loss: 4.524186134338379\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12214/100000, D Loss: 0.2359040006995201, G Loss: 4.183154582977295\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12215/100000, D Loss: 0.22227122634649277, G Loss: 3.9333739280700684\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12216/100000, D Loss: 0.18005940318107605, G Loss: 4.090414047241211\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12217/100000, D Loss: 0.19732533395290375, G Loss: 4.274233818054199\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12218/100000, D Loss: 0.17162692546844482, G Loss: 4.365232944488525\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12219/100000, D Loss: 0.17239612340927124, G Loss: 4.12257194519043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12220/100000, D Loss: 0.17677831649780273, G Loss: 4.207795143127441\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12221/100000, D Loss: 0.18357264250516891, G Loss: 4.3771562576293945\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12222/100000, D Loss: 0.18381407856941223, G Loss: 4.497651100158691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12223/100000, D Loss: 0.1737181469798088, G Loss: 4.23903751373291\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12224/100000, D Loss: 0.18412695825099945, G Loss: 4.201579570770264\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12225/100000, D Loss: 0.21378406882286072, G Loss: 3.999545097351074\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12226/100000, D Loss: 0.18847079575061798, G Loss: 4.155470371246338\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12227/100000, D Loss: 0.19385379552841187, G Loss: 4.274229049682617\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12228/100000, D Loss: 0.23866665363311768, G Loss: 4.069753170013428\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12229/100000, D Loss: 0.22789444774389267, G Loss: 3.8356146812438965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12230/100000, D Loss: 0.26243045926094055, G Loss: 3.9628796577453613\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12231/100000, D Loss: 0.2757101356983185, G Loss: 3.9438295364379883\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12232/100000, D Loss: 0.3051176369190216, G Loss: 3.811767816543579\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12233/100000, D Loss: 0.3108205497264862, G Loss: 3.65354061126709\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12234/100000, D Loss: 0.3265266716480255, G Loss: 3.6873135566711426\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12235/100000, D Loss: 0.32597866654396057, G Loss: 3.6398510932922363\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12236/100000, D Loss: 0.33276595175266266, G Loss: 3.6350388526916504\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12237/100000, D Loss: 0.3442596346139908, G Loss: 3.679323196411133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12238/100000, D Loss: 0.30527710914611816, G Loss: 3.6902644634246826\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12239/100000, D Loss: 0.27825482189655304, G Loss: 3.962423086166382\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12240/100000, D Loss: 0.30057502537965775, G Loss: 3.714244842529297\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12241/100000, D Loss: 0.30249302089214325, G Loss: 3.9433469772338867\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12242/100000, D Loss: 0.23080001026391983, G Loss: 4.299508094787598\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12243/100000, D Loss: 0.2469479963183403, G Loss: 4.3330278396606445\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12244/100000, D Loss: 0.27726341038942337, G Loss: 3.87209415435791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12245/100000, D Loss: 0.2528523951768875, G Loss: 3.6748034954071045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12246/100000, D Loss: 0.21648940443992615, G Loss: 3.9895544052124023\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12247/100000, D Loss: 0.2074376717209816, G Loss: 4.623147964477539\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12248/100000, D Loss: 0.2511870115995407, G Loss: 4.08918571472168\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12249/100000, D Loss: 0.2666873335838318, G Loss: 3.737657308578491\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12250/100000, D Loss: 0.2134508714079857, G Loss: 4.089677810668945\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12251/100000, D Loss: 0.20256604254245758, G Loss: 4.6465301513671875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12252/100000, D Loss: 0.2563732862472534, G Loss: 4.046534538269043\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12253/100000, D Loss: 0.25061751157045364, G Loss: 3.863161087036133\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12254/100000, D Loss: 0.24348697066307068, G Loss: 4.03843355178833\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12255/100000, D Loss: 0.2187020406126976, G Loss: 4.257686614990234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12256/100000, D Loss: 0.21885930746793747, G Loss: 4.289679527282715\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12257/100000, D Loss: 0.2516983300447464, G Loss: 3.8857476711273193\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12258/100000, D Loss: 0.26594166457653046, G Loss: 3.8160805702209473\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12259/100000, D Loss: 0.21260812878608704, G Loss: 4.171967506408691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12260/100000, D Loss: 0.2575230523943901, G Loss: 4.104400634765625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12261/100000, D Loss: 0.24410666525363922, G Loss: 3.8840837478637695\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12262/100000, D Loss: 0.26934245228767395, G Loss: 3.873544692993164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12263/100000, D Loss: 0.22048746049404144, G Loss: 4.036685943603516\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12264/100000, D Loss: 0.24657521396875381, G Loss: 4.072028160095215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12265/100000, D Loss: 0.25688280165195465, G Loss: 3.8859143257141113\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12266/100000, D Loss: 0.278046578168869, G Loss: 3.804473638534546\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12267/100000, D Loss: 0.26583218574523926, G Loss: 3.8564679622650146\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12268/100000, D Loss: 0.2707485556602478, G Loss: 4.002691745758057\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12269/100000, D Loss: 0.3258077949285507, G Loss: 3.80092716217041\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12270/100000, D Loss: 0.28029996156692505, G Loss: 3.9966723918914795\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12271/100000, D Loss: 0.2777147889137268, G Loss: 4.057593822479248\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12272/100000, D Loss: 0.3149496167898178, G Loss: 3.7739651203155518\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12273/100000, D Loss: 0.28750263154506683, G Loss: 3.847059488296509\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12274/100000, D Loss: 0.32930609583854675, G Loss: 3.824615240097046\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12275/100000, D Loss: 0.34938740730285645, G Loss: 3.8805627822875977\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12276/100000, D Loss: 0.3805360496044159, G Loss: 3.6221184730529785\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12277/100000, D Loss: 0.3455633372068405, G Loss: 3.6605358123779297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12278/100000, D Loss: 0.31386998295783997, G Loss: 3.8390040397644043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12279/100000, D Loss: 0.32783423364162445, G Loss: 3.8048033714294434\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12280/100000, D Loss: 0.3157533258199692, G Loss: 3.804425001144409\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12281/100000, D Loss: 0.28534895926713943, G Loss: 4.075234413146973\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12282/100000, D Loss: 0.30160268396139145, G Loss: 3.9230966567993164\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12283/100000, D Loss: 0.27283717691898346, G Loss: 3.949810743331909\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12284/100000, D Loss: 0.2800305560231209, G Loss: 4.142111778259277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12285/100000, D Loss: 0.2922467738389969, G Loss: 4.135226249694824\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12286/100000, D Loss: 0.2772614508867264, G Loss: 3.9466164112091064\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12287/100000, D Loss: 0.300850048661232, G Loss: 4.069366455078125\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12288/100000, D Loss: 0.27402952313423157, G Loss: 4.206991195678711\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12289/100000, D Loss: 0.334154836833477, G Loss: 3.8240535259246826\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12290/100000, D Loss: 0.3055709898471832, G Loss: 3.780856132507324\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12291/100000, D Loss: 0.3817989230155945, G Loss: 3.877528667449951\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12292/100000, D Loss: 0.3227396607398987, G Loss: 4.035977840423584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12293/100000, D Loss: 0.33269745111465454, G Loss: 3.754020929336548\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12294/100000, D Loss: 0.324477881193161, G Loss: 3.5901975631713867\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12295/100000, D Loss: 0.37221500277519226, G Loss: 3.873291015625\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12296/100000, D Loss: 0.35295626521110535, G Loss: 4.090019226074219\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12297/100000, D Loss: 0.2997921258211136, G Loss: 3.9793219566345215\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12298/100000, D Loss: 0.3200584277510643, G Loss: 3.7741968631744385\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12299/100000, D Loss: 0.2710171490907669, G Loss: 3.6874008178710938\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12300/100000, D Loss: 0.2654972970485687, G Loss: 4.117622375488281\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12301/100000, D Loss: 0.2216079905629158, G Loss: 4.448237419128418\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12302/100000, D Loss: 0.25572895258665085, G Loss: 4.257625102996826\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12303/100000, D Loss: 0.28568603098392487, G Loss: 3.876227855682373\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12304/100000, D Loss: 0.22860297560691833, G Loss: 4.093315601348877\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12305/100000, D Loss: 0.18645938485860825, G Loss: 4.449141502380371\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12306/100000, D Loss: 0.1917237862944603, G Loss: 4.786032676696777\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12307/100000, D Loss: 0.19168737530708313, G Loss: 4.3596954345703125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12308/100000, D Loss: 0.1907447874546051, G Loss: 4.093856334686279\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12309/100000, D Loss: 0.18998119980096817, G Loss: 4.340742111206055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12310/100000, D Loss: 0.15844538062810898, G Loss: 4.683202743530273\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12311/100000, D Loss: 0.18986454606056213, G Loss: 4.554985046386719\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12312/100000, D Loss: 0.1748587265610695, G Loss: 4.220918655395508\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12313/100000, D Loss: 0.20881790667772293, G Loss: 4.407857894897461\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12314/100000, D Loss: 0.17326868325471878, G Loss: 4.513213157653809\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12315/100000, D Loss: 0.20482568442821503, G Loss: 4.218864440917969\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12316/100000, D Loss: 0.2196938470005989, G Loss: 4.185608386993408\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12317/100000, D Loss: 0.16814421117305756, G Loss: 4.280457019805908\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12318/100000, D Loss: 0.1804221272468567, G Loss: 4.350152969360352\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12319/100000, D Loss: 0.18473856151103973, G Loss: 4.385438919067383\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12320/100000, D Loss: 0.18257830291986465, G Loss: 4.244113922119141\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12321/100000, D Loss: 0.1635662019252777, G Loss: 4.55156946182251\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12322/100000, D Loss: 0.1807437390089035, G Loss: 4.559742450714111\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12323/100000, D Loss: 0.1951395645737648, G Loss: 4.356903076171875\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12324/100000, D Loss: 0.18811355531215668, G Loss: 4.2019500732421875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12325/100000, D Loss: 0.18233289569616318, G Loss: 4.300803184509277\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12326/100000, D Loss: 0.15688055008649826, G Loss: 4.517905235290527\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12327/100000, D Loss: 0.20647353678941727, G Loss: 4.43643856048584\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12328/100000, D Loss: 0.22998552024364471, G Loss: 4.043687343597412\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12329/100000, D Loss: 0.1677674651145935, G Loss: 4.155150413513184\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12330/100000, D Loss: 0.2580355405807495, G Loss: 4.2345075607299805\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12331/100000, D Loss: 0.24537529051303864, G Loss: 4.1968560218811035\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12332/100000, D Loss: 0.23316586762666702, G Loss: 4.271572589874268\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12333/100000, D Loss: 0.24935460090637207, G Loss: 4.184881210327148\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12334/100000, D Loss: 0.2614465206861496, G Loss: 4.292835235595703\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12335/100000, D Loss: 0.2835860699415207, G Loss: 4.192704677581787\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12336/100000, D Loss: 0.27672164142131805, G Loss: 4.139736652374268\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12337/100000, D Loss: 0.3022615611553192, G Loss: 3.8529186248779297\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12338/100000, D Loss: 0.3477409929037094, G Loss: 3.857870101928711\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12339/100000, D Loss: 0.3033866286277771, G Loss: 4.008552074432373\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Epoch 12340/100000, D Loss: 0.32486943900585175, G Loss: 3.787700653076172\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12341/100000, D Loss: 0.33408358693122864, G Loss: 3.557251214981079\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12342/100000, D Loss: 0.35615333914756775, G Loss: 3.658763885498047\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12343/100000, D Loss: 0.34742172062397003, G Loss: 3.7508862018585205\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12344/100000, D Loss: 0.3464464843273163, G Loss: 4.088471412658691\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12345/100000, D Loss: 0.3788306713104248, G Loss: 3.5570735931396484\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12346/100000, D Loss: 0.39847102761268616, G Loss: 3.462477684020996\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12347/100000, D Loss: 0.33014120161533356, G Loss: 3.7393581867218018\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12348/100000, D Loss: 0.3848508596420288, G Loss: 3.8742787837982178\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12349/100000, D Loss: 0.40806442499160767, G Loss: 3.453028678894043\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12350/100000, D Loss: 0.315093070268631, G Loss: 3.9497296810150146\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12351/100000, D Loss: 0.26903345435857773, G Loss: 4.253420352935791\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12352/100000, D Loss: 0.254913330078125, G Loss: 4.092055320739746\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12353/100000, D Loss: 0.26173052191734314, G Loss: 4.29210901260376\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12354/100000, D Loss: 0.19171765446662903, G Loss: 4.5264692306518555\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12355/100000, D Loss: 0.2113293558359146, G Loss: 4.519126892089844\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12356/100000, D Loss: 0.17394719272851944, G Loss: 4.3870768547058105\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12357/100000, D Loss: 0.16459113359451294, G Loss: 4.871394157409668\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12358/100000, D Loss: 0.1657700538635254, G Loss: 4.715244293212891\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12359/100000, D Loss: 0.14331777393817902, G Loss: 4.538364887237549\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12360/100000, D Loss: 0.16479355096817017, G Loss: 4.777896404266357\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12361/100000, D Loss: 0.14522337168455124, G Loss: 4.666871070861816\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12362/100000, D Loss: 0.1624256670475006, G Loss: 4.790509223937988\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12363/100000, D Loss: 0.15902335196733475, G Loss: 4.565906047821045\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12364/100000, D Loss: 0.18894800543785095, G Loss: 4.447272300720215\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12365/100000, D Loss: 0.15985269099473953, G Loss: 4.532380104064941\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12366/100000, D Loss: 0.2063760608434677, G Loss: 4.2367634773254395\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12367/100000, D Loss: 0.18539568781852722, G Loss: 4.23807430267334\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12368/100000, D Loss: 0.20952904224395752, G Loss: 4.257193565368652\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12369/100000, D Loss: 0.24014212936162949, G Loss: 4.097224235534668\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12370/100000, D Loss: 0.22652948647737503, G Loss: 4.072649955749512\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12371/100000, D Loss: 0.2763330787420273, G Loss: 3.7583532333374023\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12372/100000, D Loss: 0.31059643626213074, G Loss: 4.085062026977539\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12373/100000, D Loss: 0.25246571004390717, G Loss: 4.400698184967041\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12374/100000, D Loss: 0.25915156304836273, G Loss: 4.460330963134766\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12375/100000, D Loss: 0.3309707045555115, G Loss: 3.6550655364990234\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12376/100000, D Loss: 0.3060740754008293, G Loss: 3.592428684234619\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12377/100000, D Loss: 0.2704411447048187, G Loss: 4.11346435546875\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12378/100000, D Loss: 0.2733464315533638, G Loss: 4.534253120422363\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12379/100000, D Loss: 0.31130915880203247, G Loss: 3.7261176109313965\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12380/100000, D Loss: 0.30192506313323975, G Loss: 3.6759796142578125\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12381/100000, D Loss: 0.27011963725090027, G Loss: 4.091086387634277\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12382/100000, D Loss: 0.23474370688199997, G Loss: 4.32103157043457\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12383/100000, D Loss: 0.25473418086767197, G Loss: 3.9901628494262695\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12384/100000, D Loss: 0.2528976649045944, G Loss: 3.7421951293945312\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Epoch 12385/100000, D Loss: 0.23563116788864136, G Loss: 3.959254741668701\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12386/100000, D Loss: 0.22854088991880417, G Loss: 4.491595268249512\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 12387/100000, D Loss: 0.22689571976661682, G Loss: 4.556008338928223\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12388/100000, D Loss: 0.18157211691141129, G Loss: 4.3694257736206055\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 12389/100000, D Loss: 0.19064801931381226, G Loss: 4.092998504638672\n",
      "32/32 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos desde un archivo CSV\n",
    "dataset = pd.read_csv('mnist_train.csv')\n",
    "\n",
    "# Extraer las etiquetas (si est√°n presentes) y las caracter√≠sticas de las columnas del conjunto de datos\n",
    "# Asumiendo que la etiqueta est√° en la columna \"label\" y las caracter√≠sticas en las columnas restantes\n",
    "labels = dataset['label']\n",
    "data = dataset.drop('label', axis=1)\n",
    "\n",
    "# Normalizar los datos al rango [-1, 1] (los datos originales est√°n en [0, 255])\n",
    "data = (data.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# Convertir los datos a un arreglo NumPy\n",
    "data = data.values\n",
    "\n",
    "# Definir el generador (G)\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=latent_dim, activation='relu'))\n",
    "    model.add(layers.Dense(784, activation='tanh'))  # 28x28=784\n",
    "    model.add(layers.Reshape((28, 28, 1)))  # Redimensionar a la forma de una imagen\n",
    "    return model\n",
    "\n",
    "# Definir el discriminador (D)\n",
    "def build_discriminator():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Definir el modelo GAN que conecta el generador y el discriminador\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # El discriminador no se entrena cuando entrenamos el GAN\n",
    "    model = models.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "# Tama√±o del espacio latente (vector de entrada para el generador)\n",
    "latent_dim = 100\n",
    "\n",
    "# Construir y compilar el generador\n",
    "generator = build_generator(latent_dim)\n",
    "generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Construir y compilar el discriminador\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Construir y compilar la GAN\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 100000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Generar muestras falsas\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Seleccionar un lote aleatorio de muestras reales\n",
    "    real_images = data[np.random.randint(0, data.shape[0], batch_size)]\n",
    "    \n",
    "    # Redimensionar las im√°genes reales a (batch_size, 28, 28, 1)\n",
    "    real_images = real_images.reshape((batch_size, 28, 28, 1))\n",
    "\n",
    "    # Etiquetas para las muestras falsas y reales\n",
    "    labels_real = np.ones((batch_size, 1))\n",
    "    labels_fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Entrenar el discriminador\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Generar ruido en el espacio latente\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "    # Etiquetas enga√±osas para el generador (queremos que el generador piense que las muestras son reales)\n",
    "    labels_gan = np.ones((batch_size, 1))\n",
    "\n",
    "    # Entrenar el generador a trav√©s del modelo GAN\n",
    "    g_loss = gan.train_on_batch(noise, labels_gan)\n",
    "\n",
    "    # Imprimir el progreso del entrenamiento\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
    "\n",
    "# Generar una imagen falsa al azar\n",
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "generated_image = generator.predict(noise).reshape(28, 28)\n",
    "\n",
    "# Escalar la imagen generada al rango [0, 255] desde [-1, 1]\n",
    "generated_image = (0.5 * generated_image + 0.5) * 255\n",
    "\n",
    "# Mostrar la imagen generada\n",
    "plt.imshow(generated_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Imagen Generada')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
